paper_title,abstract,session_name,session_id,paper_id
Optimizing Operations Managerial Performance: A Data-Driven Approach at a Post-Production Facility," Senior company leadership at an aircraft maintenance, repair, and overhaul facility made an unusual request that their industrial engineering department conduct an observation targeted on operations first line leaders (FLLs) rather than their normal study of technicians. Analysis of the data collected during the observation, an abbreviated 3-day work sampling event, showed that implementing Standard Work for operations FLLs across all programs at the facility and redistributing necessary non-value-added FLL tasks to other functions would increase FLL engagement with their employees. The findings provided valuable insights, highlighted opportunities for continuous process improvement efforts, and better resource allocation to maximize productivity. The brief study serves as the foundation for future initiatives aimed at enhancing the effectiveness of all FLL within the company.",Optimization,154,1
Discovering Puerto Rico Roads Profile Influencing Traffic Fatalities," The infrastructure of Puerto Rico (PR) was given a grade point average of ""D-"" in 2019. Transportation crashes may be influenced, among others, by environmental or infrastructure hazards. Before creating and implementing the first PR Strategic Highway Safety Plan (SHSP), the island reported more than 200,000 traffic crashes annually between 2007-2013. They resulted in a staggering 360 fatalities and 5,200 seriously injured individuals. Road fatalities dropped by 20.72%, and serious injuries decreased by 36.93% throughout the SHSP 2014-2018 implementation. Despite this progress, pedestrian traffic fatalities continue to be a major worry. Is it possible to predict collision type, crash severity and identify specific roads for safety improvement based on the trafficway’s condition profile that could be useful for the Puerto Rico Highway and Transportation Authority (PRHTA)? Authors in Indonesia have used the Naive Bayes algorithm to predict crash severity by analyzing contributing factors. This research aims to establish a PR road profile with potential high-severity crashes. Data mining and predictive analytics helped to predict crash severity and its associated road location. Outputs showed tree (standing only), live animal, wall, utility pole/light support, fell/jumped from the vehicle, other non-collision, and ditch as the first crash injury-or-damage producing event. With 88.1% likelihood of suffering a fatal injury, especially in I-2 (Aguada and Aguadilla-Int. PR 459); CR-3 (Canóvanas, Carolina, Guayama (Int. Ancha de Blondet St. and Int. PR 54)); and I-52 (Caguas, Cayey, Juana Díaz, Salinas, Santa Isabel). PRHTA could consider the findings for focusing funds’ investments on safety improvement measures.",Logistics I,122,2
Designing Manufacturing Enterprises System for Industry 4.0," Currently, researchers are concentrating their attention on design for manufacturing, design for assembly, design for cost and design for quality, design for complexity, design for reconfiguration, design for sustainability and design for X...etc., but they do not mention design manufacturing enterprises system for Industry 4.0. The design manufacturing enterprises system for Industry 4.0.is a systemic approach that simultaneously identifies elements and components for designing manufacturing enterprises for Industry 4.0, taking into consideration new urgency of adopting Industry 4.0 and challenges and risk management for implementing Industry 4.0. In this paper, The designing level will be analyzed and presented by identifying the relative importance of urgent adoption and challenges of implementing Industry 4.0.",Process Planning-I,180,3
Achieving Equitable Access to Medical Laboratory Tests through Optimal Sparse Decision Tree," In contemporary healthcare, laboratory tests play an indispensable role in precision medicine, yet their limited accessibility due to cost and disparities poses a significant challenge. The echocardiogram, a critical tool for cardiac assessment, faces increasing demand and scheduling inefficiencies. This study addresses this issue by developing an interpretable machine learning model using the Optimal Sparse Decision Tree algorithm to prioritize echocardiogram appointments. The dataset employed in this research is derived from real-world healthcare, sourced from electronic health records, comprising 34,294 records. It encompasses 64 dummy-coded categorical factors, offering diverse perspectives on patients and their healthcare journeys. These factors span various dimensions, including patient demographics, medical history, and clinical settings. They delve into past medical procedures and anticipate future ones, even incorporating diagnostic indicators for echocardiogram-justifying signs. Our method outperforms contemporary machine learning models, achieving a remarkable 2% improvement in the F1 score, underscoring its effectiveness. Additionally, the decision rules derived from the model align consistently with established medical knowledge, significantly enhancing the interpretability of our approach. This research showcases the potential of our methodology in accurately identifying appointment urgency for echocardiogram scheduling, offering a promising solution to streamline and optimize this critical aspect of cardiac care delivery.",Social Good Analytics,209,4
A Simulation-Based Case Study on ICU Patients - Simulate Nurse-Patient Interaction and Nurse Bedside Time for Critical Patients," Intensive care units (ICUs) provide critical care to unstable patients requiring constant monitoring. Even brief delays in responding to alarms can have significant impacts on unstable patients and result in adverse events such as unplanned extubation. Utilizing Simio simulation software, the research explored the impact of ICU bed-space layout on nurses’ bedside presence. We progressively increased the number of beds and nurses in the simulation from a one-bed, one nurse model to a three-bed, three nurse model. The simulation examined scenarios over 100 hours with different nurse walking speeds, bed distances, and alarm frequencies reflecting patient acuity. The simulation results showed that higher alarm frequencies, slower nurse walking speeds, and greater distances between beds led to more missed alarms. Alarm frequency had the largest impact, resulting in up to three times more missed alarms from the lowest acuity to the highest acuity. Increasing the number of beds did not significantly influence missed alarms. This case study contributes to understanding the ICU patient care and emphasizes the importance of ICU layout, workflow, and timely nurse presence at the bedside. The results obtained from the simulation experiments can also enable data validation and the development of predictive models. Further research can extend the simulation to multiple ICU rooms and utilize Python-based coding for enhanced model complexity.",Healthcare Optimization,87,5
Detection of Hazardous Gaseous and Liquid Borne Pathogens in Industrial Settings Using Embedded Piezoresistive Microcantilever Sensors," There are many instances in industry where workers may be exposed to hazardous airborne entities which may include chemicals, poisons, and other volatile gaseous compounds. At some sites, biological pathogens may be either airborne or in liquid environments. Rapid recognition and evaluation of these hazards is important for the safety of personnel working within these settings. We have designed a basic sensor platform that is adaptable to many different sensing and detection applications. Embedded Piezoresistive Microcantilever (EPM) sensors are small, inexpensive, and easily networked into sensor mesh systems. Their design makes them robust and highly resistant to shock and vibration and thus suitable for many types of industrial applications. In the Embedded Piezoresistive Microcantilever sensor, a tiny, 80-micron piezoresistive microcantilever is embedded or partially embedded into a sensing material. This sensing material may be a polymer, composite material, or biological material or composite. The only requirement for the sensing material is that it undergoes a tiny volume change upon exposure to the desired analyte or analytes. Upon this volume shift in the sensing material, the embedded microcantilever undergoes a tiny strain. In a piezoresistive microcantilever, this strain is measured as a change in the resistance of the microcantilever. In practice, strains of only a few angstroms may be detectable under some circumstances. We have tested sensors in both gaseous and liquid environments for a variety of analytes including volatile organic compounds, poisonous gases, acidic gases, and certain liquid-borne biological pathogens.",Poster Presentations,169,6
Modeling Structure Telehealth," Telehealth has the potential to enhance healthcare accessibility, especially in remote and underserved areas. The expansion of telehealth services is being developed in a transformative era in healthcare delivery, presenting opportunities and challenges for various stakeholders. Therefore, research is needed to understand the structure of telehealth from the perspective of those stakeholders. Specifically, emphasis needs to be given to addressing this problem in states and territories across the United States where telehealth has been understudied, such as the case of Puerto Rico. This research endeavors to model the structure of telehealth in Puerto Rico considering components related to four stakeholders: patients, healthcare providers, insurance providers, and government. A review of published literature and official public documents, complemented with the application of model-based systems engineering language, was used to develop an initial version of the model. By examining the interplay of the four key stakeholders, the initial model helped to: (1) gain insights into the dynamics of telehealth implementation in Puerto Rico by spotlighting the complexities and interdependencies among components across the stakeholder categories, (2) identify barriers and facilitators related to those dynamics, and (3) identify gaps in knowledge that requires further research. Results show that elements related to coverage and reimbursement for telehealth services are not well-defined. Additionally, the panorama is clearer for telehealth in the modality of live-video telemedicine, in comparison with other telehealth modalities. Such insights could potentially inform future efforts in the design of policies and interventions to drive the sustainable growth of telehealth on the island.",Poster Presentations,169,7
A Multiple Criteria Decision Analysis for the Foreing Direct Investment in The Dominican Republic and Central America Free Trade Agreement DR-CAFTA," The Dominican Republic-Central America Free Trade Agreement (DR-CAFTA) remains an essential driver for attracting foreign direct investment (FDI) in the region. This study focuses on analyzing the factors that influence FDI and the choice of the most attractive country for investment. FDI in DR-CAFTA has experienced notable fluctuations, influenced by global events such as the COVID-19 pandemic and the conflict in Eastern Europe. In 2022, FDI reached US$11.31 billion, marking a decrease of 10.10% from the previous year, following an impressive increase of 83.89% in 2021 according to data from the Economic Commission for Latin America and the Caribbean (ECLAC) (2023). The choice of the investment country has become critical, and to address this, this study employs the Analytic Hierarchy Process (AHP), as a decision-making tool. The results highlight Costa Rica as the leading option over other countries in the region, showing a notable concordance with the rankings of the ""GLOBAL OPPORTUNITY INDEX 2021” Focus on Latin America,"" by Contreras et. al. (2021). This analysis delves into the impact of global events on FDI in the DR-CAFTA region, providing valuable guidance supported by rigorous analysis, as well as contributing to the understanding of the dynamics of FDI in this constantly evolving region, helping investors make informed and strategic decisions.",Decision Analysis and Economic Evaluation,38,8
"Forests, Farms and Our Climate: A Systems Study Regarding Sustaining Some of Our Most Important Natural Resources"," From forests to farmland, adopting a systems-level approach to managing the interplay between product output, sustainable growth, and greenhouse gas emissions is becoming key for many of our important natural resources. Forests and farms are not usually synonymous with engineering, design, chemistry, biotechnology and physics. Thirty percent of greenhouse gas respiration from forests throughout the world comes from the soil, not from the trees and shrubs. Smaller, still important gas respiration is also found throughout the world’s farmland soils. Complex relationships between forest and farm plant life, ground litter, soil microbes, temperature, humidity, fertilizers and other factors all need to be considered in the future design and modeling of sustainable farms and forests. Mechanical forest thinning, forest logging and forest recovery after wildfires must adopt systems-level techniques to preserve their viability in future years. We have used a custom, portable, battery-powered quadrupole mass spectrometer in addition to other sensors to measure real-time relative soil concentrations of CO2, CH4, isoprene and water vapor in both forest and farmland soils. Over a 5-year time span, we have tracked the recovery of forests burned by wildfires, mechanically thinned or commercially logged to begin to develop relationships between the many different variables that contribute to soil respiration. Similarly, we have also begun to look at soil respiration in farms using modern design factors and practicing sustainable techniques. Using the chemical and biological data, a multi-disciplinary approach to the design and operation of future farms and forests will help us preserve these important resources.",Poster Presentations,169,9
Optimizing College Food Pantry Locker Systems through Simulation Techniques," Food insecurity affects 10.5% of households in the United States. Among those affected, college students are a group with increasing food insecurity. Through novel food pantry order methods, such as locker order systems, some effects of college food insecurity can be alleviated. The Jane B. Gearhart Full Circle Food Pantry (FCFP) at the University of Arkansas implemented a locker system, beginning in the Fall of 2020. There is a lack of investigation into locker management policies for pantries, such as how much time clients should be allowed to pick up orders after they are placed in lockers, how many lockers the pantry should operate, and on what days of the week should the pantry accept locker orders from clients. This research aims to create and use a discrete-event simulation model of food pantry locker operations to test various locker management policies. The model will determine the locker utilization, number of locker orders filled per week, and locker order reshelving ratio associated with each locker management policy tested. This research will result in recommendations for locker management policies that maximize locker utilization and number of orders filled and minimize order reshelving ratio. Recommended policies will be implemented in the FCFP locker system, and the recommendation process can serve as a resource to other food pantries in the region and in different universities for developing locker systems or managing existing locker systems to better alleviate food insecurity in these communities.",Humanatarian logistics 1,94,10
Regulating the Coordination Environment of Diatomic Cu-Fe Catalysts in Electroreduction of CO2 to Ethane via a facile seed-assisted synthetic strategy.," A promising strategy for combating climate change transforming atmospheric carbon dioxide (CO2) into valuable chemicals and fuel. Cu-based single-atom electrocatalysts (Cu-SACs) are a potential catalyst to facilitate the electrolytic conversion of carbon dioxide (CO2) into substantial amounts of multi-carbon compounds with high selectivity. However, at high current densities, CO2 conversion to multi-carbon products still has a low Faraday efficiency, which is not enough to satisfy the real commercial desire. Here, regulating the coordination environment of single-atom copper electrocatalysts and modifying them into diatomic Cu-Fe catalysts through a facile seed-assisted strategy. This technique causes copper to dimerize with iron, leading to improved atom utilization efficiency, tailored catalytic activities, and high catalytic selectivity, which surpasses C-C coupling and multi-carbon products. The synthesized electrocatalysts have been revealed to be considerably more effective than Cu SAC and Fe cluster sites at electrocatalytic CO2 reduction at 0.62 V (vs. RHE) with a Faradaic efficiency of C2H6 > 77% over a wide electrochemical potential window (0.55 to 1 V versus RHE) and a current density of 56 mA cm-2 in a 0.5 M KHCO3 solution in an H-cell setup. Furthermore, this electrocatalysts deliver FEs (Faraday efficiencies) for the CO2 reduction to C2H6 of over 86% with a current density surpassing 250 mA cm2, outperforming the abilities of the majority of the CO2 electrocatalysts that have been reported. This study offers a feasible strategy for the future development of novel, inexpensive controlled dimeric electrocatalysts with exceptional efficiency and C2+ selectivity for electrocatalytic reduction of carbon dioxide.s.",Poster Presentations,169,11
Role of Artificial intelligence (AI) in Quality Management," Artificial intelligence (AI) is transformational to business, including quality management function. Quality management is the discipline of ensuring that products and services meet or exceed customer expectations and comply with relevant standards and regulations. There is little published regarding the ability of AI to automate, optimize and transform quality management processes, such as planning, assurance, control, and improvement. This paper reviews the current state of AI applications in quality management, discusses the benefits and challenges of AI adoption, and proposes some future directions for research and practice. The paper aims to provide a comprehensive overview of the role of AI in quality management and inspire new ideas and collaborations among researchers and practitioners.",Statistical Learning and Artificial Intelligence for Quality Control I,211,12
Adherence to Colorectal Cancer Screening Using Nationwide Unbalanced Data," The study examined the current status of the colorectal cancer screening adherence for the adults aged 50-75 years old according to the U.S. Preventive Service Task Force (USPSTF) guidelines. We used the most recent nationwide representative data from the 2018 Behavioral Risk Factor Surveillance System survey. The adherence rate was 76.5% in 2018 among the 208,616 respondents that were included in the study. Factors that reflected demographic, socioeconomic, health-related or behavior characteristics of the participants were examined to evaluate their influence on the compliance with FOBT, colonoscopy, sigmoidoscopy screening methods, or at least one of the three. We found the following factors resulted in a lower colorectal cancer screening adherence: younger, Asian or Hispanic, male, never married, lower income, lower education attainment, employed/student, fair health condition, Indian health service, last checkup more than 1 year, everyday/someday smoker, heavy drinker and underweight. The unbalanced feature of the colorectal cancer screening data was also addressed in our study. By fitting logistic regression models with the original unbalanced data, oversampling data and undersampling data, we identified different strategies to tackle the unbalanced data issues. Results related to the overall screening adherence and colonoscopy adherence were not affected significantly by the unbalanced features of the dataset. However, when analyzing the screening data associated with FOBT and sigmoidoscopy, researchers need be careful about the more severe unbalanced data structure, which produces high PAC but extremely low sensitivity. To address this issue, undersampling technique provides better performance than the oversampling method.",Health Systems,78,13
A Human-Centered Assessment of Andon Boards in an Automotive Manufacturing Environment," This study examines the design and usability of Andon Boards from a Human Factors perspective. Andon Boards are visualization tools used in manufacturing plants to present the status of production stations and lines. A real case study was conducted in a modern automotive manufacturing plant where Andon Boards are used in various locations at the production area. Different employees were interviewed using semi-structured questions to gather feedback on the current design and identify areas for improvement. Qualitative analysis of the feedback using a thematic analysis method resulted in suggestions for an improved design that would enhance usability and reduce downtime. The main themes identified through thematic analysis provide recommendations for improving Andon Board design including simplifying displayed information, increasing the font size, considering additional displays, limiting the number of stations displayed, and incorporating visual and auditory cues. Future studies should consider how Human Factors improvements can factor into a complete systems analysis and redesign, and should address cost and feasibility concerns to increase the likelihood for industries to invest in improvements to Andon Boards.",Manufacturing & Design for Human Factors and Ergonomics,134,14
Relationship Between Conventional Workload Surrogates and VACP Assessments in Emergency Medical Services," Workload in Emergency Medical Services (EMS) has not been studied as a cumulative workday. This study investigates cumulative workload and the metrics this may be correlated with. Workload is estimated by utilizing a trace-based simulation which models an EMS crew member’s workday using dispatch data and distributions based on observation. The workload output is a time-weighted VACP (Visual, Auditory, Cognitive, Psychomotor) score. This measure was significantly correlated with NASA-TLX scores at the time of observation. Pearson correlation and linear regression were used to evaluate the influence of each metric on workload. Overall utilization and call response utilization explained workload the best, with strong positive correlations (0.88, 0.89) and significant linear regression models (R²=0.79, R²=0.77). Call volume yielded the lowest correlation (0.61) and lowest R² value (0.41) of the metrics studied, challenging their validity in fairly representing workload.",Healthcare Work Systems,90,15
On monitoring high-dimensional processes with individual observations," One of the significant challenges in monitoring the quality of products today is the high dimensionality of quality characteristics. In this paper, we address both Phase I analysis and Phase II monitoring of high-dimensional processes. We first propose a new charting statistic for high-dimensional multivariate processes based on the diagonal elements of the underlying covariance matrix. Then, we investigate the Phase I analysis when the available number of samples collected over time is limited and propose a robust procedure for parameter estimation in Phase I. This robust procedure is efficient in parameter estimation in the presence of outliers or contamination in the data. A consistent estimator is proposed for parameter estimation and a finite sample correction coefficient is derived and evaluated through simulation. Finally, a unified procedure for Phase I and II by employing a self-starting control chart is proposed. We assess the statistical performance of the proposed method in Phase I and II in terms of the probability of signal and average run length (ARL) criterion, respectively. This assessment is carried out in the absence and presence of outliers. We show that, in both phases, the proposed control chart scheme effectively detects various kinds of shifts in the process mean. Besides, we present two real-world examples to illustrate the applicability of our proposed method.",Statistical Learning and Artificial Intelligence for Quality Control I,211,16
An Innovative Approach for Optimal Resource Allocation in Emergency Departments," In hospital settings, emergency departments often face issues of overcrowding and operational malfunctions, given the uncertainties related to patient demand. The primary objective of this study is to identify and address operational challenges by merging design thinking principles with experimental regression design. An innovative approach is introduced that combines design thinking, the design of regression modelling, and discrete event simulation to improve resource allocation efficiency and reduce patient length of stay in hospital emergency departments. Design thinking encompasses several phases: comprehension, abstraction, ideation, testing, and implementation. Each phase incorporates discrete event simulation or regression modelling to thoroughly assess system performance. Multiple regression models were used to analyse the relationships and interdependencies between nurses, beds, physicians, and patient stay. This analysis provides insight into how key performance indicators would change with variations in resource allocation. Ultimately, the research aims to establish an optimal resource allocation strategy by exploring the dynamic interaction between resource management and patient waiting times. This, in turn, provides valuable information to hospital management decision makers, helping them to understand the key resource factors that influence patient flow. In particular, the results of a case study demonstrate significant reductions in patient length of stay, promising an improved overall patient experience. Therefore, our framework empowers healthcare institutions with the knowledge necessary for informed decision making and strategic changes that improve patient care and resource allocation, aligning with the overall objective of this study.",Resource Allocation and Workforce Planning in Health Systems,193,17
Facilitating Wider Access to Effective Medical Checklists: A Literature Search and Dataverse Expansion Project," Medical settings frequently employ checklists to enhance patient care and clinical processes. However, challenges such as poor checklist design and overreliance can limit the effectiveness of checklist interventions. We expanded a collection of checklists hosted on Borealis, a Canadian academic Dataverse repository, to promote widespread access to tested medical checklists. We collected checklists by searching through the Clinicaltrials.gov, PubMed, and CINAHL databases for relevant articles. Articles were imported into Covidence and screened for eligibility by two reviewers. articles that studied checklists as the primary intervention and had performance metrics to support the conclusions they made about their outcomes were eligible for inclusion. From 725 retrieved articles, 80 were selected for full-text review after title and abstract screening and 25 met the inclusion criteria. Most studies (n=20) reported that checklists improved outcomes by increasing worker task adherence and care quality, while reducing patient morbidity and readmission rates. However, three studies found checklists to be ineffective and two had inconclusive results. Ultimately, 18 articles describing 16 checklists were added to the Borealis repository; two articles had already been added in the past. The articles added included checklists on safe childbirths, anesthesia administration, and cardiopulmonary resuscitation training. The Borealis repository also had its searchability improved with the addition of keyword filters and Medical Subject Heading (MeSH) terms. There are now a total of 34 checklists available in the repository. As medical institutions often create checklists to support their own processes, enabling widespread access to these can prove beneficial to the greater healthcare community.",Information and Digital Systems in Health,105,18
Immersive Occupational Safety and Health Training: A Modular Virtual Reality-Based Process and Platform," For several decades, safety and health have been major concerns in the warehousing, logistics, and manufacturing sectors. Despite considerable advancements in methods, tools, equipment, and regulations, there has been no substantial reduction in accidents, particularly those of a fatal four. As a result, safety professionals and researchers have explored new and innovative ways to combat the problem. This paper contributes to workers’ health and safety by introducing an immersive training methodology enabled by a virtual reality process and platform. A modular virtual reality training platform (MVR-P) was developed, and a co-design process was applied to design each module. Three main modules related to health and safety training for the warehouse were considered namely the personal protection equipment module, pallet handling module, and pallet repairing module. In this platform, virtual interactive environments provide a solid training environment and generate syntactic data for evaluating long-term health risks. On the other hand, collaborative modular environments provide a solution to geographically distributed systems, which allows employees to connect and train remotely. The effectiveness of MVR-P is compared with traditional safety training in a pilot study. A quantitative approach was employed to analyze the data and investigate various aspects of the MVR-P. Based on the results, MVR-P is making great efforts to teach and test hazard identification situations, especially those relating to long-term health. The results also indicate that trainees' recall of knowledge would improve with MVR-P.",Organizational Ergonomics and Engineering Education,158,19
Enhancing Emergency Evacuation Efficiency through Centralized Decision-Making in Multi-Agent Systems," In the face of unpredictable hazards, such as fire and construction flaws, efficient emergency evacuation of people is a paramount concern. This research investigates the trade-offs between centralized and decentralized learning strategies, coupled with decentralized execution, within a multi-agent system tailored to emergency evacuation scenarios. Panic-induced decision-making often impedes rational thinking, and we introduce an insight into effective evacuation protocol in which non-panicked agents—non-panicked individuals—behave as super agents who make decisions for the group. Thus, it potentially expedites group evacuation in contrast to decentralized training-decentralized execution. Our primary objective is to scrutinize the merits and drawbacks of both centralized and decentralized learning strategies through comprehensive simulations. This analysis juxtaposes decentralized learning, accounting for crowd-induced clogging effects, against centralized learning, predicated on the assumption that agents possess exit proximity information and face no clogging constraints. Within a simulated single-floored library containing 20 or more agents, the study evaluates critical metrics, including the number of agents evacuated within a limited time and the total evacuation duration. Centralized learning excels over an extended period, as a short-term gain and long-term loss decision-making, against what decentralized learning result demonstrates. Concluding with delineating their pros and cons, we offer insights into potential trade-offs. Following this study, we will explore collaborative decision enhancement within groups operating under centralized decision-making frameworks. Such advancements hold the potential to revolutionize emergency evacuation protocols in multi-agent systems, ensuring a more effective response to unforeseen hazards.",Modeling Human Behavior,148,20
Exploring Challenge-Driven Learning Approaches for Competency Enhancement," Changing the learning model of an institution represents a great challenge, since it implies a change on a large scale, with many factors to be considered and with very important consequences in terms of quality and efficiency in learning. In this document, we will present an analysis of the learning process of a group of students in a design and analysis of experiments course using a new learning model and we will compare it with a series of groups that use a traditional model. We want to analyze whether the results of learning and development of skills by students provide sufficient evidence to consider that this new learning model presents results positive enough to justify the change in it. We took a sample of 60 students from our institution, and we compared them with a sample of the same size from a different institution, where they used a different learning model. To make the comparison, we used an argumentative exam that not only seeks correct answers but also provides evidence of the development of specific skills. The early results provide evidence that there is a difference in the quality of learning and skills development between one sample and another. We are sure that the results will provide statistical support that will allow conclusions to be drawn that will give us a clear idea not only of the results but also of the improvements to be implemented in both models to achieve better learning efficiency and skills development.",Innovative Learning Approaches in ISE Education,111,21
Integrated machine learning and genetic algorithms for a location production routing problem with additive manufacturing," In this research, we develop a Machine Learning (ML) based solution methodology for a location production inventory problem. The difference between the problem with classical location inventory routing problem is the production location can be moved in different periods with additive manufacturing technology. To solve the problem, we design a hybrid optimization algorithm that uses Genetic Algorithms as the main optimizer and neural network-based regression models for cost feedback for subproblems. To analyze the performance of proposed methods, the numerical tests and theoretical bounds are developed.",Routing 2,198,22
It’s All About Time - The Modernization of Work Measurement," As the demands of industry to deliver both efficiency and effectiveness climb to new levels, Time has become our new currency. Whether it is managing passengers and baggage at an airport gate, fulfilling online orders in a retail store or executing the critically important “last mile”, stakeholder success is determined by actions and decisions that are guided by Time. At the heart of all of this is Work Measurement. It is a fundamental ISE building block that enables Industrial/Systems Engineers to understand time and build solutions that optimize around it. While Work Measurement has been around for over 100 years, ew technologies and capabilities have made timely data collection more granular and accessible. ISE’s are definitely in the sweet spot as businesses convert this data to information that can be used to improve and measure business processes. With that in mind, the IISE Work Systems Division has launched a campaign labeled “It’s All About Time”, focused on rebuilding the awareness, and reinforcing the importance, of Work Measurement. Key activities include benchmarking Work Measurement in both Academia and Industry – and leveraging learnings across a multichannel communication and educational plan. By understanding what Work Measurement skills industry will need in 3-5 years, we can work with Academia to ensure new graduates have the proper skills to succeed from day one. This presentation will provide and update on our progress and dive deeper into industry applications of a “modernized” Work Measurement. Once again, It’s All About Time!!",Applications of Work Systems,17,23
Integer programming for project scheduling under storage and renewable resource constraints," Project scheduling is an important management task in many organizations across various industries. In general, projects require resources such as personnel or funds, whose availability is limited, which leads to the challenging problem of resource-constrained project scheduling. We consider the scheduling of a project consisting of a set of precedence-related project activities that require time and two types of resources for their execution: storage resources representing, e.g., the project budget; and renewable resources representing, e.g., some personnel or some equipment. Storage resources are consumed by activities at their start or produced at their completion, while renewable resources are allocated to an activity at its start and released at its completion. The resource-constrained project scheduling problem with consumption and production of resources consists of determining a minimum-makespan schedule such that all prescribed precedence relations are respected, the demand for each renewable resource never exceeds its capacity, and the stock level of each storage resource never falls below a prescribed minimum level. Due to the consideration of storage resources, the feasibility variant of this problem is NP-complete. We propose a novel compact mixed-integer linear programming model based on a novel type of sequencing variable. These variables allow us to identify which activities are processed in parallel and whether a sequencing of activities is necessary to respect the resource capacities. Our computational results indicate that our novel model significantly outperforms state-of-the-art MILP models from the literature for all considered scarcity settings of the storage resources.",Manufacturing Optimization,138,24
Advice to Graduating Students Their First Year Working," This presentation will offer some advice to graduating students applicable to their first year of working. It covers the following topics: Current Job, Volunteering, Project Management skills, Personal skills, In-house Training, Professional Societies, Career Planning, and Other Activities.",Personal Development II,163,25
Planning Your Career," Career Planning is an important and useful activity, whether you are looking for a job, thinking about changing jobs, or are just trying to figure out what to do next. This presentation will describe fifteen Career Planning steps that can be used during many stages of your career and your life. Each of the steps will be described, listing some of the key items to consider during each Career Planning step.",Personal Development I,162,26
Explore Your Career Choices," This presentation will look at a comparison of several Career Choices, in order for you to find your best choice, currently. Several Career Choices will be discussed in detail, including: changing jobs, changing companies, changing industries, changing locations, and changing careers.",Personal Development II,163,27
On Excess Risk Convergence Rates of Neural Network Classifiers," The recent success of neural networks in pattern recognition and classification problems suggests that neural networks possess qualities distinct from other more classical classifiers, such as SVMs or boosting classifiers. This paper studies the performance of plug-in classifiers based on neural networks in a binary classification setting as measured by their excess risks. Compared to the typical settings imposed in the literature, we consider a more general scenario that resembles actual practice in two respects: first, the function class to be approximated includes the Barron functions as a proper subset, hence smooth functions, and second, the neural network classifier constructed is the minimizer of a surrogate loss instead of the 0-1 loss so that gradient descent-based numerical optimizations can be easily applied. We study the estimation and approximation properties of neural networks to obtain a dimension-free, uniform rate of convergence. In the analysis of the estimation error, we obtain a novel result that relates the approximate excess risk to the approximate excess ϕ-risk, which is of interest on its own. Finally, we show that the rate obtained is, in fact, minimax optimal up to a logarithmic factor, and the lower bound obtained shows the effect of the margin assumption in this regime.",Deep Learning III,42,28
A Hybrid Structure-Based Semantic Segmentation Method for Industrial Measurement of Form and Position Tolerance on Chip Sockets," Chip socket is a mechanical and electrical system that establishes reliable electronic interconnection paths between the chip and the test board to realize signal transmission. Form and position tolerance control is the key to determine the quality of the chip socket. When confronted with highly precise CPU chip sockets with thousands of contacts distributed over a very small area, existing technologies still have difficulty satisfying the requirements for high-precision, fast, and on-line measurements simultaneously, which poses a major challenge to process stability and product quality. To resolve this, a hybrid model of tandem structure stitching (HTSS) is proposed for effective and efficient measurement of form and position tolerance of CPU chip sockets. The model front-end is a modified BiSeNet semantic segmentation network, which serves as an enhancement to the convolutional module by introducing a self-attention mechanism. Meanwhile, a RepVGG-style structural reparameterization is designed to decouple the training time and inference time architectures. Further, the feature maps extracted from the modified BiSeNet network are inputted into the OTSU model for further processing, and the chip contact form and positional tolerance is obtained by target size and position calculation. The accuracy of the HTSS model is verified by performing tolerance inspection experiments on a robotic vision measurement system. The results show that the model enables significantly more accurate and faster tolerance detection in real time. The model provides an effective and efficient method for improving the intelligence of tolerance measurement of precision devices.",Machine Learning in Manufacturing I,129,29
An optimization decision-support system to support undergraduate education planning," Academic Excellence Workshops (AEWs) at Syracuse University are one-credit classes designed for students in the College of Engineering and Computer Science (ECS). Each AEW section reinforces another class that has proven to be difficult for new ECS students, such as physics, calculus, chemistry, and designated first- or second-year engineering and computing classes. Each AEW section is facilitated by an experienced ECS undergraduate student with proven knowledge in topic of that section. At issue: ECS staff members are currently spending countless hours assigning facilitators to AEW sections that match the facilitator’s expertise, at times suitable for the facilitator and class corresponding to the section, and in classrooms that are available at the desired times. The manual process is inefficient and is incapable of handling schedule adjustments. To resolve these shortcomings, we have created an optimization system to prescribe facilitator-section-room assignments. The process begins by gathering data pertaining to facilitators, sections, and rooms into an Excel document. In particular, each facilitator indicates their time availability and preference to instruct an AEW section. The optimization support system uses this input to determine when each workshop is taught, who facilitates the workshop, and in which classroom the section is taught. The model ensures that each facilitator teaches no more than one AEW section (with limited permission to teach two AEW sections, provided that those sections support the same class). The results are then written to another Excel spreadsheet, allowing ECS staff to verify results, adjust assignments, and reoptimize as needed.",Planning and Scheduling,165,30
Are data-driven early warnings possible for wind turbine systems?," Unexpected failures in engineering systems such as wind turbines lead to most expensive maintenance actions and should be avoided if at all possible. Early warning is the key to reduce unexpected failures and the subsequent corrective maintenance actions. By ""data-driven early warning,"" we emphasize on the type of early warnings issued primarily based on the online data routinely collected by a turbine's SCADA (Supervisory Control And Data Acquisition) system. The lead time need for a beneficial early warning goes back as far as 3 months. The benefit of early warnings issued close to the failure events, like on the same day or the day before, is greatly diminished. But are data-driven early warning with 2-3 months lead time possible? If yes, how? Researchers have not agreed on this issue. This talk presents our current thoughts and preliminary work.",Predictive analytics for Wind Power Generation,171,31
Applying lessons learned throughout the project life cycle," Projects are a major contributor to organizational goals. Project milestones are indicators of the overall health of the project. Literature focuses heavily on the efficacy of lessons learned as a closing phase milestone. However, lessons learned is a living document that catalogs project activities. This information is usually shared toward the end of the project. How can lessons learned be leveraged throughout the life of the project? Recent study findings will be explored to understand the current state applications of lessons learned data. Using the constructs of complexity leadership theory, recommendations will be offered to respond to lessons learned in ways that strengthen factors that drive project outcomes. This paper seeks to reinforce the influence that project leaders have when applying lessons learned data in project team environments.",Systems Engineering & Life Cycle Management I,225,32
Routing Optimization for Last-Mile Delivery with a Truck and Heterogeneous Autonomous Robots," To address growing demands and environmental concerns in last-mile delivery, the use of autonomous robots has gained significant attention. Studies on truck-robot delivery systems have mainly focused on urban areas. However, in this study, we develop a mixed integer linear programming model to optimize the last-mile delivery routes in both urban and rural areas, which is solved by our novel heuristic algorithm. In our problem, a single truck and a fleet of heterogeneous robots are exploited to effectively deliver packages from a depot to customers while minimizing the total travel time. Robots need a time to recharge their used batteries after their rendezvous with the truck, limiting the immediate remobilization of robots. To resolve this issue, we address an alternative to swapping the used batteries of just-returned robots with new batteries. Furthermore, we conduct the sensitivity analysis to examine the impact on the quality of delivery service in urban and rural areas, considering different number of customer nodes, different types of robots, and various robot combination ratios. As a result, we find that our proposed model consistently outperforms the traditional truck-only delivery system in both areas. More interestingly, in order to deliver more effectively, robots need a longer duration time in urban areas and a larger payload capacity do in rural areas, respectively. Our study plays an important role not only to fill the operational gap on truck-robot delivery systems in rural areas, but also to provide valuable strategies for using robots in last-mile logistics across urban and rural areas.",Routing 1,197,33
Circular Economy of End-of-Life Vehicle Front and Rear Bumper Assemblies," Automotive bumper remanufacturing is the process of reprocessing an end-of-life automotive bumper to be like new while recycling is the process of disassembling car bumpers and processing them into thermoplastic elastomeric olefin pellets or TPO pellets. For either end of life bumper treatment, it is critical that a sufficient supply of used automotive bumpers are collected from key stakeholders. In this project a system dynamics approach is employed to model end of life automotive bumper collection for recycling and remanufacturing. The model was developed through the interviews with key stakeholders in the automotive bumper recovery ecosystem, which included salvage yards, collision repair shops, and bumper remanufacturers/recoverers. The system dynamics model can simulate the flow of bumpers from use, to collision repair shops, and to salvage yards yet it is constrained to the parameters and rates that could be quantitatively estimate from project interviews and existing automotive collision data. The intent of the system dynamics automotive bumper collection model is to investigate parameters that optimize the system behavior for objectives such as landfill reduction, recycling potential, or minimizing environmental impacts. This optimization has two powerful uses: to design policies, incentives, or actions to control the behavior of the system or to identify appropriate response actions to disturbances in the system.",Closing the Loop: Advancements in Circular Economy and Responsible Production (SDG 12),26,34
Cost-effectiveness of Insurance Reimbursements for Re-sealing of Child and Adolescent Molars," Although preventable, dental caries (cavities) remains one of the most common chronic childhood diseases. Dental sealants are clear coatings applied to the molars that have been shown to prevent >80% of caries in those surfaces. In general, sealant effectiveness decreases with time since placement, primarily since they can fall off - either in the short term due to insufficient bonding, or over time. However, dental insurance policies vary significantly when it comes to reimbursing providers for resealing a tooth that lost its original sealant, with many only reimbursing the original sealant placement. In this study we use discrete event simulation to model three different policies for resealing 1st molars on a hypothetical cohort of 7-year-olds who just received initial sealants: (1) Resealing at the next dental visit each time a sealant is lost (2) One-time resealing if needed at age 12 when 2nd molar sealants are typically also applied and (3) No resealing at all. Health impact will be measured by reduction in 1st molar caries and disability-adjusted life years (DALYs) and cost-effectiveness is presented as cost per averted cavity and cost per averted DALY. Results of this research will inform policymakers and insurance providers about the cost effectiveness of resealing 1st molars and if including reimbursements for resealing 1st molars in their policies is financially beneficial or not.",Recent Advances in Health Systems I,184,35
Print Optimization for Volumetric Enhancement of Additive Manufacturing Envelopes," Additive manufacturing (AM) has revolutionized the manufacturing industry by increasing the ease and intricacy of manufacturable structures. With the cost and of large-scale additive manufacturing (AM) so high, printing segmented structure can be a possible method to overcome these limitations. This work aims to present a framework for the printing of structures larger than a traditional printer envelope. Nets of solids can be printed and folded into a larger structure. Printing faces onto a flexible substrate such as a textile can be used as a hinge to hold faces together. A net of a polyhedron net can be folded from a 2D plane in a 3D structure. Printing faces of a polytope net at the size of the print bed can increase the size of manufacturable objects greatly. A chain net is a net that is unfolded in a linear fashion such that each face is connected to a maximum of two others. Finding a chain net for a convex polytope can be simplified to a Hamiltonian pathfinding problem on the dual graph of the polytope. However, some polytope nets are not as optimal to print as others. Optimization of an unfolding algorithm is required for a given polytope net to be printable. Objectives and constraints for these problems are investigated and discussed. This paper presents a methodology and algorithm for the unfolding of chain nets using optimization techniques.",Digital Thread in Additive Manufacturing Processes,49,36
Design of a distributed manufacturing network for chemicals from biomass using local renewable-powered electrochemistry," Electrochemistry has shown promise for converting biomass into chemicals in distributed facilities using green electricity. Unlike the fermentation and separation/purification steps that precede and follow it, the electrochemical conversion step does not exhibit significant economies of scale. We employ a two-step optimization approach for sizing and locating manufacturing facilities with the objective to minimize cost including the social cost of carbon emissions. First, we use the REopt package developed by the National Renewable Energy Laboratory to find the optimal capacities of wind and solar generation, as well as storage, for each candidate location and facility size. Second, we find optimal combinations of facility locations and sizes to satisfy demand for the chemicals. We conduct sensitivity analyses to identify the economic, technical, and environmental parameters that most strongly influence the viability of distributed manufacturing for electrochemical processes still under development. Previous results of a US case study with dual cost and carbon objectives, considering only electricity from the grid, indicated that cost would be minimized by constructing a single large facility, while more emphasis on carbon emissions would distribute production among several smaller facilities. Most of the emissions came from electricity generation, while material feedstock accounted for the bulk of the manufacturing cost. By considering local renewable electricity generation and storage, we aim to explore the interplay among proximity to biomass-derived feedstock sources or customer locations, availability of wind and solar resources, and partial economies of scale in the manufacturing process in determining the viability and sustainability of distributed manufacturing.",Sustainability and equitable Operations,224,37
"Reliability Engineering – key for Designing and Building Safe, Successful, and Affordable Space Systems"," In today’s space environment, aerospace system designers are seeking more innovative and efficient ways to build reliable, high quality, safe, and more affordable space systems. Reliability engineering is one area with the potential to help designing and building space systems with improved safety, affordability, and mission success. After the Challenger accident in 1986, quantitative reliability analysis and reliability predictions were given more scrutiny because of their importance in understanding failure mechanism and quantifying the probability of failure; which are key elements in resolving technical issues, performing design trades, and supporting design improvements. Since then, NASA and industry experience has shown that improving reliability can contribute to reducing the risk of space flights, increasing the probability of mission success, and lowering sustainment costs. The Space Shuttle Main Engine (SSME) upgrades that NASA introduced in the late 1990’s and the reliability improvements after the space Shuttle accident were good examples of how reliability improvements can significantly improve safety, mission success, and reduce sustaining engineering. This paper discusses reliability engineering as a design discipline, shows the relationship between design reliability, quality engineering and other disciplines. It presents case studies in design reliability and process control from NASA and industry Programs that support and emphasize the fact that reliability engineering is key to designing and building safe, successful, and affordable future space systems.",Reliability Analysis I,186,38
"Substitutive Methods in Assembly Operation: Comparing Augmented Reality, Virtual Reality, and Papers-Based Instructions."," Objective: Assess the effectiveness of three methods of instruction, including virtual reality, augmented reality, and paper-based instruction, for assembly operations. Background: Assembly operations require instruction and training. Many methods, including paper instruction and in-person and video training, have been used to guide assembly workers. Emerging technologies like virtual reality and augmented reality are gaining popularity as methods for effective training. Despite the potential, the current body of knowledge lacks sufficient comparative evidence to adopt these emerging technologies. Methods: In this study, an assembly task will be simulated with a Lego set. A virtual reality and an augmented reality training modules and instructions written on paper will be utilized to guide the participants to perform the assembly task. Different objective measures, such as task completion time and number of errors made, will be recorded along with several subjective measures, including difficulty in understanding instructions, satisfaction, and mental workload for three different methods of instruction. Results: This study will assess and compare the effectiveness and task performance of the three different modes of instruction. It will also be able to identify the cognitive workload, satisfaction, and difficulty level of each type of instruction. The working hypothesis is that augmented reality is more effective, compared to the other methods, in guiding during assembly operation based on accuracy and task completion time. Conclusion: The findings of the study will suggest the best mode of instruction for assembly operation. Application: This research can be applied in teaching and training for both industry and academia.",Digital Transformation,50,39
Dynamic Capacity Management in 5G Networks," We study the decision problem faced by the operator of a private 5G network, known as a private cell, who must allocate available capacity to meet the resource needs of the primary user of the network. The operator may lease excess capacity to external secondary users to generate additional revenue. Private cells are privately owned wireless networks independent of commercial or public 5G networks. Industries such as manufacturing and transportation utilize private cells to prevent downtime for their automated operations. Private cells use network slicing, a technological advancement made available by 5G, to meet differentiated application needs. Under slicing, the network and its resources can be dynamically segmented to support specific applications. Network slicing also allows private cell operators to share their private wireless infrastructure more efficiently with external entities. Thus, resource capacity not currently in use by the primary user can be leased to a secondary user, such as a broker. Given this setting, we study the problem faced by an operator whose main responsibility is to serve the slice instances of the private cell's primary user, but who can also lease excess resources to a secondary user to generate revenue. Primary user slice instances require a specific combination of network resources, such as spectrum, computation, or storage. The operator determines which instances will be admitted to the network for service and which resources can be leased to the secondary user. We use an MDP model to formulate this problem and characterize the optimal admission and leasing decisions.",Production and Inventory Planning,182,40
Promote Self-Balance of Bicycle Sharing Systems: A Simulation Study through Queueing Networks," With the widespread adoption of Bicycle-Sharing Systems (BSSs) and their ever-expanding scale, the modeling and management of BSSs have become increasingly challenging and costly. In this study, we aim to reduce manual relocation and promote self-balance of BSSs by implementing price incentives for customers to ride on certain routes. We identify those routes needing more riders by modeling BSSs with queueing networks and then incorporating real data through discrete event simulation. Then we show how price incentives promote self-balance and mitigate relocation through transition probabilities. The simulation model addresses the limitations of past theoretical queueing network models and accurately mirrors the operational dynamics of the BSS. Our innovative approach can provide valuable managerial insights for the efficient operation of BSSs and scooter-sharing systems with time-dependent demands.",Simulating Transportation,205,41
Optimizing Collaboration: An Integrated Approach to Cost and Carbon Emission-Based Incentive Allocation in LTL Shipping," Linear Programming (LP) model, in conjunction with cooperative game theory (CGT), can be utilized to allocate benefits, encompassing cost savings and reduced carbon emissions, among collaborating companies engaged in Less-Than-Truckload (LTL) shipping. This approach allocation adopts the nucleolus solution concept and solves it as a single joint LP, that enforces fairness with regard to completeness, marginality, and rationality, which serve as constraints. The nucleolus offers a stable and equitable solution among the participating companies, serving as the players, and showcasing all possible strategic alternatives. This ensures the rationale that no company can gain more by breaking away to form a separate group, and no player subsidizes another, guaranteeing the recognition of all marginal contributions. Additionally, it ensures the appropriate allocation of the complete benefit by maximizing the gains of the least satisfied coalition (strategic alternative) in lexicographical order, thereby minimizing the propensity for each coalition to disrupt collaboration. The order serves as an incentive structure, striking a balance between cost optimization and the reduction of carbon emissions. The proposed LP-CGT model presented in this study will function as a decision support tool for companies, demonstrating the measurable benefits of collaboration. This involves defining the characteristic function of all strategic alternatives in the cooperative game to estimate the measurable benefits. In doing so, this work provides a transparent framework for joint allocation, encouraging careful consideration among companies engaged in collaborative shipping initiatives with the proposed approach serving as an efficient allocation tool.",Supply Chain Sustainability 1,217,42
Stochastic Kernel Approximation by Transportation Distance Method," We introduce a distance metric between kernels based on Wasserstein distances, investigate its properties, and present a method for approximating solutions to forward-backward Markov systems. We establish the metric properties of the kernel distance and establish its relationship with various modes of convergence within the kernel space. Subsequently, we put forth a recursive approximation scheme for the forward system of a Markov process, employing the kernel distance to assess the error of risk evaluation by considering the errors associated with individual kernel approximations. We illustrate these results through applications to stopping problems and well-known risk measures within the context of a financial problem, employing a particle-based numerical procedure with finite support sets.",Decision Analysis and Economic Evaluation,38,43
Teaching Simulation Using the Kotlin Simulation Library," Using the Kotlin programming language, the Kotlin Simulation Library (KSL) provides a full complement of features for the development of discrete event programming models within an open-source and freely available environment. This paper provides an overview of the KSL with a focus on using the library within an educational setting. The Monte Carlo functionality of the KSL is illustrated through the use of Kotlin Juytper notebooks, which provide a stream-lined environment for scripting problem solutions, especially suitable for a Monte Carlo setting. In addition, the process-view features of the KSL are illustrated via a set of examples. While the target user for the KSL is in a research and educational setting, many of the features available within the KSL are competitive with commercial offerings.",Advanced Simulation Models,3,44
Evaluating distortion between as-designed and as-built geometries from a superposition of resonant mode shapes," In the advanced manufacturing systems of the future, we will be digitally tracking the characteristics of the manufactured part. Many of these characteristics are local and relate to specific geometric features. However, identifying geometric features is tricky when the geometries do not match due to manufacturing variability. So, to cross-reference part characteristics, we will need to map data between as-built parts and, usually, a designed CAD model. Our project leverages resonant mode shapes from finite element modal analysis as basis vectors for representing the deformation of an as-built part compared to the as-designed CAD model. Fitting the deformation defines a bidirectional mapping between CAD space and a given manufactured part. The mapping can then be used to assign measurements of the manufactured part to the correct location in CAD space, where they can be compared with measurements from other parts, tracked over time, or used as higher-quality input for machine learning. The approach is demonstrated in both simulation and experiment.",Modeling Environments,147,45
A Supervised Dimension Reduction Method for Failure Mode identification," Real-time monitoring of engineering systems through sensor technology has become a common practice in predictive maintenance. Predictive identification of failure modes can help improve maintenance efficiency and extend system life. How to improve prediction accuracy and obtain a solution efficiently presents challenges for building an effective prognostic model for large-scale multi-stream degradation signals. To address the challenges, we propose a novel dimension reduction model combining least squares and logistic regression for multivariate time series data to identify the failure type of aircraft engines. We first develop a new Iterative Reweighted Least Squares (IWRLS) method that can handle missing data to solve the optimization problem. Then, we use the extracted feature to identify the failure mode through logistic regression. A simulation study and a case study using turbofan engine degradation data are conducted to validate our method.",Industrial Prognostics and Decision-Making,102,46
"A Novel Hausdorff Fractional NGMC( p ,1) Grey Prediction Model with Jaya Optimizer"," This study presents a novel prediction approach, the Hausdorff fractional NBGMC(p,1), which is developed based on the original nonlinear grey Bernoulli model with convolution integral; NBGMC(1,1). The approach combines the Hausdorff fractional accumulation operator and provides greater degrees of freedom. The recurrence relation of the binomial in the discrete solution also provides simpler computation due to the elimination of the Gamma function calculation. The Jaya Algorithm is introduced to optimize the parameters of the new model to improve its adaptability. A case study in electronic waste forecasting is utilized to verify the efficiency of the model. The findings demonstrate that the new model exhibits superior fitting and predictive accuracy in comparison to the existing grey models.",Machine Learning II,126,47
RETROFIT: Real-time control of time-dependent 3D point cloud profiles," In modern manufacturing processes, ensuring the 3D shape accuracy of products is crucial. Nonetheless, achieving this accuracy is challenging due to the complex interactions between process inputs and the data structure of the 3D process outputs. Our solution, a 3D profile-based control framework, addresses this challenge by actively adapting and controlling the manufacturing process to enhance 3D shape accuracy. We leverage recent advancements from Koopman operator theory to create an effective model-based control strategy. Initially, we estimate the process model by exploring the relationship between 3D profiles and heterogeneous process inputs. Then, we formulate an online model predictive control law. Challenges include dealing with unstructured, high-dimensional 3D point cloud data, capturing spatial and temporal structures, and integrating heterogeneous, high-dimensional process input data into the control model. To overcome these challenges, we introduce RETROFIT, a solution designed for the real-time control of time-dependent 3D point cloud profiles and derive theoretical conditions for the stability and controllability. Unlike traditional models, RETROFIT is not bound by linear assumptions and can handle the unstructured 3D point cloud response directly. We demonstrate its effectiveness through a wire arc additive manufacturing (WAAM) case study, highlighting its potential to enhance 3D shape accuracy in manufacturing processes.",Process Monitoring and Anomaly Detection,179,48
Validation of Advanced Macro Button Toolbar System for Radiologist Report Composition," The primary role of the radiologist is to produce a report based on diagnostic imaging that helps the referring clinician develop a plan of care for their patients. The most common method used for report composition is voice recognition which is labor-intensive, prone to errors, and requires the radiologist to edit each sentence to ensure accuracy. Growing imaging demand combined with a declining radiologist workforce has necessitated the development of a faster way to compose high-quality reports. A privately-owned outpatient imaging radiology group in California developed an advanced macro-button toolbar system in response to this complex problem. With the click of a button, the report populates instantly with standardized error-free text. This study's purpose is to validate the intended benefits of the advanced macro button toolbar system. The validation study includes analysis of existing work relative value units (wRVUs) data versus nationally reported standards and direct observation of eight radiologists reading and report composition processes. The in-person observation process includes a manual time study for radiologist report turnaround time, a count of clicks on the macro button toolbars, and a count of dictation sentences per study. The direct observation process also includes assessing adoption barriers for understanding future system improvement directions. The study found that radiologists using the macro button toolbar system for report composition at any level achieve higher productivity than reported national averages. Frequent or high toolbar users experience the greatest increase in wRVU productivity and the largest reduction in report completion time.",Recent Advances in Health Systems I,184,49
"Advancing Supply Chain Sustainability: Environmental Integration, and Technological Optimization"," The pressure to enhance the sustainability of supply chain operations has significantly intensified with the emergence of the fourth supply chain revolution, commonly known as Supply Chain 4.0. This transformation has introduced several innovative dimensions in management and engineering, characterized by improved technological integration, data-driven decision-making, predictive and analytical capabilities, and sustainable efficiency. The primary goal of integrating environmental sustainability into supply chain decision-making is to reduce the ecological footprint by minimizing waste, emissions, and resource depletion. Despite an extensive body of literature discussing the advantages and disadvantages of emerging technologies concerning sustainability goals, there remains a gap in understanding how the utilization and integration of these technologies affect sustainability outcomes. This study aims to address this gap. Using a three-part methodology involving a review, thematic analysis, and graph theory analysis, we seek to examine the findings and model the relationships between advanced technology and sustainability outcomes in supply chain and logistics management. The objectives of the study encompass developing a mapping framework to illustrate the impact of investing in advanced technology on the efficacy of supply chain sustainability. Furthermore, it aims to create a multi-criteria evaluation technique that assists in the decision-making process and optimizes the utilization of 4.0 technology.",Supply Chain Sustainability 1,217,50
Aligning Consumer Preferences in the Shifting Landscape of Nursing Home Accessibility," According to a 2022 American Health Care Association report, more than 1,000 nursing homes (NHs) have closed since 2015 regardless of their quality score due to rising care costs, Medicaid underfunding, a decreasing share of private pay residents, nonprofit status, and rural location. As a result of the COVID-19 pandemic, over 44,459 residents have been displaced due to escalating NH closures and an ongoing historic workforce crisis that has yet to be fully addressed. With a growing elderly population and only three new NHs opening across the U.S. in 2023 up to now, it is crucial to understand, from a patient’s perspective, how the shifting landscape of NH accessibility impacts consumer demand and preference fulfillment for skilled nursing home (SNF) care. This study develops a weighted utility-based modeling approach used to estimate the distribution of NH preferences of Arizona older adults seeking long term care. The methodology is validated over a microsimulation created to assess the impact of SNF openings and closures on NH accessibility, patient displacement and placement satisfaction. In the microsimulation, patient transitions are considered to capture the dynamic shifts in patient flow from one setting to another. Accessibility is quantified by measuring the distance consumers must travel for a certain quality of care, while satisfaction is determined by the degree to which consumer placements align with their preferences. By accounting for facility location and quality, the microsimulation and its results provide policymakers with valuable insights into how the closure or opening of NHs impacts consumers holistically.",Home and Mobile Health Systems,92,51
The Marriage of Systematic Layout Planning (SLP) and Simulation Modeling," It’s often stated that simulation models optimize the layout of a cell or a facility. Actually, simulation models are used to test alternatives, not necessarily develop alternatives. That’s where Systematic Layout Planning (SLP) comes in. Like simulation modeling, SLP is another tool in the industrial and systems engineering toolkit. SLP is a structured approach to size, organize, and arrange work areas by analyzing processes, equipment, frequencies, positive and negative adjacencies, and distances. This session will cover the basics of SLP including an example of a simulation model built to integrate with the results of an SLP analysis.",Facilities Design & Planning IV,74,52
Quantifying the Impact of Lost Customers in Quick Service Restaurant (QSR) Operations," Simulation modeling is used extensively in the quick service restaurant (QSR) industry to help design and improve operations. These models can also be used to quantify the financial, customer satisfaction, and operational performance of QSR systems and processes with respect to lost customers. We'll discuss the types and behaviors of lost customers, relate them to simulation definitions, and see how lost revenue and customer satisfaction levels can be quantified in a simulation model. The session will include a group interactive exercise, visualizations and explanations of lost customer behaviors, a discussion of how this application can evolve to a simulation digital twin, and a demonstration of a simulation model used to analyze and tell the story of lost customers.",Supply Chain & Scheduling,214,53
Enhancing Sepsis Management in Hospital Settings: An Integrative Review and Research Agenda," Enhancing Sepsis Management in Hospital Settings: An Integrative Review and Research Agenda  Objective This integrative review aims to evaluate the effectiveness of sepsis management strategies and protocols implemented by hospitals to improve patient outcomes. It also identifies gaps in knowledge and areas requiring further research in sepsis management strategies. Methods/design Following Whittemore and Knafl's five-step strategy for conducting integrative reviews, this study systematically searched multiple electronic databases (PubMed, Embase, CINAHL, and Scopus) using a combination of keywords, Medical Subject Headings (MeSH) terms, and Boolean operators. Studies published in English within the past 10 years were included. Results This review identifies and describes various sepsis management strategies and protocols implemented in hospital settings. It evaluates the effectiveness of these interventions in improving patient outcomes. Key themes related to sepsis strategies and protocols are identified through a thorough analysis of the included studies, including early recognition and diagnosis of sepsis, prompt administration of antibiotics and fluids, use of standardized protocols and guidelines, implementation of sepsis bundles, interprofessional collaboration, and monitoring and management of sepsis-related complications. Conclusions This integrated review provides insights into the current evidence on sepsis management strategies and protocols implemented by hospitals to improve patient outcomes. Uncertainties remain regarding the effectiveness of these strategies. Implications for clinical practice This integrative review highlights the importance of early recognition and diagnosis of sepsis, prompt administration of antibiotics and fluids, use of standardized protocols and guidelines, implementation of sepsis bundles, and interprofessional collaboration in sepsis management and how it improves patient outcomes.",Poster Presentations,169,54
An inexact column-and-constraint generation method to solve two-stage robust optimization problems," We propose a new inexact column-and-constraint generation (i-C&CG) method to solve two-stage robust optimization problems. The method allows solutions to the master problems to be inexact, which is desirable when solving large-scale and/or challenging problems. It is equipped with a backtracking routine that controls the trade-off between bound improvement and inexactness. Importantly, this routine allows us to derive theoretical finite convergence guarantees for our i-C&CG method. Numerical experiments demonstrate computational advantages of our i-C&CG method over state-of-the-art column-and-constraint generation methods.",Large-scale Integer Programming,118,55
A Comparison of Logistics Routes in America: The Corridors Cases," Logistic routes within continents serve as critical arteries that reduce transportation costs, promote accessibility to more areas, and enable the timely delivery of goods and services. One of the mega projects that the current administration of the Mexican government pretends to develop is ""The Tehuantepec Isthmus Interoceanic Corridor.” This project is an integrated logistics platform linking the Gulf of Mexico, the Pacific Ocean, and the country's southern border. The Interoceanic Corridor aims to compete internationally as a site that will change how commerce routes are currently portrayed. This mega project will target approximately 10% of the current Panama Canal transit, which can also be understood as receiving 1.4 million cargo containers annually. The plan to achieve this goal relies on an aggressive legal strategy that will incentivize companies to use the Interoceanic Corridor. Also, the program is based on the geographical narrowness of the Tehuantepec region and the political factors, such as the Free Trade Agreements that Mexico has with other countries. An analysis of the different commerce routes in America was made regarding laws, considering the three American corridors that cross the American continent (The Panama Canal, the Tehuantepec Isthmus in Mexico, and the Bioceanic corridor in South America). Logistics routes within continents have enormous potential because they enhance connectivity trade and increase resilience in supply chains in case of disruptive events. Finally, these types of infrastructure will potentialize the economic development of the Mexican region by Nearshoring.",Routing 1,197,56
Harnessing Text Information for Enhanced Hurricane Resilience and Public Engagement," The recent disaster by hurricane Otis in Acapulco, Mexico, exemplifies how natural disasters, particularly hurricanes, can often arrive with a certainty that defies prediction despite technological advancements. Their impact, coupled with secondary disasters, underscores the urgency for efficient preemptive measures. Resilience research in the face of such calamities necessitates the creation of a safeguard before incurring irreversible losses. This research leverages big data, explicitly harnessing information gleaned from social media about hurricanes, to bolster the efficacy of hurricane response efforts. The focus lies in amplifying the dissemination of adequate warnings and enhancing rescue operations. Concurrently, the research aims to delve into potential disaster rescue by tracking and analyzing high-interaction discussions on social media. This exploration seeks to unveil public focal points during hurricane disasters, identifying valuable perspectives for future disaster response strategies",Energy & Environment I,62,57
Breakthrough Performance with Lightning Speed Lean," The Riggs Fellowship Team from Harvey Mudd College was invited by two companies to conduct a 10 week lean transformation in order to improve the production and efficiency of their plants. Prior to the teams’ arrival, the companies had a large backlog, an excessive amount of inventory, and extensive machine downtime. By the end of the project, the Riggs Fellows were able to incorporate significant changes such as a full line relayout with an efficient flow, a new cell design, and reduced changeover procedures using principles of SMED and kaizen. The team also focused their attention on empowering employees and transforming both companies’ culture so that it centralizes around problem-solving. These changes to the companies’ production lines required under $100,000 of investment and resulted in over $600,000 saved annually.",Process Planning-I,180,58
Infrastructure Investments for Improving Arctic Emergency Response across Multiple Man-Made Hazards," We consider the problem of investing in infrastructure across remote Arctic communities in order to improve emergency response capabilities to multiple man-made hazards, including oil spill response, search and rescue operations, and mass evacuations of cruise ships. We discuss models to assess emergency response for each of these hazards that account for the remoteness of the Arctic region. We create a multi-objective optimization problem that helps to examine the tradeoffs in terms of investments to protect against each these different types of hazards. We apply our model and tradeoff analysis to the motivating case study of Arctic Alaska. This area that will see a rise in commercial maritime activities due to longer ice-free seasons in the Arctic Ocean and, therefore, likely see more man-made hazards occur.",OR for a Resilient Future,152,59
Solving Approximated High-Dimensional Dynamic Programming Problems in Sequential Decision Problems," We investigate value-function approximation for solving high-dimensional continuous-state sequential N-stage decision problems through Dynamic Programming (DP). To address the challenge of the ""curse of dimensionality"" associated with such high-dimensional dynamic programming tasks, we propose a deep learning algorithm capable of efficiently computing a global solution for this problem class. We also compare this algorithm with other nonlinear approximation schemes such as splines of selected order and Gaussian radial-basis networks with different centers and widths. We assess the accuracy of suboptimal solutions achieved by combining DP with these approximation techniques, offering insights into the successful results reported in the existing literature on the use of value-function approximators in DP. Additionally, we evaluate these findings through a Markov Decision Process (MDP) example focus on identifying the optimal strategies for a discrete search game.","Machine learning and AI, Part 2",130,60
An agent-based simulation model to plan for continuity of care for chronic diseases after natural disasters," The rising incidence of cardiovascular disease (CVD) juxtaposed with the increasing frequency of natural hazards in Texas poses a critical public health challenge. This research examines the multifaceted impacts of natural disasters on individuals with CVD, focusing on health outcomes post-disaster and the efficacy of increased medication access. An agent-based simulation model is developed to evaluate the intersection of health behaviors, environmental factors, and demographic disparities. The study first assesses the relationship between standard health behaviors (such as smoking, diet, and exercise), physiological measures, and the heightened risk of adverse cardiovascular events during natural disasters. It also considers the role of emergency preparedness behaviors, including medication adherence and document safekeeping, in exacerbating CVD outcomes. The second phase of our research explores intervention strategies to balance healthcare demands with system capacity amid disasters, emphasizing the continuity of care for CVD patients. We utilize the agent-based simulation model to integrate real-life experiences and project future disaster scenarios, informing preparedness plans reflective of the affected populations' needs. Through longitudinal studies spanning up to 20 years, we investigate the immediate and long-term effects of these variables on CVD health outcomes. Our approach aims to influence a broad spectrum of policies, from disaster preparedness to chronic disease management during emergencies.",Simulation Models in Health Systems,206,61
Super-Resolution for Wafer Transmission Electron Microscopy Images," High-resolution wafer transmission electron microscopy (TEM) images have drawn considerable attention for measuring micro-patterns on semiconductor wafers. However, because of destructive testing, acquiring high-resolution images entails a significant human effort. To minimize human intervention, deep learning-based super-resolution shows great potential for analyzing wafer TEM images. For wafer TEM images, it is crucial to learn the wafer TEM-specific noise stemming from scattered electron beams and instable magnetic fields. In addition, wafer TEM images can form pairs of low and high-resolution training data by using either solely high-magnification images or a combination of low and high-magnification images. In this study, we examine four methods for constructing training image pairs to effectively train super-resolution models tailored for wafer TEM images: (1) human-labeling, (2) template matching, (3) bicubic degradation, and (4) complex degradation. In our experiments, the bicubic degradation and complex degradation methods that use only high-magnification images demonstrate superior generalization performance. Furthermore, the complex degradation method restores higher-resolution images than the bicubic degradation method, effectively capturing the various noises present in wafer TEM images. Such analyses can serve as comprehensive guidelines for constructing wafer TEM image super-resolution dataset.",Manufacturing I,135,62
Panel discussion - Humanitarian and Health Supply Chains," IISE special session Panel – Humanitarian and Health Supply Chains - Success and Lessons Learned : The world has witnessed a series of humanitarian crises, ranging from natural disasters such as earthquakes, hurricanes, and wildfires, to conflicts and political instability leading to mass displacement of populations. These crises have stretched the capacities of international organizations and local actors, necessitating coordinated, timely, and efficient responses. Humanitarian supply chains play a pivotal role in addressing these crises. They are essential for the timely delivery of life-saving aid, including food, clean water, shelter, medical supplies, and essential services to affected populations. A well-functioning supply chain ensures that aid reaches those in need swiftly and efficiently, mitigating the adverse impacts of crises on vulnerable communities. This special panel session will share the success and lessons learned through case studies from this expert panel. The panel includes: Dr. Yuehwern Yih, Purdue University Dr. Ozlem Ergun, Northeastern University Dr. Julie Swann, NC State Dr. Julie Ivy, University of Michigan Dr. Maria Mayorga, NC State Moderator: Mike Sherwin, Duquesne University",Panel discussion - Humanitarian and Health Supply Chains,159,63
Decomposition Methods for Solving Knapsack Problems with Uncertain Demand," We consider the knapsack problem with uncertain demand, where the objective function is to minimize the total expected cost, and the decisions include binary variables to choose items and integer variables to fulfill demand. The Benders decomposition is used to tackle the problem with high-dimensional demand realizations. Our method was developed that took advantage of the block structure in mathematical programs and utilized the parametric lower bound of the sub-problem to obtain the optimal solution iteratively. Due to the loose bound provided by the linear relaxation solution, we applied cutting planes to the sub-problems to speed up the algorithm convergence. Various cutting plane designs were investigated. Experiment results showed that our proposed method could obtain better solution qualities for most problem instances as compared with the commercial solver and prior study’s methods.",Large-scale Integer Programming,118,64
APPLICATION OF MARKOVIAN DECISION PROCESS (MDP) FOR INVESTMENT STRATEGY BASED ON US PRESIDENTIAL ELECTION," This paper focuses on the application of Markovian Decision Process (MDP) for investment decisions based on US presidential elections. The goal is to recommend optimal investment strategies depending on whether the administration is Democrat or Republican. Secondary datasets on stock market performance, treasury bills, bonds, and presidential election results are used to calculate transition probabilities and reward matrices. A dynamic programming approach is implemented to determine the investment policy that maximizes expected return over a finite number of 4-year presidential terms. Results indicate that under a Democrat administration, investing in the stock market yields the highest returns. However, under a Republican administration, investing in treasury bonds becomes more optimal in the long run despite lower short-term stock market returns. The findings provide insights into how political ideology and policies systematically affect investment outcomes. This methodology can help model investment decisions under uncertainty based on macro-political factors.",Decision Support,39,65
Multi-Criteria Clinic Allocation in Massachusetts to Reduce Healthcare Disparities," Rural populations experience health disparities related to access to clinics in the community. While equitable ambulatory healthcare facility location decisions have been widely studied, its analyses in the context of rurality and transportation related social vulnerability are limited. We developed a multi-criteria optimization model to determine how to optimally allocate p new clinics to N locations when weighing decision makers’ preferences between two objectives: (i) maximize coverage, and (ii) reduce total pairwise envy. Coverage relates to accessibility to healthcare services, i.e., to new or existing clinic locations, which is measured by rurality codes, distance to new clinics, and access to transportation. Transportation in this context refers to access to a vehicle. Envy is a measure of pairwise disparities in coverage between any two locations. We applied the model to census tract level data in Massachusetts (MA) (i.e., N = 1599 census tracts in MA). We used data from publicly available datasets, specifically, transportation related vulnerability data from social vulnerability index (SVI) 2020, location data of existing clinics from MA Department of Public Health (DPH), and rural-urban commuting area (RUCA) data from US Department of Agriculture. We conducted sensitivity analyses on the weights in the multi-objective function formulation, the distance threshold to new clinics, and the number of new clinics. Key findings highlight the tradeoff between improving coverage and reducing overall envy in the region. The model serves as a useful tool for the MA DPH to make equitable clinic location decisions.",Healthcare Optimization,87,66
How to Identify and Improve Dynamic Bottlenecks for Increase Capacity and Revenue?," Dynamic bottlenecks are in most discrete manufacturing plants, and many leaders are unaware of the dynamic bottlenecks in their plants. The only time dynamic bottlenecks are not in a discrete manufacturing plant is when the plant has all product lines balanced, such as automotive assembly lines. Few discrete manufacturing plants have 100% balanced lines, and understanding dynamic bottlenecks is crucial to increasing capacity and revenue. This paper will provide a step-by-step approach to identifying dynamic bottlenecks and how to determine and improve the most critical bottleneck in a discrete manufacturing plant. It will also show how to use cost data to determine which critical bottleneck provides the most revenue. A couple of case studies from Fortune 500 companies will be presented to give a reality verification.",Work Systems I,240,67
"Build, Experiment, Learn: Promoting Curiosity and Creativity While Learning DOE"," Design of Experiments (DOE) is a structured approach that uses statistical methods to optimize products, processes, and systems. It is a difficult topic to master in a single course, however, with a project that involves real and hands-on experimentation student learning can be guided to promote deep learning. Providing students flexibility in choosing their projects is desirable, though not all students are motivated or comfortable with developing a project topic. Integrating a Makerspace activity into the course provides a way to support students having difficulty with identifying a DOE problem. Furthermore, it helps foster curiosity and creativity and exposes students to resources that are available to them which otherwise they may not utilize. This paper describes efforts to promote active-learning in a DOE course through engaging students in a Makerspace activity to build their own devices for conducting experiments. Catapults are frequently used in demonstrating and teaching DOE concepts and principles. The Makerspace option involved making a catapult and designing and conducting an experiment using the catapult. The students were allowed to create their own design or to use a readily available design. In assessing the level of student engagement, the quality of the catapults made and the modifications implemented were evaluated. To assess the impact of the activity on student learning of DOE concepts, the student performance in projects with and without catapults were compared. A survey was conducted to gather feedback on student experience with the Makerspace integration effort. The paper provides the assessment results and implementation guidelines.",Innovative Learning Approaches in ISE Education,111,68
Filament width control by extrusion pressure and solid load of nano-fiber filled alginate-gelatin hybrid hydrogel: an analytical approach," Three-dimensional (3D) bioprinting has emerged as a groundbreaking technology in tissue engineering, offering precise control over scaffold architecture for regenerative medicine applications. To tackle the printability and shape fidelity related issues of 3D bioprinted scaffolds fabricated by mostly hydrogel materials in extrusion-based bioprinting process, the study fabricates a set of filaments using alginate, gelatin, and TEMPO mediated Nano-Fibrillated Cellulose (TO-NFC) components and solid loads. We hypothesize that when alginate-gelatin combined with nano-fiber reinforcements, such as TEMPO-oxidized nano-fibrillated cellulose (TO-NFC), the resulting composite materials exhibit improved mechanical properties, making them an ideal choice for 3D bioprinting. The filament widths and corresponding diffusion rate of each composition at various applied pressures were analyzed and recorded. Finally, an analytical relationship was established using multiple regression methods to estimate the filament width with respect to extrusion pressure and solid load of those components. The findings suggest that this method holds great promise for the creation of precisely shaped scaffolds through 3D bioprinting, opening new possibilities in tissue regeneration.",Fused Deposition Modeling Additive Manufacturing Processes,76,69
Developing a framework for human performance analysis using agent-based modeling on human-machine collaboration systems," Human performance analysis involves assessing the performance of workers and systems concerning factors like task load, time spent on tasks, and system reliability. This analysis enables the evaluation and enhancement of human-machine collaboration systems. While previous studies have explored this field, they have struggled to integrate the diverse characteristics of both humans and machines comprehensively. This study proposes a framework utilizing agent-based modeling and simulation to analyze task loads and human performance effectively, accurately representing system components and their interactions. Initially, we identified task characteristics through task analysis and designed agents with specific behavioral algorithms to mirror these traits. Employing the additive manufacturing process as a case study, we conducted task analysis using hierarchical task analysis and the VACP method with on-site workers. Subsequently, we created plausible scenarios for the additive manufacturing process. Although humans possess various traits, this study focused on stress resistance and attention levels, both related to task performance. Human behavior was modeled using an affordance-based finite state automata model, where affordance is what the environment offers to humans. Subsequent simulation under scenarios facilitated the analysis of human performance. This framework enables valid human performance analysis by accounting for human traits and behaviors, effectively depicting real work environment situations and interactions.",Agent-Based Modeling,14,70
PARAMETRIC MODEL REDUCTION USING PROJECTED GAUSSIAN PROCESS ON GRASSMANN MANIFOLD," The dynamics of complex engineering and physical systems is often described by PDEs. Although it is possible to solve many of these PDEs using numerical methods, the dimensions of the problems can be extremely high due to the spatial discretization of the mathematical model. The high computational cost prevents us from running numerical solvers for real-time operations nor repeatedly for different parameter settings. Hence, low-dimensional Reduced-Order Models (ROMs) become extremely useful in capturing the dominate behaviors of the original systems. Projection-based model reduction is one of the most widely techniques for constructing ROMs. As the name suggests, an ROM is often obtained by projecting the full-order system to a subspace spanned by chosen modal basis modes. For example, utilizing simulated data generated from full-order PDE with given parameters, the Proper Orthogonal Decomposition (POD) has been widely used to generate the optimal basis modes in an L2 sense. Note that, a governing PDE is often parameterized by a set of parameters, and challenges immediately arise when a physical system behaves differently over the parameter space. In this case, the optimal basis also needs to be updated as the parameter changes. The lack of robustness against parameter change may limit the applicability of ROMs for many design, control, and real-time operations problems where parameter changes are common. In this talk, we describe a Projected Gaussian Process (PGP) that enables us to learn the mapping between parameters and POD bases and use the constructed PGP to adapt ROMs for parameter changes.",Machine Learning III,127,71
Strata Design in Stochastic Simulations with Multivariate Inputs," Stratified sampling is one of the powerful variance reduction methods for analyzing system performance, such as reliability, with stochastic simulation. It divides the input space into disjoint subsets, called strata, to draw samples from each stratum. Partitioning the input space properly and allocating greater computational effort to crucial strata can help accurately estimate system performance with a limited computational budget. How to create strata, however, has yet to be thoroughly examined. Strata design faces the curse of dimensionality and data scarcity as the input dimension increases. We analytically derive the optimal stratification structure that minimizes the estimation variance for univariate problems. Further, reconciling the optimal stratification into decision trees, we devise a robust algorithm for multi-dimensional problems. Numerical experiments and a wind turbine case study demonstrate the superiority of the proposed method in terms of variance reduction, leading to computational efficiency and scalability.",Advanced Topics of QCRE Applications I,5,72
Metaheuristics based Order Batching and Routing in a Warehouse," Order picking is the process of retrieving items from their locations in a warehouse based on customer order information. In a warehouse with many orders, picking by single order is inefficient, so it is common to pick multiple orders together. This process includes the order batching and routing problem which involves grouping different orders into one batch and assigning it to a single picker with an appropriate route decision. Improved batching and routing can shorten the travel distance for order pickers and enables efficient warehouse operations. Consequently, there have been numerous studies on order batching and routing problems. However, their application to real-world problems has been limited, because previous papers used relatively small datasets, considering limited number of orders. Additionally, in many papers, the travel distance is calculated using major routing policies such as S-shape, Return, Largest-gap and so on. This often results in a calculated distance that is far from the optimal value, even though the calculation time is short. Therefore, in the present study, metaheuristics-based algorithm is proposed to solve the order batching and routing problem simultaneously. The proposed mathematical optimization model is formulated as a mixed integer linear programming problem. In our model, a two-block warehouse with cross-aisles is considered. Considerations on the order grouping, aisle-based distance and batch selection probability significantly improve the solution compared to previous results. Numerical experiments were demonstrated the effectiveness of the proposed methods.",Facilities Design & Planning I,71,73
Pseudo Node Insertion Method for Synchronization in Drone-Truck Combined Operations," The drone-truck mixed fleet operation solutions are based on truck routes and locations, usually customer nodes, where drones depart from and return to trucks. Since synchronous rendezvous of both vehicles can be very rare, these solutions may contain waste time. In this research, a pseudo node insertion method is proposed to resolve the drone-truck asynchronization issue. Pseudo nodes are created at the point where a drone and a truck can meet simultaneously. We present a detailed method to calculate the location of the pseudo node, and provide a detailed analysis for the travel completion time saving conditions. Furthermore, we explore a variety of scenarios to enhance the efficiency by way of inserting pseudo nodes. An algorithm for the pseudo node insertion method is provided, and numerical examples are presented to discuss efficacy and efficiency of our proposed approach.",UAV logistics,233,74
Cyberthreat Modeling and Mitigation for CNC Machining Systems Using Attack Graphs and Stochastic Programming," This paper proposes an attack graph-based methodology to enable cybersecure computer numerical control (CNC) machining. Cybersecurity has become imperative as manufacturing systems continue to integrate information technology (IT). However, modeling cyber threats in manufacturing environments remains underexplored. This work addresses this gap by presenting an approach to represent a CNC machine as an attack graph. The graph captures vulnerabilities in components like the motion control system, spindle, tool changer, sensors, network interfaces, and connectivity through potential attack vectors. Based on previous research, a two-stage stochastic programming model can be formulated based on the attack graph to optimize allocation of countermeasures under a budget constraint to minimize expected cyber risk. Uncertainty in attack success can be handled through sampling, while a hybrid Sample Average Approximation and Progressive Hedging Algorithm solution methodology is implemented. The proposed methodology enables data-driven, risk-aware cybersecurity strategies for manufacturing. With CNC machining as an example application, this work contributes a broadly adaptable decision framework for cybersecure digital manufacturing. The chapter conveys how the attack graph and optimization approach could be customized to improve cybersecurity for a CNC machine in a manufacturing setting while highlighting the critical methodological and application contributions.",Cybersecurity in Manufacturing,35,75
How to succeed large organizational OPEX transformation and case studies, - Key results - Key success factors - Key change management programs with examples and case studies,Organizational Culture,157,76
Interdisciplinary Collaboration for Sustainable Innovation: A Systematic Review of Open Innovation and SDGs," Open innovation can be decisive for a sustainable and collaborative future, boosting the Sustainable Development Goals (SDGs). This relationship is a fundamental question to be explored by industrial and systems engineering. We conducted a systematic literature review on the interaction between open innovation (OI) and SDGs, mapping scenarios where interdisciplinary and inter-organizational collaboration encourages sustainable innovation. Our research examines how OI contributes to achieving the SDGs in different contexts and presents future perspectives for studies. The relationships identified between OI and SDGs, the SDGs most frequently impacted by OI, and trends and opportunities for future research are highlighted. The results revealed fourteen scenarios where OI is key in promoting interdisciplinary and inter-organizational collaboration for sustainable innovation. By bringing together diverse actors, such as companies, governments, and communities, OI enables the development of more effective solutions to face challenges related to the SDGs. The analysis suggests a fertile field for research, with multiple aspects that may be explored. This study paves the way for future research and highlights the relevance of OI to advance sustainable development in line with the 2030 Agenda. Finally, we propose a refinement in the definition of OI within the scope of the SDGs: OI refers to engaging stakeholders in transparent and open collaborations, aiming for innovative solutions that positively impact the SDGs.","Innovating for Impact: Exploring Interdisciplinary Collaboration, Sustainability Challenges, and Indigenous Design (SDG 9)",107,77
Machine learning-based battery state-of-health prediction for unmanned aerial vehicle predictive maintenance," Battery state-of-health (SoH) prediction aims to estimate the remaining capacity by modeling battery degradation through its life cycle. Machine learning (ML)-based SoH models can accurately predict the battery remaining capacity based on voltage, current, and temperature. Batteries SoH prediction for unmanned aerial vehicles (UAVs) is a crucial yet overlooked domain that features data scarcity and high variability. Accurate battery SoH information contributes to efficient predictive maintenance, enhancing UAV profitability and flight safety. However, UAVs are compatible with a variety of batteries and the available data for each type of battery are scarce. Furthermore, the available input features from UAV batteries are limited to the built-in sensors because of the lightweight requirements. This research aims to develop an ML pipeline for UAV battery SOH prediction while mitigating data scarcity using knowledge transfer. 342 and 289 flight experiments have been conducted to collect operational data from lithium polymer batteries of 2200 mAh and 1100 mAh, respectively. Voltage, current, and throttle are selected as the input features of the ML model according to existing literature and sensor availability. The remaining capacity is measured at every 10th experiment to label the dataset. The state-of-the-art ML models for battery SoH prediction, transformers, are trained using the acquired time-series data. However, transformers that require large datasets cannot provide accurate predictions under data scarcity. Thereafter, the features are transformed into images to fine-tune a pre-trained ResNet-50 to utilize its image analysis capability. Finally, accurate SoH prediction models were obtained using transfer learning between two battery types.","Smart and Sustainable Maintenance: Machine Learning, Blockchain and Circular Economy Approaches",208,78
Classification for Predicting Recidivism: Challenges and Scopes," In the realm of criminal justice, recidivism pertains to individuals exhibiting persistent patterns of reoffending. This subset of repeat offenders poses a significant burden on the policing system due to its recurring nature. An ability to predict recidivism holds the potential to empower law enforcement with strategic interventions aimed at disrupting this cycle. This study delves into the Recidivism Forecasting Challenge presented by the National Institute of Justice in the Summer of 2021. Two years of data from the State of Georgia and two performance metrics, Brier score and fair and accurate, are used. The data involved a mix of both qualitative and quantitative input variables with potentially complex relationships with the probability of recidivism. In this research, application of a classification model, potential data challenges and scopes are discussed.",Social Good Analytics,209,79
Towards AI-Enhanced Process Planning: Assessing Machine Tool Capability based on Part Design," The advent of the fourth industrial revolution, or Industry 4.0, calls for an automated approach to manufacturing process planning, starting with an appraisal of the capacity of machine tools to handle specific part geometries and microstructures. Where capabilities match requirements, the task then becomes to devise an efficient method for translating design elements into tangible components. The decline in the U.S. manufacturing sector's skilled labor force, due to an aging demographic and the loss of seasoned experts, underscores the critical need for a shift towards an Industry 4.0 autonomous paradigm. This work seeks to create and validate a framework that determines the manufacturability of design features by the available machinery and materials. The ultimate aim is to enhance process planning by ensuring the seamless conversion of designs into physical products, with a particular focus on the intricate details of geometry, microstructure, and cost.",Process Planning-II,181,80
An effort to Three dimensionally Fabricate Finger Prosthesis Using Hybrid Materials with Integrated Tactile Sensing," This study presents a novel approach to fabricate a finger prosthesis utilizing hybrid materials and 3D printing techniques. The fabrication process integrates both extrusion and Stereolithography (SLA) printing techniques, employing Polylactic Acid (PLA) and bio-resin to construct the scaffold structure. Additionally, a tactile sensing scaffold will be fabricated on the fingertip using Polydimethylsiloxane (PDMS) releasing through a pneumatical extrusion-based 3D bioprinter. This hybrid-material approach combines the mechanical strength of PLA, dimensional accuracy, and biocompatibility of bio resin, enhancing the prosthesis's structural integrity and user comfort. The integration of PDMS-based tactile sensing offers a crucial advancement in providing a naturalistic haptic experience for prosthesis users. This research represents a significant step forward in the development of functional and sensory-enhanced finger prostheses, demonstrating the potential for personalized, high-performance solutions in the field of prosthetic technology.",Bioprinting and Biomedical Manufacturing Processes-II,20,81
Development and Operationalizing of the Learning Experience Design Process to Create STEM Interventions," Despite significant investments in research and development aimed at improving STEM education in K-12, a critical gap exists in a comprehensive theoretical framework that describes the necessary process for the development of STEM interventions that have substantial results and are replicable in practice. This research addresses this gap by proposing a framework grounded in Education Design Research (EDR) and Learning Experience Design (LXD). Using the LXD approach, which integrates instructional design, human-computer interaction, and user-experience design, this framework seeks to prioritize the needs of high school teachers, who in most cases are not engineers, by placing them at the center of the STEM intervention development process. The framework addresses key inputs that must be understood, analyzed, and intentionally incorporated into a new STEM intervention such as existing teacher knowledge, culturally relevant pedagogy and content, content adoption and usability, and fidelity of implementation so that the intervention can ultimately achieve meaningful student outcomes and be able to be widely adopted. This paper demonstrates the application of this new framework in the development of a transdisciplinary high school course called Introduction to Engineering. By applying the framework to develop a STEM intervention, future STEM intervention developers can follow this step-by-step practical guidebook to include teachers in the design and development process for a more intentionally designed end product that will have meaningful and replicable results.",Innovative Learning Approaches in ISE Education,111,82
GIS and Modeling for Probabilistic Risk Assessment and Uncertainty Analysis for Flood Events," Disaster events, particularly floods, have notably increased in recent years, posing significant community threats. Considering their escalating frequency, it is imperative to address and mitigate the risks associated with floods. This study focuses on understanding the dynamics of flood-affected areas and their inhabitants, which is crucial for assessing evacuation capabilities, shelter accessibility, and emergency responder reach. By leveraging Geographic Information System (GIS) tools, extreme event data, American Community Survey (ACS), Social Vulnerability Index (SVI), and agent-based behavioral models, a comprehensive geographic digital twin of a flood event is constructed. The research employs Probabilistic Risk Analysis (PRA) to identify and prioritize high-risk census tracks in a small rural Tennessee county. This prioritization is based on the anticipated number of stranded individuals, integrating mobility data and GIS event models. Additionally, the study delves into the impact of varying levels of population-compliant evacuation behaviors. Simulations explore different magnitudes of compliance, offering insights into the potential risk reduction achievable through enhanced community response. Results from the analysis effectively pinpoint the most vulnerable census tracks regarding persons stranded or requiring rescues. The study also calculates the events contributing the most to the overall risk in terms of the inability to evacuate due to lack of mobility, evacuation routes, or evacuation behaviors, demonstrating that the probability of evacuation significantly influences risk reduction. This research provides valuable information for emergency response managers, aiding them in strategic disaster preparation planning efforts.",Resilience & Hazard Analysis,190,83
Water Resource Portfolio Rebalancing: An Isomorphic Application of Financial Portfolio Management Techniques," When managing a financial portfolio, it is often advantageous to periodically rebalance the distribution of investments according to current market conditions. Rebalancing may also be necessary to ensure that the portfolio conforms to pre-established parameters concerning risk tolerance. Such rebalancing is particularly important for investment portfolios with a long-term time horizon. Given the increased application of financial portfolio optimization techniques to strategic water resources planning, it is valuable to understand how rebalancing can and should be applied in this domain. The “market conditions” for water resource systems include changes in population, economic activity, and climate. Water managers must take these into account when developing water budgets and deciding which interventions designed to meet anticipated demand should be funded, reevaluated, and/or implemented. Portfolio rebalancing confers a substantial level of reflectivity in the planning process and can enhance adaptability; one cornerstone of resilience management. This research analyzes a conjunctive water resource system located in a semi-arid region of the southwestern United States and demonstrates a method for rebalancing a water portfolio in way that enhances system resilience. This research adds to the technical body of knowledge of resource management. It has implications for industrial engineers in practice as well as for researchers in the domains such as systems engineering, engineering management, and engineering economics.",Resource and Asset Management,194,84
Mechanical and Material Properties of Additive Manufactured Metals with Different Infills," Additive manufacturing is a growing field, and it currently reaches all sectors of engineering, from aerospace to biomedical, and everything in between. This type of manufacturing is commonly used for prototyping, fixturing, and small-scale manufacturing. Metal additive manufacturing is a relatively new field, and it is becoming larger because of its benefits of lightweight metals and creating parts that could not be created with traditional manufacturing methods. During the metal additive process, a three-dimensional shape is built from metal powders or filaments with the help of lasers or filament extrusion nozzles. Because metal additive manufacturing is so new, little research has been done on the properties of each filament or powder. It is important to characterize material properties while printing to ensure the correct material selection for additive manufacturing. The purpose of this study is to investigate the tensile strength and material properties of additive manufactured metals with different infills and print orientations. This study aimed to determine the impact of light-weighting metals on tensile strength and the impact of print orientation on material properties and tensile strength. To accomplish this, tensile bars were prepared, filled with a total infill, triangular infill, or gyroid infill, and printed in the horizontal or vertical orientation. Tensile testing, durometer testing, and microstructure examination were performed on the specimens. The test results display a change in properties between print orientation and the different types of infill.",Fused Deposition Modeling Additive Manufacturing Processes,76,85
Control of Industrial Robots Based on Artificial Intelligence: Current and Future Trends.," Industrial robots are a crucial technology for developing smart factories. These smart factories will require more efficient robot control strategies. Hence, researchers and practitioners are putting significant efforts into enhancing this field. One can find in the literature remarkable developments that go from the control of articulated arms, routing planning decision-making, self-decision-making, object recognition, and human-robot interface. This manuscript aims to summarize the literature on artificial intelligence in robotic control systems. Moreover, these strategies are analyzed, and the most promising techniques are discussed. This manuscript is intended to guide future directions in this field.",Machine Learning in Manufacturing I,129,86
Using Digital Tools to Enhance Construction Safety & Health Management Systems," Maintaining a safety culture has become a challenge with the increase of inexperienced workers entering employers existing safety and health management systems. Transient, temporary, contract and gig workers entering the workforce to replace an experienced aging workforce is a reality that must be addressed. The case study shows a training regimen supplemented with digital IoT tools and AI which enhance situational awareness of both workers and moving equipment. Finally, an introduction of a predictive safety process model will be introduced. Leveraging the data gleaned from the IoT devices, a model is built that may predict unsafe patterns of travel, worker / equipment conflict and enhance hazard analysis. The crux of safety management is about anticipating hazardous conditions and mitigating them. The case study shows how safety managers can leverage data modeling / predictive analysis to anticipate hazards using frameworks like REDECA. Industrial environments continue to utilize more automated equipment which potentially place workers in harm’s way.",Construction Safety,31,87
A Linear Programming Application for Generating Running Routes Based on Individual Preferences," We present the first application to utilize linear programming to generate running routes. Route generation is beneficial for runners visiting new and unfamiliar locations. Current applications forgo linear programming, utilizing their own methods to create custom routes. Our objective is to create a linear programming model that produces optimal closed-loop routes based on user preferences. The model proposed is an extension of TSP. The model processes a street network G = (V, E). The first set of decision variables (1) (see figure 1) are the network edges. The second set of decision variables (2) are the sequence variables, which apply to the selected nodes. The objective function (3) minimizes the total distance traveled in the route. (4) is a modification of the flow conservation constraint, and deviates from the original TSP constraint by ensuring a node can be visited and departed at most once. (5) sets the root node and requires it be visited. (6) forces the distance of the route to be greater than the input distance. (7), (8), and (9) are the subtour elimination constraints found in the TMZ formulation and prevent subtours and ensure connectivity. The model UI is implemented as a website. This will enable feedback for verification and validation testing. Users will be able to input parameters such as their starting location, preferred distance, terrain type, and elevation to help further optimize their route. In conclusion, the linear programming model will help runners plan the most optimal running routes according to their preferences.",Optimization Application,155,88
CHEATING OR DELIGHTING CUSTOMERS ON QUALITY? MARKETING IMPLICATIONS UNDER DELAYED INFORMATION DISCLOSURE," This paper seeks to investigate the marketing implications in terms of pricing and advertising policies respectively associated with cheating and delighting customers on quality. In the respect, we first characterize the economic model that corresponds to the absence of cheating and delighting, that is, fair (or non-deviant) quality policy. We then successively formulate the models that respectively apply for the deviant quality options, i.e., cheating and delighting, wherein a misalignment prevails between the product offering and customers’ expectations. In the first model, cheating is described as a mean to inflate goodwill through false advertising while keeping a low unit production cost in order to draw a cheating rent as long as the cheating is not disclosed. In the second model, delighting is a mean to enhance goodwill through an extra quality in order to benefit from a delighting rent once the delighting is awarded. We consider that the probability for the information disclosure about cheating (delighting) depends on the cumulative number of customers cheated (delighted) and formulate the expected profit functional associated with each case. The following research questions are addressed: i) Under which conditions is a deviant policy more beneficial than the non-deviant one? ii) How are the price-advertising time-paths affected by a deviant policy compared with the non-deviant one?",Decision Support,39,89
PERFORMANCE EVALUATION OF A SINGLE CYCLONE FLASH DRYER FOR INSTANT POUNDED YAM FLOUR PRODUCTION," Yam tuber is predominantly found in the eastern, northern, and western parts of Nigeria, providing food for over 180 million people. Despite its significance, yams do not store well, and one of the stable foods derived from them is yam flour. This flour, used to make a porridge-like food called Amala when eaten with vegetable soup, is considered a delicacy in West Africa, often consumed three times a day in some regions. It has historically addressed issues of poverty and malnutrition. Recent research has introduced Instant Pounded Yam Flour (IPYF), a staple food produced through the pounding of boiled yams. This flour, when reconstituted with hot water, yields a porridge-like dough similar to pounded yam, eliminating the laborious process of pounding. Combining these two products with boiled yam, various vegetables, and proteins creates a balanced diet, effectively addressing malnutrition. Drying plays a crucial role in producing flours, such as IPYF and Amala yam flour. For IPYF, flash drying stands out due to its high operating temperature (up to 200°C) and quick drying time. However, concerns persist about the thermal efficiency and heat loss rate, making the operational environment less conducive. High energy consumption, coupled with low energy efficiency, underscores the need for insulation, reduced spent oil usage, and decreased heat in the operational environment. This study reviews and investigates the drying performance of a single cyclone flash dryer for the production of quality IPYF, aiming to recommend modifications for sustainable and profitable production, ensuring an affordable product for the populace.",Harvesting Hope: Innovations in Food Security and Ending Hunger (SDG 2),77,90
Heart Disease Prediction Using Machine Learning Models," The heart attack cases occurring each year motivate the healthcare field to create and develop classification support software or tools to help with heart disease diagnosis. Machine learning is a powerful tool that can be used in the battle against cardiovascular diseases. The prognosis of heart diseases can be enhanced by analytical prediction to identify the risk level of patients and the required medical care at an early stage. This research developed several machine learning models, logistic regression, classification tree, naïve Bayes, and random forest to classify and predict heart diseases based on the patient’s historical health-related data. Principal components analysis was also conducted to reduce the dimensionality of the independent variables and identify the most influential variables for the risk of heart disease. The analysis shows that the classification tree model provides the best results with 98.5% accuracy, 97.2% precision, and the highest area under the curve (AUC) level 98.5%, compared to other machine learning models. The most three essential features that have a significant impact on heart disease are the patient's age, emotional stress, and cholesterol levels as per the classification tree results. Additionally, the features have been ranked based on their effect on the heart disease. Logistic regression sigmoid function was identified to estimate the probability of heart disease occurring.",Machine learning in health systems,131,91
A Multi-Objective Evolutionary Machine Learning Method for the Strip Hardness Prediction in Continuous Annealing," In the steel industry, the hardness of the steel strip is the key performance index to evaluate the quality of the steel strip and guide the continuous annealing line. In this paper, a multi-objective evolutionary machine learning method is proposed for the strip hardness prediction in continuous annealing. Moreover, the factors affecting the hardness of steel strip are analyzed and the prediction model based on a hybrid kernel support vector regression (HKSVR) is established. In order to improve the prediction accuracy and generalization, a multi-objective evolutionary algorithm with a knee solution is used to optimize the key parameters of HKSVR model. It is verified by the actual production data that the proposed method has high prediction accuracy and can meet the actual production demand. Considering that many quality indicators in the steel industry cannot be detected online, this brings great difficulties to process monitoring, control and operation optimization. The proposed method can help practitioners to construct quality prediction models for many other similar production lines. It has good universality and can provide guarantee for quality control and optimization of industrial production process.",Statistical Learning and Artificial Intelligence for Quality Control II,212,92
A Two-Phase Approach for Supplier Selection and Order Allocation Considering Demand Forecasting," Supplier Selection and Order Allocation (SSOA) is an important problem in practice. Both qualitative and quantitative criteria should be considered in this problem. In this talk, a new two-phase approach for SSOA is discussed. In the first phase, four techniques, including ARIMA, RF, GBR, and LSTM are applied to forecast the demand parameter. Then, the results are compared, and the best method is selected. The output of this phase is used in the second phase in a new optimization model for SSOA. Both qualitative factors (using a fuzzy logic model) and quantitative factors (using a developed optimization model) are considered in this phase. The application of the two-phase approach is shown using a real dataset, and the results are discussed.",Inventory Management,117,93
Optimizing In-Store Picking Efficiency: An Integrated Approach for Retail Backroom Management," Omnichannel retailing necessitates a reevaluation of business operations, particularly in terms of in-store order fulfillment. A viable strategy to enhance in-store picking efficiency involves integrating a 'fast forward' area within the backroom. This study initially explores the operational differences between traditional warehousing and retail settings. Subsequently, we introduce a storage assignment optimization model tailored for selecting articles for this fast forward area. Following the validation of our results, the practical application of our model is demonstrated through a real-world data example, underscoring its efficacy in improving in-store picking processes in the evolving landscape of omnichannel retailing.""",Warehousing,238,94
Advancing Simulation Environments: An Approach for Automated Layout Generation," Current practices in transferring layouts to simulation environments predominantly rely on manual methods, often involving the direct adaptation of CAD layouts. This manual approach becomes particularly burdensome during design phases characterized by frequent layout changes, necessitating significant effort to maintain up-to-date representations. This study introduces a comprehensive framework designed to automate the layout generation process from CAD files. Our framework comprises a versatile data model coupled with a transformation module, employing a boundary representation approach for efficient layout conversion. We conclude by showcasing the efficacy of our tool through various proof-of-concept use cases, and discuss the overarching benefits of implementing our automated method in dynamic design environments",Facility Design,75,95
Review of the interaction of online and stochastic optimisation in a warehousing environment," In modern distribution centres, especially in B2C environments, a large number of decisions have to be made during operations. The objective is to organise the operation of existing resources efficiently and to fulfil customer expectations. The paper presents an exploration of optimization methods for enhancing warehouse operations, addressing the critical need for efficient resource allocation and process optimization in the ever-evolving logistics landscape. The research begins by defining use cases within warehouse operations, ranging from storage allocation to order fulfillment, where decision-making plays a pivotal role. Through a review of existing methodologies, the paper evaluates the efficacy of various optimization techniques such as mathematical programming, heuristic algorithms and online optimization approaches in addressing the unique challenges posed by warehouse environments. The paper not only assesses the performance of these optimization methods in the specific use cases but also explores their adaptability and scalability. Insights gained from this analysis contribute to a nuanced understanding of the strengths and limitations of each approach, guiding practitioners in the selection of the most suitable optimization method for their specific warehouse context. In conclusion, the paper provides an outlook on future research activities, identifying areas for further exploration and development. Emphasizing the dynamic nature of warehouse operations, the research aims to inspire future endeavors in applying optimization methods to meet the evolving demands of modern logistics.",Warehousing,238,96
Nested Learn-to-branch-and-price Framework for Large-scale Network Optimization Problems," In this study, we propose a nested learn-to-branch-and-price framework to accelerate the classic branch-and-price for large-scale network optimization problems. First, we developed a physical-information decision variable decomposition to select a promising subset at the root node. In addition, to accelerate the column selection procedure, we collect the feature vectors and labels of contributing columns in an online fashion to train a Graph Neural Networks (GNN) clustering method. We use the trained GNN to select the promising columns during each column generation iteration. As the next learning-based approach to accelerate the whole process, we use a linear regression model to predict the lower bound (for the maximization problem) on the objective function of the pricing problem. The predicted bound is then used to prune the search space of the pricing problem, resulting in a lower computational budget for this component. We used a set of randomly generated instances and a city-scale case study of the Oklahoma City transportation network for a customized network design model to show the superiority of the proposed framework in terms of computational time. We achieved an average improvement in the computational time by 19% for random networks with up to 500 nodes and 15% for instances from a city-scale transportation network with up to 4000 nodes, respectively. We also obtained around 5% improvement in the solution quality (total met demand over the planning horizon) for networks up to 4000 nodes where the emergency nature of the problem forces an execution time limit.",Methods in Network Optimization,144,97
Collation Tube Utilization Prediction in Central Fill Pharmacy through Discrete Markov Chains," Recently, the pharmaceutical industry has acknowledged the crucial role of reliable automated robots in improving operational efficiency. The Central Fill Pharmacy (CFP) has embraced these advanced technologies, becoming a notable trend to address workforce gaps, manage the increasing demand for prescriptions, and enhance overall efficiency. Among the various types of automated robots used in the CFP, collation stations play a pivotal role in assembling orders received from auto-dispensing robots. Given the highly customized nature of each order, collation in different tubes before packing is necessary. A fully occupied collation tube can lead to a system block, underscoring the importance of accurately predicting the number of orders stored in these stations. Monitoring collation tube utilization is critical for maintaining operational efficiency. To achieve this objective, the present study employs a practical Discrete Markov Chain (DMC) approach to predict collation tube utilization in the CFP. The primary focus is on estimating the probability of changes in the number of tubes utilized and forecasting utilization in subsequent states. Through a thorough analysis of historical data, a transition probability matrix is derived, serving as a fundamental component of the prediction model. The accuracy of these predictions is assessed by comparing them with simulation outcomes, providing valuable insights and validating the model's performance. The research findings significantly contribute to an improved understanding of collation tube utilization patterns, offering valuable insights for determining the tube release rule for collation stations in the CFP.",Healthcare Applications,82,98
Online Lead Time Quotation under Contingency," The success of make-to-order (MTO) firms relies on offering competitive bids for sparse demand and ensuring each quotation aligns with the ability to deliver customised orders as promised. In each planning horizon, demand is contingent on pending decisions of previous customers, which are dependent on the quoted prices and lead times. Due to uncertainty about pending decisions, MTO firms often hedge against losing bids by bidding on multiple profitable orders, overbooking shared resources in expectation. Upon evaluating an order's profitability, a firm must quote an attractive lead time, balancing between aggressive quotations the customer is more likely to accept and conservative quotations the firm has more flexibility to deliver on time. Given this dilemma, we develop solution algorithms that aim to maximise the total expected profit from all arriving orders in a single machine environment. Profit is defined as the net revenue penalised by the tardiness cost. We evaluate the performance of various algorithms against conventional rules used in practice to make online quotation decisions under uncertainty, ensuring improved capacity utilisation, reduced tardy orders, and enhanced profits.",Supply Chain & Scheduling,214,99
A Model for Fortifying Distribution Network Nodes Subject to Disruptions," We consider a distribution network that delivers a natural resource or physical good to a set of nodes, each of which serves a set of customers, where flow disruptions may occur at one or more nodes. This talk will focus on networks containing a tree structure in which each node has at most one immediate predecessor. In such a network, each node receives flow through a path from a source node, implying that a node experiences a disruption if a disruption occurs at one or more nodes on the path from the source node. All nodes in the network are subject to a future disturbance of an uncertain degree of severity, and we assume that the degree of severity follows some well-defined probability distribution. For each node in the network, we determine a fortification level that enables the node to withstand a disturbance up to some level of severity. The fortification cost is nondecreasing in the maximum-severity fortification level chosen, and we maximize the expected number of customers who do not experience a disruption following the occurrence of a disturbance, given a limited fortification budget. We formulate this problem as a mathematical program, characterize useful properties of optimal solutions for networks containing a tree structure, and provide methods for determining optimal fortification levels under various assumptions on the probability distribution of the disturbance severity.",Network Optimization,149,100
"Chisels, Drills and Cyberspace: A Novel Workflow for Surgical Management of Craniosynostosis Surgery"," Craniosynostosis is a congenital disability that is caused when one or more sutures of an infant's skull fuses prematurely. Craniosynostosis correction relies on manual tools with high variability based on case complexity and surgeon experience. This study introduces a novel technique leveraging 200 years of advancements in woodworking and engineering technologies to improve the efficiency and accuracy of the procedure. A systematic review using PRISMA methodology identified 12 studies showing quantifiable improvements for craniosynostosis correction. Extracting technologies from studies, the novel workflow was as follows: 1) 3D Reconstruction of Bony CT anatomy; 2) Surgical planning in virtual reality; 3) Precise pattern micro-osteotomy (kerfing pattern) planning in CAD/CAM; 4) Design and 3D printed patient specific guides; 5) Execution of the osteotomy pattern with a computer-controlled (CNC) milling machine. The technique was tested on 5 porcine calvarial specimens. Surgical planning, CAD/CAM conversion, and osteotomies execution proceeded smoothly without complication in any specimen. The mean machining time was 11.25min (±2.98min). The CNC cutting tool was capable of creating micro-osteotomies with a kerf of 1/32” (0.8mm) and 0.8mm proximity to adjacent osteotomies, enabling micropatterns otherwise impossible by hand. This preserved adjacent bone microstructure (confirmed by hematoxylin-eosin stain) and avoided thermal necrosis (temperature using optimized parameters: 26.10°C). Maximum CNC osteotomy deviation was 0.010”. The study combines woodworking and well-established modern technologies for a digital workflow that offers speed, accuracy, and reduced bone injury. Applicable to surgeries involving nonvascularized bone grafts, this approach enables precise and intricate osteotomies, enhancing flexibility of bone segment.",Bioprinting and Biomedical Manufacturing Processes-I,19,101
Analytic Network Process for Multicriteria Decision-Making in Sustainable Composites Supply Chain Management," In recent years, bio-based materials have attracted attention as a compelling choice for the development of environmentally friendly products. Natural fibres biomass, as one of the raw material sources, requires processing decisions that relate to collection and particle size reduction. These decisions play a vital role in the viability and profitability of pertinent Supply Chains (SC) for biomass conversion into a value-added product. Moreover, a holistic decision should include the environmental and social impacts of the SC. In this study, a multi-criteria decision-making model is developed to support the sustainable development of a hemp-based biocomposite SC by introducing a multi-criteria modelling framework integrating economic, environmental, and social practices. For economic and environmental impacts, outputs of the techno-economic and Life Cycle Assessment (LCA) models are used to quantify the required decision factors. On the social dimension, a set of decision criteria, combining qualitative and quantitative data is required. This includes data on the number of job opportunities involved, along with opinions from group-based decision-makers for qualitative criteria such as employee productivity and safety. As experts assisted in acquiring qualitative data, a fuzzy decision process is employed to improve attribute values due to their subjectivity. The results identified the most appropriate biomass processing equipment set, which would assist the SC managers in utilizing the available natural resources in the most sustainable manner in this case study. Moreover, to investigate the robustness of the model, a sensitivity analysis of the decision-makers preferences over sustainable indicators is conducted.",Renewable Sustainable Supply Chains (SDG 12),189,102
Integrated Regenerator Planning and RWA in WDM Optical Networks under Link Failures," The widespread deployment of wireless telecommunication networks and growing Internet traffic globally leads to a substantial increase in signal traffic demands in fiber optic networks. This demand surge places significant pressure on the survivability of optical networks, specifically when faced with fiber cable failures that prevent failed optical fibers from satisfying connection requests. To address this challenge, in this paper, we consider integrated planning of regenerator installation, optical connection routing, and wavelength assignment (RWA) for wavelength division multiplexing (WDM) optical networks under link failures. To the best of our knowledge, we are the first to consider such an integrated problem. We minimize the number of backup regenerators required to fulfill all connection requests under all potential link failures while accounting for the wavelength and routing constraints. We formulate the problem as an integer program, while its size exponentially increases with the network size by nature. To solve large-scale instances for practical uses in the industry, we propose efficient algorithms to generate near-optimal solutions that are practically implementable. We perform extensive numerical experiments to demonstrate the effectiveness of our approach in solving real-world instances provided by our industry partners. The results show that our approach can efficiently obtain high-quality solutions while ensuring a minimal increase in backup regenerators as the network grows. Our solutions also offer valuable insights into planning a cost-effective and reliable fiber optic network for network operators.",Methods in Network Optimization,144,103
Research on Carbon Emission Reduction Pathways for Motor Vehicles in New York State from a Carbon Neutrality Perspective," In recent years, along with the sustained development of New York State's economy and society, the environmental protection issues have become increasingly prominent. Thanks to a series of stringent policies introduced by the government of the state of New York, greenhouse gas emissions (GHG) in the transportation and industrial sectors across the entire state have been controlled effectively within a certain range. A trend of continuous carbon emission is harmful for both the ecosystem and human health. Among the various sources of carbon emissions, the transportation carbon emissions require greater attention due to the extensive nature of logistics activities, including warehousing, transportation and distribution. These activities consume a significant amount of energy and are accompanied by substantial carbon emissions. In order to construct the green cities and sustainable supply chain, carbon neutrality has become more essential than ever before as it can drive economic development across industries and every aspect of our lives through reducing carbon emissions. Based on the in-depth analysis of the transportation carbon emissions within NYS, this paper utilizes big data analysis and data mining techniques to identify the environmental hotspots and evaluate supply chain performance. Several models: PCA, LMDI, ARIMA are combined together to assess the environmental impact of supply chain activities within the state of New York, including carbon footprint and transportation energy consumption, which can provide useful information for the public and policymakers. By using LEAP model, a series of scenarios are conducted to explore the potential strategies for energy-saving and carbon emissions reduction.","Advancing Climate Action in Business, Technology and Transportation (SDG 13)",13,104
Patient Experience Feedback Sentiment Analysis Using Deep Neural Networks and Genetic Algorithms," Patient experience is a fundamental component in evaluating the provided care’s quality. This experience is nearly solely impacted by the interactions the patient has with the environment and medical staff members encountered during their hospital stay. Surveys addressed to patients contain a free-text section that allows them to share these experiences in a self-reported format. This results in a significantly large textual data collection. In this research, patient experience feedback collected from their responses to surveys received from the hospital under consideration following their stay from 2018 to the third quarter of 2023 is investigated. The survey considered is the Hospital Consumer Assessment of Healthcare Providers and Systems (HCAHPS) survey. This paper focuses on conducting the sentiment analysis of these reviews. As a result, the overall sentiment of the hospital stay from the patient’s angle is extracted. This allows the hospital to measure their satisfaction level and take a step towards more patient-centered care. Besides, negative comments enable the identification of improvement areas. Prior to text classification, a first analysis contrasting various vectorization techniques is conducted. The selection of methods includes TF-IDF, Word2Vec, and GloVe. Their comparison is conducted using Linear SVM evaluation based on F1-score. Following, multiple Deep Neural Networks architectures are fitted for polarity classification. The sentiments considered are: Positive, Neutral, and Negative. The hyperparameters of the best performing architecture are afterwards tuned using Genetic Algorithm. Thereby, sentiments are assigned to patient experience feedback and an understanding of the patient's journey from their point of view is concluded.",Healthcare I,83,105
Energy Security in Remote Communities: A Resilient Bio-Hub Coordinated Biomass Supply Chain Network Design," Establishing a meticulously devised biomass supply chain (BSC) is of great importance to ensure continuous access to bioenergy at a reasonable price, particularly in small off-grid remote communities. Variations in location, types of feedstocks, and dispersion of demand points can undermine the economy of scale and continuity of biomass supply. This situation is compounded by the seasonality of biomass and price fluctuations, which can reduce the viability of the BSC. As such, evaluating the resilience of the BSC network in the presence of uncertainties and disruptions is crucial. This research aims to design a resilient bio-hub coordinated BSC that operates efficiently in the face of disruptions. Here, bio-hubs serve as a node for intermodal transportation as well as centralized biomass to deal with supply and demand fluctuations. The purpose of the research is twofold. First, a multi-agent simulation model is developed to evaluate the resilience degree of the proposed BSC networks, given the predetermined locations and capacity of bio-hubs under supply disruption scenarios. Then, based on the networks’ behaviour, some preparedness/recovery strategies (e.g., prepositioning extra-inventory and backup suppliers) are implemented to restore the state. The performance indicators of the redesigned networks are quantitatively assessed under disruption propagation by calculating some metrics related to absorptive, adaptive, and restorative capacities of resilience. These metrics collectively contribute to a comprehensive understanding of the networks’ overall resilience. A real BSC case study of remote off-grid Nunavik communities in Quebec is considered to illustrate the applicability of the proposed approach.",Network design and analysis,150,106
A Proposed Model for Laptop Third-Party Reverse Logistics Provider Selection," Recognizing the importance of Reverse Logistics (RL), companies have increasingly explored outsourcing their RL activities to Third-Party Reverse Logistics Providers (3PRLPs) for cost saving and enhanced efficiency. These providers specialize in managing processes like recycling, refurbishing, and disassembling, allowing them to mitigate waste and optimize the value of returned items. The selection of a suitable 3PRLP aligned with business goals is critical, given variations in service levels. Therefore, evaluating 3PRLPs plays a pivotal role in establishing and maintaining successful partnerships. This study focuses on the Canadian laptop industry, where used devices are collected, disassembled, and processed by 3PRLPs. In this study, criteria for evaluating 3PRLPs are categorized into three groups: beneficial, non-beneficial, and target-based criteria. The Best Worst Method (BWM) is employed to weigh criteria, and a normalized decision matrix is generated using the target-based method. Then, a modified WASPAS method (target-based WASPAS) is used to evaluate and select the best 3PRLP. The study's findings, obtained through analyses, are discussed in the conclusions section.",Supply chain Risk & resilience 2,220,107
Exploring the Dynamics of Cancer Patient Experience: A Bayesian Belief Network Analysis of NHS Data," The trajectory of cancer patients is marked by a multifaceted journey, encompassing diagnosis, medical consultations, in-hospital and home-based treatments, culminating in the post-treatment phase. Ensuring a positive experience throughout this difficult journey is imperative for delivering high-quality care to cancer patients. Despite numerous studies recognizing diverse factors influencing Cancer Patient Experience (CPE), a paucity of research has systematically explored the interplay and relative significance of these factors. This paper addresses this research gap by employing Bayesian Belief Network (BBN) modeling, leveraging data sourced from the National Health Services (NHS) CPE survey in England. Four distinct structural learning algorithms were rigorously assessed for developing data-driven networks. Sensitivity and scenario-based analyses were subsequently conducted to elucidate the intricacies of interactions within the network. In addition to modeling CPE factors, this study introduces a novel dimension by investigating the impact of varying values of K in K-fold validation on the accuracy of the resulting Bayesian Network. The insights derived herein serve as valuable guidance for healthcare managers and decision-makers in formulating and implementing effective policies, optimizing resource allocation, and ultimately elevating the overall well-being of cancer patients.",Cancer Care,24,108
The Use of Text Mining to Identify Trends and Relationships between Social Determinants of Health and Congestive Heart Failure," In recent years, there has been a mounting recognition of the influence that Social Determinants of Health (SDOH) exert on health outcomes, especially for chronic illnesses. Chronic illnesses such as congestive heart failure (CHF) are the leading cause of hospitalization for older adults in the United States. Understanding the web of associations between SDOH and CHF might direct intervention development that can reduce the morbidity, mortality, and cost associated with CHF. This objective of this paper is to describe the development of methods using the hierarchical clustering method and Latent Dirichlet allocation topic modeling procedure on the statistical software R to find developing trends, patterns, topics, and previously unknown correlations between SDOH and CHF. These text mining and natural language processing techniques will be used to extract, analyze, and synthesize textual data from a variety of recent sources, such as medical literature (journals and conference proceedings), and public health institute reports to expose that the onset, progression, and successful management of CHF are influenced by factors other than traditional clinical risk factors. The major strength of the proposed method is that it employs an unsupervised machine learning technique to identify all themes and latent relationships from thousands of medical publications on SDOH and CHF, which would otherwise be time-consuming and labor-intensive, or even humanly impossible to uncover using traditional literature review.",Recent Advances in Health Systems I,184,109
Dynamic Modeling for the Parking Allocation Problem: A Framework for Real-Time Optimization," Parking problems have become one of the most pressing issues in urban transportation planning and management. In many cities throughout the world, they are a well-known cause of traffic congestion and significant economic and environmental losses. In this research, we study a parking allocation problem aiming to reduce total travel time. We propose an exact network flow based model and a greedy heuristic that prioritizes vehicles based on their arrival times. Additionally, we propose a dynamic framework that responds to real-time parking demand and supply fluctuations, factoring in vehicles' stay duration and upcoming parking requests. The validity and adaptability of our method are demonstrated using numerical experiments with parking data from different cities, showing potential for enhanced urban parking management.",Optimization Application,155,110
A Novel Bio-inspired optimization algorithm inspired by Arctic Terns for Engineering Informatics and Systems," This study introduces an innovative bio-inspired optimization algorithm named the Arctic Tern Optimizer (ATO), which draws inspiration from the migration and foraging behaviors of Arctic terns in nature. The ATO algorithm simulates the exploration (migration) and exploitation (foraging) behaviors observed in real-life Arctic terns. This simulation is built upon two key migration rules observed in Arctic terns: their movement patterns and stopover behaviors (including walking and flying in spirals). To assess the performance of the ATO algorithm, conducted evaluations on a set of fifty widely recognized benchmark test functions. These functions encompass both unimodal separable and non-separable problems, as well as multi-modal separable and non-separable large-scale functions. The results of the study indicate that the ATO algorithm outperforms all other meta-heuristic algorithms considered. Specifically, the ATO algorithm excels on 45 out of the 50 benchmark functions, successfully reaching the global minima in 39 of them. In comparison, other algorithms such as the FBI, SOS, TLBO, and WOA attain the global minima in 37, 35, 34, and 30 out of the 50 benchmark functions, respectively. These findings highlight the remarkable performance of ATO in addressing both small-scale and large-scale real-world engineering problems. Additionally, we applied the ATO algorithm to predict the peak shear strength (friction angle) of fiber-reinforced soil. The results were notably superior, with Mean Absolute Percentage Error (MAPE) and R values of 98.84% and 2.82, respectively. These outcomes underscore the effectiveness of the ATO algorithm in global optimization and its applicability to engineering scenarios specially in geotechnical engineering systems.",Poster Presentations,169,111
A New Facility Location Model to Design a Closed-loop Apparel Supply Chain Network Under Uncertainty," Utilizing a Closed-Loop Supply Chain (CLSC) network to manage the apparel wastes is of utmost importance for the health of our planet, our environment, and our species. In this study, a Mixed Integer Linear Programming (MILP) model is developed to design a new apparel CLSC with the aim of minimizing the total cost. The uncertainty of demand and different types of returns are considered in the model for the first time. In addition, a new hybrid robust possibilistic flexible programming method is applied to tackle the uncertainty of parameters and flexibility of soft constraints. Hexagonal fuzzy membership functions are utilized to represent the uncertain parameters for the first time. The model is applied to a Canadian company. The results show that considering the hexagonal fuzzy numbers, to present the uncertain parameters, leads to obtaining more reliable solutions in comparison to the triangular fuzzy numbers.",Network design and analysis,150,112
An Economic Evaluation for the Renovation of Fire Brigade in Low and Middle-Income Countries: Case of Lebanon," This paper focuses on the economic efficiency of investing in firefighting and rescue services in low and middle-income countries. A case study is developed by analyzing the intervention of two United Nations agencies, and funded by the European Union, in the renovation and enhancement of the Fire Brigade in the Urban Community Al-Fayhaa (UCF) in North Lebanon. The number of residents within the geographical area of UCF has increased by 25% after the Syrian crisis. This drastic increase, coupled with (i) protests and riots, (ii) devaluation of the currency, and (iii) lockdown due to COVID pandemic, negatively affected the efficiency and the level of services provided by the Fire Brigade to serve all residents including Lebanese citizens, displaced Syrian, and Palestinian refugees. The intervention aims to enhance the function of the Fire Brigade in performing firefighting services by building capabilities, enhancing equipment, renovating the facility to respond and accomplish the assigned tasks. The hypothesis tested is that the intervention will enhance the efficiency of the internal operations, which will increase the responsiveness and decrease the intensity of fires. A Benefit-Cost Analysis was conducted to project the reduction in response time, and all benefits related to minimizing fatality rates, injuries, and property losses. The study spanned over a ten-year period and considered the time value of money. The findings aim to advise policymakers, and aid organizations involved in similar interventions on the role of the economic feasibility in integrating social inclusion in promoting public safety and community well-being.",Decision Analysis and Economic Evaluation,38,113
Pioneering Glass Recycling: A Feasibility Study on Reverse Logistics in the Dominican Republic," In the face of mounting environmental concerns, this study presents a pioneering feasibility analysis for launching a glass recycling enterprise in the Dominican Republic, leveraging the principles of reverse logistics. This initiative stands at the intersection of environmental stewardship and economic opportunity, aiming to transform glass waste management through innovation and sustainable practices. The investigation begins by highlighting the critical issue of glass waste proliferation and the pressing need for a robust recycling infrastructure. A thorough market analysis reveals a significant untapped demand, positioning the proposed venture as a catalyst for change in the recycling landscape. The technical exploration delves into the operational blueprint, spotlighting the judicious selection of technology and the strategic refinement of the supply chain to maximize efficiency and impact. An in-depth environmental impact study not only quantifies the ecological advantages but also crafts a suite of proactive measures to mitigate potential operational risks. From an organizational and legal standpoint, the study delineates a clear framework for the enterprise's structure, ensuring full regulatory adherence and strategic agility. The financial prognosis underscores the project's economic soundness, projecting a favorable balance of costs, revenues, and profits that promise enduring viability. This venture is more than a business proposition; it is a step towards a greener future, resonating with the global momentum towards a circular economy and fulfilling the Sustainable Development Goals.",Closing the Loop: Advancements in Circular Economy and Responsible Production (SDG 12),26,114
Unveiling Service Excellence in the Electrical Sector: A SERVQUAL Odyssey in the Dominican Republic," In the dynamic and customer-centric electrical sector of the Dominican-Republic, service quality emerges as a pivotal element for competitive advantage. This research explores the service quality at Edenorte by leveraging the SERVQUAL-instrument, renowned for its efficacy in juxtaposing customer service expectations with actual experiences. The study's cornerstone is a robust statistical analysis that identifies and quantifies the service quality gaps, thereby charting a course for strategic enhancements. Adopting a comprehensive quantitative approach, the research canvassed a statistically significant cohort of clientele. The survey's reliability was ascertained through the Cronbach's coefficient, ensuring the integrity and applicability of the findings. The empirical data revealed critical discrepancies, particularly in the tangible aspects of service delivery and the empathetic interaction between service providers and customers. These dimensions were found to be instrumental in shaping customer satisfaction and loyalty. The study's outcomes extend beyond mere identification of service shortfalls. They encapsulate a series of targeted recommendations for Edenorte, aimed at refining customer service protocols, training, and infrastructure. Moreover, the research contributes to the academic discourse by validating the SERVQUAL model in the electrical sector context, offering insights that resonate with the global narrative on service quality. The implications are manifold. For practitioners, it provides a diagnostic tool to fine-tune service delivery. For strategists, it offers a data-driven foundation for customer service enhancement. For the academic community, particularly within the industrial and systems engineering sphere, it presents empirical evidence that underscores the criticality of service quality in sustaining business success and customer satisfaction in utility industries.",Process & Operational Improvement I,177,115
A Multi-layer Network Analysis Approach to Disinformation Diffusion and its Impacts on Physical Infrastructure Performance," This study delves into the dynamics of multi-layer networks representing an information layer and an underlying physical infrastructure layer. We focus on processes of diffusion (i.e., the spread of information or influence) in the information layer, and we focus on the performance of the flows in the physical infrastructure layer. We investigate how diffusion within one layer impacts performance in other interconnected layers under diverse conditions. Notably, we explore the effects of increasing the number of inter-layer edges, variations in diffusion parameters, and higher network density on physical infrastructure behavior. We integrate diffusion and network optimization models to study different characteristics, including potential points of failure and importance measures for critical components in both layers, and we develop strategies to improve robustness across both layers.",Advanced Topics of QCRE I,7,116
Leveraging Industry Advisory Boards for “Beyond the Text Book” Education," Preparing students with “real world” skills is a core focus of our Universities. Industry Advisory Boards can support this by partnering with Faculty to balance fundamental learning with evolving industry needs and expose students to multiple industries. This abstract provides a best practice on how the Cal Poly SLO Industrial and Manufacturing Engineering Department (IME) Faculty/IAB partnership accepted this challenge by leveraging Cal Poly’s “Learn by Doing” tradition to deliver a course entirely taught by IAB Members. The course is structured along the “Value Chain” with IAB members delivering weekly content and activities, including a real industry challenge. Based on current trends, extra emphasis is placed on industry examples including Lean, Financial Analysis and Data Analytics. In teams, students work with specific industry partners throughout the term to relate the Weekly Value Chain components to a chosen product. This course bridges academia to industry by preparing students in multiple ways. Students are provided a broad view of IE roles in the Value Chain and gain experience with real products throughout the Value Chain. They are also exposed to emerging industry trends and participate in active mentorship. Industry partners have also benefited by becoming energized about their ability to make an impact in the education of engineering students.",Preparing Students for Industry:  A panel discussion on the Win/Win benefits of Co-Op programs and a Case Study of Industry led “beyond the textbook” learning opportunites,172,117
Advancing Sustainability in Tobacco Manufacturing: A Strategic Proposal for Tobacco Strand Waste at La Aurora S.A.," In the face of growing environmental concerns and the need for sustainable manufacturing practices, this study presents a strategic initiative to enhance the utilization of tobacco strand waste at La Aurora S.A., one of the leading tobacco companies. By integrating a multidisciplinary approach that synthesizes market, technical, and environmental analyses with organizational and legal considerations, the project sets forth a blueprint for sustainable waste management. Commencing with an in-depth problem analysis, the research identifies market opportunities and outlines a suite of marketing strategies to support the proposed sustainability efforts. The technical study assesses the operational feasibility and environmental implications of the initiative, advocating for process improvements that promise to elevate both eco-efficiency and cost-effectiveness. The organizational and legal framework developed herein ensures that the proposed changes are not only implementable but also compliant with current regulations, paving the way for a smooth transition to greener practices. The economic analysis underscores the project's viability, projecting a favorable return on investment and positioning the initiative as a financially sound venture. This proposal exemplifies the pivotal role of industrial and systems engineering in fostering eco-innovation within traditional industries. It offers a pragmatic yet forward-thinking approach to waste reduction and resource recovery, contributing to the global dialogue on sustainable industrial practices and corporate environmental stewardship.",Towards Responsible Production: Innovations in Sustainability and Ethical Practices (SDG 12),231,118
Assessing the Impact of Green Practices on Life Cycle Emissions and Energy Costs in Pulp & Paper Industry," The pulp and paper sector, characterized by its substantial energy demands, stands as a major contributor to global greenhouse gas (GHG) emissions and environmental pollutants. In pursuit of the Net Zero 2050 goal, considerable research has focused on assessing carbon footprints and fostering sustainable practices, particularly in recycling and energy efficiency. Nevertheless, a gap persists in the comprehensive estimation of emissions, with most life cycle assessments (LCA) confined to gate-to-gate or cradle-to-gate scopes. Concurrently, debates surface over the actual benefits rendered by recycling and on-site energy generation. By integrating databases on upstream activities and estimating downstream data, with a detailed analysis of material and energy composition, this study establishes new benchmarks for cradle-to-grave emissions and cradle-to-gate energy costs in the U.S. pulp and paper industry, which were1.81 ST CO2 eq./FST and 276.02 USD/FST respectively. The impacts of predominant green technologies and practices were evaluated though their change to emissions and energy cost, offering comprehensive assessment in different stages of life cycle. The scenario with recommended technologies was derived on further decarbonizing pulp and paper industry.",Towards Responsible Production: Innovations in Sustainability and Ethical Practices (SDG 12),231,119
Patient-centered Care from Patient’s Experience and Perspective," Understanding the patient's healthcare experience holds significant importance. This understanding not only enhances communication between providers and patients, promoting patient-centered care, but also contributes to fostering a culture of patient safety while reducing the risk of medical malpractice. The focus of this study is to explore how data from the Agency for Healthcare Research and Quality (AHRQ) and the Consumer Assessment of Healthcare Providers and Systems (CAHPS) surveys can play a role in improving patient safety and the well-being of healthcare professionals. Additionally, the study involves a comparison between these survey results and patient reviews and narratives found online, giving a more comprehensive view of healthcare experiences. Furthermore, the study aims to identify and address aspects of patient feedback that are not covered by CAHPS, including hospital accidents, hospital visit policies, malpractice incidents, COVID-related procedures, facility operations, and cases where patients were discharged without proper treatment. This comprehensive investigation seeks to ensure that patients are actively involved in their care and decision-making processes at both individual and systemic levels. Timely sharing of care plans is emphasized to enable patients and their families to make well-informed decisions regarding their healthcare.",Patient Care and Treatment I,160,120
Economic and Operational Feasibility of an Interactive Cultural Museum in Puerto Plata: A Systemic Approach to Innovation in Cultural Engagement," This study pioneers the conceptualization of an interactive cultural museum in Puerto Plata, leveraging a systemic approach that marries cutting-edge market analysis with a comprehensive economic and financial evaluation. The research utilizes industrial and systems engineering methodologies to craft a multifaceted proposal that promises both financial sustainability and cultural enrichment. Employing a robust market analysis, the study identifies untapped consumer segments and crafts strategic entry tactics, informed by a deep understanding of cultural trends and competitive landscapes. The technical study meticulously outlines the operational blueprint, focusing on interactive technology integration and visitor experience enhancement, to ensure the museum's operational feasibility and service excellence. The project's environmental strategy is rooted in sustainable design principles, evaluating the ecological footprint and promoting green initiatives throughout the museum's lifecycle. The organizational and legal framework is meticulously developed to ensure robust governance and adherence to regulatory standards. Central to the study is a granular financial model, featuring detailed cash flow forecasts, sensitivity analyses, and risk assessments. The financial projections affirm a robust return on investment and a viable break-even analysis, underscoring the museum's potential as a profitable cultural venture.",Economics and Strategy,59,121
Handling disruptions in a logistics network with cross-docking," Cross-docks are transshipment facilities between shippers and customers used for consolidation of freight by destination. In this research, it is assumed that each inbound truck collects freight from multiple suppliers and delivers it to the cross-dock. There, the freight is redirected to outbound trucks where each has deliver to multiple customers. This research focuses on two important practical operating issues that, to the best of our knowledge, have not been addressed in the literature. The first is producing a feasible schedule for the material handling devices (e.g., forklifts) within the cross-dock to support inbound and outbound truck schedules. The second is to accommodate disruption of inbound trucks in such a way that outbound delivery deadlines are impacted as little as possible and that the forklifts can support the new arrival and departure schedules. Models and heuristics for both problems will be discussed and results will be presented as well. This work has a direct connection to daily operations so these types of insights will be highlighted. For example, the cross-dock models allow for either fixed door or mixed door operation so the two strategies can be compared. Or the impact of having additional trucks to help mitigate the impact of a disruption can be explored and quantified.",Network design and analysis,150,122
Lean Six Sigma-Driven Enhancement of Fabric Production at Dominican Knits: A Case Study in Reducing Rejection Rates," In the competitive landscape of textile manufacturing, Dominican Knits confronts the challenge of excessive fabric lot rejections. This study delineates a Lean Six Sigma-informed intervention, utilizing the DMAIC framework to systematically diminish defects and augment production efficacy. The research encapsulates a fusion of Lean Manufacturing tenets and Six Sigma precision, fortified by FMEA and Statistical Process Control to dissect and rectify process inefficiencies. A meticulous research design underpins the investigation, employing empirical data collection and robust statistical tools to excavate the root causes of quality lapses. The diagnostic phase uncovers pivotal shortcomings within the dyeing and finishing processes, catalyzing the development of a comprehensive improvement strategy. Subsequent hypothesis testing and statistical scrutiny validate the efficacy of the proposed enhancements. The culmination of this study is a strategic control plan, crafted to perpetuate the gains achieved and to institutionalize a culture of continuous quality advancement. The findings articulate a persuasive narrative for Lean Six Sigma's integration into textile operations, projecting not merely incremental gains in process performance but also substantial strides in organizational profitability.",Manufacturing Organizations I,139,123
Implementation of a Sustainable System for Plastic Waste Management in Santiago de los Caballeros: A Systemic Approach to the Conservation of the Yaque del Norte River Tributaries," This industrial engineering capstone project tackles the escalating issue of plastic waste in the streams and tributaries of the Yaque del Norte River, in the municipality of Santiago de los Caballeros, Dominican Republic. Through systematic analysis and rigorous methodological design, a sustainable system for the collection and management of plastic waste is proposed, aiming to mitigate environmental impact and promote conservation practices. The study is structured into five chapters, beginning with a detailed problem statement and followed by a theoretical framework that grounds the research in previous studies and key concepts. The methodological framework defines the population and sample, as well as the data collection and analysis techniques used to assess the current situation and project improvements. The market study and technical analysis provide a comprehensive view of the proposed product and service, profiling the consumer, analyzing demand and supply, and determining unsatisfied potential demand. Furthermore, an environmental impact study assesses the types of pollution generated and waste management strategies. The project culminates with an implementation proposal that includes a detailed action plan and a control plan to ensure the long-term sustainability of waste management. This work represents a significant effort in applying industrial and systems engineering to solve complex environmental problems, offering a replicable model for other communities facing similar challenges.",Sustainability I,223,124
"Enhancing Service Quality in Telecommunications: A SERVQUAL Model Assessment at Telecable Global, Santiago de los Caballeros"," In the dynamic realm of telecommunications, service quality is the linchpin of customer loyalty and competitive advantage. This pioneering study at Telecable Global, Santiago de los Caballeros, harnesses the analytical prowess of the SERVQUAL model to dissect and elevate the customer service experience. The research transcends traditional quality assessments, employing a sophisticated stratified sampling matrix to juxtapose customer expectations with perceived service performance, across the model's five pivotal dimensions. With a laser focus on tangibles, reliability, responsiveness, assurance, and empathy, the study deploys cutting-edge statistical methodologies to unearth service delivery gaps. These insights are not mere data points but catalysts for transformative quality enhancement strategies, poised to redefine industry benchmarks. The market analysis is not just an examination but a strategic exploration of untapped potential, guiding Telecable Global towards not only meeting but anticipating customer needs. The technical study goes beyond operational assessment to envisage a future where every customer interaction is an exemplar of excellence. The culmination of this investigation is not a mere set of recommendations but a visionary blueprint for Telecable Global, promising to propel the company to the zenith of service quality.",Advanced Topics of QCRE Applications I,5,125
Roadmap to Resilience: Transforming Traffic Safety Norms into Lifesaving Strategies in the Dominican Republic," This groundbreaking study addresses the critical issue of traffic-related fatalities in the Dominican Republic by proposing a strategic approach to enhance road safety. Recognizing the high incidence of traffic accidents in the country, the study conducts a thorough examination of the Dominican traffic safety landscape. It compares this with global best practices, drawing insights from countries like Switzerland and Norway, known for their outstanding traffic safety records. The research is underpinned by a solid theoretical framework and employs a comprehensive methodology combining qualitative and quantitative analyses. This includes a detailed review of the World Health Organization's safety recommendations and a comparative analysis of international traffic norms. The findings are adapted to the specific socio-economic and cultural context of the Dominican Republic, ensuring the recommendations are relevant and applicable. Key recommendations of the study include a blend of educational, infrastructural, and legislative initiatives. These initiatives aim to change public attitudes through awareness campaigns, improve road conditions through infrastructural developments, and enforce safety through legislative reforms. Each proposal is supported by a technical feasibility study, ensuring the measures are not only innovative but also practical. Overall, this study provides a well-rounded and contextually adapted set of strategies to improve road safety in the Dominican Republic. It stands out for its methodological rigor and its tailored approach to integrating global safety standards within the local context, offering a hopeful perspective on reducing traffic-related fatalities in the country.",Work Systems I,240,126
"Enhancing supply chain resilience: evaluating trade-offs between process flexibility, capacity, and inventory in the face of disruptions"," Enhancing supply chain resilience has become a prevalent research topic following the widespread product shortages during the pandemic and other environmental shocks. How supply-side disruptions impact the supply chain, and how to redesign mitigation strategies considering supply disruptions are still open questions. We focus on a production network managing several plants and product lines, confronted with demand uncertainties and random plant disruptions of varying frequency and length. We seek to minimize costs using process flexibility, excess capacity, and inventory. Process flexibility lessens product mix mismatches, capacity tackles long-term and systematic demand variations, and inventory addresses short-term fluctuations. We built an optimization model to determine the optimal capacity allocation and inventory setting. Our numerical experiments show that a long chain configuration with 5% redundant capacity reduces cost from 33% to 59% compared with a balanced dedicated system when plants are susceptible to disruptions. Furthermore, strategic inventory will enhance the resilience of the long chain system and make it almost as good as a fully flexible configuration.",Resilience & Hazard Analysis,190,127
Sustainable Education Packaging Calculator Tools: Economic Fines for Residuals of Food wrapping," The implementation of an environmental fine calculator for a Major Transnational Food Industry in the countries of Spain, the United States and Chile would be an excellent educational tool for the company and the environment. This calculator would allow the Major Transnational Food Industry as an IEP to evaluate and quantify the environmental impact of its operations in each of these countries, facilitating compliance with environmental regulations and avoiding possible fines. This Major Transnational Food Industry, as a leading company in the food and beverage industry, has demonstrated its commitment to sustainability through its environmental plans and policies as well as its commitment for education as an industry educational partner (IEP). Implementing this calculator would further strengthen their sustainability plans by providing a specific tool that would allow them to assess and reduce their environmental footprint more accurately. By using the environmental fine calculator, the Industry Educational partner could identify problem areas in terms of regulatory compliance and environmental efficiency. This would allow them to take timely and effective corrective measures to minimize negative impacts on the environment. For example, if the calculator shows that a certain production plant in Spain is emitting an excessive amount of greenhouse gases, Major Transnational Food Industry can implement cleaner, more efficient technologies at that plant to reduce emissions and avoid fines. In addition to avoiding sanctions, the environmental fine calculation tool would also benefit Major Transnational Food Industry by helping them improve their corporate image as a socially and environmentally responsible company.",Towards Responsible Production: Innovations in Sustainability and Ethical Practices (SDG 12),231,128
Comparing User Perception of Inclination in VR: Slope Gradient in Real vs. Virtual Environments," Perceiving slope gradient in a virtual environment differs greatly from perceiving it in the real world. However, experiencing realistic and similar slope gradients in virtual reality (VR) is crucial for the development of VR environments involving elevated and inclined worksurfaces; for example, in the field of construction. Literature shows that inclined surfaces with angles beyond 20 degrees pose an increased risk of slips and falls. However, most instrumented treadmills for research have an inclination limited to below 20 degrees. This research aims to investigate the variability in human perceptions of slope gradients for different inclined surfaces within VR without exact replications of the inclination in the real environment. The current study will test human perceptions of slope gradients for three trials with varied inclinations between the real and virtual worlds. Ten participants will be randomly exposed to different slopes within VR: no difference, 10-degree difference, and 20-degree difference between VR and real environments. The study will collect Electromyography (EMG) data of muscle activation, limb position, and heart rate variability data from each participant for three trials with three replications. The researchers hypothesize that higher variation in slopes between the virtual and real worlds will not create a significant difference in the perception of slope gradients in terms of participants’ postural balance, muscle energy expenditure, muscle contraction, and heart rate variability. The study's outcomes have implications for designing the VR environments for the analysis of fall hazards while exposing people to different heights and varied inclined surfaces with limited resources.",Poster Presentations,169,129
Offline Reinforcement Learning for Electric Vehicle Charging Control," Batch reinforcement learning (RL) tries to solve the problem of decision-making without interacting with the environment by making use of static data. Charging control of electric vehicles (EV) presents a scenario where exploration of actions in online-RL might be prohibitive or may possess risk in real-time operations. While the current line of research has suggested online-RL schemes that involve exploration, we propose a methodology that takes advantage of learned policy and value function trained on static dataset using Batch-RL. In order to generate this dataset, we train an online-RL agent on an EV charging simulator, representing the residential charging behavior. Dataset obtained using the simulator captures the transition dynamics and costs associated with charging behaviors in residential EV charging. A policy is learned from the dataset using Batch-RL algorithms. The proposed methodology involves using this learned policy in real-time without exploration of actions. Since the simulator might not always capture dynamics of a real-time system, the sequential decision problem of EV charging is broken down in two horizons. This facilitates the transformation of the N-horizon problem into an H-Horizon problem, such that H<N. We use stochastic programming to obtain the actions in the near future H and approximate the tail-subproblem with the values of actions from the learned policy. The choice of H is pivotal in ensuring real-time control and applicability of the model. Our contributions combine accuracy of sequential decision algorithms like stochastic programming with speed of Batch-RL methods enhancing adaptability and responsiveness of EV charging residential control.","Machine learning and AI, Part 2",130,130
Financial and Cost Accounting: Academic Exposition to Real Projects," During several years the main scope of the Financial and Cost Accounting project was the financial comparison among major industries as evidence of financial indicators understanding. After being in manufacturing industries for more than 27 years, the main purpose as an Industrial Engineers was to design new ways of improving process performance by developing capital ideas and be able to justify them through cost accounting analyses. From this moment, the approach in this course has included a real time project where teams of 2 students are responsible to analyze at least 30 accounting transactions, develop a budget with the owner, analyze the financial variances, select the worst offenders, develop two productivity alternatives, develop the financial justification analysis, and present their results to the company. Since the time is only three months, the selected companies need to be small with approximately 5 employees. The exposure has achieved a great deal of student confidence in realizing operational excellence projects that are going to be developed in the future courses of the program. Two examples will be shown.",Engineering Education Pedagogy and Assessment,67,131
Sustainable Engineering Education in Circular Economy: An alternative to a polarizing view such as “The Earth or us”," Sustainability is presented as the need to cover the necessities of the present generations without jeopardizing those of future generations. In response to this, Sustainability encompasses three fundamental dimensions, social, environmental, and economical. The balance between the three dimensions is what we call Sustainable Development. Moreover, some authors consider the political dimension as the fourth dimension of Sustainability since the decision making that influences the previous three depends on this dimension. Consequently, monetary and biophysical Sustainability indicators have been proposed as useful measurements in order to know how well we comply with the Sustainable Development utopian model.Furthermore, this essay is based on the principle that every activity must have its respective environmental evaluation in order to assess the different engineering areas and their respective environmental impact. In this context, it is brought to light that there are a plethora of engineering projects that appeal to Circular Economy, minimization of Programmed Obsolescence and generating better and more productive renewable energies. The relationship between Industrial Engineering and Civil Engineering with Circular Economy is shown through the minimization of Programmed Obsolescence of a product and the reuse of concrete as granular material to produce more concrete. Likewise, the connection between Chemical Engineering and the development of new sources of renewable energies through alcoholic fermentation is exposed. Correspondingly, the trilemma that affects the further development of Sustainability and the conflict of interests between the care of the environment, economic remuneration and social needs with their respective demand for resources is exposed and hence questioned.",Closing the Loop: Advancements in Circular Economy and Responsible Production (SDG 12),26,132
Flowing Towards Excellence: ISE in Water/Wastewater Utility Evaluation," This paper explores the transformative impact of adopting an Industrial and Systems Engineering (ISE) centric approach in the evaluation of water/wastewater utilities, using the case study of DC Water's mandated five-year independent engineer's assessments. The 2018 report and its predecessors were traditionally led by civil engineers, while the 2023 evaluation witnessed a paradigm shift, entrusting the lead to a Professional Industrial Engineer and a lead investigator with an M.S. in Business Administration focusing on Operations Research. Highlighting the divergence in methodologies, the study underscores the heightened value derived from an ISE-centric perspective. Key differences include the implementation of tailored questionnaires and both quantitative and qualitative self-assessments, enhancing the depth and breadth of data collected. The adoption of prespecified criteria ensuring a more rigorous and objective reporting process during site visits. Furthermore, benchmarking practices were integrated to evaluate and effectively communicate the quality of utility management. A notable innovation in the 2023 evaluation was the incorporation of historical and forecasted capital expenditures, providing a comprehensive context for understanding findings. The paper emphasizes the significance of including a detailed management and operations evaluation, offering valuable insights for utility management. This shift towards an ISE-centric framework showcases a holistic approach that transcends traditional engineering boundaries, presenting a dynamic model for future utility evaluations, optimizing system operation and maintenance, and facilitating informed decision-making for infrastructure enhancements.",Sustainability I,223,133
Developing a Visual Feedback Mechanism for Monitoring System Equity in Maternal Health," Racial and ethnic disparities in adverse maternal outcomes persist in high-income countries. In the United States(US), pregnancy-related mortality is 2-3 times higher for Black women compared to White women. Current patient-safety approaches fail to assess how adverse outcomes may disproportionately impact racialized women. Hence, this research aims to develop an equity dashboard to help identify variations in maternal care processes and outcome measures. To develop the dashboard, Patient safety incident (PSI) reports and delivery data from 2019 and 2020 were collected from a US hospital. Patient demographic data were linked to process and outcome measures and disaggregated by race/ethnicity: non-Hispanic White(NHW), non-Hispanic Black(NHB), Hispanic, and Others. Selected measures were informed by existing research on maternal care disparities. The dashboard was iteratively developed in Tableau Desktop (2023.2). Statistical analysis was conducted to examine differences in the selected outcomes by race/ethnicity using R Studio (2023). The dashboard included visualizations on morbidity indicators, adverse events, and delivery processes. NHB patients experienced the highest usage of spinal anesthesia (20.4%), lowest usage of epidural anesthesia (53.3%), higher odds of cesarean delivery (OR = 1.30, 95% CI: 1.15, 1.47, p < 0.001), and highest length of hospital stay 1.8 days (SD = 4). The work highlights how an equity dashboard can be developed to help identify variations in maternal care processes and outcomes that require further investigation. With additional testing, the utility of the dashboard in enabling clinical stakeholders to make informed decisions about quality improvement initiatives and interventions to support equitable care can be established.",Health Systems for Human Factors and Ergonomics 1,79,134
Supervised multi-modal fission learning," Multi-modal datasets widely exist in various science and engineering domains. Learning from multi-modal datasets can leverages complementary information and lead to improved performance for prediction tasks. Early works concatenated features from different modalities and then applied off-the-shelf single modality methods, which failed to analyze feature correlations within and across modalities. To account for feature correlations in high-dimensional datasets, a commonly used strategy is the latent variable approach. In the past decade, several latent variable methods have been proposed for multi-modal datasets. These methods either focus on extracting the shared component across all modalities or extracting a shared component and individual components specific to each modality. There is limited work that consider correlations among any subset of modalities. To address this gap, we propose a Multi-Modal Fission Learning (MMFL) model that (i) simultaneously identifies globally-shared, partially-shared, and individual components underlying the features of multi-modal datasets, (ii) uses supervision from the response variable to identify predictive latent components, and (iii) has a natural extension to incorporate incomplete multi-modal datasets. We discuss how MMFL embeds complementary and consensus principles from multi-modal learning. Through simulation studies, we demonstrate that MMFL outperforms a variety of existing multi-modal algorithms when partially shared components are present in the data. We applied MMFL to a real-world case study for the prognosis of Alzheimer’s Disease conversion using multi-modal imaging (MRI and PET) and GWAS genetic data (SNP) from the ADNI dataset. Compared with existing methods, MMFL provided more insights for understanding existing correlations within and across the modalities.",Machine Learning II,126,135
Optimizing Railcar Movements to Create Outbound Trains in a Freight Railyard," This study addresses a problem arising in freight rail transportation requiring a large number of railcar movements within a railyard. A freight railyard typically contains numerous railcars on classification tracks, some of which must move to outbound tracks to create trains with designated destinations. Assembling an outbound train requires pulling cars from their existing locations and moving them to a designated outbound track. The objective is to minimize the cost of relocating cars to their designated outbound tracks. We formally define the railcar movement (RM) problem, design a mixed-integer programming model that allows simultaneous movements of multiple railcars, and prove the problem’s NP-hardness. Additionally, we present an alternative formulation of the RM problem using a dynamic programming method, followed by three heuristic solutions: an approximate dynamic programming heuristic, a decomposition-by-railcar-destination heuristic, and a decomposition-by-track-group heuristic. The computation time and the quality of heuristic results obtained from representative data demonstrate an ability to obtain high quality solutions in acceptable computing time for various scenarios.",Optimization Application,155,136
"Examining the Development, Design, and Effectiveness of Hospital Command and Control Centers: A Narrative Review"," Hospitals are increasingly adopting command and control centers (CCCs). These CCCs serve as central hubs integrating real-time data, simulation modelling and predictive analytics to enable efficient management of processes like patient flow. However, further research is needed regarding the design and development of CCC, the processes supported, and their overall effectiveness. This work investigates CCC deployment in hospitals and synthesizes the evidence on their effectiveness. A comprehensive narrative review was conducted using four major databases: PubMed, EMBASE, Scopus, and Web of Science. The initial search yielded 105 articles, which were imported into Covidence for screening. Following title and abstract screening, 82 articles were identified for full-text review, and subsequent data extraction was completed for 27 articles. Our review identified two main CCC models: event-based CCCs for emergencies like pandemics, and operational CCCs for daily hospital functions like bed management. The centralized operational model is prevalent, featuring multiple screens, data tiles, and co-located staff. Decentralized models, commonly adopted by smaller hospitals due to funding constraints, involve different departments working collaboratively with screens and controls distributed across multiple offices, utilizing shared software to access real-time data. The adoption of both operational and event-based CCCs yielded increased capacity, throughput, and financial benefits. Event-based CCCs aided in planning and risk mitigation by organizing institutional response and improving communication efficiency. Although hospital CCC’s have demonstrated positive outcomes, further research is needed to provide guidance for optimal design and development. Additionally, future work should statistically assess outcomes of CCC implementation and calculate their return on investment.",Diverse Topics for HFE 3,54,137
Functional Connectome Identifiability through Semi-Symmetric Tucker Decomposition," The human functional connectome (FC) represents the functional couplings between brain regions derived from blood oxygen level-dependent (BOLD) signals. Studying the FC enables obtaining insights about individual traits from subjects. In this study, we aim to maximize FC identifiability by performing semi-symmetric Tucker decomposition in data from the Human Connectome Project (HCP). Identifiability is the general paradigm of correctly pairing FCs that belong to the same subject within a dataset where there is test and retest for all subjects. Here we measure identifiability via a measurement denominated matching rate (Chiêm et. al, 2022). Studying identifiability through FCs enables verifying their consistency over time and understanding how subjects differ from each other at an individual level. Here we used test-retest fMRI data from 426 unrelated subjects from the HCP dataset. For each subject, test-retest data includes resting state and seven tasks (Gambling, Emotion, Language, Motor, Relational, Working Memory, and Social). To analyze the high-complexity data, we structured it into a tensor and used tensor decomposition to project the data into a lower dimensional space. By doing so, we separated the data into three components. The first two components capture information related to the brain's functional couplings, whereas the third component captures subject-specific information. Results show that subjects can be correctly matched with 80-100% accuracy across resting state and all seven evaluated tasks. We also extended this approach to assess identifiability when using resting state data as test and task data as retest. This resulted in cross-condition matching rates of over 80%.",Healthcare I,83,138
Automated Ontology Generation for Zero-shot Defect Identification in Manufacturing," The scarcity of measured data due to budget and time restrictions, which are crucial for understanding process-defect relationships and process certification, often presents a challenge to manufacturing process development. Knowledge transfer and information sharing among manufacturers have become an emerging solution to cope with small-data challenges in quality control. However, a major barrier for each manufacturer to implement this approach is to balance the need for useful data sharing to help others while reducing privacy leaks. This study integrates the differential privacy model in cybersecurity with federated learning to investigate the data structure of defect knowledge and strategies for sharing knowledge on the cloud. This paper first introduces a hierarchical knowledge graph consisting of defect attributes, called defect ontology, as the data structure for sharing. In addition, a self-supervised learning problem is formulated to automate the generation of defect ontology for sharing without labor-intensive annotation. Based on the ontology model, the information leaks due to the sharing of ontology branches and depths are modeled by epsilon differential privacy. Under the privacy budget, the proposed method optimizes the sharing strategy for defect ontology to facilitate zero-shot defect classification under a federated learning environment with missing or fragmented data between clients. A case study demonstrated the correlation between federating rounds and accuracy, outlining the need for balancing the privacy budget and gain from collaborative machine learning.",Advanced Topics of QCRE I,7,139
Supporting Sleep Health and Chronic Care Management Information for Patient Self-Care," Sleep health is a multidimensional concept affected by multiple cognitive, environmental, and physiological factors, including the circadian rhythm. Poor sleep health causes short-term impairment to cognition, emotional regulation and mood, and functional performance. Poor sleep health is also implicated in long-term health risks such as mental health conditions, diabetes, cardiovascular diseases, and cancer. Circadian rhythms that are unsynchronized with desired sleep-wake schedules are both causes and outcomes of chronic conditions affecting cognitive and physical functioning and interactions. Conditions like fibromyalgia, mood disorders, type I diabetes, and post-concussive syndrome disproportionately affect women. Unfortunately, current physiological monitoring technologies do not support real-time assessment of the circadian rhythm, especially in everyday contexts (i.e., outside a sleep lab). This gap complicates circadian misalignment detection and severely limits timeliness and effectiveness of interventions and patient self-care efforts. This paper explores the system dynamics associated with a continuous physiological monitoring system that tracks the circadian rhythm via melatonin levels. Melatonin fluctuations and subsequent circadian phase shifts due to environmental time-cues, as well as interactions between circadian misalignment and other chronic conditions, represent feedback control and homeostasis loops affecting the patient. A continuous melatonin monitor and patient-facing display would support patient self-care through enhanced health literacy and situation awareness regarding their current and projected future states. These outcomes will enable timely, effective interventions and patient-led supervisory control actions to improve sleep health and thus ultimately enhance overall patient condition.",Patient Care and Treatment I,160,140
Development of Price Forecasts that Satisfy the Requirements of Agricultural Planning Models," Traditional supply chains (SCs) for fresh fruits and vegetables (FFVs) are not flexible enough to accommodate sudden shifts in demand and, at times, are incapable of reacting to disruptive events. One of the root causes of this problem is that there is a lack of data-driven planning to aid decision-making across the SC to better match supply and demand. To address this challenge, works that focus on designing tactical planning optimization models for the FFV SC have emerged. These models help to better plan production according to a grower’s resources and the needs of the market – as such, they help match supply and demand. All these models rely on the accuracy and quality of the input data – especially market prices, which is one of the key input parameters. Unfortunately, because publicly available price data in the US is limited, price estimations are often based on the grower’s experience which can lead to biased or incorrect results and have serious implications on the operation of a grower’s business. As such, there is a need to develop a framework that precedes the planning models and focuses on providing them with data-driven information. In this work, we provide the basis for this needed framework and develop various data-driven price prediction techniques to satisfy the requirements of different planning optimization models (i.e., deterministic vs stochastic). Case studies are presented to demonstrate the developed methodologies.",Energy & Environment I,62,141
Adapting the Inventory Routing Problem to Optimize Water Deliveries in Water Insecure Areas," Access to clean drinking water can be a luxury in impoverished communities in the United States. Nationally, more than 2 million people lack access to safe drinking water and indoor plumbing, and this figure does not include homes with a working tap of unsafe drinking water. Therefore, a far larger number of Americans face water insecurity. A recent examination of US Census and Safe Drinking Water Act violation data reveals that rural, low-income and minority communities are significantly more likely to be burdened with unavailable or unsafe in-home drinking water. Among community advocates, practitioners, and researchers, a consensus has emerged: alternatives to traditional infrastructure must be explored in the U.S. One promising alternative is delivering water to residences without access to reliable, clean water sources. This research explores how to optimally deliver drinking water to households by adapting the inventory routing problem (IRP) and creating heuristic algorithms to schedule efficient water delivery. The IRP and heuristics inform three key decisions: when to serve a customer, how much to deliver, and which delivery routes to use. These algorithms will be verified through implementation in central Appalachia and the Navajo Nation with a nonprofit organization dedicated to combating the water crisis in the US.",Center for Excellence in Logistics and Distribution (CELDi),25,142
Investing in Tomorrow: The Benefits of Engineering Co-op Programs," Engineering cooperative education (co-op) programs are structured programs through colleges and universities that provide students with hands-on work experience in a non-academic setting. These programs are uniquely different from internships or senior capstone projects, but many Industrial Engineering students do not fully understand the benefits. Students with co-op experience are valued by hiring managers and often have an easier time transitioning to their first jobs out of college. Students are able to participate in classroom discussions for their last year or two with more maturity and perspective. Employers are able to utilize co-op engagements as a recruiting and initial training tool. This presentation will: Define what a co-op is and how it is different from an internship. Describe the different structures that may exist for a co-op program. Describe the benefits of co-op for the student, employer, and university. Offer suggestions for stakeholders to get the most out of participation in a co-op program. The presenters will discuss their personal journeys with co-op programs. One presenter had a valuable co-op experience 23 years ago. Another presenter now actively hires co-ops and has helped universities set up co-op programs.",Preparing Students for Industry:  A panel discussion on the Win/Win benefits of Co-Op programs and a Case Study of Industry led “beyond the textbook” learning opportunites,172,143
Industrial Engineers to the Rescue! Solving Your Labor Shortages," These last few years have put a strain on the supply chain of most industries. Early 2020 created a massive labor shortage following restrictions imposed by various Covid mandates and distribution facilities have been suffering since. Industrial Engineers have all the skills required to tackle the labor shortages issues in general and – more specifically – within the supply chain. Critical examination of the problem should lead us to two drastically different solutions: virtually eliminate the labor component from key steps in the supply chain, or significantly improve the productivity of the current labor. Both solutions are viable, but also contain risks and limitations. The goal of this presentation is to assess in which conditions should one be chosen over the other. Are these solutions appropriate for every supply chain? How quickly can these solutions alleviate the labor challenges? Automation or a high degree of mechanization represents the path towards eliminating the labor component and therefore solving the labor shortage. This represents the ultimate solution, but is it a realistic approach for every situation? What IE skills are most important towards justifying, implementing, managing, and ultimately running such a project? Our second solution targets improving the efficiency of our labor force, which obviously involves a more traditional IE approach. How much can we improve by optimizing work methods? How much can we gain by implementing engineered labor standards? A more crucial question – is there anything we can do to improve retention? It’s time to put your skills to work!",Innovative topics in supply chain 1,112,144
Emergency Response Management Plan for Occupational Safety and Health at Pontificia Universidad Católica Madre y Maestra," This paper delineates the development of a strategic emergency response management plan aimed at fortifying occupational safety and health protocols at the Pontificia Universidad Católica Madre y Maestra (PUCMM). The initiative underscores the application of industrial and systems engineering methodologies to institutional safety challenges. Adopting a rigorous systems engineering perspective, the research employed a comprehensive risk and vulnerability assessment framework, referencing ISO 22320 standards for emergency management. The approach integrated quantitative risk qualification matrices with qualitative analyses to construct a robust emergency response infrastructure. The emergent strategy encompasses a meticulously structured emergency response protocol, detailing preemptive measures, incident reporting mechanisms, and a tiered response system tailored to the university's unique environmental and infrastructural context. The plan delineates specific procedures for a spectrum of potential emergencies, thereby streamlining crisis management and response efficacy. The formulated plan is a testament to the pivotal role of systems engineering in crafting effective emergency response mechanisms within educational institutions. It serves as a model for similar establishments seeking to enhance their emergency preparedness and systemic resilience. This work contributes to the discourse on safety and emergency preparedness in the academic sector, highlighting the synergy between systems engineering principles and occupational health and safety practices. It offers a replicable blueprint for emergency response planning that is both systematic and adaptable to diverse institutional settings.",Emergency Response and Preparedness  in Health Systems,60,145
Alternative police response models to crisis calls," A crisis call is when one or more individuals suffer from a mental- or behavioral health-related issue that may require a police response. Many police departments have introduced specially trained crisis response teams to replace the traditional police response with new response paradigms that may involve sending different or multiple types of vehicles to a crisis call. We introduce queueing models and performance measures to capture the dynamics of new response paradigms. We evaluate the queueing models using discrete event simulation with a case study based on data from Madison, Wisconsin, and we compare the crisis response to a traditional response to elucidate performance across a range of input parameters.",Human trafficking and other humanitarian crises,93,146
Panel on ISE Careers in Consulting," Tens of thousands of ISEs chose to work in the consulting industry. Many begin their careers immediately after receiving an undergraduate or master’s degree. Others spending years working in another industry before transitioning to consulting. This session will be a panel discussion on the diverse careers ISEs can have working in the Consulting Industry. Panelists will describe how they got into consulting, their different experiences, some of their lessons learned and take questions from the audience.",ISE Careers in Consulting Panel Discussion,99,147
Expanding the UNIVERSE: UNderstanding Industrial Engineering VERSatility for K-12 Educators," The Industrial Engineering (IE) profession needs more post-secondary students who want to be engineers, who can because they have the knowledge, skills, and messaging necessary to be successful along the way. Per ASEE, in 2021, 23.6% of BS degrees in engineering were awarded to women; at Iowa State University (ISU), the percentage of women studying IE ranged from ~30-38% from 2011-2021, leaving a significant, untapped source of potential IEs. While many high school students are dissuaded from pursuing engineering because of insufficient math/science prerequisites, an additional challenge for IE is that students have never heard of the profession. K-12 educators have significant influence on students’ career considerations. With NASA funding, this project’s first objective is creating and offering a state-approved professional development course for license renewal credit, to be offered the first time in June 2024. In each offering, thirty K-12 educators will experience IE at ISU with hands-on activities, lesson planning with faculty, and interactions with alumni who work at/with NASA and other space-related companies like SpaceX and Collins Aerospace. The second project objective is creating lesson(s), example(s), and messaging about IE to share with K-12 educators. With more K-12 educators who understand, appreciate, and teach students about the importance of IE, we will increase the number of students ready to apply to first-year engineering programs and thus, increase the number of students, including women, pursuing IE careers. This paper shares the fully developed course, K-12 lessons, logistics, and other information for other IE departments to use.",Inclusive Excellence in ISE Education,100,148
Revisiting Continuous p-Hub Location Problems with the L1 Metric," Motivated by emerging urban applications in commercial, public sector, and humanitarian logistics, we revisit continuous p-hub location problems under the L1 metric, where several facilities are to be located in a continuous space such that the expected minimum Manhattan travel distance from a random service provider to a random receiver through exactly one hub facility is minimized. Firstly, we obtain expressions for the objective function and the closed-form optimal solution in the one-dimensional case, where the convexity of the problem is proved. Secondly, we determine the optimal solution for the two-dimensional, one-hub case. Moreover, we extend the approach to the two-dimensional, two-hub case and derive the objective function expression, which permits numerical characterization of the optimal solutions. Finally, we propose sample-based formulations and heuristic solution methods for problems with more than two hubs.",OR Methods,151,149
Optimal Design of a Bioethanol Supply Chain Considering Government Subsidies: Mixed-Integer Linear Programming Model," Renewable energies have gained a significant attraction due to the increasing growing demand for energy and environmental concerns. As one of the alternatives to fossil fuels, bioethanol from switchgrass is considered. To realize the strategic and tactical Bioethanol Supply Chain (BSC) decisions, in this study, we developed a mixed-integer linear programming model aiming to minimize total annualized costs over a 5-year planning horizon by incorporating financial incentives. Using this model, the optimal allocation of material flows is determined along with supply and pre-processing locations for producing a gasoline-ethanol blend (E5). The monetary incentives include i) a constant budget for the whole BSC planning; and ii) treating the distribution of the budget as a decision variable. A comparison is made between incentive policies to find a better strategy for minimizing costs. To illustrate the application of the proposed model, a case study of Iran is investigated. Results indicate the requirement of a monetary incentive to produce bioethanol and establish plants for processing. The cost savings resulting from the optimum allocation of monetary incentives were higher than the constant monetary incentives. It is concluded that the model with the decision on budget allocation is a better alternative for economical BSC design. To investigate the model robustness, sensitivity analysis was also performed to evaluate the impact of variations in cost parameters and feedstock yield, and gasoline-ethanol blend. This model helps decision makers and managers as the model is accessible and adjustable to the different applications.",Logistics & Supply Chain Best Paper Competition,121,150
Subjective vs. Objective measures of mental workload of rail traffic controllers," General tools such as the NASA-TLX as well as railway-focused workload assessment tools such as the Integrated Workload Scale (IWS) help in measurement of mental workload. However, such tools are subjective and can also not provide continuous workload measurement. We investigated the use of eye-tracking to measure workload of railway controllers while they performed railway traffic-control tasks of varying levels of complexity. Nine experts and nine novice railway controllers participated in a study where they completed tasks in four different scenarios, each consisting of varying levels of traffic and varying number of unexpected events (e.g., track closures) across a selected area of the Belgian railway network, in a railway traffic simulator. Along with the objective pupillometric measures for mental workload, performance and subjective workload measures were collected. Initial analysis of subjective mental workload ratings suggests that novices were not different from experts in information gathering and knowledge retrieval phases of the tasks, but they had experienced more workload during the decision-making phase, when reacting to critical safety events. The correlations between pupillometric measures and subjective ratings are being analyzed, to assess the validity of pupillometric measures to indicate the fluctuations in mental workload during railway traffic-control related task demands. The goal is to generate a robust set of measures of mental workload which can be used to continually assess traffic controller state.",Transportation,232,151
Industry 4.0 technologies applied to Supply ChainIntegration in Retail," Due to the scarcity of research that addresses Supply Chain Integration (SCI) in the current scenarios about industry 4.0 technologies, this paper aims to carry out a systematic review of the literature on Supply Chain in the retail segment and seek an understanding for decision-making in the applications of technologies. Are presented two specific objectives: (I) Identify which I4.0 technologies are helping retail companies evolve in supply chain integration ; (II) Verify how the retail segment is benefiting from the application of these technologies. This research conducts a systematic review of the literature with descriptive and qualitative data, a flowchart demonstrates the process of selecting and reviewing articles. It also sought to provide tables with the current scenario and the applications of I4.0 technologies for the SCI, from the perspective and in the retail business. According to the review, the potential impact of not applying an I4.0 technology on the SCI was demonstrated, and future application possibilities were prospected. This gap is suggested by authors of qualified and recent papers, as evidenced by the review developed by (Benitez et al., 2021; Chiarini et al., 2020; Bruni and Piccarozzi, 2022). This research contributes by offering guidelines and delivering a conceptual model on opportunities in the application of I4.0 in the Supply Chain.",Innovative topics in supply chain 2,113,152
Leveraging on RFID-IoT technologies and simulation to design and develop a smart shelf for managing low-value medical supplies.," In this collaborative research project between one of the largest hospitals in the province of Quebec and university researchers, we are exploring the use of Radio Frequency Identification-Internet of things (RFID-IoT) technologies to improve the management of medical supplies in point of care units. While most of the research on RFID-IoT in the healthcare sector focuses on mobile device management and patient monitoring, this research contributes to our understanding of the potential of RFID-IoT’s to improve (internal) hospital’s logistics processes for low-value medical supplies associated with patient care activities. The first objective is to contribute to the development of a “smart” shelf prototype that will combine different technologies including passive ultra-high frequency RFID technology and indicative LED. Since testing realistic impacts of such solutions on operational performance is not easy, the second objective is to use a hybrid simulation approach to evaluate the impact of an IoT 2bin Kanban “smart” shelf replenishment system for medical supplies that can be used in a hospital nursing unit. The simulation approach is therefore used to facilitate the selection of the “best” replenishment system. The originality of this project lies (a) in the open innovation approach which is of great value in the healthcare context (b) in the combination of physical prototyping of an RFID-IoT smart shelf and simulation, which uses real operations data to explore the impact of the solution on business and operational processes.",Smart Manufacturing and Design,207,153
Leveraging on RFID-IoT technologies and simulation to design and develop a work-in-process prototype in a manufacturing plant.," In this collaborative research project between a manufacturing company and university researchers, we are exploring the use of Radio Frequency Identification-Internet of things (RFID-IoT) technologies to improve the work-in-process (WIP) tracking of production. Like many manufacturing companies, the industrial partner faces a number of operational management challenges. During the production progress units are moved, and sometimes stored in inappropriate locations, or misplaced in one of the company's many zones. This complicates operations planning, increases delays and lost productivity. To respond to this problem and ensure real time visibility of these units, several technological designs are being tested. Given the harsh-metal operating environment, the envisioned solution needs to (a) be deployed in a multi-zone location (b) minimize maintenance management (c) minimize implementation complexity. The first objective is to design and develop a real-time location solution (RTLS) prototype to track WIP units (e.g. buckets of screw), using fixed readers and high ceiling passive RFID readers. The second objective is to compare and evaluate the impact of different designs on operational performance and select the most interesting one. For this purpose, we will use simulation modeling approach. The originality of this project lies in the combination of physical prototyping of RFID-IoT technologies and simulation, which uses real operations data to explore the impact of the solution on business and operational processes.",Smart Manufacturing and Design,207,154
Bridging Human-AI Collaboration: A User-Friendly Interface for Optimizing Patient Safety Event Classification," Efficient and accurate classification of patient safety events (PSEs) is crucial for monitoring patient safety in hospitals. Erroneous PSE classification usually leads to reclassification and can potentially confound the database during pattern searches for developing solutions. Previous studies have leveraged machine learning (ML) classifiers to enhance the classification process. However, none of these studies have investigated the potential integration of the classifier within the PSE reporting system in a manner that aligns with the PSE reporters' workflow. In this study, we introduced an interface to facilitate the human-AI collaboration for PSE classification. We designed a proof-of-concept interface in Figma (2023). The interface integrates the ML classifier with Local Interpretable Model Agnostic Explanations (LIME), which identify influential words in a PSE that contribute to the classifier’s prediction. The interface provides multiple probable event types and associated explanations for the ML classifier's prediction, allowing PSE reporters to select the most appropriate category after inputting the description of the event. This approach aligns with the principles of level 2 automation, where the ML classifier aids human decision-making by providing recommendations. This collaboration aims to combine human expertise with ML capabilities, potentially reducing cognitive workload, and eliminating the need to memorize the taxonomy. While the interface is innovative, its efficacy in supporting PSE classification necessitates further exploration. Our next steps involve investigating the interface’s influence on cognitive demand and reliable classification through usability testing with healthcare professionals. While our work focused on PSE categorization, with larger datasets, the interface can provide intelligence on trends.",Poster Presentations,169,155
"Examining the Effectiveness, and Limitation of Computer-Aided Diagnosis Systems for Retained Surgical Items Detection: A Systematic Review"," Retained surgical items (RSIs) pose a serious risk to patient safety, leading to severe complications, and infections, with morbidity rates as high as 84.32%. There has been rising interest in utilizing Computer-aided detection (CAD) systems for enhancing RSI detection, therefore it is crucial to comprehensively assess their capabilities. This systematic review aims to summarize the characteristics of CAD systems developed for RSI detection, as well as evaluate their effectiveness, and limitations, and propose opportunities for enhancement. Five electronic databases were searched from inception to March 2023. Studies that have developed and evaluated CAD systems for identifying RSIs were eligible for inclusion. The systematic review adheres to PRISMA 2020 guidelines. Following the screening process, eleven studies met the inclusion criteria. The sensitivity of the CAD systems ranged from 0.61 to 1 and specificity varied between 0.73 and 1. Most studies (n=10) relied on simulated RSI radiographs for the development and evaluation of CAD systems. Moreover, the majority of the CAD systems (n=9) utilized deep learning algorithms but without incorporating explainable AI techniques, and none of the systems were tested in clinical environments. Based on the limitations of reviewed studies, we recommend 1) creating a comprehensive benchmark dataset, encompassing authentic RSI radiographs that can support rigorous testing and refinement of CAD systems; 2) incorporating XAI techniques to enhance the transparency and trustworthiness of CAD systems. With these improvements, we can then establish the appropriate way of integrating CAD systems into clinical workflow and subsequently validate their effectiveness in detecting RSIs.",Information and Digital Systems in Health,105,156
Simultaneous Treatment Effect Estimation and Variable Selection for Observational Data," Causal inference is a useful tool for assessing the effects of intended changes to a system. Given the challenges associated with conducting controlled experiments on industrial systems, resorting to effect estimation using observational data becomes a practical alternative. However, a major difficulty in causal inference from observational data is that the underlying causal structure is unknown. This may result in the misidentification of potential sources of causal estimation bias, such as confounders, which must be controlled for accurate estimation. To consider all possible confounders and other relevant information, conventional methods predominantly use all observed covariates indiscriminately. However, previous studies have shown that including all covariates without considering their causal relationships may deteriorate the estimation performance. Although several data-driven variable selection methods have been proposed for effect estimation, they cannot distinguish the confounders from other outcome-related covariates and are limited to simple regression forms. In this study, we propose a method called the variable selection causal estimation network (VSCEN) that performs effect estimation and causal variable selection simultaneously. Through end-to-end differentiable training, the VSCEN selects only the covariates beneficial for effect estimation and uses only those selected for effect estimation.",Advanced Topics of QCRE Applications II,6,157
Production Scheduling and Cutting Stock Problem Under Stochastic Yields in Silicon Wafer Manufacturing," This study aims at silicon ingot manufacturing in the semiconductor industry, where production planers decide production scheduling and cutting patterns with the consideration of capacity and demand under stochastic segregation coefficients. Among product specifications, resistivity is the most important characteristic to be considered, and the resistivity of finished goods is affected by the cutting position on the ingot, chemical dopant type and volume, and processing time in ingot growing. Also, unexpected interruptions could result in resistivity uncertainties. When a finished good does not satisfy the required specifications, it will be counted as a trim lose. To address above challenges, we first estimate the segregation coefficient for resistivity distribution. Then, we formulate a stochastic integer program to determine both lot-sizing and cutting stock decisions considering uncertain resistivity. To solve the problem, we develop two decomposition schemes through linear transformation by introducing binary variables representation. The experimental results compare the performance of our proposed methods and the commercial solver for solving different problem sizes. The result shows that using the piecewise linear transformation can obtain the best solution quality. Finally, we validate our solutions through a real-world case study as a demonstration to apply our method for making decisions.",Planning and Scheduling,165,158
The Hybrid Separation Procedure of Subtour Elimination Constraints for Solving Symmetric Traveling Salesman," This study focuses on Symmetric Traveling Salesman Problems with the development of cutting plane algorithms. We developed the hybrid separation procedure that integrates heuristic and exact methods to generate sub-tour elimination constraints. Also, our method adopted an efficient global min-cut algorithm when heuristics failed to find a cutting plane in a Branch-and-Cut iteration. Computational experiments showed that our methods outperformed the existed separation procedures with regard to run times for solvable cases and solution qualities for unsolvable cases.",Large-scale Integer Programming,118,159
Integration of Feedback and Feedforward Control in Laser Powder Bed Fusion," Laser powder bed fusion is one of the most promising methods to fabricate metal parts with complex geometries, but ensuring a high geometrical tolerance is challenging. One of the primary causes of the shape error is the melt pool size fluctuation due to heat accumulation. However, it is challenging to implement power compensation precisely because quantifying the heat accumulation in both part and local scales is computationally expensive. This work addresses this issue by integrating feedforward and feedback control on real-time laser power adjustment. More specifically, the part-scale heat accumulation resulting from the part-substrate-powder interaction is considered by the FEA model, which uses a heuristic method to suggest a laser power setting to each layer, namely, feedforward control on the laser power. On the other hand, the heat accumulation due to raster line length change and random variations (spatter and powder spreading quality) are regulated by a high-speed feedback thermal-based laser power controller. In the case study, we demonstrated our method by printing a testing shape containing both bulky and fine features. Such shapes were printed with four conditions, namely, no control, feedback control only, feedforward control only, and feedback & feedforward control combined. A high-spatial-resolution 3D scanning result demonstrated that the integrated feedforward and feedback control results in the best geometrical accuracy for both fine features and overall shape.",Sensing and Control in Additive Manufacturing Processes-II,203,160
Simultaneous Long-tailed Learning and Multi-modal Fusion with Highly Imbalanced Multi-modal Data," It is common in quality control problems that the number of normal samples exceeds that of defective ones, and it is necessary to take this imbalance into consideration when modeling with such data. To solve this issue, most of the existing quality control models utilize long-tailed learning methods, which attempt to address the problem of training class-balanced models from class-imbalanced training datasets. They typically assume that the input data are single-modal and are designed to handle single-modal inputs only. However, with the access to large-scale, high-dimensional data collected from multiple sources, it becomes increasingly important to integrate such multi-modal data to take advantage of their complementarity. In this article, we propose a long-tailed learning model that is capable of processing multi-modal inputs by introducing a multi-modal fusion strategy. We modify the structure of an existing long-tailed learning model constructed under a multi-expert framework so that all the input modalities are combined into a single representation within each expert. We further employ a separate module consisting of multiple networks, one for each modality, to compute and reflect the relative importance of each modality during the modality fusion. Finally, we propose distinct training and test procedures for different combinations of modalities to bypass the need for self-supervised test-time expert aggregation for tabular data. Empirical results on benchmark datasets and a real-world medical dataset demonstrate that the proposed model is capable of processing multi-modal data ubiquitous in quality control problems and is able to generalize better than the baseline methods.",Advanced Data Analytics for Quality Control and Reliability,2,161
Balancing reliability and manufacturing output through condition-based production: Optimal policies and learning," Production systems used in the manufacturing industry degrade due to production and may eventually break down, resulting in high maintenance costs at scheduled maintenance moments. This degradation behavior, and hence the system's reliability, is affected by the system's production rate. While producing at a higher rate generates more revenue, the system's reliability may also decrease. Production should thus be controlled dynamically to trade-off reliability and revenue accumulation in between maintenance moments. We study this dynamic trade-off for (i) systems where the relation between production and degradation is known as well as (ii) systems where this relation is not known and needs to be learned on-the-fly from condition data. For systems with a known production-degradation relation, we cast the decision problem as a continuous-time Markov decision process and prove that the optimal policy has intuitive monotonic properties. We also present sufficient conditions for the optimality of bang-bang policies and we characterize the structure of the optimal interval between scheduled maintenance moments. For systems with an a-priori unknown production-degradation relation, we propose a Bayesian procedure to learn the unknown degradation rate under any production policy from real-time condition data. Numerical studies indicate that on average across a wide range of practical settings (i) condition-based production increases profits by 50% compared to static production, (ii) integrating condition-based production and maintenance interval selection increases profits by 21% compared to a state-of-the-art approach, and (iii) our Bayesian approach performs close, especially in the bang-bang regime, to an Oracle policy that knows each system's production-degradation relation.",Advanced Topics of QCRE I,7,162
Effects of Exoskeletons on Low-Back Muscular Demands During Unloaded Intermittently Performed Bending Tasks," Repetitive tasks, even when not physically strenuous, can cause overexertion injuries over prolonged durations. Handling heavy loads may be assigned to automated equipment in modern workspaces, yet tasks requiring forward bending remain common in a worker’s daily routine. Exoskeletons assist to offset loads to less critical body regions and can provide cumulative benefits over multiple task cycles. We assessed the effects of Back-Support Exoskeletons (BSEs) in unloaded bending tasks (each task cycle of 60-secs: standing-still (15-sec), bending, sustaining bent posture (30-sec), retracting, standing still (15-sec)) performed intermittently with 15-sec rest (task cycle: relax - 4:1). Twelve participants performed multiple task cycles with/without assistance (of BSE) and in symmetric/asymmetric postures until fatigued. Both subjective (Borg Ratings of Perceived Exertion (RPE) in back and legs) and objective (muscle activation from left (LES) / right (RES) erector spinae muscles) were recorded for each task cycle. Findings revealed that peak amplitude during sustained bending portion in LES was lower with assistance (17%, p-value < 0.001) and in asymmetric vs. symmetric condition (18%, < 0.002), while in RES was lower in symmetric (15%, <0.02). Performing tasks with assistance led to the highest median frequency (82%) in LES vs. no assistance (68%) at medium back and low leg fatigue levels (p-value <0.02) and the trend was similar in RES (78%, 71%, p-value =0.07). Our findings demonstrate the effects of BSEs in intermittently performed trunk flexion tasks that lack handling of heavy loads and may be beneficial for effective implementation of BSEs in industrial workspaces.",Modeling & Simulation for Human Factors and Ergonomics,146,163
How Do Exoskeletons Affect Balance During Intermittently Performed Sustained Bending Tasks?," Exoskeletons are beneficial in reducing effort and risk of overexertion-related injury, yet they can also induce side-effects in their wearers. The added weight, as well as interplay of assistive forces of the device can affect wearers’ body posture while performing tasks. Factors like fatigue and awkward postures can affect neuromuscular systems, eventually affecting balance. We examined how back-support exoskeletons (BSEs) affect body movement and stability in wearers who performed intermittent forward bending tasks with/without ~45-degree asymmetric rotation in the transverse plane. Twelve participants performed multiple trials of sustained trunk flexion tasks with 30 sec durations, until they reached a medium-high fatigue level with/without assistance of BSE. Participants were asked their fatigue level using ratings of perceived exertion (RPE) in back and legs on the Borg CR-10 scale as they stood with one foot on each of two floor-embedded force plates. Findings revealed that both maximum deviation and mean velocity of center of pressure (COP) were ~39% (p-value<0.01) and 133% (p-value<0.05) lower respectively, with assistance vs. without in asymmetric posture and remained lower at both low and medium fatigue level in legs. Overall, the difference between ground reaction forces in left vs. right foot was ~28% lower (p-value<0.01) while wearing BSE. Lastly, distance of COP during standing still to the distance during sustained bent posture was 33% lower with the BSE, indicating possible adaptations in posture while performing the tasks. Findings from this study may be beneficial in understanding the risk of fall while performing tasks with wearable assistive devices.",Modeling & Simulation for Human Factors and Ergonomics,146,164
A real-time temperature prediction method based on CNN-LSTM with MODE in steelmaking process," : Quality prediction of molten steel is a key issue in the converter steelmaking process. Due to high temperature and physical and chemical reactions, it is difficult to predict the temperature and composition content of molten steel in real-time through mechanism analysis. This is a challenging problem with black box characteristics. Here we propose a CNN-LSTM model based on multi-objective differential evolution (MODE) algorithm for the real-time prediction problem in the steelmaking process. Specifically, the CNN layer can extract features between multiple variables that affect the temperature of molten steel, and the LSTM layer is suitable for modeling the temporal information of irregular trends in time series components. The multi-step output of CNN-LSTM method is used to construct the temperature prediction model of molten steel, and the complexity and accuracy of the optimization model are used as the two optimization objectives of the MODE algorithm. And the inflection point solving strategy is used to improve generalization ability. The experiments were conducted using real data collected during the converter steelmaking process. The results verify the effectiveness of the proposed method on multiple steel grades and outperform other data analytics methods.",Statistical Learning and Artificial Intelligence for Quality Control II,212,165
Optimizing Ideal Time in Stochastic Assembly Line Balancing through Chance-Constrained via K-means Algorithm," To tackle the assembly line balancing problem (ALBP), we present an integer mathematical formulation that integrates both the stochastic nature of task times and equipment selection by task. The proposed approach aims to optimize task allocation along the production line, considering variations in task durations and the specific equipment requirements for each task. Our main goal is to minimize the total ideal time while ensuring efficient equipment utilization and maintaining a balanced workload across workstations. We achieve this through the development of a mathematical model that assigns tasks to workstations, considering both stochastic task times and equipment needs. To address the complexity of the problem, we propose a clustering method based on K-means technique, allowing for efficient grouping of tasks based on their characteristics and equipment requirements. Through iterative improvement of task assignments, our objective is to attain a near-optimal solution that minimizes both the ideal assembly time and equipment requirements. Hence, enhancing overall production line efficiency. Initial experimentation and validation using datasets provide insights into the effectiveness of our approach, demonstrating significant improvements in efficiency and cost savings across production line operations.",Manufacturing & Design Best Track Paper,133,166
Human-Robot Matching Policies in Order Picking Systems using Queuing Models," Pick-Support Autonomous Mobile Robots (PS-AMRs) collaborate with human pickers to enhance order-picking efficiency by minimizing unnecessary walking for human pickers. A study by Locus Robotics in autonomous mobile robots reveals significant improvements in the system. Quantified benefits include a remarkable 100% improvement in picker productivity, leading to increased order fulfillment. PS-AMRs can collaborate with humans under two policies: (1) Swarm - where robots and human pickers operate independently, moving to pick locations and waiting for pickers to collect required items. Simultaneously, the order picker is instructed on which robot to serve. After picking an item, the robot proceeds to the next pick location while the picker moves to another waiting robot. Once all items for an order are picked, the robot transports the items to the depot. (2) System-Directed - in this scenario, the human picker receives necessary picking information, and the robot follows the picker. Once all required items are collected, the picker sends the robot to the next zone or depot, continuing order picking with another available robot. This study models the Swarm policy as a closed queuing model to determine system throughput capacity. It examines the impact of order profiles, matching policy (closest or random), and the ratio of AMRs to pickers on overall system performance. Initial results indicate that the Swarm policy can outperform the System-Directed strategy by up to 34.26%, contingent on order profiles and the AMR-to-picker ratio.",Logistics & Supply Chain Best Paper Competition,121,167
Spatio-temporal Probabilistic Forecasting of Circular Variables: Enhancing the Value of Wind Power Prospective Models by Incorporating Wind Direction Probabilistic Forecasts," The pressing need to mitigate climate change has led to a shift in attention towards renewable sources of energy. In particular, energy derived from wind has increased its capital supplying role in the market, becoming even a critical component of the supply portfolio for countries with high penetration of renewable sources, due to its low marginal costs and potentially ubiquitous exploitability. However, its stochastic and climate-influenced variability makes it challenging to consider it a reliable source. Hence, cutting-edge models derived on historical data are key to a) understand and model the randomness involved in wind dynamics, b) quantify the uncertainty associated with the wind power conversion process; and finally, c) ensure wind energy’s full utilization within the grid. Several models have been proposed in the literature to characterize the evolution of the physical phenomenon of wind and its impact in the energy conversion process. These efforts, though, have focused mainly on studying the spatio-temporal evolution of wind speed’s magnitude. Considerably fewer works have highlighted the importance of modeling wind direction and its variation as an important predictor of wind power output. This work will justify the importance of forecasting both the magnitude (wind speed) and direction of the wind velocity vector when quantifying the wind power potential of a given location, by developing a spatio-temporal probabilistic model for high-resolution wind data, gathered by the West Texas Mesonet network. To ensure parsimony of the model without oversimplifying the complexity of the underlying process, a random-effects approach will be considered.",Risk and Uncertainties In Energy Planning,196,168
Risk Assessment and Identification for Food Supply Risks in the Department of Defense," In military operations, evaluating the food supply chain is paramount, necessitating a robust risk assessment and identification framework. Annually, military organizations must scrutinize their existing food supply contracts and make decisions regarding renewal or engagement with new suppliers, all while contending with multifaceted risks, especially during crises. This paper introduces a novel data-driven methodology designed to identify and assess risks inherent in the military food supply chain, with a particular focus on factors that pose potential threats to its stability. Drawing inspiration from Supply Chain Risk and Crisis Management literature, the paper amalgamates various elements to build a risk assessment methodology. This approach incorporates qualitative and quantitative risk factors, utilizing historical data and expert consensus through the DELPHI method. The resultant methodology provides a comprehensive analysis, yielding risk indices at various stages of the military food supply chain. To demonstrate the practicality and efficacy of the proposed framework, a paper is presented, examining the risk factors associated with a military food supply chain during a crisis, such as natural disasters or geopolitical events. The model is tested and validated using historical data, showcasing its applicability in different scenarios. Results indicate that the model effectively identifies and quantifies risk factors within the military food supply chain, providing decision-makers with valuable insights for proactive risk management. This data-driven risk assessment methodology is not only implementable but also enhances the resilience and stability of the military food supply chain, contributing to strategic decision-making in times.",Supply chain Risk & resilience 1,219,169
Workforce Planning through Process Mapping: A Case Study at the Cape Breton Cancer Centre," Background In a new healthcare facility, it can be a challenge to determine the workforce that will be required for patient care. The Cape Breton Cancer Centre currently serves 45,000 patients per year, triple for which it was designed. A new building is under construction, but there is a need to estimate the number of clinical and clerical staff that will be required for the facility's operation. Methods We process-mapped 38 patient flows within the new Cape Breton Cancer Centre, identified roles, and estimated process times and probabilities for each decision point through a series of process mapping exercises with staff members. We considered patient, non-patient-associated activities, time away from work, and the current and future forecasted patient volume. This allowed us to calculate the current and future number of staff, for each role and within each clinic, enumerating the workforce that will be required. Validation of these calculations is underway with current Centre management. Significance For the first time, this approach will be used by Nova Scotia Health to determine staffing requirement for the new facility. The process maps will aid initial operation of the facility and future planning as they form the basis of the facility's operational procedure documents. We believe our process mapping approach for workforce planning is applicable across sectors for planning resources to meet demand.",Resource Allocation and Workforce Planning in Health Systems,193,170
Operational Excellence: Efficiency in Work Measurement and Impactful Results in Banking," The project was conducted at a commercial bank in Puerto Rico. The first phase involved measuring a repetitive task using the stopwatch method, the second phase used Methods Time Measurement, and the third involved Work Sampling for a non-repetitive and multi-task operation. The first and second phases took place in the Claims Department to obtain normal and standard time. A sample size of 165 data points was collected, divided into three elements: first, verifying customer information; second, investigating the claim; and third, documenting the resolution. Control charts were generated for each element to assess process control. It was recommended to add a third monitor placed vertically for better visibility and to change the logical order of the systems on the screens to encourage smoother information flow. In the third phase, a single employee in the forms management department was evaluated. The goal was to identify productive and non-productive tasks. A total of 300 observations were collected, with 37 (12%) identified as non-productive and 263 (88%) as productive. Using the Westinghouse method and ILO standards, total compensation was calculated at 28.7%, and a rating factor of 1.23 was determined. This information was used to calculate normal and standard times for each productive task and provided recommendations based on activities that consumed the most time, aiming to create a balance between tasks. It is concluded that their application can be effective and have a beneficial impact on any company, whether in the pharmaceutical or service industry.",Poster Presentations,169,171
Enabling Personalized Design with Digital Twin and Generative Design," The current industrial revolution, Industry 4.0, has had a profound impact on how things are manufactured. The advent of the Internet of Things, digital twins, big data, and extended reality has made manufacturing more flexible and given deeper insights into manufacturing systems. This has led to offering the customer more design choices. The average consumer has grown to expect this, demanding the ability to customize products even more. This has led to the manufacturing paradigms of mass customization and mass personalization. The difference between these two is the role the customer takes in the design process. In mass customization a set number of choices are offered to the customer to select from. In mass personalization the customer takes an active role in the design of the product, offering input on design requirements and functional needs. Most research around mass personalization has been on how to produce in small to one batch sizes, but because of the increased customer involvement in the design phase more attention should be given to designing personalized products. The key issues with personalized design are the time and resources invested in the design phase and in gathering accurate requirements. This work will explore solving both problems. The first phase will focus on creating a customer/product interaction digital twin. The second phase will focus on creating a design system that will generate a set number of design possibilities. Combining the outcomes of these two research phases will explore a feasible solution to the personalized design problem.",Digital Manufacturing and Industry 4.0-III,47,172
Using Data Analytics and LMS to Improve Teaching," Many universities use Learning Management Systems (LMS) such as Canvas or Moodle. In addition to posting assignments, collecting homework, and recording grades, there is much more an LMS does. These systems collect a wealth of data. A single item in a system, such as a video lecture, will have data on the student utilization, time spent on the activity, and when the item was used. Most instructors either ignore this information or do not even know the LMS collects it. In this presentation, we will demonstrate how analysis techniques can be applied to this type of data to improve the quality of teaching and learning in higher education. Questions about how material is being used or not can be answered. Differences between the more successful students and the struggling students can be identified. Along with many other results to improve the learning process.","Data Analytics in Controls, Measurement, and Education",36,173
Introducing Discrete Event Simulation to Facility Leadership," Pratt and Whitney is in the process of revitalizing its Industrial Engineering discipline. As part of this effort, Plant Simulation has been selected for expanded use across the company. Several methods have been employed to increase adoption and utilization of simulation including multiple small projects across different sites, a large high-visibility project, and information sessions at all hand events. The response to these methods is positive but follow-up engagement varies. We found that introducing simulation during smaller standard work improvement events helps foster greater acceptance and utilization. Simulation has been able to help the team visualize process flow and provide feedback on the design. This decision support effort has been the most successful in getting buy-in from facility leadership and follow-up requests. We believe this method to be successfully reproducible at other enterprises.",Poster Presentations,169,174
Willing to charge smart? Preferences for smart charging contracts for plug-in electric vehicles," A comprehensive charging infrastructure is necessary to support widespread deployment of plug-in electric vehicles. In addition, it is crucial to provide smart charging solutions to manage significant plug-in electric vehicle loads, provide ancillary services to the grid, scale up intermittent renewable energy use, and reduce the overall cost of the energy system. This study investigates relevant determinants for current and potential plug-in electric vehicle drivers’ willingness to accept smart charging contracts in a scenario where the main objectives of the energy provider are the management of intermittent renewable energy sources and grid stabilization. Using a choice-based conjoint analysis, this paper will analyze preferences for both one directional and bi-directional smart charging contracts considering tradeoffs between charging convenience, control of the vehicle by the energy provider, remuneration, flexibility, and CO2 emission reduction. Additionally, the influence of battery degradation concerns on the willingness to accept smart charging contracts based on vehicle-to-grid will be determined. A comparison of consumers in the United States and Germany reveals how differences in preferences in the two countries are influenced by technical, socio-economic, and cultural factors. The approach employed results in statistically relevant insights that apply to a larger population and can inform decision making on the design of smart charging contracts.",Decarbonizing Mobility,37,175
Rule-Based Detective Model for Medical CPT Coding Errors in an Outpatient Community Health Medical Center," Medical coding has been in place for years in the healthcare industry and has been constantly evolving. Errors in medical coding can happen for multiple reasons such as improper understanding of medical coding guidelines, the complexity of the coding systems, and continuous changes in medical coding. This paper develops a computer support rule-based model that detects certain types of medical CPT coding errors in an outpatient rural setting. The Python-based model can detect three types of predefined errors: under-coding, over-coding, and mismatched codes. Each error type contained several scenarios, or categories, of mistakes. The model was evaluated by medical coding experts using three datasets for validation (1,922 visits), testing (2,132 visits), and implementation (2,031 visits). The model identified 80 percent of the errors flagged by the experts during their review. Mismatched codes are the most common errors and 90% of these errors the model identified were corroborated by the expert panel. The model performance is found to be consistent as the detection accuracy is highly similar for each error scenario using the three evaluation datasets. Based on the results, the model can be effectively used to reduce the labor time and cost needed for manual audits by medical coders, generate more revenue, reduce costs of miscoded visits and claims, and improve the coding practices and accuracy. The expected annual monetary benefit of the model at FLCH is between $70,000 and $100,000. The model can be implemented at any outpatient medical center, as medical coding is standardized and universal.",Healthcare I,83,176
Case Study; A Practitioners Guide to Implementing Supplier Risk Modeling," Within the Department of Defense, ensuring a secure and resilient food supply is crucial for sustaining military operations. This case study introduces a comprehensive risk assessment and evaluation methodology tailored to the unique challenges of the DOD's food supply chain. The focus is on developing a robust framework that facilitates the identification and assessment of risks, with a practical application for evaluating industries within the Department of Defense. Building on established principles in Supply Chain Risk Management, the methodology integrates both qualitative and quantitative risk factors, leveraging historical data and expert consensus through the DELPHI method. The resulting framework provides a nuanced understanding of the vulnerabilities and potential disruptions within the DOD's food supply chain. To exemplify the methodology's practical application, a case study is presented, examining the risk factors associated with the food supply chain in a DOD context, especially during times of crisis or heightened security concerns. The model is tested and validated, showcasing its adaptability to various scenarios and demonstrating its utility in assessing and mitigating risks specific to DOD industries. The results affirm the efficacy of the proposed methodology in evaluating food supply risks within the Department of Defense. By providing decision-makers with actionable insights, this data-driven approach becomes an invaluable tool for proactively managing risks and enhancing the resilience of DOD industries. The application of this methodology not only strengthens the DOD's ability to address potential disruptions but also contributes to strategic decision-making, ensuring the continued availability and security of the military food supply.",Supply chain Risk & resilience 2,220,177
A Systematic Literature Review of Application Processes," Our comprehensive literature review delves into an extensive analysis of application methodologies, drawing insights from both military and civilian spheres. This meticulous review incorporates various criteria crucial to assessing an applicant's overall suitability. Factors such as biodata, prior experience, intelligence tests, psychological assessments, education, job knowledge, and health records serve as pivotal indicators informing our assessment process. While each factor contributes significantly to candidate evaluation, our in-depth analysis underscores that biodata, prior experience, and intelligence tests exhibit the most substantial commonality and relevance across multiple studies. The selection methodologies highlighted in these studies employ a judicious blend of quantitative and qualitative measures, aiming to discern the positive correlation between these factors and the overall success of candidates within an organization. We completed a systematic literature review to assess the success of application processes, which practitioners can use to determine the success of a future applicant.",Work Systems I,240,178
Order Batching Optimization for a Warehouse Digital Twin Based on Heuristics and Mixed Integer Programming," A warehouse digital twin is a virtual model that can accurately simulate and capture the key functional attributes of physical system operations including order-picking. Order-picking is a labor-intensive task that often contributes to over 55% of the warehouse operating costs. With growing online orders and customers demand for rapid delivery, commercial warehouses have sought to exploit dynamic order-batching optimization software in their product retrieval processes. However, order-batching is an NP-Hard problem that requires grouping the received orders into batches before beginning the actual shelf-picking process. This study introduces a warehouse digital twin based on a discrete event simulation platform which incorporates practical constraints when performing the dynamic order-batching process. To address the limitations of existing order-batching optimization algorithms, a hybrid method employing a heuristic algorithm and mixed integer programming technique is proposed. Specifically, a seed algorithm is employed for batching customer orders in near real-time. The methodology utilizes practical three-dimensional bin packing constraints such as volume, stacking, orientation, and weight. Feasible batching solutions are then determined by using the CP-SAT solver. Simulation tests with experimental data from an Australian furniture company show a throughput time reduction of 13.3% using proposed dynamic order-batching algorithm. Furthermore, the study also showed that 7.6% of the batches could not be picked in a single tour if the practical constraints were not adequately considered by the algorithm. The research results demonstrate that the effectiveness and efficiency of the order-picking optimization process can be theoretically improved by integrating real-world considerations into the digital twin model.",Logistics & Supply Chain Best Paper Competition,121,179
Unveiling Patient Insights and Experiences: An Integrated Approach to Multi-Criteria Topic Modeling and Classification," ""This paper unveils a pioneering two-phase integrated framework for analyzing patient experience surveys. The first phase employs unsupervised sentiment and multi-criteria topic modeling using BERT and LDA algorithms, while the second phase involves supervised multi-label classification using BERT and RF algorithms. Leveraging 1772 patient comments from Finger Lakes Community Health (FLCH), our approach demonstrates robust performance, facilitated by the model's multi-label capability that allows discernment of multiple topics within each patient comment. The sentiment analysis revealed 59.1% positive, 26.3% negative, 8.4% mixed, and 6.2% neutral comments. The topic analysis identified seven topics including scheduling, care and service quality, experience with staff, call center, prescriptions and labs, waiting time, and other issues. Notably, the care and service quality topic received overwhelmingly positive sentiments (74.6%), while the call center and waiting time topics exhibited high negativity (66.1% and 70.3%, respectively). The text classification models, particularly the BERT-based model, demonstrated strong performance with balanced accuracy ranging from 82% to 97%. The call center topic achieved the highest balanced accuracy (93%) in the RF-based model. The study contributes to healthcare analytics, providing actionable insights for administrators to enhance patient satisfaction and underscores the efficacy of sentiment and topic modeling approaches in understanding diverse patient experiences.""",Healthcare IV,86,180
IMPROVING CUSTOMER SATISFACTION BY IMPLEMENTING WORK MEASURES AND JOB DESIGN," Companies are required to use proper methods to reduce their costs and increase productivity levels so that they can promote the competitive conditions of the existing business environment. Work study conducted in House of Sports by Dick’s Sporting Goods helped us understand the importance in the application of those highly effective productivity improvement methods in labor dependent industry, while focused on customer satisfaction. This work was divided into three (3) phases. Phase I and II – Stopwatch technique and MTM on cash register, and Phase III – Work Sampling on the Assistant Store Manager (ASM). Determination of standard times is one of the important steps of a work study that provides a critical input for process improvement. Work sampling, based on statistical technique that involved random observation of the ASM activities to assess the productivity and efficiency, as well as, allowing us to identify work patterns and resource for optimization. For the cash register operation, we applied the stopwatch technique and MTM obtaining a % difference between them of 3.7% showing an accuracy in the conduction of the study less than 5%. This states that the observation and data collection were in control. As for the ASM, the work sampling showed a decrease in the standard time regarding the observed time, which implies an increment in productivity and efficiency of 2%. The application of work study and job design are crucial to improve productivity, help establish expenses and labor standards as well as work environment in any business field.",Poster Presentations,169,181
A Moderate Realist Worldview of Soft Systems Methodology: Strengthening Flexibility with Objectivity," Soft Systems Methodology is a systems approach designed to bring about resolution when conflicting interests and perspectives between stakeholders exist in an organization. It has been perceived by practitioners to provide value through its adaptability, flexibility, ability to identify points of conflict between stakeholders that may require intervention, and ability to improve communication by recognizing multiple stakeholder perspectives. Despite its strengths, Soft Systems Methodology has limitations. The methodology's flexibility means that each organization requires separate modeling practices that are not necessarily replicable. The fact that Soft Systems Methodology is, at its core subjective, limits the real-world applicability of the methodology to objective applications. Additionally, the models used in Soft Systems Methodology are not taken to represent real-world applications due to their constructivist nature, which inhibits the applicability of the methodology’s results. Efforts have been taken to remedy these limitations by supplementing Soft Systems Methodology with other systems modeling techniques. However, these new approaches are still applied only in individual contexts, and thus still lack a holistic interpretation of the systems to which they are applied. To address these limitations, this research utilizes a moderate realist perspective to 1) propose applicable levels of abstraction for modeling all kinds of purposeful human activity systems, 2) expand Soft Systems Methodology by integrating the proposed levels of abstraction, and 3) provide an example application of this framework. This approach will help practitioners apply Soft Systems Methodology in a general context while addressing the limitations in replicability and representation of real-world situations.",SE Concepts and Theory,199,182
On Solving the Maximum Value Dynamic Network Flow Problem," Some network flow applications require dynamic network flow solutions characterized by a schedule of flows consecutively transmitted over a sequence of successive periods. For these schedules, we assume flows transmit via arcs during periods while flows reside at nodes from one period to the next. Within this context, we introduce the Maximum Value Dynamic Network Flow Problem (MVDFP) in which we seek to maximize the cumulative value of a non-simultaneous network flow schedule that accumulates node value whenever some minimum amount of flow resides at a node between periods. For solving the MVDFP, we first introduce a large mixed-integer program (MIP). As this MIP can become computationally-expensive for large networks, we also present a computationally-effective heuristic that sequentially solves a series of smaller, more manageable MIPs. This heuristic approach determines a high-quality solution significantly faster than the MIP obtains an optimal solution by dividing the full network flow schedule into a sequence of consecutive shorter network flow subschedules. In many cases this approach produces an optimal solution in a fraction of the MIP’s computational time. We present extensive computational results to highlight our heuristic’s efficacy and discuss future research avenues.",Methods in Network Optimization,144,183
Navigating Aerospace Challenges : A Real World Problem Solving Journey," What: The Boeing Company is facing issues with receiving damaged parts from a supplier, impacting flow time to our fuselage build and increasing costs. This presentation showcases the journey of problem solving, driven by the need to ensure 100% first pass quality and eliminate delays in aircraft deliveries. We traced the part lifecycle from supplier production to factory installation and found two out four fuselage sections are consistently damaged. Why: Delays in repairing and replacing damaged parts hinder delivery schedules, making it imperative to uncover the root cause. Our aim is to present genuine industry difficulties, emphasizing the application of practical problem-solving techniques. Benefits: This root cause analysis will drive solutions that are anticipated to reduce repair costs by 65%, streamlining part transport and installation. Tools: The Boeing Problem Solving Model (BPSM) for a structured lean approach, the Production Preparation Process (3P) for the creation of a new system, the Manufacturing Execution System for manufacturing scheduling, time study analysis for work efficiency ,Tableau reports for data collection, cross-functional workshop, Gemba walks and benchmarking.",Organizational Culture,157,184
Smart maintenance framework in an Industry 4.0 using blockchain and smart contracts," This research addresses the potential implementation of Blockchain Technology as a decentralized database and smart contracts into maintenance management within the Industry 4.0 paradigm. The preliminary objective is to investigate the blockchain’ role as a transformative tool in enhancing transparency, traceability, and efficiency in maintenance management. This study includes a thorough literature review, pointing out the gaps in the Industry 4.0 era, maintenance management, and blockchain technology. By leveraging blockchain’s decentralization and immutable characteristics, the research develops a smart contract-based system to integrate blockchain into maintenance operations, focusing on the overall process efficiency and the design of a blockchain-based architectural framework. The key aspects of this methodology are the smart contracts to automate and regulate maintenance tasks, providing immutable maintenance records, and a user-friendly interface for stakeholder engagement. The development of this proof of concept demonstrates valuable enhancements in process efficiency, accountability, and data security. The significant contributions of this study are instrumental for practitioners in optimizing maintenance activities in the Industry 4.0 context. Overall, this study provides good insights for broader explorations in implementing blockchain technology with other disruptive technologies such as Internet of Things and Artificial Intelligence, to more advanced maintenance management in Industry 4.0.","Smart and Sustainable Maintenance: Machine Learning, Blockchain and Circular Economy Approaches",208,185
The Impact of Investment in Technology and Learning Techniques in Work Design and Ergonomics Lab for Diverse and Inclusive Interest of ISE Students in Human Factors and Ergonomics," Ergonomics and Industrial Engineering intersect at one of their most important objectives: promoting productivity and efficiency while easing discomfort. This research conducted at Rutgers University's Work Design and Ergonomics lab delves into the impacts of improved laboratory experiences on student motivation and their choices in senior design projects within the field of Human Factors and Ergonomics (HF/E), paying special attention to gender and ethnic diversity. The study methodically examined the technological enhancements in the lab and their subsequent influence on student participation in HF/E-related senior design projects, employing statistical analysis to discern participation discrepancies across different gender and ethnic groups. The results revealed a significant link between laboratory advancements and an upsurge in student engagement in HF/E-related projects post-2019, with notable variations in involvement among diverse ethnic groups, especially Middle Eastern Amer and Hispanic American students. Although there was an increase in female participation, it was not as statistically significant as the marked increase observed among male students. Ultimately, the study underscores the critical role of practical laboratory experiences in shaping students' interests in HF/E and brings to light considerable disparities in participation based on gender and ethnicity. These insights point to the urgent need for more inclusive and equitable educational practices and highlight the importance of ongoing efforts to boost ethnic diversity in the field of ergonomics education.",Inclusive Excellence in ISE Education,100,186
A Simulation Based Scheduling Tool for Herbicide Manufacturing," The Nufarm facility in Chicago Heights produces a wide range of herbicide formulations for the agricultural, turf and specialty markets in North America. Estimating the capacity of the system is difficult for 2 main reasons: Random downtime events. Capacity is directly and significantly impacted by product mix, which changes monthly, and production sequence. Without a good understanding of system capacity, production plans may be unachievable. If production plans are not achievable, demand planning falls out of sync and last minute “hot orders” must be accommodated. These last-minute changes break campaigns previously optimized for productivity, reducing actual capabilities of the facility, introducing even more error into long term plans. Without accurate planning, materials cannot be given adequate notice to provide resources to the line. This further causes the production schedule to be missed, creating another negative reinforcing loop. A discrete event simulation model was developed, validated, and used to: Create facility capacity estimate tables for a variety of product mixes. These included risk profiles to allow understanding the likelihood of success, given the random nature of equipment downtimes. Use the simulation model on a long-term, monthly basis to run firm planned orders or work orders. The simulation model includes washout (changeover) minimization logic to provide Nufarm with the optimal sequence of products to run over the course of the month. The tool allows planners to understand where the system is over or under planned, so they can pull forward demand from future months.",Manufacturing,132,187
A branch-and-price algorithm for emergency humanitarian logistics with a mixed truck-drone fleet," Humanitarian aid distribution often prioritizes rapid relief operations or emergency services under time constraints, as opposed to commercial transportation problems, where the primary objective is to minimize operational costs. Drones can offer immense potential to achieve this goal by leveraging their aerial mobility. Specifically, drones can surpass ground transportation and navigate directly through disrupted or inaccessible roads, ensuring the quickest path to deliver aid where the ground vehicle may face obstacles. However, drones have limitations in terms of flying range and load capacity. To effectively provide time-sensitive emergency services, combining a ground vehicle with one or more aerial vehicles enhances coverage. Our approach integrates a truck as a mobile depot for multiple drones, where a drone battery is replenished on landing after a flight, and the fleet operates in tandem to serve the locations visited. We formulate a mixed-integer linear programming (MILP) model to maximize the weighted sum of locations served by this mixed truck-drone fleet under time constraints. We further develop a branch-and-price algorithm to solve this problem, where the pricing subproblem is solved using dynamic programming recursions with dominance rules. Our results demonstrate the computational superiority of this method compared to a commercial optimization solver and its potential for expediting aid distribution during an emergency.",Methods in Network Optimization,144,188
Robust Queue Inference from Waiting Times," Observational data from queueing systems is of great practical interest in many application areas since it can be leveraged for better statistical inference of service processes. However, these observations often only provide partial information of the system for various reasons in real-world settings. Moreover, their complex temporal dependence on the queueing dynamics and the absence of distributional information on the model primitives render estimation of queueing systems remarkably challenging. To this end, we consider the problem of inferring service times from waiting time observations. Specifically, we propose an inference framework based on robust optimization, where service times are described via sets that are calibrated by the observed waiting times. We provide conditions under which these data-driven uncertainty sets become asymptotically confident estimators of the service process, i.e., they contain unknown service times almost surely as the number of observations grows. We also introduce tractable optimization formulations to compute bounds of various service time characteristics such as moments and risk measures. In this way, our approach is data-driven as well as free of distributional assumptions on unknown model primitives, which is required by existing methods. We also generalize the proposed inference framework to tandem queues and feed-forward networks, offering broader capability in estimation of real-world queueing systems. Our simulation study demonstrates that the proposed approach easily incorporates information of arrival processes such as moments and correlations, and performs consistently well on queueing networks under various settings.",OR Methods,151,189
Revolutionizing Urban Delivery: Integrating Automated Charging Stations into the Drone Resupply Model for Enhanced Efficiency and Range," The advent of the COVID-19 pandemic in 2020 catalyzed a paradigm shift in the global delivery market, exponentially expanding its scope and scale. This unprecedented growth brought to the fore the critical challenge of optimizing delivery systems for speed, accuracy, and efficiency. Traditional delivery methods, particularly in urban and inaccessible areas, have struggled to keep pace with these evolving demands. In response, this study presents a refined approach to the existing drone resupply model, integrating of automated drone charging stations. The drone resupply model increases the efficiency of drones with the reliability of human couriers, ensuring a swift and precise delivery mechanism. The incorporation of automated charging stations strategically addresses the challenge of maintaining drone operational readiness, significantly enhancing their availability, and extending their operational range. The proposed mathematical model demonstrates an extended operational duration compared to existing drone-based delivery systems, indicating a leap forward in delivery optimization.",Poster Presentations,169,190
Megacity Dhaka: Escalating Threat to Atmospheric and Public Health Unsustainability," Particulate matter and gaseous emissions in Dhaka’s atmosphere make it one of the most environmentally unsustainable cities in South-Asia. The megacity’s air quality is not only hazardous to human health but also a perpetuating exacerbation to climate, some consequences being atmospheric degradation, weather fluctuations, environmental disaster, acid deposition in environment, chronic health diseases, increased mortality rate, and monetary depletion of Bangladesh. Dhaka’s traditional brick kiln factories are one of the culpable sources of degraded air quality. Certain brick kilns are corrosive to the natural habitat, human health and society. Environmental authorities will find long-term benefits in considering advanced environment-friendly technologies and in replacing traditional clay-fired bricks with green bricks (‘eco-bricks’). Responsible leaderships, Bangladesh DOE, MEFCC, and HBRI are encouraged to apply strategies in leading the nation to shift from the old, energy-intensive factories to modern, efficient and environment-friendly options. More proliferate research investigations and publications containing constructive recommendations wherever applicable will add value in assisting the Bangladesh Government and in improving Dhaka’s atmospheric pollution.",Poster Presentations,169,191
Using Machine Learning to Analyze Hospital Admissions," This work studies the application of changepoint detection on daily hospital patient admissions to develop a decision support system for hospital management. Changepoint detection is a statistical technique used to identify abrupt shifts or changes in a time series. By employing this statistical technique to identify shifts in admission trends, this system aids healthcare administrators in optimizing resource allocation, responding to structural changes due to external factors, improving operational efficiency, and offering predictive capabilities for capacity planning. We demonstrate the potential of this approach in enhancing patient care, resource optimization, and healthcare service delivery.",Machine learning in health systems,131,192
Using Model-Based Systems Engineering to Successfully Replicate Business Operations for a Startup Food Delivery Company," In the dynamic landscape of the food industry, the success of startup food delivery companies hinges on efficient and scalable systems to meet the demands of a rapidly expanding market. This research project adapts the formalized methodology of model-based systems engineering (MBSE) to support a small business startup operations expansion. An adapted MBSE methodology was used to create a replicable business blueprint specifically for a campus food delivery startup. This startup is based on hyper fast delivery, which means this model has an emphasis on quick internal processing and delivery. The current state was captured in a variety of different viewpoints or artifacts to simplify communication of the complex business. A use case diagram provides a high-level look at key stakeholders and their major responsibilities. Activity diagrams map out the specific steps in major processes. Block diagrams are used to capture context and display the system structure. These artifacts and more were then analyzed and updated to improve operations and overall customer service. These artifacts for the optimized operations were used to rapidly replicate operations on another campus. An overview of how MBSE was adapted for the startup environment and an assessment of the methodology’s usefulness for rapid expansion will be presented. This project contributes valuable insights into the establishment of a small delivery service, offering a roadmap for startup companies to navigate the complexities of their initial expansion phases while fostering a resilient business model.",SE Methods and Applications,200,193
Machine Learning Based Progressive Hedging Algorithm for Uncertain Integrated Energy Systems," Progressive hedging (PH) is a classical decomposition algorithm for solving multistage stochastic problems. In this research, we propose a planning method and use the PH algorithm to address regional integrated energy systems considering the uncertainty of multi-energy loads in cooling, electricity, and heating. Based on the classical improved energy hub (EH) model, we establish a regional integrated energy system model, which includes CHP, electric boilers, gas boilers, electric chillers, absorption chillers, batteries, thermal storage, and cold storage to solve an energy optimization problem. Utilizing historical/forecasted 8,760-hour multi-energy load data, we derive multiple typical daily load scenarios. This model is then equivalently transformed into a mixed-integer programming model with convex subproblems for solution. We develop a new PH algorithm based on machine learning techniques. Case study results demonstrate the effectiveness of this planning method and simultaneously show that the proposed machine learning based PH algorithm outperforms directly invoking the PH algorithm.",Risk and Uncertainties In Energy Planning,196,194
Multimodel Transportation based Reconfiguration towards Sustainable Supply Chain Managment," Even though multimodal transportation has been frequently applied in international supply chains, it has been scares adopted in domestic agri-food supply chains to achieve sustainability. With the perishable nature of agri-food, the reduction in food miles and travel time has directly impacted the receiving quality for customers. Furthermore, transportation costs are directly influencing the price fluctuations of the vegetables. Being restricted to the unimodal transportation structure results in a high empty truck return frequency, which is leading to global warming potential (GWP). Therefore, it is timely to investigate how multimodal transportation strategies can impact reducing food miles, lead time, transportation costs, and emissions. In this study, multimodal transportation has been tested for the Sri Lankan main-stream vegetable supply chain, combining truck and railway transportation. A sample of farmers, economic centers, and retailers was derived using multistage sampling combined with the Perato principle at each stage. The existing and multimodal transportation adopted configurations were simulated as an agent-based simulation model in a simulation environment and compared in terms of food miles, lead time, transportation cost, and emissions. Results of the simulation model demonstrated that the application of multimodal transportation strategies to the main stream vegetable supply chain in Sri Lanka was capable of reducing food miles, lead time, transportation cost, GWP and empty truck return significantly. In further studies, intermodal transportation strategies can also be combined with multimodal transportation strategies to test potential further reductions in performance measures.",Renewable Sustainable Supply Chains (SDG 12),189,195
Collaborative Optimal Design," Optimal design is a critical yet challenging task. This challenge arises from the need for extensive trial and error. Fortunately, Bayesian optimization has played a key role in accelerating the design process through efficient sequential sampling strategies. However, a key opportunity exists nowadays. The increased connectivity of edge devices sets forth a new collaborative paradigm whereby different clients effectively distribute their experimentation efforts to improve and fast-track the design process. To this end, we bring the notion of consensus to Bayesian optimization, where clients reach a consensus on their next-to-sample designs. Our approach provides a generic and flexible framework that can incorporate different collaboration mechanisms. Theoretically, we show the sub-linear growth in regret for our proposed framework. Empirically, through a real-world collaborative material discovery experiment, we show that our framework can effectively accelerate and improve the optimal material discovery process and benefit all participants.",Manufacturing III,137,196
Optimizing Graph Representations with Generative Models for Predicting Multiple Chronic Conditions," Predicting the development of multiple chronic conditions (MCCs) is a crucial yet intricate challenge in contemporary healthcare. Effective management and treatment of MCCs require precise and early identification of at-risk individuals. This study introduces a groundbreaking two-stage graph generative model designed to address this need by enhancing the predictive accuracy of MCC progression. The first stage of the model employs a Graph Auto-Encoder (GAE) to refine patient similarity graphs, effectively optimizing the latent space representation of patient data. This optimized representation captures complex relationships and patterns in patient histories and characteristics, enabling a more nuanced understanding of patient health trajectories. The second stage leverages an advanced Graph Neural Network (GNN), capitalizing on the refined graph structure to predict the progression of MCCs with heightened accuracy. By integrating these two cutting-edge technologies, our model provides a robust framework for understanding and anticipating the complex dynamics of MCC development. The model's efficacy is demonstrated through its application to the Cameron County Hispanic Cohort study dataset, a rich source of patient data with significant implications for public health. The results showcase a marked improvement in performance compared to traditional predictive models. This enhancement underscores the potential of our approach to revolutionize predictive healthcare analytics, offering a more personalized and proactive approach to managing MCCs. In conclusion, this study paves the way for advanced, graph-based methodologies in the realm of healthcare prediction, setting a new standard for precision medicine and patient care optimization.",Healthcare IV,86,197
Unlocking Census Insights: A Comprehensive Workflow Integration of Census API and ArcGIS API for Python with Emphasis on Statistical Implications," This presentation dives into the statistical implications of selecting the appropriate American Community Survey (ACS) estimates and outlines a workflow to track the estimates by synergizing the functionalities of the Census API and ArcGIS API for Python to harness the full potential of demographic, social, and economic data. The American Community Survey is conducted on a rolling basis and is summarized into single-year and multi-year estimates. Single-year estimates are more current and sampled from geographical areas with a population of 65,000 or higher. For smaller populations, only multi-year estimates exist as data from multiple years are pooled to reduce the sampling error. Considerations of confidence interval, currency, overlapping data inform the choice of these period estimates. The Census API offers the functionality to query many census datasets, including the ACS. A script-based workflow utilizing the Census API allows for consistent tracking of the selected estimates, and integrating the ArcGIS API for Python in the script opens up visualization and dashboarding capabilities. The presentation provides a walkthrough of the workflow through an example of visualizing socio-economic indicators across the cities of Georgia.",Poster Presentations,169,198
NetworkTouch: A haptic device for network traffic monitoring and cyberattack detection," The volume of contemporary network traffic makes monitoring and visualizing information challenging for human operators. Therefore, effective tools for network traffic monitoring and analysis are needed to gain situational awareness to cybersecurity threats. This work develops a vibrotactile feedback system, NetworkTouch, to assist users in monitoring network traffic for cyberattacks, relying upon innate human perceptual abilities to detect changes in traffic patterns. To mitigate potential issues with the phenomenon of change blindness, a hand-shaped, rest-able desktop device is designed to condense traffic until the operator decides to “check-in” for a replay, as opposed to being pushed notifications or receiving continuous feedback. Multiple elements of network communication are mapped to variables of the haptic message. For example, binary TCP control flags are assigned to specified fingers, whereas temporal changes in frequency of TCP control flags are mapped to a set of diverging vibrational patterns presented to successive fingers as a wave. Perceptual studies on the NetworkTouch device were conducted to (a) evaluate rates of change detection, (b) recognition of the five vibrational patterns and differentiability between them, and (c) cyberattack detection of simulated port scan and synchronization flood cyberattacks. The results indicate the five patterns are detectable, differentiable, and recognizable per finger, with accuracies above 85%. Moreover, without extensive training or knowledge of network traffic, all participants could readily detect simulated cyberattacks amidst normal traffic.",Modeling & Simulation for Human Factors and Ergonomics,146,199
Optimizing Support Services for Individuals with Disabilities: A Lean Six Sigma Approach," Happiness Bag, Inc., located in Terre Haute, Indiana, stands as a unique facility committed to delivering tailored educational experiences, recreational services, and purposeful programs catering to individuals with disabilities, spanning from five-year-olds to adults. In a collaborative effort, the Six Sigma Project Class at Rose-Hulman Institute of Technology joined forces with Happiness Bag for DMAIC and Lean projects in both the 2022 and 2023 spring quarters. The primary focus of our most recent spring project was to optimize the functionality of Happiness Bag's facilities. Specifically, we aimed to enhance the durability and accessibility of equipment for administrators and staff while concurrently creating more efficient storage solutions for both staff and program participants, referred to as ""friends."" Through a strategic reorganization and thorough cleaning of existing building spaces, our objective was to provide a more streamlined and effective facility, temporarily meeting their needs as they await donations and secure grant funding for an extensive expansion. This presentation illuminates the specific actions undertaken by the class, employing the lean and DMAIC tools and techniques taught in Lean and Six Sigma Courses, to achieve the outlined objectives and contribute to the improvement of Happiness Bag's operational efficiency and overall effectiveness.",Optimization,154,200
GRI Standards for Environmental Sustainability – A Brief Review," Considering the United Nations (UN) 2030 agenda, understanding sustainability goals related to Environment, Society, and Governance (ESG) and their proper reporting are pivotal for transitioning to sustainable development. Sustainability disclosures and their reporting related to ecological sustainability have become necessary due to prevailing climate crises, global warming, and climate change-related issues. Researchers also linked the corporate carbon disclosures to the firm's market value. Literature on sustainability reporting guidelines and standards is also in the development process by different bodies - Global Reporting Initiative (GRI), International Sustainability Standards Board (ISSB), European Financial Reporting Advisory Group (EFRAG), etc., under diverse headings, terminology, and publications. It is still evolving, thus creating a challenge for user organizations to properly understand their purposes and applications, which leads to inconsistent and incomparable reporting practices among organizations. Therefore, there is a need to brief and simplify the framework/structure of global sustainability reporting guidelines and standards for business managers and practitioners, sustainability managers, academia, and researchers. This paper reviews and simplifies the structure of Global Initial Reporting (GRI) Standards issued by the Global Sustainability Standards Board (GSSB) first and then explains the GRI environmental standards (GRI 300 series) and their application for organizations to align their organizational goals with UN Sustainable Development Goals (SDGs), and reporting their sustainability performance related indicators along with financial statements so that investors and other stakeholders could be able to make informed capital allocation decisions.",Industrial Engineering Solutions for Sustainability Planning and Reporting,101,201
Productivity Unboxed: A Productivity Study of a Bag-in-Box Production Line searching for Enhanced Performance.," Introduction In this study, the purpose is to analyze the production floor productivity of a post-mix syrup filling and packaging line. This is to identify current problems in the line and establish recommendations for improvement. Method The method used is the work sampling for non-repetitive and multi-task operation method. Random data sets were obtained from the production line at random times of the day and verified that each machine was up and running. If there was any equipment idle, the reason why was identified and wrote down. Based on these notes, an analysis of the productivity of the line was carried away and recommendations were given. Results and Discussion After an extensive analysis of the data gathered, the following were obtained. The productivity percentage of the line is 54.69% and the idle percentage is 45.37%. The main reason that causes this idle percentage is that Warehouse doesn’t pick the pallets, however that issue is out of the manufacturing team’s control. Another reason for the idle percentage were changeovers in the production line and the Person #1 out of cycle. Some of the recommendations are standardizing the changeovers and replacing the Pearson #1 equipment. This would help reduce the idle percentage and increase productivity. An ROI analysis was carried aways to further support the machine change. Conclusion Concluding this study, areas for improvement were identified to increase productivity as mentioned before. These improvements increase productivity, therefore affect positively the production and machine maintenance operators do not overwork.",Poster Presentations,169,202
Views by Design: An Analysis of Meta-Level YouTube Video Features and their Impact on Video Views," YouTube, as the largest video-sharing platform, serves as a vital platform for content creation. Certain meta-level features of a video, such as its title, thumbnail, description, and tags must be optimized in the video creation process to attract viewer attention and maximize the number of views. This research identifies and fills a gap in existing research, there is a lack of a conceptual model which clearly outlines the cause-and-effect relationship between video features and views. The research will explore different features, such as the inclusion of people on thumbnails, use of certain colors, capital letters, and brightness, to show how they impact video views. The objective is to develop a model that not only enhances the understanding of the relationship between video features and views but also offers practical guidance for content creators.",Social Media & Information Analytics,210,203
Powering Healthcare by Switching Gears: Electrifying Vehicle Delivery Fleets with Operations Research," This study addresses the challenge of transitioning a healthcare organization's courier fleet to Electric Vehicles (EVs) in a cost-effective manner. The primary problem tackled was the development of an optimization model to identify the most cost-efficient fleet composition over a forecast horizon. This was done for a specific company in Corvallis, Oregon. The project employed linear programming techniques to construct a model that could determine the minimal-cost solution for replacing the existing fleet. This model was crucial in assessing the feasibility and financial implications of adopting a fully electric fleet. Given the dynamic nature of the EV market and the varying requirements of the fleet, the model needed to be adaptable and responsive to future changes. The solution presented three distinct scenarios: maintaining the current fleet of Internal Combustion Engine (ICE) vehicles, transitioning to a fully electric fleet, and a conservative approach utilizing EVs from established manufacturers. The model's flexibility allowed for adjustments in response to evolving EV technology and market conditions, ensuring that the organization could make informed decisions on fleet composition and investment in the coming years. This approach represents a significant step in integrating environmental sustainability into operational practices while reducing operation costs.","Healthcare for a Sustainable Future: Innovations in Operations, Design, and Environmental Management (SDG 3)",91,204
The Economy of Early Child Development," Research shows that balanced nutrition, good health, and a nurturing environment in the first 1000 days of children’s lives have a strong impact on lifetime well-being and productivity. The second 1000 days are important to prepare children for school life. In the US, there are more preschoolers who face malnutrition, neglect or abuse than in other developed countries. Many government programs provide help. The Food and Nutrition Service (FNS) spent $19 Bil in 2019 on the Supplemental Nutrition Program for Women, Infants, and Children (WIC), and $3.7 Bil in 2018 on the Child and Adult Care Food Program (CACFP). The Children's Health Insurance Program (CHIP) spent $18 Bil in 2018 on health coverage to eligible children. The Children’s Bureau in the Administration of Children and Families provides adoption and foster care. Many NGOs and charity organizations also provide help. However, these programs are for risk mitigation, but insufficient for development. Underprepared children are more likely to face challenges in schools and fewer job opportunities with shorter quality-adjusted life years (QALY). Worse yet, some may be on welfare and even commit crimes. The estimated cost of one unwell person to society can be over a million dollars! They contribute directly to poverty, hunger, poor health, poor education, crime and inequality UNSDG 1, 2, 3, 4 and 10 are to address. The first part of this project is to quantify the costs associated with unwell in early Child Development. The next step is to propose alternative and more efficient solutions.","Building Sustainable Communities: Enhancing Early Child Development, Infrastrucure, Park Access and Industrial Efficiency (SDG 11)",22,205
Solution Path Algorithm for Kernel Distributionally Robust Support Vector Machines," The Distributionally robust optimization (DRO) method has emerged as a robust and effective framework for addressing the challenges posed by data distributional uncertainty in machine learning problems. This paper presents a kernel distributionally robust support vector machine model, which integrates the kernel and DRO methods with the capability of capturing complex, nonlinear decision boundaries, and making robust classifications to a wide array of real-word applications. A solution path algorithm is proposed to efficiently solve this model and speed up the hyperparameter tuning. Numerical experiments are performed on different datasets to validate the efficiency and effectiveness of the proposed approaches.",Machine Learning I,125,206
Determining the Effectiveness of Infectious Waste Management of District Hospitals in Bulacan: A Basis for Infectious Waste Management System," The management of healthcare waste, particularly infectious waste, requires more consideration to avoid the substantial disease burden associated with poor practice, including exposure to infectious agents and toxins that might be encountered by the community and the personnel assigned in the whole process of waste disposal. The study's main objective is to evaluate if the infectious waste management of government hospitals complies with the standard set by the Department of Health (DOH) and to determine workers' knowledge of infectious wastes. A descriptive cross-sectional design was used in the study. A questionnaire was used to obtain information and assess the practices from generation up to transportation of infectious wastes. The target community of the study was the six (6) government hospitals located in the Province of Bulacan. The data was analyzed using inferential statistics, which is a test of hypothesis (one sample T-test). The results indicated that five out of six hospitals comply with the DOH standards with a computed P-value greater than 0.05. The hospitals are compliant, but there is some problem regarding segregation and disposal of hospital waste; preliminary treatment is not always conducted, and some utility personnel only go through a short training; because of this, the researchers provided recommendations that satisfy the guidelines set by the Department of Health.",Health Systems,78,207
Block Relocation Problem Considering Maximum Feasible Cleaning Moves with One Degree of Freedom," The look-ahead algorithm (LA) tackles the block relocation problem (BRP) prevalent in industries like container shipping and others utilizing inventory systems for storing identical cubic items. The BRP involves retrieving identically-sized items in a specified order with the fewest moves from last-in-first-out (LIFO) stacks. An extension of the LA, considering an empty stack in the original bay configuration (one degree of freedom, 1-DOF) with and without a cleaning move, was introduced. The parent LA algorithm and its two extension versions were previously tested. Results showed that the LA extension, featuring one degree of freedom and one cleaning move, outperforms both the original LA algorithm and the extension without cleaning moves. This study further explores the LA extension with one degree of freedom and the maximum feasible number of cleaning moves. Comparative testing is conducted against the original LA algorithm and different versions of the LA extension algorithm.",Innovative topics in supply chain 2,113,208
ADs: Active Data-sharing for Data Quality Assurance in Advanced Manufacturing Systems," Machine learning (ML) methods are widely used in industrial applications, which usually require a large amount of training data. However, data collection needs extensive time costs and investments in the manufacturing system, and data scarcity commonly exists. Thus, an intelligent data-sharing framework is urgently needed to ensure the quality of the shared data such that only beneficial information is shared to improve the performance of ML methods. There still exist two main challenges in tackling this problem: (1) the labeling information is usually unavailable to distinguish data points from different distributions; (2) it is not straightforward to evaluate the “quality of information” in each data point. Thus, an Active Data-sharing (ADs) framework is proposed to ensure the quality of the shared data among multiple machines. It is designed to simultaneously select the most informative data points benefiting the downstream tasks and mitigate the distribution mismatch among all selected data points. To validate the effectiveness of the proposed ADs framework, we collected real-world in-situ monitoring data of one additive manufacturing process from three different machines, and two of them are more similar than the rest. The results demonstrated that our ADs framework is very promising, since it can successfully ensure that data-sharing is conducted between these similar machines, and thereby the ML methods can receive better performance with the high-quality augmented dataset.",Advanced Topics of QCRE I,7,209
Advancing Acute Kidney Injury Management through AI Modeling," Acute Kidney Injury (AKI) is a prevalent and severe condition posing significant challenges in perioperative care, impacting patient outcomes and healthcare resource utilization. This research leverages the transformative capabilities of AI for early risk identification and proactive intervention in AKI, aiming to bridge the gap between AI's potential and its tangible impact on patient care, particularly in the complex socio-economic system of healthcare. From a system engineering perspective, the initiative encompasses three foundational pillars: the development of a machine learning (ML) algorithm to predict and categorize patients at high risk for AKI, and the construction of a Bayesian Belief Network (BBN) model integrated with a Decision Support System (DSS) for comprehensive scenario analysis. These efforts represent a collaborative, interdisciplinary approach to revolutionize AKI management, signifying a shift towards a proactive, well-informed, and data-driven future in healthcare. The potential of this work to significantly impact clinical practices and enhance patient safety is immense, demonstrating the power of integrating advanced analytics with clinical expertise in a complex healthcare system.",AI in Health Systems,1,210
Streamlining Sepsis care for timely intervention within the Critical 'Golden Hour'," Sepsis is a life-threatening medical condition caused by a dysregulated host response to infection leading to high rates of morbidity and mortality. While early warning systems have been developed to assist in the identification and management of sepsis cases based on patients' clinical conditions, there is a lack of extensive research into the influence of organizational factors, such as staffing and communication between healthcare providers, within the complex and dynamic health systems. These factors might significantly influence timely interventions within the critical golden hour in healthcare settings as every hour delay in treatment cause the increase in death rate. The transition into deteriorating condition which lead to the patient outcomes is determined by time to first administration of appropriate antimicrobial therapy and effective source control of infection. This study bridges the existing gap by utilizing Bayesian Belief Network (BBN) algorithms and developing a decision support system (DSS) to proactively identify high-risk patients and facilitate risk-based decision-making for sepsis prevention and management. Additionally, the study underscores the vital importance of integrating systems thinking principles into DSS development, acknowledging diverse perspectives including system, design, people, and risk within sociotechnical healthcare systems. Combining these factors and characteristic of clinical features including biomarkers extracted from prediction model, this study analyze the causal relations between variables to capture knowledge and provide framework for decision making with human expertise in the loop.",Process & Operational Improvement I,177,211
A Connected In-store and Online Customer Data Set for Omnichannel Retail Logistics Research," Omnichannel is a business strategy that works to provide a seamless shopping experience across all channels so that a customer can buy, receive, and return their products using different channels. Omnichannel services, such as buy online pickup in store, in-store returns, ship from store, and home delivery, thus, shift the in-store logistics once done by shoppers to retailers. New innovations are needed in facility design, material handling equipment, and operational policies. In order to support this emerging research area, this work provides new data sets and insights to facilitate relevant omnichannel logistics research.",Facilities Design & Planning IV,74,212
Developing a Systematic Code Structure for a Manufacturing Energy Efficiency Improvement Recommendation Program," For energy audits or consulting for manufacturing facilities, a recommendation code system plays a significant role since it assigns a distinctive code to each different type of recommendation to improve energy efficiency. Another reason for such a well-organized code system is that recording and accumulating the recommendation data is vital as the resultant recommendation database can be utilized for a variety of purposes, including academic research and policy development. Widely used current code systems are, however, not straightforward to use. More specifically, current numerical codes are unintuitive and challenging to interpret without further information. In addition, the content of current recommendations often tends to be overly abstract or duplicative. To better utilize the recommendations later, a more systematic code structure needs to be built. This study therefore aims to systematize the current content and code structure of manufacturing energy efficiency improvement recommendations to facilitate following data analysis. For that, we review the existing systems and develop an alphabetic code system that can overcome the shortcomings of the current systems. Finally, the applicability of the proposed code system is demonstrated by applying it to existing systems.",Energy & Environment I,62,213
New cutting planes for open pit mine production scheduling, Open pit mine production scheduling problem (OPMPSP) is a crucial part of mine planning which entails considering the block model of a mine and determining the excavation sequence over a time horizon with the aim of maximizing the net present value of the profit. The complexity inherent in the problem results in high computation time for large instances. This article proposes adding new cutting planes to the OPMPSP modeled with mixed-integer programming. The model is strengthened through the addition of user-defined cuts developed through a combination of production capacity constraints and precedence relationships amongst the blocks. The efficacy of the developed cuts is tested over a few instances using real mine problem datasets. They are compared with cuts present in the existing academic literature for comparative analysis. The combination of cuts is later integrated into the model to assess the overall impact.,Scheduling/Real-Time Execution,201,214
Real-time Adaptation for Condition Monitoring Signal Prediction using Label-aware Neural Processes," Building a predictive model that rapidly adapts to real-time condition monitoring (CM) signals is critical for engineering units. Unfortunately, many current methods suffer from a trade-off between representation power and agility when dealing with online data. For instance, parametric methods that assume an underlying form for CM signals facilitate efficient online prediction updates. However, this simplification leads to vulnerability to model specifications and an inability to capture complex signals. On the other hand, approaches based on over-parameterized or non-parametric models can excel at explaining complex nonlinear signals, but real-time updates for such models are challenging. In this paper, we propose a neural process-based approach that addresses this trade-off. It encodes available observations within a CM signal into a representation space and then reconstructs the signal's history and evolution for prediction. Once trained, the model can encode an arbitrary number of observations without requiring retraining, enabling on-the-spot real-time predictions that can quantify uncertainty and can be readily updated as more online data is gathered. Furthermore, our model is designed to incorporate categorical information (i.e., labels) from individual units. This integration not only enhances individualized predictions for each unit but also enables joint inference for both signals and their associated labels. Additionally, we present a functional data augmentation scheme for cases where CM signals are insufficient for model training. Numerical studies on synthetic and real-world data in reliability engineering highlight the advantageous features of our model in real-time personalization, enhanced signal prediction with uncertainty quantification, and joint prediction for labels and signals.",Advanced Data Analytics for Quality Control and Reliability,2,215
From awareness to action: An exploratory research for advancing gender equality in industrial engineering education," This research seeks to create a more equitable and inclusive industrial engineering community by promoting gender equality in education. To achieve this, we are conducting an exploratory research project that takes a critical look at the current state of gender equality in industrial engineering education. Our project intends to identify specific challenges that hinder the participation of women in this field. Conduct a thorough review of existing literature on gender equality in industrial engineering education to understand the current state of research, key concepts, and identified strategies and initiatives implemented in other fields or disciplines to promote gender equality in education. Through a comprehensive statistical analysis of enrollment trends over time, academic performance, and faculty composition, we aim to uncover the root causes of gender disparities in educational settings. By pinpointing areas where inequities exist, we can propose evidence-based strategies that will enable educational institutions and industry stakeholders to collaboratively contribute to Sustainable Development Goal (SDG) #5. Our research findings will provide recommendations for reshaping curricula, implementing mentorship programs, and promoting inclusive teaching practices to enhance the educational experience and retention of female students in industrial engineering programs. Our goal is to drive transformative change and contribute meaningfully to the broader agenda of sustainable development.",Inclusive Excellence in ISE Education,100,216
Experimental Wargaming: Applying the Scientific Method to Human Behavior," Professional wargames are strategy games used for numerous purposes, including specialized training, problem exploration, and scientific experimentation. Professional military wargaming in the United States Department of Defense (DoD) is steeped in time-honored method and tradition. Rapid advances in technology including mobile computing, artificial intelligence, networked information sharing, and digital gaming have transformed the way in which people make fundamental tactical and operational decisions, while giving researchers new tools for studying human behavior in conflict. Wargaming with these tools provides greater clarity and precision through enhanced graphical and computational resources, variable gameplaying modalities, and exponential increases in data capture and analysis. To date, analytical wargaming has lagged in the DoD, in favor of proven educational and experiential games developed over many decades, largely because data collection and analysis of analog games are imprecise, inefficient, and limited in opportunity and quantity. Recent success has been found, however, in leveraging technology to conduct analytical wargames as a method of experimentation. This experimental wargaming is conducted specifically to generate and analyze data scientifically, using controlled, repeatable games with objective measures, to confirm or reject predetermined hypotheses about methods, behavior, technology, capability, or policy. In this paper, the authors provide an overview of experimental wargaming, defining and discussing related terms, baselining its current state, analyzing strengths and weaknesses, and summarizing results obtained by researchers who are using experimental wargaming across domains. The authors also review lessons learned and benefits gained from this research, and offer recommendations on employing experimental wargaming as a scientific research method.",Modeling Human Behavior,148,217
Optimizing parcel delivery by vehicle and drone with practical considerations," We examine a vehicle routing and drone problem for parcel delivery in last-mile logistics. The proposed formulation incorporates practical considerations with regard to the proportion of customers eligible for a drone delivery and ordered customer clusters generated in the town of Amherst, MA. We explore the impact of pre-fixing the relative order of certain streets in the delivery effort and the incorporation of valid inequalities.",UAV logistics,233,218
Boosting Discriminability of the Transferable Features in Unsupervised Domain Adaptation," Unsupervised domain adaptation aims to learn feature representations that are both transferable and discriminative across different domains. However, most existing methods are centered around aligning the source and target domains using different discrepancy measures or through adversarial training, which may compromise the discriminability of the features in the target domain. In this study, we adopt the idea of linear discriminant analysis to enhance the inter-class separation and intra-class compactness of the features, while minimizing the domain discrepancy by leveraging the mutual information between source and target data. Extensive experiments demonstrate that our proposed method outperforms the state-of-the-art methods in terms of accuracy. Moreover, we provide theoretical analysis on the generalization error bound and the computational complexity of our method.",Machine Learning III,127,219
Improving Operational Efficiency and Reducing Downtime: Applying Lean Six Sigma in Material Recovery Facilities," In response to challenges within the solid waste industry, this research focused on enhancing Material Recovery Facility (MRF) operations using Lean Six Sigma. Employing the DMAIC framework, the study tackled recurring downtime at a Guaynabo, Puerto Rico MRF. Key findings include identifying root causes, such as conveyor jams and material entanglements, and proposing improvements like ongoing training, proactive maintenance, and specialized equipment like the Industrial Bag Opener and Motorized Brush. The study projected a 30% downtime reduction, yielding an annual saving of around $97,630. This ROI calculation factored in operational enhancements and equipment costs, highlighting the financial benefits of Lean Six Sigma integration. Emphasizing Lean Six Sigma's value in MRF operations, the study provides insights for the industry and underscores data-driven waste management enhancements. Moreover, its alignment with UN Sustainable Development Goals 8, 9, and 11 highlights contributions to decent work and economic growth (SDG 8), industry, innovation, and infrastructure (SDG 9), and sustainable cities and communities (SDG 11). The research showcases the practical advantages of Lean Six Sigma in MRF operations, serving as a model for the wider waste management sector and affirming the value of data-driven enhancements.",Optimization,154,220
Image-based Genotype Encoding for Phenotype Trait Classification," Genotype-phenotype association study aims to capture the informative features from the extremely long genotype sequence and predict the observable traits. High-dimensional genotype sequences are usually converted to low-dimensional latent representations using dimensionality reduction techniques such as principal component analysis. However, such dimensionality reduction methods may compromise the informative features due to the conversion. In this study, we introduce an image-based encoding technique of the high-dimensional genotype sequence that ensure data integrity. The encoded images are then employed to train a state-of-the-art deep neural network to build a phenotype trait classifier. Moreover, to pinpoint the most significant single nucleotide polymorphisms (SNPs), we employ Gradient Class Activation Map (Grad-CAM) and generated an interpretation of the genotype-phenotype association. To validate the predicted significant genomic loci, we train a Long Short-Term Memory (LSTM) network with the sequential genotype data encoded in sliding windows. Our results demonstrate remarkable potential of this approach for genome-wide association studies.",Innovative Applications of Artificial Intelligence II,110,221
Evaluating an Elbow Exoskeleton for Reducing Work-related Musculoskeletal Disorders Risk: An Interdisciplinary Study.," This study aims to evaluate the effectiveness of an elbow exoskeleton in mitigating risk of Work-related Musculoskeletal Disorders (WMSDs). WMSDs continue to pose significant health and economic challenges in occupational settings, particularly in tasks involving repetitive or forceful motions. Thirty percent of all days away from work cases in the US are attributed to WMSDs. The elbow exoskeleton, developed by the University of Texas at Arlington Research Institute (UTARI), offers a potential solution by providing assistive motion, aiming to reduce muscle strain and enhance task efficiency. To assess the elbow exoskeleton’s efficacy, three occupational tasks will be simulated: (a) a weightlifting and carrying task, (b) an assembly task with basic tools (no vibration), and (c) an assembly task with power tools (vibration). Ten participants from the UTA student population will be recruited to perform the tasks with and without the exoskeleton. Metrics, including muscle activation (using Electromyography) and heart rate (using Electrocardiogram), will be captured, and analyzed. The working hypothesis is that the exoskeleton will significantly reduce muscle activation, perceived workload, and fatigue, suggesting its potential to assist arm and hand movements across various work scenarios. In addition to testing the hypotheses, the findings of this research will also identify the need for design refinements to enhance usability and acceptance. The findings of this study will contribute to the growing field of wearable robotics aimed at enhancing occupational safety.",Health Systems for Human Factors and Ergonomics 1,79,222
A Decision-Making Framework for Maximizing Post-Hazard Accessibility to Essential Services," Sufficient and equitable access to essential services, including healthcare and fire and rescue services, is a crucial metric of community resilience. Accessibility to essential services requires functioning critical buildings, e.g., hospitals and fire stations, and a functioning transportation infrastructure. In the aftermath of a hazard event, damage and resulting functionality loss in critical buildings and transportation networks significantly impact accessibility to essential services. This study proposes a decision-making framework to develop mitigation plans for critical buildings and transportation network components to improve community-level resilience in terms of accessibility to essential services following uncertain hazard events. The framework employs fragility functions for engineered structures to translate the effect of hazard intensities and mitigation actions into functionality, which are then used as inputs to an optimization model. The optimization model is framed as a risk-averse two-stage stochastic programming model to consider the uncertainty of hazard intensity and the risks associated with rare, high-impact events. The framework is applied to develop optimal mitigation strategies for critical buildings and the road and bridge network in Shelby County, Tennessee, subjected to earthquake hazards. The effects of risk preferences and other sensitive parameters on retrofit decisions and accessibility metrics are investigated.",Optimization Application,155,223
An Interpretable Optimal Pricing Strategy for E-Commerce Platforms," Strategic and optimal pricing plays a significant role in ensuring profitability in the recent ecommerce world. Due to fierce competition and the dynamic nature of the market, pricing decision-making has become highly challenging. The manual methods of pricing are inefficient and prone to generating suboptimal solutions. However, the availability of large volumes of data generated by e-commerce platforms calls for a data-driven approach. With the improvement in statistics and machine learning methods, it is now possible to make informed decisions based on historical data that will ensure optimal pricing and increased profit. In this study, we propose an interpretable LSTM-XGBoost-based optimal pricing strategy that simultaneously forecasts the relevant variables for the projected time window and optimizes the pricing decision based on correlations between potential price points and relevant dependent variables. The computational complexity of the proposed approach has been critically discussed and compared with existing reinforcement learning based method. Empirical results of the live testing phase indicate that the proposed model can increase the profit and lead to an upward trend in the profit curve.",Innovative Applications of Artificial Intelligence II,110,224
Application Process Optimization," An application process is necessary to effectively evaluate and assess candidates for an organization. Selecting personnel who are unable to pass an organization’s standards can have adverse impacts for an organization. On the other hand, selecting personnel who are the right fit for the organization’s needs can positively impact the organization while also reducing wasted funds and lowering the attrition rate. Many forms of application processes exist, employers across different industries collect a wide range of factors, data, and test results. Deciding the correct data to collect from applicants is an important aspect in gaining an accurate representation of each candidate. Additionally, the design of an application process can vary in many ways with different interview processes, intelligence tests, and mental ability tests. Therefore, it is extremely important to build an application and an application process that best predicts the qualification of each candidate for the organization. This paper seeks to optimize the application process through an analysis of application factors with the greatest predictive ability. Our research endeavors are directed towards enhancing the application process utilized by the U.S. Army's 160th Special Operations Aviation Regiment (SOAR). Acknowledging the substantial 40% attrition rate within the enlisted Green Platoon course, our primary focus is to refine the screening process for candidates and effectively identify unsuitable applicants. We investigate the effectiveness of the current application model for the 160th and assess the impact of adding additional application questions.",Process & Operational Improvement I,177,225
Weed Detection in Cotton Fields Using YOLOv5: Prototype Development and Deployment," Weed control is a critical task for any crop production, as weeds are a substantial threat to the crop yields. To ensure effective weed control with site- and species-specific herbicides, it is essential to precisely classify and localize them in the field. In this study, we employ deep learning and machine vision technology to address this issue. We train a state-of-the-art deep object detector, the YOLOv5 model, on images collected from real cotton fields to detect weeds. We also apply various context-based data augmentation techniques to enhance the model robustness. The trained YOLOv5 model has been deployed on a cost-efficient Single Board Computer to develop a prototype that can be used in the field. The prototype can detect the cotton weeds in real-time with a high confidence score. This study will serve as a valuable resource for the development of next-generation prototypes and eventually industrial-scale field-deployable equipment for weed detection.",Energy & Environment II,63,226
Developing a Product Architecture for a Window Manufacturing Company by using UML Class diagrams and Design Structure Matrix: Challenges and lessons learnt," To meet customer needs and market fluctuations, in recent years, the focus of the industry has shifted from mass production towards mass customization. Product customization increases the cost associated with processes, materials, and technologies, thus increasing the complexity of the production system. A proper product architecture of identifying all the possible product variants is necessary to positively impact manufacturing processes in terms of assembly complexity, time, and manufacturing equipment. However, many researchers have shown that, due to the lack of consistent methodologies in different fields, the definition of a Product Family Architecture is not an easy task. This work is an attempt to develop a framework for highly customized production lines by using UML class diagrams and Design Structure Matrix (DSM) tools. A UML class diagram will be used to analyze the genetic code of different products, by identifying their components along with their properties, and attributes. Then a system modelling tool, DSM, will be used for visualizing product complexity assembly. DSM will help to determine the product family architecture by listing all component variants that can exist in a particular product. The study is conducted in a window manufacturing industry that has a high product variation which varies according to customer requirements. The aim of this paper is to create a model that can be used to pave the way for further research areas such as discrete event simulation and assembly tasks with each individual product having a unique identification process.",Manufacturing,132,227
Scaffold 3D Printing Case Study Implementing a Biofabrication Digital Twin Framework," The integration of digital manufacturing concepts into biofabrication holds great potential for addressing the complexities and challenges in engineering biologically relevant tissue constructs. A primary consideration in this domain is ensuring consistent, scalable, and adaptable processes that are amenable to clinical translation. Herein, we introduce a new framework for integrating digital twins in biofabrication to facilitate comprehensive monitoring, accurate prediction, and real-time feedback. This provides faster and more reliable means to optimize biofabrication processes and ensure that final products meet desired quality attributes. The proposed framework incorporates key building blocks for implementing digital twins in biofabrication, which includes defining the objectives of biofabrication; comprehensive data acquisition using multi-modal sensing to integrate biological, material, and process-related data; advanced modeling methods utilizing machine learning algorithms to refine process parameters; and a feedback loop for real-time process adjustments. The framework's utility is demonstrated through a case study highlighting step-by-step implementation for the 3D printing of polycaprolactone scaffolds. Insights from the digital twin refined decisions on printing parameters and post-processing, ensuring that the printed scaffold met desired mechanical properties and biocompatibility, thereby significantly enhancing printing resolution and cell proliferation. The main advantages of this approach include optimized biofabrication outcomes through integrating physical and biological models, promoting scalability and reproducibility with an accelerated research and development phase. This work underscores the promise of digital convergence in biofabrication, which can significantly advance the domains of regenerative medicine and tissue engineering.",Digital Thread in Additive Manufacturing Processes,49,228
Monitoring Drug Poisoning Mortality Across States Using Control Charts: A Comparative Analysis," This investigative study examines the impact of drug abuse on mortality rates in two US states: Minnesota, and Vermont. The data was obtained from the DATA.GOV website that consists of thirteen quantitative variables and five qualitative variables of which describe the drug poisoning mortality by each state in the United States. Control charts were utilized to analyze trends in drug-related deaths over time and assess the effectiveness of various policies and changes implemented to reduce drug abuse. The control chart for Minnesota exhibits data that is in control with an increasing trend in drug poisoning mortality. On the other hand, the control chart for Vermont showed in-control data with cyclic behavior. The results conducted from the control charts suggest that Minnesota has a high rate of drug abuse and drug poisoning mortality that is increasing, while Vermont’s drug poisoning mortality fluctuated due to different government policies implemented to prevent drug abuse. Further studies can be conducted to verify trends within these states based on this study.",Health Systems,78,229
Reducing Cycle Time for the Ingevity Cable Pre-bond PU Treatment Process," A medical device company located in Puerto Rico has the process of PU-Pre Bond for the Ingevity cable. This pivotal process plays a fundamental for ensuring customer satisfaction and maintaining a competitive edge in the market. To optimize quality and efficiency, the DMAIC approach has been chosen to address the challenges associated with this process. This project rigorously applies statistical tools and quality control methods to identify critical areas for improvement. Various surveys, including the Voice of the Customer, was conducted, and relevant Critical to Quality characteristics was defined. Furthermore, comprehensive statistical tests, such as One-Sample Hypothesis Testing, Two-Sample Hypothesis Testing, linear regression comparisons, control charts, and Pareto charts, among others to deep analyze the problem with cycle time. Through a data-driven approach centered on statistical tools and quality control methodologies, we have gained a deeper understanding of the factors affecting process performance. Our detailed analysis revealed differences between cycle times in the AM and PM shifts. Although statistical testing did not confirm significant variability differences, this finding served as a starting point for implementing improvement and control actions. The proposed recommendations, including optimizing the layout, rotating employees between stations during shifts, and improving the loading and unloading process, have the potential to generate significant improvements in process efficiency and quality. To ensure sustainable improvement, effective control measures are recommended, including the adoption of key performance indicators (KPIs), the use of Statistical Process Control (SPC), the development of Standard Operating Procedures (SOPs), and the implementation of a Visual Management System.",Poster Presentations,169,230
Assessing the Effects of Cyclic Loading on Tensile Properties of 3D-Printed Auxetic Scaffolds," 3D-printed auxetic scaffolds possess enhanced elasticity compared to traditional scaffold designs, which is especially beneficial for tissue engineering applications that require biomechanical functionalization. Fatigue properties of auxetic biopolymer scaffolds when subject to cyclic tensile loading have not been well investigated in current literature. In this study, we characterized the effect of cyclic loading on tensile properties of missing rib auxetic scaffolds under three different unit cell scenarios. First, missing rib auxetic scaffolds (unit cells: 2×2, 3×2, 3×3 mm2) were 3D-bioplotted (strand Ø = 400 µm) using polycaprolactone (Mw = 37,000) and tested (n = 3) for monotonic tensile properties (displacement rate = 0.1 mm/s). Both 3×2 and 3×3 mm2 scaffold groups demonstrated significantly higher yield strain (62.9% and 48.2%, respectively) and lower yield stress (4.3 and 5.4 MPa/g, respectively), elastic modulus (6.7 and 11.5 MPa/g, respectively), and tensile strength (12.3 and 10.0 MPa/g, respectively) compared to the 2×2 mm2 group (p<0.05). To assess fatigue properties, the scaffolds were tested (n = 3) after 6,000 tensile loading cycles at 10% of maximum strain at 0.5 Hz. The 2×2 mm2 group exhibited substantial degradation in tensile strength (95% reduction) compared to the 3×2 and 3×3 mm2 groups (21% and 42% reduction, respectively). Post-cyclic loading, no significant differences were observed in the tensile properties of the 3×2 and 3×3 mm2 groups, highlighting their relevance for applications requiring mechanical stimulation. The biocompatibility of these groups is being evaluated and this knowledge will be leveraged in future to engineer scaffolds for connective tissues.","Advancements in Bioprinting: Techniques, Materials, and Applications",12,231
"Systems Engineering – Contributing to a Strong, Successful Program"," Systems Engineering (SE) is beginning to show a tremendous positive impact for programs at Spirit AeroSystems, Inc. As the discipline matures, the tools and processes utilized by SE are demonstrating value through cost avoidance and a minimization of liability as programs go through set up and maturation. This presentation will go through the life cycle of a Program and touch on the major milestone of SE involvement and what contributions are made.",SE Concepts and Theory,199,232
The Interacting Effects of Time Pressure and Reward Value on Naturalistic Visual Search in Virtual Reality," The visual search literature emphasized various guiding factors, but less attention has been given to how environmental factors interact to impact visual search. The visual search literature has primarily been based on 2D laboratory tasks, which lack the complexity of real-world search tasks. Thus, the present study investigates how time pressure and reward value interact to impact visual search performance in a naturalistic environment presented in virtual reality (VR) system to: (a) closely emulate a real-world environment and (b) collect eye tracking data to determine visual attention allocation during target searches. The present work also implements a novel method of capturing 3D eye tracking data. Forty participants were tasked to search for objects in a virtual living room under different timing conditions and varying reward incentives. The results showed that time pressure induced a speed-accuracy tradeoff, where it reduced search time but decreased accuracy. Time pressure also induced an attentional tunnelling effect. While reward value improved search accuracy, it did not mitigate the negative impact of time pressure on accuracy. The study also found that the best performers were surprisingly neither faster nor more efficient in their search than the worst performers. Rather performance differences hinged on individual differences to perform under time pressure. Overall, the findings inform operator training guidelines in visual search-focused occupations like luggage screening, aviation control, and emergency response.","Systems Engineering, Logistics and Supply Chains for Human Factors and Ergonomics",228,233
A simulation modeling approach to quantify fatigue and recovery patterns in nursing work over multiple days," Healthcare systems are struggling to measure and manage nurse workload despite its impact on care quality, fatigue, and staff burnout rates. A nurse-focused discrete event simulation (DES) approach was developed to examine and quantify nurse workload for a given healthcare unit configuration and current patient needs. This work extends the DES approach to include nurse physical fatigue and recovery effects across one or more shifts. The DES model provides task time-history and a digital human model provides biomechanical load for associated tasks. We then apply a maximal endurance time model to quantify task fatigue with respect to the work time. A recovery model determines recovery need for the task, which is related to recovery time available, and determines accumulated physical fatigue. We demonstrate this concept using a hospital medical-surgical unit. We examine nurse physical fatigue and recovery patterns under varying shift schedules (i.e. with extra shifts added) and with different recovery rate scenarios. Preliminary simulation results show that a recovery efficiency of 25% between shifts cumulatively increases physical fatigue over consecutive shifts until multiple days off, resulting in time spent in full recovery under half the time of 100% recovery efficiency. Adding extra shifts (i.e. to cover staff shortages) induced a fatigue response resulting in nurses having no time in a full recovery state in extreme conditions. This approach is undergoing validation study at a partner hospital.",Healthcare Work Systems,90,234
"""Empowering Research: Open-Source LLMs, Semantic Search, and Domain-Specific Knowledge in a Multi-Document Q&A Assistant"""," In the age of information abundance, accessing and extracting knowledge from vast repositories of research documents pose significant challenges for researchers, students, and professionals. Existing chatbot systems, relying on general-purpose Large Language Models (LLMs), often fail to provide accurate responses to domain-specific inquiries. Additionally, the high cost of fine-tuning LLMs for specific domains hinders widespread adoption. To address these limitations, this paper proposes a novel methodology that combines the power of LLMs and vector databases. The system efficiently understands natural language user queries and retrieves relevant information from research documents provided by the user, circumventing the need for extensive and resource consuming fine-tuning. Furthermore, the paper compares 2 open-source models hosted in HuggingFace based on metrics like output accuracy, factuality, output token length, and response time. The proposed approach showed an overall accuracy of more than 90% when comparing expected output and LLM generated output using various text comparison metrics including ROUGE and Semantic Answer Similarity. Our comprehensive evaluation of Falcon and Flan T5's responses unveils distinct strengths. Flan T5 shines with remarkable accuracy exceeding 90%, efficient response time of 2.2s, and a truthful output in 87% of the cases. These insights also contribute to understanding each model's unique area of excellence.",Information Systems & Software,104,235
Industry 4.0 in Mexico´s State of Advancement: Manufacturing and Academic Cases.," The evolution of markets requires precision, which is achieved through technology and information systems; this transformation, termed Industry 4.0 (i4.0), requires companies to integrate operations with computer systems for enhanced efficiency. This research examines Mexico’s position, advances, opportunities, and evolution of i4.0; including industrial, government, and academic impacts. This article offers insights into the challenges that must be addressed for the nation to excel in innovation and technological readiness and the potential advantages that i4.0 can bring to Mexico’s economy and society, presenting actionable recommendations to successfully embrace the fourth industrial revolution. The gap in technology adoption partially due to government´s lack of initiative in procurement of advanced technology products sets a challenge for advancement, this presents a substantial opportunity for growth and modernization in Mexico’s industries: automotive, aerospace, and chemical industries, among others present progress in the roadmap of i4.0, on the other hand, some vulnerable industries to automation on Mexico are wood, furniture, food, transportation equipment, clothing, and manufacturing in terms of labor. In academia, an accelerated adoption of digital transformation, catalyzed by the COVID-19 pandemic, amplified the imperative for universities to swiftly integrate digital technologies into their plans and pedagogical strategies, ensuring sustainability and relevance in a rapidly evolving digital realm. Complementary topics for i4.0: Internet of Things, additive manufacturing, robotics, cloud compounding, big data analysis, systems integration, modeling, and simulation are included in this research. Findings indicate that research should leverage knowledge from regions like Europe, the US, and Asia, for Mexico to embrace i4.0 fully.",Digital Excellence I,43,236
Automated Real Time Visual Inspection System for Pharmaceutical Tablet Manufacturing," Tablets are a solid pharmaceutical dosage form that contains a drug substance along with various excipients or diluents. The pharmaceutical manufacturing industry prioritizes product quality and safety due to the impact of pharmaceutical products on human health. Traditional visual inspection methods in pharmaceutical manufacturing are time-consuming, subjective, and susceptible to human error, which may threaten product quality and safety. To overcome these challenges, we propose a state-of-the-art automated visual inspection system based on deep learning for pharmaceutical tablet manufacturing. Our proposed system utilizes advanced object detection techniques including YOLOv8, RT-DETR, and Faster R-CNN to detect common flaws that may occur during the manufacturing process, such as incorrect colorization, cracks, and missing pills. A dataset of 333 images is collected and used for training and testing of the proposed system. The YOLOv8-based system has demonstrated superior performance compared to the others. Our experimental results demonstrate that the proposed system achieves high accuracy in detecting defective pills in real time, which can significantly reduce the time and cost required for inspection while increasing the accuracy and reliability of the inspection process. In conclusion, the proposed automated visual inspection system based on object detection methods has the potential to improve quality control and safety measures in the pharmaceutical manufacturing industry.",Manufacturing I,135,237
Time of Receipt of Materials in the Warehouse," Supply Chain Department for a Pharma Company noticed that daily and weekly priorities were not being met. The percentage of “GR” (Good Received) generated per week hardly exceeded 50%. According to the historical data of the receipt reports, the best week since the year 2022 began, 65% of the plan's receipts were generated for one of the weeks in May 2022. However, the subsequent weeks did not come close to the percentage. The objective of the project was to increase the efficiency in the receipt process, decrease its time, and therefore the time of the tasks that comprise said process. The DMAIC methodology was implemented, which allowed to identify the problem and, in turn, move the project to the point of improvement. To do this, a sample of 30 data equivalent to 30 material receipts was collected to understand the causes that put the receipt timing at risk. The MINITAB program was used for the analysis of the data focused on statistics. Once the tasks that put the receipt time at risk were identified, a time reduction of 88% was achieved in repalletizing tasks, the material transport capacity was increased by up to 50% and increased by 7%. the capacity of empty locations in the “site”; These results lead us to meet the objectives. Subsequently, the reduction of time in the tasks is achieved (especially in the activities of locating and repalletizing the materials); and increase in transportation capacities and empty locations on the site, achieving the objective.",Poster Presentations,169,238
Stochastic Simulation of Bulk Electric Power System Operations to Understand Risks from Weather and Climate Uncertainty and Extremes," Electricity grid operators must rapidly reduce greenhouse gas emissions while also withstanding extreme weather events that are becoming more frequent and severe due to climate change. Incorporating hydrometeorological stressors into computational power systems analysis allows modelers to capture the spatial and temporal structures of different natural hazards (e.g., droughts, heat waves, cold snaps, floods) and translate those into meaningful impacts to the grid (e.g., demand and supply shocks that cascade across connected networks). However, a persistent challenge for power system modelers is striking an appropriate balance between model fidelity (e.g., scale and resolution) and computational tractability (e.g., wall clock run-time). This talk will discuss ongoing efforts to develop open source modeling tools that allows users to customize direct current optimal power flow (DC OPF) models of the three major electrical interconnections in the United States. We demonstrate how these models can interact with weather and climate datasets to provide stationary and/or forward-looking assessments of physical grid reliability and market risk for different stakeholders under a range of climate can technology futures.",Risk and Uncertainties In Energy Planning,196,239
"Design and Implementation of Environmental Management System (EMS), A Pathway To Achieve Sustainability Goals using ISO 14001:2015 standard in a medical supply chain organization"," Organizations across various industries have widely implemented Environmental Management Systems (EMS)since the late 1980s. The system comprises policies, procedures, processes, and multiple documents and formats essential to attain organizational governance and establish a robust management system. In the last decade, the need to enhance environmental performance and achieve sustainability objectives has become a business imperative for organizations across the world. Organizations are mandated to comply with environmental requirements and regulations through contractual agreements between customers and their business partners. Globally, the ISO 14001:2015 standard in its current version is the most implemented environmental management system (EMS) across organizations. It is a framework based on the ‘PDCA-Plan, Do, Check, Act’ cycle. Medical and healthcare organizations are varied, from hospitals, emergency care centers, and clinics to humanitarian aid supply establishments. This case study paper will present a practical, real-world example of how an environmental management system (EMS) was implemented in a large medical supply organization in the UAE. The organization caters to humanitarian aid and relief customers by supplying a range of medical products, often in intricate and challenging geographic locations. The medical supply organization faced a critical challenge in managing and reporting its environmental impact and sustainability practices. Without a structured environmental management system, the company lacked a systematic approach to address environmental issues, such as transportation and distribution, packaging, and waste management. Therefore, there was an immediate need to implement the ISO 14001:2015 standard to implement a robust framework for environmental management and enhance environmental performance for a sustainable future.","Healthcare for a Sustainable Future: Innovations in Operations, Design, and Environmental Management (SDG 3)",91,240
Leverage Behavior Management to Accelerate & Sustain Operational Excellence Behavior Change," Decades of research show that the majority of operational excellence / technology deployment initiatives fail to meet performance expectations. We believe this disconnect occurs because there is: A lack of leadership involvement and ongoing, effective engagement, Initiatives tend to be technology-driven creating a lack of business ownership, and Specific, desired behavior changes are not adequately identified and prioritized. Typically, we see change initiatives that: Rely on communication about the case for change as the primary leadership engagement activity, Lead with the technology solution while the business user impact is a secondary consideration, and Speak about behavior using “behavioral” clichés that do not define specific leader and performer behaviors. accomplir® Behavior Management defines behavior as “what I say or do”. Behavior Management complements Change Management’s focus on people’s feelings and attitudes. But, it is Behavior Management that has the most immediate impact on behavior change sustainability. We have demonstrated that engagements leveraging Behavior Management dramatically improve user change acceptance and yield more sustainable results, especially in white-collar, technical, service, and professional environments. accomplir® has pioneered next-generation Integrated Methodology toolsets by embedding Behavior Management concepts into Lean Sigma and technology deployment methodologies. Refining these toolsets over the last fifteen years, has enabled us to: Effectively drive business ownership of the change Explicitly identify and prioritize desired behaviors for performers and leaders Increase Leaders’ involvement and accountability for sustaining behavior-change Achieve an 80%+ behavior change success rate across an array of operational excellence and technology deployments",Organizational Culture,157,241
Decision Support for Event Portfolio Management in Convention Centers," In the field of event management, creating an efficient event portfolio is a multifaceted challenge that involves selecting the right mix of events to maximize their economic impact and profitability. Convention centers must also take into consideration the unique goals and constraints of their organizations, including available space, equipment, and staffing capacity constraints. This paper addresses this issue by proposing a new decision support tool designed to evaluate and prioritize events held at convention centers. Our proposed tool is designed to support an event evaluation process that is aligned with the portfolio management methodology of the Project Management Institute (PMI), which integrates strategic alignment best practices. The proposed model empowers managers to craft an event portfolio that both maximizes economic benefits for the host city and strives for optimal financial outcomes for the convention center. The evaluation part of the tool uses AI techniques such as clustering algorithms and neural networks to significantly improve the accuracy of revenue and expense predictions for each event in the portfolio. This new decision support tool is expected to not only improve the financial performance and optimize resource utilization within convention centers but also to yield significant economic advantages for the host city. However, its implementation necessitates a comprehensive overhaul of existing operational procedures. Our forthcoming presentation will showcase our initial findings and delve into the obstacles encountered by convention centers when integrating such tools.",Decision Support,39,242
Use Behavior Management to Improve Root Cause Analysis (RCA) and Future-State Designs," I’ve experienced traditional Root Cause Analyses more times than I can count. In the ‘90s, I learned about Dr. Geary Rummler’s Human Performance System framework for understanding human behavior. Fifteen years ago, I began developing enhanced Lean Sigma & Business Process Management tool-sets (Integrated Methodologies) that incorporates Behavior Management (Behavioral Science) concepts. It soon became apparent that RCA was well-suited to product, technical, and mechanical issues, but not effective for “behavioral issues” (behavioral failure modes or disconnects). Though behavioral issues reside on the “People” rib of the Fishbone, the typical root causes noted are limited to training, procedures, job aids, etc. These are Antecedents in the Antecedents-Behavior-Consequences (ABC) framework from Behavior Management. Though at times Antecedents are a root cause factor, the majority of “behavioral” issues exist due to inadequacies in the Consequence (& Feedback) component. Behavior Management has proven that Consequences have a significantly greater impact on behavior change and sustainability than Antecedents alone. Learn how to use these ABC tools and you will have a more lasting and effective improvement in your RCA activity. This session focuses on Behavior Management key concepts that illustrate, in a DMAIC framework, the “WHY” and “HOW” to improve the Behavioral Dimension in Root Cause Analyses. Attendees will learn how to 1) identify behaviors, 2) annotate Behavior Issues and Key Behaviors on Current-State process workflows, and 3) facilitate an ABC (Antecedent-Behavior-Consequence) Analysis. These three skills are important in educating project teams and leaders on the relevance of Behavior Management, especially the Consequence component.",Continuous Improvement Tools and Methodologies I,33,243
Learning from the Legends: A Panel Discussion with Wellington Award Winners," The panel discussion will feature past winners of the prestigious Wellington Award who will share their experiences and insights on the field of engineering economy and its future directions. Each panelist will give a brief presentation on their contributions to the field, their experience winning the Wellington Award, and how it has impacted their career. The panelists, led by a moderator, will then collectively discuss current issues in the field of engineering economy and how they see the field evolving in the future. This will be a great opportunity to learn from the legends of engineering economy and to network with fellow researchers and practitioners in the field. The Wellington Award is the highest honor in the field of engineering economy, recognizing outstanding long-term contributions and service that enhance the visibility of the engineering economy division of IISE. The award is named after Arthur M. Wellington, author of “The Economic Theory of the Location of Railways” published in 1887. The award winners are selected by a panel of experts who identify and select potential recipients based on their outstanding long-term contributions and service in the field of engineering economy.",Learning from the Legends: A Panel Discussion with Wellington Award Winners,120,244
A Bi-objective Bi-level Network Interdiction Problem with Applications in Human Trafficking Disruption," We consider a bi-level network interdiction problem where the follower, who operates the network, aims to maximize the flow in the post-interdiction network whereas the leader, who interdicts the network, aims to minimize both the number of arcs from a critical set that have positive flow on them, i.e., active arcs, in the maximum flow solution obtained by the follower as well as the maximum flow value obtained by the follower. Our problem is motivated by an application in human trafficking disruption where a trafficker (the follower) seeks to maximize the profit from the operation whereas the leader represents a consortium of two anti-trafficking agents; one that seeks to minimize the number of victims affected by the operation, and the other who wants to minimize the maximum profit obtained by the trafficker. We investigate modeling and solution challenges as well as insights from computational experiments.",Human trafficking and other humanitarian crises,93,245
Sample size reduction in Manufacturing Facilities," The purpose of this study was reduced and standardized the sample size collected for the destructive inspection tests performed at medical devices company. The tests performed were pull force, torque to break and torque to unseat which test for the safety specifications established for the Blood Transfer Device (BTD) and Luer Lock Access Device (LLAD). The methodology DMAIC was used to analyze the problem, to measure and analyze the variation, and capacity of the process. It was determined that the samples sizes used for inspection of the three tests vary between each lot. The process was found to be capable of complying with the required specifications although there is significant variation in the data of each inspection test. Based on these results, our suggestion entitled standardizing the sample sizes and frequencies based on the sample plan ANSI/ASQ Z1.4, reducing by 50% the material cost of inspection per lot. Additional training for the sub-assembly machine operators and supervisors is required to maintain said improvements as well as monitoring the sample sizes after each shift. In conclusion, based in the results of our study, the company would improve its inspection process by standardizing and reducing the sample sizes collected per lot. This would additionally reduce the time spent in each inspection test. Through the sampling plan ANSI/ASQ Z1.4, the company would comply with the requirement of sample size per lot while ensuring the safety of its products.",Poster Presentations,169,246
Economic Dispatch of Hybrid Renewable Energy Systems with Battery Energy Storage and Gas Turbines using Deep Reinforcement Learning," Both battery energy storages (BESs) and gas turbines (GTs) are suitable to compensate for the fluctuations in intermittent renewable energies, each with its own strengths. BESs can be charged with excess energy and discharged nearly instantaneously but are limited by the amount of energy stored. GTs can supply large quantities of energy over long periods but are less efficient when operated on partial loads and started frequently, which increases maintenance cost. Combining a BES with a GT and renewables can result in a more efficient plant with lower operating costs. This is because the BES can be dispatched during short periods of renewable undergeneration in lieu of the GT. Assessing the benefits of this combination is difficult due to the inherent uncertainty in variables such as power demand and renewable generation. To optimally dispatch BESs and GTs in parallel, a control algorithm is needed. In this study, we apply deep reinforcement learning (DRL) to this problem. DRL has recently been applied successfully to several problems in energy systems due to its ability to handle uncertainty by training on large quantities of historical data. We first formulate a GT-BES-wind-solar hybrid system operating in a microgrid and then train different DRL algorithms to minimize the cost of system operation. Despite not having access to forecasts, DRL successfully learns to use GTs and BESs economically in our case study. Compared to a GT-wind-solar hybrid, the combination with BES requires less GT start-ups and operating hours, reducing the cost of operation by 21%.",Microgrids and Energy Storage,145,247
Nonparametric Multivariate Importance Sampling in Stochastic Simulation," We propose a new multivariate importance sampling method in stochastic simulation. Importance sampling has the potential to significantly reduce the estimation variance when its instrumental density is well-designed. A nonparametric technique has been shown to provide benefits in the literature for capturing the significance of input variables and interaction effects between inputs. However, when the input dimension is high, it easily faces the curse of dimensionality. This study presents an adaptive method to identify crucial input variables and devises a nonparametric instrumental density using those selected variables. Empirical results from numerical examples and the wind turbine reliability case study demonstrate the method's efficiency.",Advanced Simulation Models,3,248
Enhancing International Passenger Throughput and Minimizing Missed Connections at a U.S. Airport via Discrete Event Simulation," This study investigates the intricate process of international passenger arrivals at Miami International Airport, the busiest international airport in the United States, with international travel exceeding pre-COVID levels. The study emphasizes the passenger sojourn experience from arrival to airport exit or connecting flight. Utilizing a discrete event simulation model, we analyze and optimize international passenger throughput under this setting. In this process, upon disembarking, passengers navigate the U.S. Customs and Border Protection Federal Inspection Services (FIS) area for immigration and passport control, followed by baggage claim and customs clearance. Usually, a substantial number of arriving passengers have connecting flights, and therefore, need to recheck their checked baggage for their connecting flights and undergo security screening at a TSA checkpoint. The long queues or delays in immigration and customs processing, especially during peak hours, may not allow some passengers sufficient time to make it to their connecting flights. The simulation study is deployed to analyze staffing, routing, and queueing design in place to identify the bottlenecks in the overall process. Based on the results of the analysis, we propose an efficient queuing configuration that stipulates dedicated lines for passengers with tight connections at both the FIS and TSA stages. We demonstrate via simulation that our proposed solution can achieve significant sojourn reduction times across all levels, resulting in less misconnections, and thus yielding millions of dollars in savings annually. The study offers key insights for enhancing the passenger experience and operational efficiency for international arrivals with connections at international airports.",Simulating Transportation,205,249
DOES SCREENING FOR SDOH FACTORS IMPACT HEALTH OUTCOMES IN SEPSIS PATIENTS? A RETROSPECTIVE STUDY," Social determinants of health (SDOH) are known to influence health outcomes. The Medicare Hospital Readmissions Reduction Programs (HRRP) and other national initiatives are prompting healthcare institutions to identify and address social needs to improve patient health outcomes after discharge. Healthcare institutions utilize survey and in person screenings to collect patients’ SDOH information and include it in their electronic health records. Health practitioners at a regional hospital believe that the screening process itself may be leading to improved outcomes (regardless of SDOH data collected) in patients with sepsis, a common and costly primary diagnosis. This study investigates the significance of SDOH screening on sepsis patients’ outcomes of 30-day readmission. Patient data was collected from one hospital for one year (May 2022 – May 2023). T-test and Chi-square test are utilized to determine the relationship between the presence of SDOH screening and sepsis patients’ outcomes. The purpose of this analysis is to highlight whether there is a difference in outcomes between a patient who has been screened and one who has not been screened. The results help quantify the value of SDOH screening as a means of improving health outcomes, in this case, for sepsis outcomes.",Health Systems,78,250
Applying DMAIC for Cost Savings at Molding Area," The Manufacturing Industry in Puerto Rico is dedicated to designing, molding, and distributing products. It highly values outstanding customer service that meets and surpasses expectations, guaranteeing timely deliveries. However, over the past year, the molding area has witnessed a notable increase in scrap, nearing the 2023 waste limit of $76,000 by approximately 15%, resulting in material and productivity losses, leading to delays in product delivery and rework. XYZ Corporation aimed to reduce scrap, enhance production quality, and reduce manufacturing costs. They achieved this by implementing preventive and corrective actions, including using dummy sheets to prevent scratches on the last piece. In response to an unforeseen increase in a short period, the Manufacturing Industry in Puerto Rico applied the DMAIC methodology to effectively address the problem, ensuring that neither the company nor its customers are further affected. By the end of October 2023, a more precise data collection system will be implemented in the Molding Area, targeting a 5% reduction in scrap, equivalent to approximately $2,930 monthly. This initiative aims to enhance efficiency in material usage, productivity, and delivery times. Data analysis has highlighted operator errors as the primary contributor to scrap production, with operators depending on engineers and mechanics to halt production when defects are identified, causing the continued production of defective batches. It was recommended to count, register, and analyze nonconformities batches; and train the operator to follow quality standards, stop and fix and manage the MS Access database.",Manufacturing Organizations I,139,251
Surface Roughness Prediction of a Hard-Turning Operation via Machine Learning Models," In this work, we consider the problem of predicting surface roughness in the manufacturing context of hard-turning operations. Feed rate, cutting velocity, depth of cut, and force are considered as input parameters affecting the final quality of the manufactured part, which is reflected in a measure of surface roughness. In particular, the problem of predicting such a response in the presence of low availability of data, typical of such a manufacturing setting, is studied. Under data scarcity, machine learning models that rely on copious amounts of data for good predictive performance, such as neural networks, might not perform well in predicting the process response. Due to the stochastic behavior of the response variable, we propose a Kriging model, also known as Gaussian Process Regression, allowing us to interpret this turning process as a stochastic process, thus seeking to approximate the unknown functional relationship of the underlying manufacturing parameters to the surface roughness response. We provide computational results for a data set of turning operation surface roughness measurements and compare the predictive performance of the proposed Kriging model against classical machine learning approaches such as neural networks and various linear models.",Manufacturing I,135,252
The Economics of Higher Education Modeled as a Thermodynamic Heat Engine," The Carnot Cycle is the most efficient, reversible heat engine described via thermodynamic processes. As demonstrated by Khrennikov, the Carnot Cycle is also adept at modeling microeconomic processes. The economics of higher education is the embodiment of a specialized microeconomy relevant to many aspects of the modern world. From soaring tuition costs to the relevant return on investment for higher education, modeling this microeconomy would be beneficial to developing a better understanding of the mechanics of higher education as well as new strategies and approaches to financing it better and getting the most from investments in higher education. The Carnot Cycle represents the ideal situation against which all other cycles and processes operating between the same thermal reservoirs are measured to develop a representative measure of an actual cycle’s performance. An economic Carnot model fundamentally represents the best possible outcome within a set of prescribed circumstances against which other similar models can be compared. Furthering the isomorphology of thermodynamics and economics, i.e., thermoeconomics, this paper develops the case for developing an economic model based on a Carnot-framework, specifically related to the economics of higher education, as an ideal economic heat engine.",Resource and Asset Management,194,253
Enhancing Efficiency in Material Handling: A Comparative Study of AGVs and Conveyor Systems Across Industries," Central fill pharmacies (CFPs) and various industries extensively utilize conveyor systems to transfer goods between filling and packing stations. However, these systems present operational challenges in terms of efficiency and cost. The conveyor-based system, a longstanding method in CFP operations, involves manual filling of vials that are then transported via conveyors. This traditional approach, while established, is costly and time-consuming. The primary issue lies in the manual filling process at the filling stations, which results in higher operational costs and inefficiency, partly due to the extended length of the conveyors used. This study aims to explore the effectiveness of Automated Guided Vehicles (AGVs) as an alternative to conveyor systems, focusing on reducing cycle time and operational costs. A simulation model using FlexSim software was employed to assess the impact of transitioning from a conveyor system to an AGV system in a CFP setting. The simulation mimicked existing operations to validate the results. The adoption of AGVs led to a significant reduction in cycle time by 25%. Moreover, the cost analysis revealed that the AGV system is 50% cheaper than the traditional conveyor system. The implementation of AGVs in CFP operations substantially enhances efficiency and reduces costs. It is recommended that central fill pharmacies and similar industries consider integrating AGVs into their operations to achieve improved efficiency and cost savings. This transition not only streamlines processes but also provides a scalable and flexible solution for future operational demands.",Manufacturing,132,254
Vehicle Routing Problems with Volunteer Coverage," In disaster relief operations, modelers typically adopt a pessimistic approach, where we optimize for the worst-case scenario. In reality, there is a chance for human compassion and support which we can incorporate in the operations: specifically, we often see volunteers that are willing to offer their help and services. In this work, then, we present a series of vehicle routing problems that exploit this notion of volunteers who are able to optionally provide aid to surrounding areas. We incorporate human volunteers into our problems and determine the optimal routing scheme to minimize time and cost while meeting the demands of the locations in need in the network. We develop a novel model based on the Miller-Tucker-Zemlin constraints, which introduces the concept of optional demands for the benefit of supporting the aid effort in an area. We reintroduce fundamental problems in vehicle routing now with a more realistic (and optimistic) component. We present computational results that showcase how volunteers can dramatically reduce the response times of the affected areas. We also present a sensitivity analysis over varying levels of volunteer availability, ability to reach farther areas (volunteer radius), and robustness of transportation infrastructure.",Optimization in Transportation,156,255
Computer Simulation Modelling of Nursing Workload - A Scoping Review," BACKGROUND: For decades, healthcare systems have been plagued by high nurse workload levels. This has induced physical, mental, and emotional harm to nurse well-being leading to compromised care quality and staff shortages. A challenge healthcare systems face in addressing workload is its measurement. Recently, computer simulation has become a popular tool to quantify workload and analyze the outcomes of workload-related policies or design decisions. RESEARCH QUESTIONS: 1) How has computer simulation been used to model nurse workload? 2) Where are the opportunities for future nurse workload research? METHODOLOGY: The protocol followed PRISMA® Scoping Review Guidelines. Keywords and scholarly databases were selected in consultation with academic librarians. Studies with computer simulation models of nurse workload published in an English-language peer-reviewed journal prior to September 30, 2023, were included. RESULTS: 36 studies were selected. Inpatient acute care units were the most frequently modeled clinical environments. Discrete event simulation was the most used simulation method. Common variable types studied were staffing, care demands, and patient outcomes. Key understudied areas included modelling cost factors, psychosocial factors, emotional workload, and individual off-shift characteristics. DISCUSSION: Considering the cost consequences of workload within these models is important for uptake by healthcare administrators as decision support tools. Methodological challenges included the selection of keywords and a focus on breadth over depth. CONCLUSION: This is the first scoping review for simulation models of nurse workload. Simulation appears viable for quantifying and analyzing nurse workload, but workload cost-related consequences need to be added to current approaches.",Poster Presentations,169,256
Attention-Deficit/Hyperactivity Disorder Prognosis using Multi-Modal and Multi-Channel Polysomnography Data," Attention-deficit/hyperactivity disorder (ADHD) is one of the most prevalent neurodevelopmental disorders of childhood, and its effects on a patient's behavior may persist throughout their lifespan. ADHD is characterized by a persistent lack of concentration, hyperactivity, and impulsivity. ADHD exerts a significant adverse impact on millions of individuals globally, incurring substantial financial and resource costs. For instance, individuals grappling with ADHD often face challenges related to focus and time management, culminating in diminished academic and occupational performance. In addition, ADHD can engender strained interpersonal relationships due to impulsivity, leading to conflicts and social isolation. Nevertheless, there remains a considerable deficit in public comprehension and awareness of ADHD. Furthermore, the diagnostic process for ADHD is protracted, consuming valuable time and impeding the timely commencement of treatment for patients. To rectify the research gap, the overarching objective of this study is to establish supervised machine learning frameworks and algorithms for prognosticating ADHD of children using multi-modal and multi-chanel PSG data. This endeavor is anticipated to serve as a valuable adjunct or even a potential replacement for traditional survey-based diagnostic methods, offering advantages in terms of cost-efficiency, expeditiousness, and efficacy while benefiting patients. Furthermore, our research seeks to contribute to an enhanced comprehension of the factors intricately correlated with ADHD.",Healthcare II,84,257
A Review of Cultural Frameworks and their Influence on Engineering Identity Development," Culture has a tremendous influence on identity formation because it impacts behaviorally shaped norms and beliefs and defines interpersonal structures within a society. Culture can no longer be restricted to ethnicity or location due to globalization. Meanwhile, over the past decades researchers have increasingly focused on engineering education with a specific emphasis on professional identity formation. In the field of engineering education, identity has been shown as an indicator for academic and professional persistence. Thus, it is critical to enhance engineering education by preparing students as best possible in their identity development. To achieve this goal, it is crucial to understand how cultural characteristics impact engineering identity formation. Measuring culture is a complex process. Theoretical cultural frameworks are helpful tools in analyzing and understanding the different aspects that comprise culture. This paper undertakes a comprehensive literature review to study different cultural frameworks, such as Geert Hofstede’s six cultural dimensions, Edward T. Hall’s three cultural dimensions, GLOBE’s nine cultural dimensions and others, to evaluate their potential use in further exploring engineering identity formation. This study provides a comprehensive breakdown of the critical cultural measures that are viewed as impactful in better understanding professional identity formation. This paper is relevant to researchers and practitioners in engineering education and technical management.",Engineering Identity & Global Engineering Education,68,258
Effective and Sustainable Strategies for Federally Qualified Health Centers to Engage Young Adults," Federally qualified health centers (FQHCs) are instrumental in providing top tier healthcare and other resources to underserved populations. Whether they administer services in house or refer patients to other providers, FQHCs aim to provide comprehensive primary and preventative care services to people of all ages. They offer a range of services, from doctor and dental appointments to mental health and substance abuse counseling, regardless of a patient’s insurance status. To receive funding, FQHCs must follow the regulations and quality standards set forth by groups like the Joint Commission on Accreditation of Healthcare Organizations (JCAHO) and the Health Resources and Services Administration (HRSA). A variety of barriers prevent young adults (18-25), particularly from underserved communities, from accessing resources available at community health centers (CHCs). Encouraging more people to utilize the preventative care resources provided by community health centers will increase quality of life for underserved populations, reduce the future burden on the healthcare system, and allow CHCs to access more funding. Strategies to reach this currently hard-to-reach population were developed through interviews with health educators, analysis of existing patient data, benchmarking FQHCs across the United States, and surveying the target population. Barriers to utilizing preventative care resources were collected and current patient outreach strategies were assessed. New strategies were proposed and evaluated by current patient educators at multiple FQHCs. This research will outline a cohesive set of effective patient outreach strategies for FQHCs to increase their young adult patient base, particularly regarding preventative care.",Recent Advances in Health Systems II,185,259
Flow-Shop Scheduling Optimization through Discrete-Event Simulation and Neural Networks.," Schedule optimization of manufacturing systems is critical to improve operational efficiency. Typically, these scheduling problems become challenging because they involve coordinating various production tasks, resource management, and makespan minimization. These challenges are particularly evident in flow-shop manufacturing systems, where the operation sequencing significantly impacts overall performance. The main objective of this manuscript is to present the methodology followed to optimize the schedule of a flow-shop manufacturing system through the combination of discrete-event simulation and neural networks. With a specific focus on enhancing operational efficiency, the study aimed to employ the built-in neural network capabilities of Simio simulation software to optimize the makespan, consequently reducing the overall production time required for processing manufacturing orders. By exploring the integration of advanced simulation techniques with neural network functionalities, this research highlights the advantages of this powerful tool to model and optimize complex manufacturing processes. Moreover, the study emphasized the potential benefits for the manufacturing industry by implementing this methodology to facilitate informed decision-making and drive improvements in productivity and resource utilization within the context of manufacturing operations.",Integrating AI/ML in Simulation I,114,260
A Flexible and Synthetic Transplant Kidney Exchange Problem (FASTKEP) Data Generator," The Kidney Exchange Problem (KEP) optimizes a pool of incompatible patient-donor pairs and non-directed donors to determine the optimal cycles and chains of length-N that maximize transplants. A direct impact of KEP optimization is an improved quality of life for transplant recipients at a lower cost to the healthcare system (as opposed to dialysis treatments). To improve this process, synthetic data is commonly used to test and develop KEP algorithms. The canonical KEP data generation process is referred to as the Saidman Generator. The generator utilizes attributes of the donors and recipients that determine compatibility, such as blood type and protein compatibility, alongside known data distributions, including the percentage of different blood types comprising an exchange, to create datasets that aim to mirror the real world. Prior published Java implementations of this generator exist. However, in this work, an open-source data generation package implemented in Python is proposed for the KEP which mirrors the Saidman generator’s output. The proposed implementation is compared to a common Java implementation for scalability and efficiency. This generator allows for the integration of additional recipient and donor features that produce data better matching real-world exchanges. The result is an open-source Python implementation of a KEP data generator. The efficient creation of directed exchange datasets enables future work, including the use of the presented data generation process by ML/AI researchers in application to large-scale machine learning model training.",Healthcare Applications,82,261
GIFR: A Graph-Informed Functional Regression Model for Process-Structure-Property Relationships," High Temperature Superconductors (HTS) have demonstrated profound applications in capital-intensive industries. These high-field applications of superconductors have led to high demand for cost-effective superconducting tapes on a large scale. However, challenges arise from the instability in the growth conditions during the HTS manufacturing process, leading to nonuniform tape performance. This nonuniformity has, in turn, hindered the broad commercialization of HTS. To address this issue, it is critical to understand the Process-Structure-Property (PSP) relationships in the HTS manufacturing process and develop appropriate monitoring tools with enhanced interpretability and reproducibility. In this study, we present a novel approach, a graph-informed functional regression (GIFR) model, to achieve two primary objectives. The first objective is to unearth the intricate interactions among multivariate time series data, allowing for the systematic investigation and visualization of the underlying PSP relationships. The second objective is to leverage these PSP relationships to real-time predict and monitor the uniformity of tape performance in the HTS manufacturing process. The proposed GIFR model seamlessly integrates the discovered PSP relationships from a functional graphical model, with a functional regression model for real-time uniformity prediction and monitoring. The evaluation of our model using real data from HTS tapes demonstrates that the GIFR model can effectively discover PSP relationships and enable improved prediction of HTS tapes’ uniformity compared to other benchmark models.",Advanced Topics in Smart Manufacturing I,4,262
A Reinforcement Learning Approach to Solve A Remanufacturing Problem," The fourth industrial revolution (Industry 4.0) has led to numerous changes in how controls are implemented in industrial systems. This research considers a remanufacturing system in which there is usually a significant imbalance between supply of cores (or used material) and the demand for the finished remanufactured product. The problem of supplier selection in an Industry 4.0 setting can be set up as a Markov decision process (MDP), which allows the firm to select the appropriate supplier in order to meet demand from its customers while also ensuring its own profitability. The quality and timing of cores add significant variability to the system's behavior, making the associated MDP a challenging problem to solve. A reinforcement learning approach is suggested as a solution approach. Some numerical results are presented.","Data Analytics in Controls, Measurement, and Education",36,263
A Novel Roughness-based Metric for Uniformity Modeling and Monitoring in High-Temperature Superconductor Manufacturing," High-Temperature Superconductors (HTS) are widely recognized for their efficiency and minimal energy loss, making them essential in industries such as power transmission, energy storage, and electronics. Nevertheless, the challenge of maintaining a consistent critical current (Ic) along HTS tapes has posed a significant obstacle to their broad commercialization. Quantifying the uniformity of critical current over long HTS tapes is a complex research problem due to the inherent uncertainty of critical current and its dynamic evolution. In this study, we introduce an innovative approach using the Roughness-based Uniformity Metric (RUM) for assessing the uniformity of Ic. By integrating the roughness measure of functional regression with 1D fused lasso, this study aims to achieve two key objectives: (1) accurately measuring the uniformity of the critical current, and (2) minimizing the measurement noise. By employing the roughness measure of functional regression for uniformity assessment and applying 1D fused lasso for smoothing, our method enhances the precision in detecting changes in the critical current. The statistical process control techniques will then be utilized to monitor and capture the significant drop-out events on the tape. We demonstrate the effectiveness of the proposed approach through uniformity modeling and monitoring on three different HTS tapes. The results will also be presented for comparison with the conventional uniformity metric, e.g., the coefficient variation.",Advanced Topics in Smart Manufacturing I,4,264
Dynamic workforce allocation to respond to workload variability," Achieving operational readiness and making effective decisions to allocate resources in dynamic environments present significant challenges. This study explores how cross-training staff can enhance adaptability to workload fluctuations, elevating process flexibility to improve responsiveness. Investment in cross-training levels is complex to quantify and entails trade-offs between increased payrolls, process rates, improved resource utilization, and uncertainties regarding task performers. Our research focuses on assessing the impact of workforce cross-training strategies within a warehouse container movement scenario. Employing a two-phase approach that combines planned and dynamic resource allocation through optimization and simulation, our model enables us to: (1) identify adaptive strategies for addressing task variations, (2) measure the impact of job interruptions on task completion, and (3) establish a feedback loop linking process variability and cross-training levels to achieve optimal workforce flexibility levels.",Facilities Design & Planning III,73,265
Option valuation of energy storage integration considering renewable electricity production tax credit," This paper delves into the challenges and opportunities in the wind energy sector, particularly focusing on the role of wind energy as a sustainable energy source amidst growing environmental concerns and the need to mitigate carbon emissions. A primary challenge for wind energy is its variability and the issues it poses for grid stability, often leading to grid instability and energy curtailment when production does not match demand. In response to these challenges, this study explores the financial feasibility of integrating energy storage systems into wind energy operations. The central question is whether the high capital costs of energy storage can be justified within the operational and economic framework of wind energy firms. To address this, we adopt a real options analysis approach, utilizing a binomial lattice model. This methodological choice allows for a detailed assessment of the financial viability of energy storage, factoring in the uncertainties of electricity demand. A significant consideration in our analysis is the potential for energy storage to extend the operational period of wind energy systems. This extension allows the wind firm to achieve increased financial incentives through the Renewable Electricity Production Tax Credit for renewable energy generation. Our research aims to quantify the added value of energy storage in light of this benefit. By providing a comprehensive financial analysis under varying conditions of uncertainty, our paper contributes to informed decision-making in the renewable energy sector.",Energy Markets,64,266
"Multi-Agent Game-theoretic Framework for Managing the Local Electricity Market with Electric Vehicles, Renewable Resources, and Commercial Prosumers"," Local electricity markets (LEM) are pivotal in optimizing active distribution systems, driven by renewable resources, electric vehicles (EVs), and flexible loads. In this paper, we propose a novel multi-agent competitive bi-level framework for LEMs, where a local transaction center (LTC) is at the upper level of the market and responsible for ensuring the active participation of business entities in the market while improving grid stability. In the second level, load aggregator (LA), charging station (CS), and commercial prosumer (CP) are the aggregated representatives of different utilities in an LEM aiming to maximize their profit through bilateral links and dynamic negotiations. LA is an aggregated representative of residential complexes with flexible loads, CS is an EV charging station with V2G technology, and CP is a no-load agent of the market with medium-scale energy storage and PV. Each pair of agents negotiates to determine a price-quantity curve for their direct link and then decides on the hourly amount of energy transaction through a competitive game. We solved this problem using game theory with a focus on identifying Nash equilibrium solutions to optimize energy transactions and enhance grid stability. Results based on a realistic case study demonstrate that our proposed framework results in a significant reduction in energy transactions with the grid, improving grid stability compared to other market structures. Results indicate that a benevolent LTC benefits the second-level agents by increasing their overall profit while a selfish LTC prioritizes earning more profit to enhance its resources and improve grid stability.",Energy Markets,64,267
DESIGNING A RESILIENCE LOGISTICS NETWORK USING METAHEURISTICS," The global manufacturing sector faces significant logistics challenges due to rising costs, longer lead times for materials delivery, and demand uncertainties. Additionally, relying more on third-party logistics providers might pose a threat of having a limited routing network. In literature, logistics network design is a complex combinatorial optimization problem that involves intermodal transportation options. Several scholars addressed this problem through linear programming, non-linear integer programming, simulation techniques, and metaheuristics algorithms. A US-based manufacturing facility is confronted with redesigning its logistics network to distribute materials across its facilities worldwide. The network model includes suppliers consolidating their materials at a distribution center, transferring them to the manufacturing facility, and distributing them to other facility locations. This research aims to optimize an intermodal logistics network using metaheuristics algorithms. The objective also involves minimizing transportation time and costs and designing a more reliable network. The model employs metaheuristics algorithms such as simulated annealing (SA) and particle swarm optimization (PSO) to address transportation options' complexities. Furthermore, this work compares the algorithm's performance in optimizing the network. Additionally, sensitivity analysis is utilized to estimate the model's robustness by assessing the impact of parameter variations on the network. The expected result includes developing a more robust, efficient, and diversified logistics network with reduced costs and transportation lead times for the manufacturing company.",Supply chain Risk & resilience 2,220,268
EFFECTS OF HUMANOID FEATURES OF CO-ROBOTS ON PERCEIVED SAFETY AND MENTAL STRESS," The rising prevalence of human-robot collaboration (HRC) across diverse domains necessitates understanding participants’ perceptions of robot humanoid features like appearance and voice. This study explores the effects of these features on mental stress, crucial factors shaping HRC system effectiveness and acceptance. Previous research has shown that the appearance and voice of robots can influence participants’ perceptions and attitudes towards robots. For instance, research has shown that participants tend to perceive robots with a more human-like appearance as more approachable and trustworthy than those with a more mechanical appearance. Similarly, research has also shown that the voice of a robot can affect participants' perceptions of its personality and emotional state. Yet, research primarily relies on self-report measures, leaving gaps in understanding physiological responses. This study aims to bridge this gap by integrating subjective ratings and physiological assessments. It hypothesizes that variations in robot voices and appearances will significantly influence mental stress of participants in HRC tasks. The study employs a 3 × 3 randomized factorial design involving a co-robot (Universal Robot 5e) with varied appearances (human face, cartoon robot face, blank screen) and voices (human-like, robot-like, beeping sound). Tasks involve handover movements of Lego parts from the robot and assembly into specific shapes across nine experimental conditions. Measurements of mental stress include subjective reports, skin conductance, eye tracking, and electrocardiogram. By analyzing these measures, the study aims to uncover appearance and voice effects on mental stress, offering insights to refine co-robot design for improved effectiveness and user-friendliness in collaborative scenarios.",Digital Transformation,50,269
Advancing Resilience and Survivability of Buildings by Integrating Life-Cycle Assessments with Multi-Objective Linear Programming," The increasing frequency of natural disasters has been affecting communities, economies, and the built environment. To address this issue, there is a need for a holistic sustainability framework that considers resilience and survivability engineering in building design. Sustainability in building practices ensures that modern infrastructure requirements are seen, while preserving future considerations to economic, environmental, and social aspects. Further, resilience and survivability engineering contribute to the design and formation of buildings by optimizing specific life-cycle performance criteria. Integrating Life Cycle Assessment (LCA) with Multi-Objective Linear Programming (MOLP) is a promising way to enhance the resilience and survivability of infrastructures and promote sustainable building performance over time. Therefore, this study summarizes the current ways of measuring resilience and survivability and points out important gaps, possibilities, and limits of LCA-MOLP underway projects. It suggests parameters that should be used in objective functions to get the most use out of a building, while minimizing damage, waste, and the chance of tearing it down using the LCA-MOLP method. The model is useful to outline a blueprint for sustainable building in disaster-prone areas, focusing on optimal material use and design. In future research, the model can be adjusted by measuring the values of design elements, testing the framework with real-life examples, making sure local building codes are followed, and using decision-making tools to find the best design options.",Resilience in Construction,192,270
Neural Embedded Optimization for Integrated Location and Routing Problems," We present a novel framework that combines machine learning with integer programming for solving the Location Routing Problem. The latter is a classical yet complex model that integrates strategic facility location with operational vehicle routing decisions, with the goal of simultaneously minimizing both fixed and variable costs. It is strongly NP-hard and subsumes two classical combinatorial optimization problems: the discrete facility location and vehicle routing problems. We develop a new solution method that first learns a permutationally invariant and sparse neural network to approximate the optimal vehicle routing cost of arbitrary assignments of any subset of customers to any candidate facility. The trained neural network serves as a surrogate that we then embed in a mixed-integer program. Specifically, the neural surrogate is reformulated using additional variables and constraints and solved with off-the-shelf MIP solvers. Notably, the proposed approach is completely modular in terms of both problem class and size and it does not require any problem-specific knowledge or tuning of parameters. Computational experiments on large-scale test instances containing up to 200 customers reveal that our proposed method can identify near-optimal solutions significantly faster than existing problem-specific heuristics, even finding new best-known solutions for some large-scale instances. These findings also suggest that the proposed neural embedded framework can be a viable method for solving more general integrated planning and scheduling problems.",Logistics & Supply Chain Best Paper Competition,121,271
"Characterization of multimodal logistics systems for agricultural development, a systematic review identifying the Latin American case."," Characterization of multimodal logistics systems for agricultural development, a systematic review identifying the Latin American case. Climate change is forcing agricultural supply chains to become more productive as part of meeting the Sustainable Development Goals. This summary presents a systematic review of the literature that allows to roughly characterize the current state of multimodal logistics systems for agricultural development in the world, focusing on the Latin American case and particularly on the Colombian case. This work is framed in the proposal of a doctoral thesis that seeks to increase productivity in agricultural supply chains in Colombia, using numerical methods and operations research.",Supply chain design 1,221,272
"The Price of Inaction: How Climate Change is Affecting the Bottom Line for Sectors, Companies, and Financial Instruments"," Climate change is one of the greatest risks facing the global economy today. Transitioning to a low-carbon economy is key to mitigating the risks of climate change. The transition to a climate change economy will affect various sectors, companies and financial instruments. Transition risks include financial risks from the loss of assets and operational risks from changes in business models. At the same time, it is also important that companies and investors continue to work with policymakers and regulators to help shape the policy and regulatory frameworks needed to support the transition to a low-carbon economy. This includes advocating for policies and regulations that support the implementation of the Paris Agreement and other international climate frameworks and promote sustainable and responsible investment practices. Ultimately, the transition to a low-carbon economy represents one of our time's greatest challenges and opportunities. By taking a proactive, strategic and collaborative approach, companies and investors can mitigate the risks of climate change and make the most of them. About the opportunities to drive the transition to a more sustainable, low-carbon future.",Aligning Profit and Planet and Addressing Water Challenges (SDG 6/SDG 12),16,273
PCT Market Development – An Opening to New Employment & Entrepreneurial Opportunities in Green Operations?," It is well documented in literature that carbon emissions are a major component of greenhouse gas emissions causing global climate changes. Some developed countries are also in the process of devising policies and procedures to reduce their carbon emissions in various sectors of their economies. Transportation and household sectors’ energy use for heating and cooling contributes 20% to 40 % of their total emissions in the USA and UK respectively. Researchers working in the UK proposed personal carbon trading (PCT) schemes to reduce carbon emissions, and it is proposed that every individual in the country would be allocated a fixed quota of personal carbon trading allowance each year. Those who need more than their allocated quota can buy it from those who save part of their allocated quota. However, the review and analysis of literature related to PCT allowance have shown that the nature of PCT allowance, and its market is unique, and significantly different from corporate shares and its market. In this paper, the unique characteristics of PCT allowance certificate/s and its market are identified along with the identification of basic policy tools needed to develop efficient PCT market. Understanding the nature of PCT allowance, and its market along with the implementation of suitable policy tools to market operations efficient can open new employment and entrepreneurial opportunities in the area of green finance and green operations in future. The content of the paper may be useful to researchers, professionals, entrepreneurs, academicians, and government policy makers.","Advancing Climate Action in Business, Technology and Transportation (SDG 13)",13,274
Reliability Modeling of Human Lumbar Functional Spinal Units System Degeneration," The degeneration of the human lumbar functional spinal units system greatly threatens human health and has caused enormous socio-economic burdens worldwide. The functional spinal units system consists of multiple subsystems, each of which has interdependent components that degenerate subject to stochastic uncertainties. Existing regression-based statistical models fail to characterize the system’s temporal changes under uncertainties mathematically. The time-related progression of the system’s degeneration and the failure time of the degenerated system are yet to be quantitatively demonstrated by the prediction model. In this paper, we develop a stochastic model for the human lumbar functional spinal units system degeneration. More specifically, we investigate the combined effect of each component’s individual degeneration mechanism, their spatial and mechanical interdependencies and their failure mechanisms on the overall system reliability. Statistical metrics such as reliability function, failure time distribution, remaining life prediction, etc. are proposed. The simulation and case studies are conducted and the actual time-series degeneration data are collected for model validation. The results show the accuracy of the proposed models. This work fills the gap in modeling and predicting a system degeneration in the human body and provides a framework for the degradation modeling of such complex systems in future research.",Reliability Analysis I,186,275
Evaluation of Wood-based SNG & FPL Options for Zero-Fossil Fuel DHS," Due to technological and economic limits woodchip fueled biomass-based district heating systems (DHSs) typically operate as baseload units, leaving peak load and backup heat production to fossil-fuel based boilers. Most woodchip-based heating systems replace 70% to 80+ % of the fossil fuel, leaving some residual fossil fuel use associated with Greenhouse Gas emissions. Literature review related to wood-based biofuels have shown that wood based Synthetic Natural Gas (SNG) and Fast Pyrolysis Liquids (FPL), also known as Pyrolysis Oil, can be used to replace fossil fuel, and technically be integrated into the natural gas grid in British Columbia due to recent changes in gas quality standards. Given the technical feasibility of SNG and FPL to replace fossil fuel to meet peak load demand in District Heating Systems (DHSs), eleven SNG, and one FPL related production scenarios are evaluated and compared with base case scenario related to burning natural gas that produce greenhouse gas emissions. This paper is based on a case study of a DHS operating in a Northern British Columbia Community (Canada) and is helpful to compare the cost of wood-based SNG and FPL production scenarios to replace peak load fossil fuel based natural gas burning scenario. The findings of this paper could be useful to researchers, educators, students, community mayors, and managers of DHSs in planning to create zero-fossil fuel district heating systems. The findings of this study could also be useful to communities in other parts of the world having similar climate, forest, and agriculture resources.","Unlocking the Potential of Clean Affordable Energy: Innovations in Biomass, Biofuels, and Offshore Wind (SDG 7)",235,276
Deep Latent Factor Model for Spatio-Temporal Forecasting," In environmental monitoring systems, enhancing the accuracy of predicting future responses at unmeasured as well as measured locations (i.e., spatio-temporal forecasting) is crucial for improving the quality and reliability of their monitoring services. Over the decades, latent factor models have been studied as a prevalent approach for spatio-temporal forecasting, and they commonly achieve this by modeling temporal dependence using latent factors and considering spatial dependence using a spatial prior on factor loadings. However, their forecast accuracy may be limited because the latent factors are typically assumed to follow a classical linear time series model, such as a vector autoregressive model. This limitation can result in a failure to capture complex spatio-temporal dependence. In this study, we propose a deep latent factor model for spatio-temporal forecasting that can model complex spatio-temporal dependence more flexibly by leveraging the high expressive power of a deep neural network. Specifically, the latent factors are modeled using a recurrent neural network and the factor loadings are modeled using a distance-based Gaussian process. We derive a stochastic variational inference algorithm for scalable inference of the proposed model and validate the model using simulated and real data examples.",Innovative Applications of Artificial Intelligence II,110,277
"Estimation of Global Horizontal Irradiance in Tustin, California, using Several Deep Learning Approaches"," The design of solar energy systems poses significant challenges, encompassing issues related to infrastructure, installation costs, and land availability and selection. In the practical implementation of such projects, location selection is critically dependent on numerous vital criteria, one of which is the estimation of received solar radiation. For instance, solar radiation estimation is pivotal for designing proper energy storage systems, load balancing, and the management of photovoltaic and thermal systems. Machine and deep learning approaches have been commonly utilized in solar radiation forecasting and estimation. This paper deploys multiple deep learning techniques, including feed-forward neural networks, Long Short-Term Memory (LSTM), and Convolutional Neural Network (CNN) to estimate the amount of Global Horizontal Irradiance (GHI) received in the city of Tustin, California using multiple metrological factors. California was selected for this study because it is characterized by receiving high amounts of solar radiation and having numerous solar energy installations and projects. The paper compares the three examined deep learning methods using evaluation metrics like the Root Mean Squared Error (RMSE) and the Mean Absolute Deviation (MAD). The findings indicate that the LSTM approach emerges as the most effective deep learning technique for estimating the hourly GHI.",Energy & Environment II,63,278
Quality prediction of hot rolled products based on penalized quantile mixed regression model," Quality prediction of hot rolled products is the key to reducing costs and increasing efficiency, and the steel composition and process parameters are key factors affecting product quality in hot rolling process. The high complexity and volatility of actual production data have an impact on the accuracy of data-driven models, which poses a huge challenge for product quality prediction. In this paper, a framework for quality prediction combining data-driven and physical metallurgical models has been proposed with complex data. A penalized quantile mixed regression model is used to aggregate differently sourced data for robust variable selection and estimation in high-dimensional and complex data analysis. Functional data analysis and hot rolling knowledge naturally integrate the dynamic information into the model to improve the prediction accuracy. The proposed formulation is convex, and thus it is numerically and efficiently solved with the proximal gradient descent algorithm within the Alternating Direction Method of Multipliers (ADMM) framework. The accuracy and efficiency of the proposed method are verified by applying the method to the product quality prediction of a hot rolling production line in a steel mill.",Statistical Learning and Artificial Intelligence for Quality Control I,211,279
Sustainability in Manufacturing: A Guide to Circular Economy Practices and Key Performance Indicators," In today's push for sustainability, applying Circular Economy (CE) principles, United Nations Sustainability Development Goals (UN-SDGs), and the 6R concept (Reduce, Reuse, Recycle, Recover, Redesign, and Remanufacture) is crucial for the manufacturing industry. Amidst escalating global challenges such as resource scarcity, economic inefficiencies, social inequalities, and environmental degradation, the CE model has emerged as a pivotal framework for sustainable development. This momentum is derived from its ability to replace the conventional linear economy model (i.e., take, make, use, and dispose). This work highlights the significance of the proper selection of Key Performance Indicators (KPIs) and their crucial role to decision-makers in the manufacturing industry. These KPIs are intended to effectively measure and reflect system changes and address global issues concerning UN-SDGs. The study involves a comprehensive literature review across various manufacturing sectors. It collects several key performance indicators (KPIs) and categorizes them into two proposed sorting phases. The first phase aligns each KPI with the seventeen Sustainability Development Goals, showcasing their potential to describe and contribute to assessing the UN's promising goals. The second phase delves deeper, strategically recategorizing KPIs based on the 6R concept. The paper's core aims to explore the crucial role of the CE indicators in fostering sustainability within the manufacturing industry. Manufacturers can align their KPIs with different 6R practices by proposing a systematic guide for tailored KPI selection, aligning with global initiatives such as UN-SDGs. The findings serve as a compass for manufacturers, business partners, and practitioners that guide them through a successful decision-making process.",Manufacturing process improvement,141,280
A Supervised Learning Approach for Throughput Determination in Automated Storage and Retrieval Systems," As automated storage and retrieval systems (AS/RS) evolve, their increasing complexity poses challenges in developing accurate and runtime-efficient analytic models for throughput determination. Timely and precise throughput calculations during the design phase are crucial for effective system planning. While discrete event simulation (DES) is a common alternative, it may be computationally intensive and lacks adaptability to storage system changes. In this study, we propose a novel approach by integrating supervised learning into the throughput determination process. Based on the results of DES, we train an artificial neural network (ANN) to predict throughput based on various system parameters. The ANN is trained using historical data generated through DES, allowing it to learn complex relationships and patterns. To assess the prediction quality of our neural network, we compare its results against DES results for unseen instances. The evaluation demonstrates the effectiveness of our supervised learning approach in accurately predicting throughput under diverse system scenarios. Additionally, for simpler instances, we explore the use of analytic models for comparison, shedding light on the trade-offs between traditional analytical methods and our machine learning-based approach. This research contributes to the advancement of throughput determination methodologies for AS/RS, offering a robust and adaptable solution that complements existing techniques and addresses the challenges posed by system complexity.",Facilities Design & Planning I,71,281
Decision Support System for Digital Credit Users Prioritizing Privacy," In the rapidly evolving landscape of digital credit, users encounter the challenge of selecting the most suitable provider from a plethora of options. In this research we proposes a Multiple Criteria Decision Making (MCDM) to empower digital credit users in choosing a provider aligned with their unique preferences and privacy concerns. This model aims to bridge the gap between the dynamic nature of digital credit operations and the need for robust decision-making tools that prioritize user preferences and privacy. Users have the ability to tailor their preferences by assigning weights to various criteria based on their individual needs, fostering a sense of empowerment and customization. The model integrates ""digital data privacy"" as a central criterion, acknowledging the growing significance of privacy considerations in the digital credit space. Privacy metrics are carefully selected and weighted, allowing users to make decisions that align with their privacy preferences. By providing users with a transparent view of how different digital credit providers perform concerning privacy and other criteria, the model contributes to building trust between users and providers. Transparency is a cornerstone in fostering a positive and secure user-provider relationship. Additionally, the model is designed to adapt to changing conditions, such as regulatory updates or shifts in industry practices. It serves an educational purpose by raising awareness about the importance of digital data privacy, empowering users with knowledge to make informed decisions. This research seeks to establish a holistic and adaptable user-centric digital credit ecosystem.","Privacy, security, and resilience",174,282
Improving Patient Access to a Rural Autism and Developmental Medical Center," The Geisinger Autism & Developmental Medicine Institute (ADMI) in Lewisburg, PA, completes approximately 1000 new diagnostic evaluations annually for a range of neurodevelopmental disabilities (NDDs), including global developmental delay, intellectual disability, and autism spectrum disorder. ADMI has excessive wait times due to a shortage of neurodevelopmental pediatricians and developmental-behavioral pediatricians. Additionally, ADMI is located in a rural area serving a large catchment region. Because of this, patients cannot return for multiple visits, and new visits need to include developmental and medical evaluations on the same day. To solve these issues, ADMI developed a unique pathway for evaluations, which has increased capacity and decreased wait times. Visits are paired between clinical psychologists for diagnostic evaluation and advanced practice providers for medical assessment in a single visit. While this multidisciplinary approach reduces wait times, it also complicates scheduling. Modeling different patient variables and wait times will allow ADMI to refine its scheduling to reduce wait times further.",Patient Care and Treatment II,161,283
Instrument Tray Coordination between Sterile Processing and Surgery: Navigating Challenges," The sterile processing department (SPD) can significantly affect surgical effectiveness. A well-designed SPD workflow can enhance patient safety, minimize operating room (OR) delays, and boost overall productivity. To gain insights into the dynamics of sterile processing and the interactions between OR and SPD, we employed process maps and task analyses derived from direct observations of key SPD functions: decontamination, assembly, sterilization, storage, and case cart preparation. Rapid turnover of trays and add-on cases can put a strain on the SPD’s capacity, leading to increased stress levels in the SPD. As a result, the possibility of errors increases, and trays may contain bioburden, missing instruments, or non-functional instruments. Furthermore, it may lead to OR personnel requesting duplicate trays beyond actual needs, placing strain on the SPD inventory and its capacity to process dirty trays. This cyclical behavior then increases or creates mistrust between OR and SPD. This research also addresses other challenges such as replacement tray needs, on-time start pressures, flash sterilization, and fast-tracking trays. Using a discrete event simulation modeling approach, we assess overall system performance based on tray availability and the likelihood of surgical delays using varying levels of the following conditions – surgical volumes, resource staffing, and staff workaround behaviors that include duplicate tray requests and flash sterilization. This approach will enhance the ability of an organization to understand tactical and operational decision-making in SPD.",Recent Advances in Health Systems I,184,284
Optimizing Operational Efficiency: A Comprehensive Time Study at Curtis Instruments Inc. for Enhanced Workflow in Electric Vehicle Controller Manufacturing," At Curtis Instruments Inc., a leading international manufacturer of speed technology controllers for electric vehicles, our comprehensive time study project aimed to elevate operational efficiency through a three-phase exploration. In Phase 1, utilizing the stopwatch method, we meticulously examined the repetitive assembly process of the PB-75 product. Our analysis involved identifying key elements, constructing flow diagrams, and leveraging floor layouts for guidance. Rigorous outlier removal based on Dixon test results and control charts paved the way for determining standard time using Westinghouse and ILO's allowance approach. Actionable insights emerged, steering us toward workflow improvements that encompassed the optimization of workstations and procedures. Transitioning to Phase 2, we closely observed workers' movements during the assembly of PB-75, employing the MTM approach. The resulting MTM table provided invaluable Time Measurement Units (TMU), informing both observed and standard timings. Suggestions for a new procedure surfaced, with MTM results indicating potential developmental areas and showcasing efficiency gains compared to the Stopwatch method. In Phase 3, our focus shifted to Work Sampling across three ICT machines in the inspection test lines. These machines rigorously validate the proper functioning of each board. Over a preliminary 8-hour shift study spanning five days, we meticulously collected 900 observations through random sampling. Leveraging this rich dataset, we conducted diverse analyses, including production tables, P-Charts, Pareto charts, productivity percentages, and standard time calculations. The outcome aimed to uncover and address potential areas for improvement, completing our holistic effort to enhance operational efficiency at Curtis Instruments Inc.",Poster Presentations,169,285
The Industrial and Systems Engineering role in enabling synergies between lean construction and sustainability," Lean construction has emerged since the early 1990s as a solution to wasteful practices in the construction industry that have limited productivity and inflated costs. Approximately 70% of traditional projects exceed their proposed schedule or as well as their budgets. Research studies by the Construction Industry Institute (CII) and the McGraw-Hill organization have identified the losses due to wastes in traditional projects as approximately 30% of the construction dollar. Glenn Ballard and the late Greg Howell, co-founders of the Lean Construction Institute (LCI), described lean construction as a new project delivery method that maximizes value and minimizes time, motion, and other wastes. While lean construction has reduced construction costs - often by 10% or more, and improved stakeholder satisfaction, it has not been focused on promoting environmental sustainability. In fact, many construction owners view the adoption of initiatives such as LEED as imposing higher initial costs, and representing a “green premium” that disincentives sustainable construction. This paper posits that the savings from lean construction can synergistically offset the green premium and promote the “triple bottom line”. a) Leveraging lean construction to offset the premium” b) Enabling a smaller carbon footprint and c) Positioning industrial and systems engineers as lean facilitators in sustainable construction projects.",Construction Performance,30,286
A New Matheuristic for Improving Political Districting Plans," Every ten years in the United States, lawmakers sort the citizens of each state into groups of roughly equal population in what is called a “redistricting plan”. These plans optimize multiple objectives, including geographic compactness, minority representation, and metrics relating to partisan fairness. These plans may be vetoed, struck down by courts, or otherwise invalidated. In this case, a new plan must be drawn to improve and replace the invalidated plan. We present a new matheuristic method that takes an existing redistricting plan as input, and iteratively solves a mixed integer program (MIP) based on local search regions of individual districts in the plan. Our method can improve a plan’s performance across several metrics, including compactness, partisan fairness, minority representation, competitiveness, and/or number of county splits in the plan. We present computational results, including examples of improvements to currently contested redistricting plans.",Policy-driven Decision Making,168,287
Early prediction of patient disposition decisions in emergency departments, Emergency department (ED) boarding refers to the practice of holding admitted patients in the ED while awaiting an inpatient bed. Timely transitioning patients from the ED to inpatient units within the hospital is a common issue in the US. The early prediction of disposition decisions and the likelihood of admitting patients to inpatient units is one mechanism for addressing this issue. We have developed a prediction model utilizing patients' clinical and demographic characteristics. This model serves as a decision support tool to provide the inpatient unit managers with near real-time predictions of their unit's demand when the patients are still in the early stages of their caregiving process in the ED. The study proves that predicting the likelihood of admitting patients to inpatient units will improve the communication between units and help to proactively manage the inpatient bed capacities before any surge in demands happens.,Predictive Models in Health Systems,170,288
A Comparative Study of Manufacturing Methodologies and Their Interconnectedness for Operational Excellence," Optimizing manufacturing processes is vital to maintain global competitiveness. Organizations strive to enhance operations through diverse continuous improvement philosophies, yet face challenges in determining context-specific effectiveness. This paper will investigate key manufacturing methodologies, including Synchronous Manufacturing, Theory of Constraints, ERP Systems, Lean Manufacturing, Design for Manufacturing, Just-In-Time (JIT), and Computer Integrated Manufacturing (CIM). This research provides a comparative analysis of each methodology's frameworks, strengths, and limitations. The results show that no universal ""best"" methodology exists and advocates for a nuanced approach, to deepen the understanding of their interconnectedness. Considering the integral role of data information flows in manufacturing optimization, the need for new methodologies that apply similar efficiency frameworks and philosophies to data and information flows is imperative to bridge the gap from physical systems to advanced data-driven cyber-physical systems.",Manufacturing process improvement,141,289
3D-Printed Sacrificial Mesh Inserts for Interconnected Hydrogel Tissue Scaffolds," Tissue engineering is a multidisciplinary field that combines manufacturing, biology, and material science to fabricate functional biomimetic tissues. By utilizing various methods such as 3D printing and bioprinting, specific structures can be designed and fabricated for cell proliferation and differentiation. However, common issues such as overhang limited the printing of intricate internal geometries. Also, bioprinting is challenged by the conflict between improved printing resolution and cell damage caused by the extrusion nozzle. Here, we designed 3D-printed sacrificial mesh inserts with cell-embedded hydrogels injected into the mesh structure for interconnected channels and improved cell viability. We compared the injected hydrogel scaffolds with bioprinted scaffolds for shape fidelity, mechanical strength, and channel size. This project shows the potential of using 3D-printed sacrificial molds/inserts as potential tissue scaffolds.",Bioprinting and Biomedical Manufacturing Processes-II,20,290
From Crisis to Strategy and Action: Understanding the Impact of COVID-19 on Implementing Knowledge Management in Organizations," As Knowledge Management (KM) offers significant benefits for organizations, its implementation is crucial for them to make sure they take advantage of those benefits. However, risks and uncertainties are undeniable when working towards a goal on almost every project. As a result, when approached as a project, Knowledge Management Implementation (KMI) would require taking Risk Management (RM) into account. With the changes that organizations underwent during the Coronavirus (COVID-19) Pandemic (CP), it is clear that managing risks when it comes to such a situation is exceptionally important. To address this issue, the paper utilizes an RM approach for KMI project within organizations, with a special attention to the risks particularly caused by the CP. More specifically, to address each identified risk of the project, this paper suggests possible effective strategies and actions to deal with it. As a result, organizations will have a better understanding of how CP can affect KMI in their organizations and what strategies and actions would be helpful in dealing with them. Doing so can help organizations ensure that they can implement KM in their organizations more smoothly and use the KM benefits provided for them. Accordingly, it has been concluded that under the CP environment, KMI project managers should embrace a proactive approach to RM. Towards this end, they should strive to minimize the negative repercussions of threats and maximize the positive outcomes of opportunities.",Engineering Management Best Student Papers,69,291
Innovative Mobility: Unveiling the Adaptive Spool Cart for Enhanced Operator Efficiency and Sustainable Manufacturing Practices," In response to identified ergonomic challenges in wire spool handling at Lutron, we developed a mobile and adjustable spool cart with a high weight capacity, aiming to enhance operator well-being, streamline workflow efficiency, and provide a cost-effective solution. The product development process incorporated a comprehensive Google Forms survey with 64 respondents, gauging potential demand and a Master Production Schedule estimating a market size based on survey responses categorized by age and gender. Our materials management method detailed the necessary raw materials, components, and sub-assemblies for manufacturing, associated costs, and a procurement planning system. While observing potential applications across industries, we recognized the cart's potential to mitigate ergonomic challenges, prevent injuries, and enhance worker well-being. Furthermore, the product aligns with UN Sustainable Development Goals (SDGs) 8, 3, and 10, promoting safe working environments, well-being, and social inclusion. Despite the promising survey results, caution is warranted due to the limited sample size and potential self-reporting bias. Actual market demand may vary, necessitating ongoing monitoring and assessment. Although alignment with UN SDGs is beneficial, success in achieving these goals is not guaranteed. The study, focusing on ergonomic challenges in electronic manufacturing, introduces a spool cart designed for adaptability, mobility, and high weight capacity, supported by robust market insights, cost estimation, and alignment with global sustainability objectives.",Poster Presentations,169,292
Ingredients Portions Standardization in Pizza and Calzone," One of the great challenges that a local pizzeria faces is how to control the amount of ingredients/toppings that are placed in each product that is made, such as cheese, sauce and pepperoni. One of the areas of opportunities identified was the lack of standardization in the quantity of ingredients, causing waste on the one hand and customer dissatisfaction on the other. Currently they do it in plain sight and whether the pizza maker has a large or small hand will be an element of variability. Which brings inconsistency in the quality of the pizzas. After defining the problem and using the problem-solving technique, DMAIC, was observed with the use of the boxplots for the big pizza and calzone, there are great variations of the toppings. The confidence interval was very wide which also helps observe the great variation in the weights by products. This can create a negative impact on the business since there is no standardization in the topping’s weights. Using ONU goal 12 one of the solutions was promote more sustainable production and consumption, reducing excess ingredients, promote efficiency of the pizzeria. This is, the standardization of the weight of the toppings in the pizza and calzone, define a standard weight, do operator training, and follow a standard work with visual guides. Then, to keep the standardization of weight going and create a culture, the pizzeria would have to do regular audits, do topping consumption monitoring and evaluate continually the topping purchasing process.",Poster Presentations,169,293
Multi-Crane Operation Scheduling Problem of Power Grid Warehouse, This research investigates a multi-crane scheduling problem from a power grid warehouse. The objective of this problem is to optimize the sorting and allocation of tasks while ensuring that the crane operation meets the safety standard. We formulate the problem as a mixed integer programming model and solve it via a commercial solver. The data experiment of a power grid warehouse shows this model can effectively reflect the operating characteristics of multiple cranes in the warehouse and offering significant multi-cranes operation solutions.,Urban Logistics,237,294
Circular Biomass-bioenergy and Biofuel with Carbon Capture and Storage Supply Chain Network Optimization," Biomass-bioenergy and biofuel have great potential in alternative renewable energy production and carbon reduction. Biomass can be converted into various bioenergy and biofuels via fermentation, pyrolysis, gasification, or combustion with carbon capture and storage. In this paper, we evaluate the techno-economic feasibility and the environmental impacts of major terrestrial and aquatic biomass-bioenergy and biofuel conversion technologies for using the primary terrestrial and aquatic biomass feedstocks with biochar recycling. We also develop a two-stage stochastic programming model with incorporate spatial and techno-economic data to optimize the renewable bioenergy and biofuels with carbon capture and storage supply chain network. The model economically optimizes the geographic distribution and scale of biomass resources, conversion refineries, and the major fuel consumers in the United States for 20 years.","Unlocking the Potential of Clean Affordable Energy: Innovations in Biomass, Biofuels, and Offshore Wind (SDG 7)",235,295
Addressing Imbalanced Datasets: A GAN-Based Approach with Active Learning," In various industrial applications, particularly those related to failure detection in advanced manufacturing systems and medical disease diagnosis in healthcare systems, classification tasks grapple with imbalanced class labels in training datasets. The skewed distribution of class labels significantly impacts prediction accuracy, necessitating preprocessing of data before analysis. This research explores the adverse effects of imbalanced domains on predictive models, with a particular emphasis on addressing class imbalance through the generation of minority samples. The primary objective is to develop effective methods for handling imbalanced problems, focusing on the generation of minority samples using generative adversarial network (GAN) and the selection of the most crucial samples through Active Learning. In contrast to traditional oversampling methods, GAN-based models exhibit improved performance, as the generator learns the true distribution through adversarial learning. The research aims to enhance model performance and effectively address the imbalance problem, with potential applications in improving failure detection and medical disease diagnosis in industrial and healthcare systems.",Deep Learning I,40,296
Pattern Recognition in Residential Energy Consumption for Predictive Load Forecasting," This study presents an approach to understanding residential energy consumption through pattern analysis of electricity usage. Without prior knowledge of individual appliance energy requirements, a methodology is developed to infer operational periods of household appliances solely based on the overall consumption patterns observed. By employing advanced pattern recognition algorithms, this project categorizes distinctive energy consumption signatures, correlates them with probable appliance activity, and estimates the individual contributions of each appliance to the total load. The key objective is to construct a predictive model capable of anticipating appliance-level energy demands, contributing to more efficient energy management and conservation strategies in residential settings. The implications of this research extend to enhancing smart grid operations, promoting consumer awareness, and facilitating demand-side energy optimization. The outcomes of this project could impact energy consumption analytics, enabling power utilities to predict and plan for variations in energy demand, optimize load management, and design targeted energy efficiency programs.",Advanced Data Analytics for Quality Control and Reliability,2,297
"Enhancing Supply Chain Efficiency in Textile Recycling: A Lean Manufacturing Approach at JPE ECOFIBER in, Santiago Domincan Republic"," This study addresses the implementation of Lean Manufacturing tools to optimize the supply chain at JPE ECOFIBER, a company specializing in textile waste recycling. The main purpose of the research is to improve the operational efficiency of the company through the adoption of Lean strategies, focusing specifically on increasing storage capacity and solving problems related to management and organization. For this purpose, SWOT analysis, 5S, Value Stream Mapping, and AMEF methodologies were used, along with process optimization and inventory management. The research revealed significant improvement opportunities at JPE ECOFIBER, including limited storage capacity and challenges in its administration, factors that directly impact the effectiveness of the supply chain. The application of Lean Manufacturing tools proved to be effective, proposing viable solutions to increase storage capacity, reduce costs, and improve production efficiency. Additionally, the adoption of a Lean culture in the company is suggested, aiming to promote a comprehensive approach towards operational efficiency and sustainability. This study concludes that the implementation of Lean Manufacturing in JPE ECOFIBER's supply chain can lead to significant improvements in terms of capacity, costs, and efficiency, establishing a framework for the adoption of sustainable and efficient practices in the textile recycling industry.",Supply Chain Sustainability 2,218,298
Industry 4.0 technologies and the critical success factors for transitioning to circular agri-food supply chains," This research aims to analyze the circular economy practices adopted by agri-food supply chains and how Industry 4.0 technologies assist this process, identifying the critical success factors for the transition to circular supply chains in the context of the food industry. For that, we conducted a systematic literature review of 123 articles using the Scopus database, on the intersection of Food Industry 4.0 and circular supply chains. Our findings underscore stakeholder collaboration as the most frequently cited critical-success factor, emphasizing the exchange of knowledge, information, and problem-solving solutions. Optimization of resources emerges as the predominant benefit, underlining its role in preserving natural resources by maximizing the use of raw materials. In contrast, the lack of supportive legislation stands out as the most cited barrier, emphasizing the need for governments to facilitate the necessary changes in companies’ business models towards circular economy. Notably, the most cited circular economy practice is material reuse, emphasizing the importance of repurposing materials discarded in one phase of the production process, for use in another. Lastly, Internet of Things is the most cited industry 4.0 technology, as it helps companies in understanding and linking different parts of the production system. The main contribution of this study resides in the systematic categorization of the subjects in the extant literature to convey, to both industry practitioners and researchers, a better understanding of the discourse in the intersections of food supply chain and circular economy.",Renewable Sustainable Supply Chains (SDG 12),189,299
Optimizing Asset Management at Ochoa Hardware: Integrating ISO 9001:2015 and ISO 55001:2014 Standards," The study addresses the strategic enhancement of asset management processes at Ochoa Hardware Store, a leading national hardware company, through the integration of ISO 9001:2015 and ISO 55001:2014 standards. Recognizing the significance of efficient asset management in optimizing operational performance, the research focuses on the maintenance and physical plant department of the company. Ochoa Hardware Store, with its established market position and a history of steady organizational growth, identifies the need for a refined approach in managing its extensive asset base. The study proposes the implementation of the ISO 55001:2014 standard, in conjunction with the existing ISO 9001:2015 practices. This integrated approach is designed to comprehensively address the challenges in the maintenance and physical plant operations, aligning with international protocols for optimal asset management. The primary objective is to elevate the performance and quality of the maintenance department, ensuring it aligns with the company’s growth trajectory and market reputation. The expected outcome is a more efficient, standardized, and quality-focused asset management system, positioning Ochoa Hardware as a model for excellence in retail industry asset management.",Manufacturing & Design for Human Factors and Ergonomics,134,300
Modeling Transportation Risk for Spent Nuclear Fuel," Spent nuclear fuel (SNF) transportation is a critical aspect of nuclear energy infrastructure. This paper introduces a Monte Carlo based computational approach to assess the risk associated with SNF transportation, including low-probability, high-consequence events. The Spent Nuclear Fuel Transportation Risk (SNFTR) code developed is presented; furthermore, this paper outlines its foundational assumptions. The SNFTR code provides a concise visualization of simulation results, offering a risk assessment and a risk communication tool. The SNFTR code empowers local communities to autonomously evaluate transportation risks in the current nuclear power system, essential as the federal government advances plans for SNF storage. This computational modeling approach enhances transparency and technical understanding, facilitating informed decision-making and fostering confidence in SNF transportation safety.",Supply chain Risk & resilience 2,220,301
Facility Layout Reformulation Methodology in Response to Covid-19 Impacts on Supply Chain: A Case Study on a Small Circuit Manufacturer," The Covid-19 pandemic resulted in supply-chain disruptions that affected consumers and suppliers worldwide resulting in larger than expected backlogs. Due to the continuing unsteady supply, companies needed to overproduce to accommodate the backlogs and potential shortage of supplies. For smaller businesses, the lack of existing designated space to store additional WIP and potential strict budget resulted in the need for reorganization of the current layout to accommodate the additional needs of the business. This work documents from beginning to end the procedures needed to efficiently collect quantitative and qualitative data of a small company, development of process flows and facility space requirements, development of layout alternatives and measure of comparison, and execution of spatial relationship analysis, including future business growth. These are applied to a case study of a small circuit company in Western New York. The company was looking for a potential restructuring of their current facility to optimally accommodate the backlogged WIP and unknown increased inventory for their growing overseas market. In addition to the procedures mentioned, this work discusses how to effectively relay and report information to industry partners. While it is important to accurately develop facility layouts, the ability to effectively present the ideas and findings to the client is arguably just as important.",Facilities Design & Planning II,72,302
Optimizing a Closed-Loop Supply Chain for Electronic Waste Management," This study explores the integration of reverse and forward supply chains into a Closed-Loop Supply Chain (CLSC) in the context of electronic waste network design and optimization in business and governance. It emphasizes the economic advantages and efficient management of Electronic waste (E-waste), particularly in the context of End-Of-Life (EOL) products, as a response to the global E-waste crisis. This research introduces a novel mixed-integer linear programming model for an E-waste CLSC network, featuring hybrid manufacturing facilities and an objective function that maximizes the total profit to reduce disposal in landfills. The application of this model to a computer manufacturing network in Ontario, Canada is discussed. To this aim, the distances are calculated using Google Maps. The proposed model provides insights into the design and optimization implications of an electronic CLSC network. The proposed approach seeks to decrease E-waste by incorporating new and recycled components, with some recycled items sold in a secondary market. Findings offer a comprehensive understanding of product and part flows. The open facilities and the number of parts and products dispatched within each segment of the network are determined. This study concludes with a summary and recommendations.",Supply Chain Sustainability 2,218,303
A VNS approach for a joint fulfilment and consolidation problem in e-Commerce," Recent advances in supply chain and logistics illustrate that consolidation of orders may reduce transportation costs and CO2 emissions considerably. In this paper, we study the impact of consolidation on order fulfilment in e-Commerce. We consider a retailer with an online platform and network of physical stores, who must decide the optimal locations from which to fulfill a set of multi-item orders, as well as the optimal consolidation points for each order. To model the economy of scale obtained by consolidating orders, we consider piecewise linear concave transportation costs. Our model extends the existing literature by considering multiple orders at a time and stores with limited inventory. We formulate the problem as a mixed integer linear programming MILP and propose a Variable Neighborhood Search (VNS) to find good quality solutions in a short time. We test the performance of the proposed algorithm on different scenarios, where stores have a varying percentage of overlapping items and different inventory levels. The numerical results, focusing on scenarios with sufficient inventory at stores, indicate promising performance for the proposed VNS. Compared to MILP, we observed a 1% average relative increase in cost using VNS for instances with a large overlap in items among stores and a 3% average relative increase for the other scenarios. On average, the VNS is 6 times faster than the MILP formulation.",Supply chain design 1,221,304
Joint Optimization of Production and Maintenance in Offshore Wind Farms: Balancing the Short-and Long-Term Needs of Wind Energy Operation," The rapid increase in scale and sophistication of offshore wind (OSW) farms poses a critical challenge related to the cost-effective operation and management of wind energy assets. A defining characteristic of this challenge is the economic trade-off between two concomitant processes: power production (the primary driver of short-term revenues), and asset degradation (the main determinant of long-term expenses). Traditionally, approaches to optimize production and maintenance in wind farms have been conducted in isolation. In this paper, we conjecture that a joint optimization of those two processes, achieved by rigorously modeling their short- and long-term dependencies, can unlock significant economic benefits for wind farm operators. In specific, we propose a decision-theoretic framework, rooted in stochastic optimization, which seeks a sensible balance of how wind loads are leveraged to harness short-term electricity generation revenues, versus alleviated to hedge against longer-term maintenance expenses. Extensive numerical experiments using real-world data confirm the superior performance of our approach, in terms of several operational performance metrics, relative to methods that tackle the two problems in isolation.",Energy Systems Maintenance and Forecasting,65,305
Network microgrid restoration using Reinforcement Learning," This paper presents network microgrid (NMG) restoration using Reinforcement Learning (RL) to address the inherent complexities and uncertainties in power system restorations. Traditional methods often struggle with the multi-dimensional challenges of NMG, including non-linearity and uncertainty, leading to inefficiency and increased restoration time. Our study leverages a modified Q-learning algorithm and Deep Reinforcement Learning (DRL) to enhance the operational efficiency and adaptability of microgrids. The proposed RL methodology uniquely adapts to dynamic environments, overcoming the limitations of conventional optimization-based strategies, particularly in scenarios with stochastic elements. Unlike traditional methods that commence optimization post-fault, our RL approach continuously learns from the environment, ensuring a more rapid and accurate response during grid disturbances. This adaptability is crucial in managing the unpredictability of power grid restoration. Our empirical results show that the RL method performs well in navigating complex restoration scenarios, offering significant improvements in both decision-making speed and accuracy. By integrating RL into existing microgrid frameworks, we provide a scalable, efficient solution to contemporary power restoration challenges, paving the way for more resilient energy infrastructures.",Microgrids and Energy Storage,145,306
Identification of the potential causes of scratch in the Roll Conditioning Line," At Outokumpu, the world's leading company in stainless steel and high-performance alloys, the only one of its kind in San Luis Potosi, we specialize in the production, treatment, and distribution of stainless steel. Variability in processing methods and roller design leads to the appearance of multiple defects. Among these, scratches are one of the most significant, particularly at our plant in San Luis Potosi. These scratches, cracks no longer than 10 mm, create thickness disparities, complicating the process and impacting the appearance, potentially triggering other defects. The project focuses on reducing the quantity of products relegated to the second quality category due to these scratches, aiming for a 30% improvement in the LAR area. This action is crucial since second quality products are marketed at a lower price. The central purpose is to minimize this defect by directing the highest tonnage of steel towards the prime, our highest-quality material, allowing its sale at higher prices. This will not only maximize our profit margins but also mitigate potential customer complaints regarding aesthetic issues, thereby avoiding material returns and associated financial losses, which could impact our monthly internal objectives.",Advanced Topics of QCRE Applications I,5,307
Dynamic Replenishment Optimization for Networked Fulfillment Operations," The choice of replenishment decisions has a significant impact on a supply chain network's fulfillment capabilities. Traditionally, inventory replenishment provisioning and e-commerce fulfillment have been studied in separation. Current practices, however, do not cushion against a turbulent high-velocity world that is becoming the new normal. Turbulence has been seen throughout the Covid-19 pandemic such as high degrees of demand and supply volatility and uncertainty, while high velocity results from responding to increasing customer expectations and shrinking product lifecycles. Conversely, the digital capabilities of supply chains are also rapidly increasing. It is now much easier technologically to interconnect supply chain nodes, share databases, automate processes, and obtain sensor-based signals. In this work, we propose a unified framework that takes advantage of the augmenting visibility and interoperability potential of a sentient supply chain, which is capable of autonomous and collaborative goal-oriented perception, reasoning, decision-making, and action in a coordinated synergistic way. We formulate the replenishment provisioning problem as a mixed integer program that accounts for the interplay between inventory management and e-commerce fulfillment, as well as lateral transshipment and product substitution. The framework presented herein is applied to a real word retailer test case to demonstrate the advantages of our methodology in terms of service level and resilience.",Inventory Management,117,308
"Predictive and Prescriptive Analytics for Offshore Wind Energy: Uncertainty, Quality, and Reliability"," The rising U.S. offshore wind sector holds great promise—both environmentally and economically—to unlock vast supplies of clean and renewable energy. To harness this valuable resource, Gigawatt (GW)-scale offshore wind (OSW) projects are already under way at several locations off of the U.S. coastline and are set to host turbines that are larger than many of the world’s tallest buildings. Realizing this promise, however, is contingent on innovative solutions to several challenges related to the optimal management of such ultra-scale assets, which would operate under harsh environmental conditions, in fairly under-explored territories, and at unprecedented scales. This presentation will highlight our progress in formulating tailored machine learning (ML) and operations research (OR) solutions aimed at mitigating some of those operational uncertainties, including: (i) how can we develop ML-based solutions that can make use of the multi-source, multi-resolution data in OSW energy regions to accurately forecast their power output at high spatial and temporal resolutions; and (ii) quality/reliability: how can we translate those forecasts into optimal operations and maintenance (O&M) decisions through offshore-tailored optimization models that consider the multi-source uncertainties and complex decision dependencies in the OSW environment. Our models and analyses are tailored and tested using real-world data from the NY/NJ Bight—where several GW-scale wind farms are in-development.",Predictive analytics for Wind Power Generation,171,309
A Statistical Deep Learning Approach for Offshore Wind Energy Forecasting," The unprecedented scales and capacities of modern offshore wind turbines present both an opportunity and a challenge to depart from existing univariate forecasting methods that have been historically tailored to a single turbine’s hub height. In response, we propose a multivariate statistical deep learning method which fully embraces the full vertical wind profile by incorporating spatial, temporal, and height dependencies, in order to reflect the true complexity of wind interactions coincident with ultra-scale offshore wind turbines. The proposed approach marries the probabilistic rigor and parsimony of the multivariate integro-difference equation framework, with the representative power of deep learning. We present our progress in making probabilistic offshore wind forecasts using the proposed approach, and present preliminary results about its performance relative to prevalent forecasting benchmarks.",Predictive analytics for Wind Power Generation,171,310
Physics-guided data-driven coarse-graining using Gaussian process regression," Coarse-grained models describe the macroscopic mean response of a process at large scales which derives from stochastic processes at small scales. Most existing techniques for constructing coarse-grained models feature ill-defined parameters whose values are arbitrarily chosen (e.g., a window size), are narrow in their applicability (e.g., only applicable to time series or spatial data), or cannot readily incorporate physics information. Here we advocate the development and application of physics-guided Gaussian process regression as a machine-learning-based coarse-graining technique which is broadly applicable and amenable to input from known physics-based relationships. Using a pair of case studies derived from molecular dynamics simulations, we demonstrate its superior performance for coarse-graining relative to prevalent data-driven benchmarks.",Machine Learning III,127,311
Characterization of seat-to-head vibration transmissibility in rotorcraft occupants," Aerospace structures generally have flexible and lightweight components which are susceptible to large amplitude and low-frequency vibration. In the case of rotorcrafts, the main and tail rotors generate vibration that substantially contribute to the exposure of the pilot and crew to whole-body vibration (WBV) over a wide frequency range. WBV exposure is generally more severe in rotorcrafts compared with ground vehicles, as the vibration is generally dominated by the blade passage frequencies which typically lie within the range of frequency to which human is most sensitive.. The fundamental blade passage frequencies of different helicopters generally occur in the 4 to 8 Hz frequency range which coincides with the whole-body vertical mode resonance of the seated human body. The WBV exposure, together with prolonged sitting in confined spaces during long flight missions, has been associated with various adverse health effects on human biomechanical and physiological responses. Seat-to-head vibration transmissibility (STHT) response functions capture the flow of vibration through the body and vibration transmissibility of various body segments. The specific objective of the present study is to experimentally measure the STHT responses to WBV encountered by the rotorcraft pilot/crew and to investigate the effect of helmet and helmet-mounted equipment on the STHT responses.",Poster Presentations,169,312
Data-informed smart drying strategies for advanced manufacturing," Drying is a critical process that includes many modern manufacturing processes such as 3D printing of straw material. The primary objective during drying process is to expedite water content reduction without compromising the structural integrity of the product by preventing cracks. This is challenging to achieve for new materials and processes. To achieve this goal, we design and implement a smart drying setup with real-time weight and humidity sensors, and a camera on the top of the product. In this talk, we will introduce our exploration of various material parameters and fan speeds and the sensor data analysis during this exploration.",Sensing and Control in Additive Manufacturing Processes I,202,313
RHEOLOGICAL CHARACTERIZATION OF ALGAE INFUSED HYDROGEL PRECURSORS.," Hydrogels, known for their excellent water-absorption and biocompatibility, play a crucial role in biomedical and engineering applications. However, ensuring the long-term structural stability of hydrogels, particularly when incorporating live cells for bio ink formulations, poses challenges. The study focuses on rheological properties, especially the complex shear-thinning behavior of cell-infused hydrogel precursors, addressing these challenges, hybrid hydrogel compositions, including sodium alginate, carboxymethyl cellulose (CMC), and TEMPO-mediated Nano-fibrillated cellulose (TO-NFC), were prepared, and algal constituents were added to each formulation. The rheological behavior of these composite hydrogel precursors was studied over time to understand their potential as bio ink formulations. Surprisingly, the investigation revealed a significant decrease in viscosity in many compositions, influenced by the growth of algae integrated into the hydrogel precursor. The composition sodium alginate (4%), CMC (1%), and TO-NFC (1%) is predicted to have the best printability under a 3D bio printer. This emphasizes the need for careful consideration when introducing components into hydrogel precursors, as viscosity changes can impact the performance of these hybrid systems. These findings have practical relevance, contributing to a broader understanding of complex relationships and facilitating the development of innovative materials with superior properties. Awareness of viscosity modulation in hybrid systems holds the potential to optimize the design and use of hydrogel-based materials, especially in 3D bio printing for biopharming, biomedicine, and tissue engineering.","Advancements in Bioprinting: Techniques, Materials, and Applications",12,314
A Domain-Informed Ensemble Learning Approach and Its Application in Materials Informatics," Ensemble learning (EL), e.g., mixture or product of experts, is a prevalent data-driven framework to combine several local machine learning models in order to capture local functional behavior while maintaining scalability. While there has been an emerging literature on physics- and/or domain-informed machine learning, little attention has been focused on their extension to the EL framework. In this work, we investigate and propose new methods to invoke domain-informed knowledge and/or constraints within the EL framework. We highlight our progress in developing such domain-informed EL models using relevant problems from materials informatics, and showcase preliminary results about its out-of-sample performance relative to existing data-driven and EL benchmarks",Manufacturing II,136,315
Integrating Urban Design into Optimal Spatial Deployment of Electric Vehicle Charging Stations," The adoption of electric vehicles (EVs) increases the need for charging stations, especially the public charging infrastructure. Tailored to various land use functions within various regions, the urban planning schemes for such infrastructure should be properly designed to improve user experience. This paper proposes a multistage stochastic optimization approach for spatial deployment of charging stations with the consideration of four urban design schemes to meet uncertain charging demands in multiple future years. To capture the increases of EV adoption rates, a scenario tree is generated based on the collected data in a specific region in Tucson, Arizona, and both flow-capture location and location-allocation are applied to predict the charging demands. The expected costs associated with such deployments of charging stations will be minimized while the user experience with respect to urban design schemes will be maximized. Numerical experiments are performed to demonstrate the effectiveness of the proposed approach.",Driving Towards Clean Affordable Energy: Advances in Electric Vehicles and Battery Management (SDG 7),57,316
A KNN-based bandit distance for balancing exploration and exploitation in LinUCB," We propose a novel modification of the Linear upper confidence bound (LinUCB) method for the stochastic multi-armed contextual bandit problems which tunes the confidence bound of a given bandit based on its distance to others. Our distance tuning (LinUCB-DT) formulation enables improved performance as measured by expected regret by preventing the MAB algorithm from focusing on non-optimal bandits. ""Distance tuning"" of the LinUCB is done using a KNN based distance measure, which we call bandit distance, that is parameterizable, and which therefore can be optimized to control the transition rate from exploration to exploitation based on problem requirements. We empirically demonstrate increased performance of LinUCB-DT versus many existing state-of-the-art methods which use the LinUCB formulation for the MAB problem.",Statistical Learning and Artificial Intelligence for Quality Control III,213,317
A Space-Limited Human-Robot Collaborative Assembly Line Balancing Problem with Safety Consideration.," Collaborative robots (Cobots) are one of the enabling technologies in Industry 4.0 that perform repetitive or strenuous jobs in assembly processes. This study solves an assembly line balancing problem in which Cobots and humans with different capabilities work together or in parallel to deliver assembly tasks. Human workers are prone to errors and thus unexpected contacts with cobots in a fenceless collaborative workstation are probable. These contacts endanger workers' safety and affect assembly line efficiency by disrupting workflow. Therefore, we formulate the problem as a mixed integer programming (MIP) model that contains a constraint to restrict the available allowed area for executing each task. Space limitations mainly relate to the specific requirements of tasks, workforces, and workstations. The developed MIP model finds the optimal decision for tasks-to-stations assignment that minimizes cycle time while offering a safe distance between human workers and cobots to mitigate manufacturers’ safety concerns. Finally, analyzing the model with a numerical example reveals how it aims to maintain assembly line productivity in a human-robot collaborative environment.",Digital Manufacturing and Industry 4.0-III,47,318
"Non-Fungible Tokens (NFTs): A Systematic Review of the State of Art of Valuation, Regulation, and Perception"," While Non-Fungible Tokens (NFTs) emerged as the common application of blockchain technology, there is a lack of detailed literature around the concepts of NFTs. This study aims to 1) address the contributing factors for the valuation of NFTs and correlation, 2) survey existing legal framework relating to NFTs, 3) discuss the role of regulators and 4) examine perception. This review includes research articles published in Engineering Village, IEEE Xplore, Scopus, Web of Science, ScienceDirect, Business Source Complete, and ABI/INFORM Global databases. The keyword “Non-Fungible Token” generated over two thousand of research articles, but only English-language peer-reviewed journals being selected for an initial pool of 362 journals. Finally, 22 articles were selected by following the 2020 Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) protocols. The articles were categorized into three areas: valuation, regulation, and perception of NFTs. The results of a detailed analysis of the three areas consisted of 16 studies on valuation, 4 on regulation, and 2 on perception. These studies highlighted 1) the historical prices of NFTs as a key predicting factor for future pricing , 2) legal copyright and shared ownership issues, and 3) digital vs physical perception of objects. This initial analysis conducted one keyword due to the exploratory nature of this research is a limiting factor in the results obtained. Nonetheless, the results provide sufficient indicators that additional analysis of NFTs and its other contributing factors would be of value to the understanding and adoption of these emerging technologies for both researchers and practitioners.",Technology and Digital Economy,230,319
On locating prescription drug collection boxes," Prescription collection boxes have been deployed in many communities to collect unused prescription opioids as well as other prescription drugs to protect against their misuse. However, they are generally deployed in an ad hoc manner and not all communities have access to such boxes. This paper explores how to evaluate the performance of prescription collection boxes and to locate new collection drop boxes. To do so, we introduce performance measures based on the set cover problem to identify prescription collection box ""deserts."" Then, we propose an integer programming model based on the maximal covering with mandatory closeness problem to identify sites for new prescription collection boxes. We discuss alternative formulations to capture different criteria and preferences. A case study is presented based on data from Wisconsin.","Healthcare for a Sustainable Future: Innovations in Operations, Design, and Environmental Management (SDG 3)",91,320
Oral-Anatomical Knowledge-driven Semi-supervised Semantic Segmentation for Dental CBCT Image," Dental cone beam computed tomography (CBCT) offers three-dimensional images of oral cavity, including oral structures (i.e. teeth, bones, restorative materials, and lesions) in a single scan. Dentists distinguish these oral structures with their oral-anatomical knowledge to create segmentation maps. However, manual segmentation is labor-intensive and prone to have human errors, resulting in limited labeled dataset and many unlabeled dataset. Deep learning (DL) has assisted in the automatic segmentation of CBCT images, but ironically to train DL model, sufficient labeled dataset is required. Segmenting lesions is most affected with limited labeled dataset among all classes due to their comparatively smaller size, similar intensities to adjacent structures, and variations in size and shape. This study presents a novel semi-supervised segmentation framework for automatic dental CBCT semantic segmentation, integrating oral-anatomical knowledge about lesions. The knowledge that ‘lesion must be located near the root of the tooth’ is incorporated in the loss function, guiding the DL model the potential locations of lesions. The effectiveness of the method is evaluated on both regular size lesions and smaller-sized lesions, comparing it with supervised and other semi-supervised learning methods. The proposed method showed better lesion dices and lesion detection accuracies for both regular and smaller size lesions, implying its effectiveness in guidance for potential lesion locations. Furthermore, our analysis using GradCAM demonstrates that the proposed method learns more discriminative features for lesions and tends to converge toward flat minima, thereby reducing false positive lesions.",Healthcare III,85,321
Power Grid Resilience Optimization Using Decision-Dependent Uncertainty," Extreme weather events can cause unplanned disruptions in power distribution systems, highlighting the need for resilience-oriented action. This ongoing study proposes a two-stage stochastic mixed-integer program with decision-based uncertainty to determine how to optimally protect power distribution systems against such disruptions. In the first stage, a set of lines are hardened. A random set of destroyed lines is then realized. The probability for each element is dependent on the hardening decisions made in the first stage, i.e., decision-dependent uncertainty. In the second stage, network reconfiguration and DERs (Distributed Energy Resources) utilization decisions are made. The model seeks to minimize the expected cost of load shedding. To find a computationally fast way to solve the model, the study explores a decision-independent reformulation.","Privacy, security, and resilience",174,322
Investigating Jet Stability in Inkjet Printing through a Novel Sensing Modality," In recent years, inkjet 3D printing has rapidly gained prominence as a disruptive fabrication technique. However, the dynamic nature of the process introduces significant challenges related to consistency and quality control, especially in terms of reproducibility and repeatability. The key input parameters governing this process, such as pressure, voltage, jetting frequency, and duty cycle, are interrelated, entailing the identification of optimal settings in order to realize high-quality jetting. At present, the data collection heavily relies on image-based methods which are inherently slow and often fail to encompass the entirety of the data, making it difficult to determine the relation between the input parameters and jet characteristics. To address this multidimensional difficulty, we developed a unique approach based on light-beam field interruption to collect critical jet data at high speeds. This novel approach collects both temporal and spatial information on droplet evolution, making it a vital tool for enhancing our ability to attain high accuracy and control in inkjet 3D printing. We further model the droplet size and jetting behavior and use the insights gained from the time series data, deploy a 1D convolutional neural network (CNN) to analyze the temporal aspect of the data. The synergy between this novel sensing approach and the 1D CNN model not only contributes to the stability and precision of inkjet printing but also propels the inkjet printing domain toward a future of efficiency, adaptability, and enhanced performance, offering valuable applications across an array of industries.",Inkjet Additive Manufacturing Processes,106,323
Predictive Modeling Using Artificial Intelligence for Quality Control in Multi-Stage Manufacturing Processes at GE Aerospace Bromont.," Multi-stage manufacturing systems involving processes like machining, stamping, and assembly, quality control challenges arise from the cumulative variations in the quality characteristics’ produced dimensions compared with the design specifications across the stages. The absence of quality prediction can lead to increased scrap, production downtime, rework, and the need for multiple inspections. In such scenarios, in-process inspections are used for successive quality product evaluation. This paper presents the use of artificial intelligence (AI) models to predict product quality at successive multi-stage production processes. In previous research, most predictive models depend on processes’ parameters for modeling the predicted quality. We introduce an approach using quality inspection measurements from stage n-2 as input to predict quality characteristics at stage n-1. Consequently, from stage n-1, we predict the quality characteristics at stage n. AI algorithms like Partial Least Square Regression and Support Vector Machines have demonstrated effectiveness when confronted with limited data. The approach is implemented using a real case from GE Aerospace Bromont Manufacturing, which manufactures airplane engine parts. Results showcase predictive performance with a substantial portion of predicted quality characteristics at stages n-1 and n exhibiting an r2 greater than 0.60 and an average RMSE of 0.00029 and 0.00020, respectively. This emphasizes AI's ability to predict quality characteristics without process parameter data, demonstrating the feasibility of our approach within multi-stage manufacturing processes. Future endeavors aim to extend quality characteristic prediction to multi-stage prediction using quality inspections at any stage n-i as input to predict the quality characteristics at the final stage n.",Advanced Topics of QCRE III,9,324
Survival Signature Estimation Using Optimization and Monte-Carlo Simulation for Two-Terminal Networks with K ≥ 3 Classes of Nodes," This research aims to develop an efficient approach to estimating survival signatures for two-terminal networks with more than two classes of components. Recently, the survival signature has gained substantial attention in the literature on network reliability estimation due to its unique separability property, which enables passing the network topology information independent of the failure distribution of the components. Following recent results from the literature, we show that estimating the survival signature by Monte Carlo simulation entails solving a multi-objective max capacity path problem in each replication. We adapt a multi-objective Dijkstra’s algorithm from the literature to construct the set of non-dominated paths solving the multi-objective bottleneck path problem for each replication of the Monte-Carlo simulation. We have carried out experiments on networks with three types of components. We compare the run-time of our approach with a benchmark Breadth First Search (BFS) based approach.",OR Methods,151,325
Intermodal Transport Optimization with Efficient Energy Usage and Reduced Greenhouse Gas Emission," With the growing concerns about global warming, there is mounting pressure on major logistics stakeholders to reduce greenhouse gas emissions and energy consumption in logistics operations. Intermodal Transportation emerges as a strategic solution for achieving both environmental and organizational objectives. Consequently, there is a need for optimized models to address this complex challenge. This paper presents a multi-objective optimization model that concurrently optimizes parameters such as cost, transportation time, energy consumption, and greenhouse gas emissions, with a primary focus on energy consumption and greenhouse gas emission reduction. To ensure consistency, the multi-objective optimization model is transformed into a mixed-integer linear program using coefficients for certain variables. Given the diverse advantages and disadvantages of different transportation modes, achieving the right balance is crucial. Integrating mode selection with route choice plays a significant role in optimizing intermodal transport operations. The development of an optimized intermodal transport model considering the stated objectives proves to be an effective approach in aligning with environmental and organizational goals. The proposed model evaluates individual objectives during transportation and at transshipment locations. This enables stakeholders to gain detailed insights into where efforts should be concentrated to achieve desired outcomes. The model is applied to a sample case study, producing a set of solution pathways for mode choice and route selection that optimize greenhouse gas emissions, energy consumption, and overall operational costs.",Supply Chain Sustainability 1,217,326
Strategies for Minimizing Regional Repositioning of Empty Containers," Intermodal transportation is becoming increasingly important due to the policies induced by state and federal agencies encouraging this freight modal shift to alleviate emissions and traffic congestion. However, intermodal freight transportation is currently less efficient than it could be because of the import-export imbalance that necessitates empty container repositioning (ECR). Empty container movements generate unproductive empty vehicle miles, causing economic, environmental, and sustainability impacts. To this end, this study proposes two ECR strategies: street turn with extended port stay and in-route container sharing to reduce the regional empty container movement. This study aims to evaluate and contrast the proposed strategies' impact on reducing empty repositioning miles and corresponding carbon emissions. An agent-based simulation model represents the complex regional empty container supply chain, estimating empty kilometers traveled, carbon emissions, and costs for both strategies.",Supply Chain & Scheduling,214,327
Transfer Learning for Predictive Maintenance: A Case Study," In light of recent strides in high-performance computing, the concept of transfer learning has emerged as a prominent paradigm within the realm of Artificial Intelligence and Machine Learning methodologies. Analogous to the human brain's capacity to assimilate information across related domains for pattern recognition, transfer learning has swiftly asserted its dominance, particularly in deep learning applications such as image classification and natural language processing. Despite its ascendancy in these domains, there exists a lack of comprehensive investigations in alternative domains, notably those encompassing tabular data formats. This research paper seeks to redress this gap by conducting an empirical examination of transfer learning within the context of predictive maintenance. The study employs a case study methodology involving induced misalignments in various levels of horsepower motors. A comparative analysis is undertaken, juxtaposing transfer learning techniques against standard deep learning approaches, with the aim of elucidating the overarching efficacy and viability of transfer learning within the domain of predictive maintenance. This empirical exploration contributes to the broader discourse on the applicability and optimization of transfer learning methodologies across diverse domains, specifically addressing its efficacy in the nuanced context of predictive maintenance for machinery.",Reliability I,187,328
Novel Machine Learning Model for Software Defect Prediction," Software product refers to the software which is developed for a specific requirement. Simultaneously, engineering deals with the development of product using explicit technical fundamentals and methods. The software defect can be predicted in diverse stages in which data is utilized as input and pre-processed, attributes are extracted and classification is performed. This research work makes the implementation of several classifiers in order to predict the software defect. These classifiers are GNB (gaussian naive bayes), Bernoulli NB, RF (random forest) and MLP (multi-layer perceptron) which are employed with the objective of forecasting the software defect. The performance of the software defect is enhanced by developing an ensemble classifier. In the introduced ensemble classifier, the PCA (Principal Component Analysis) algorithm is integrated with class balancing. Python is executed to implement the introduced model. Diverse metrics are considered to analyze the results concerning accuracy, precision and recall.",Reliability I,187,329
"FairMARS: Towards Transparent, Interpretable, and Fair Predictive Analytics for Social Good"," Predictive analytics has become integral in decision-making across diverse domains, with applications ranging from healthcare to finance. In the realm of such sensitive domains, however, the widespread use of proprietary and opaque predictive models has raised concerns regarding accountability, ethical design, and the potential introduction of bias. This paper addresses these critical issues by proposing a fair predictive model based on Multivariate Adaptive Regression Splines (MARS), a non-parametric regression model known for its feature selection, handling of non-linear relationships, and generation of interpretable decision rules.To enhance transparency and fairness, our proposed fairMARS model incorporates fairness metrics throughout the learning process, with a focus on the knot optimization algorithm. The paper provides both theoretical and empirical evidence showcasing how the infusion of fairness considerations results in equitable knot placement. Real-world data applications demonstrate the model's effectiveness in terms of predictive accuracy and equity.The fairMARS model not only ensures fairness but also enhances interpretability for end-users. The paper illustrates how fair decision rules are generated, shedding light on the reasoning behind predictions and elucidating the trade-offs associated with different fairness criteria. To facilitate user interaction, a graphical interface is presented, allowing stakeholders to explore the impact of various fairness constraints on predictions and decision rules. By emphasizing transparency, interpretability, and fairness, the fairMARS model strives to empower researchers, practitioners, and officials with a tool that not only predicts outcomes accurately but also promotes accountability and mitigates biases in decision-making processes.",Social Good Analytics,209,330
Revolutionizing Healthcare Through Advanced 3D Simulation: A Novel Approach to Patient Monitoring and Operations Management," This groundbreaking research introduces an innovative software solution merging computer vision and 3D simulation for advanced healthcare applications. The technology extracts key points from video footage, creating real-time, interactive 3D models in Unity. With profound implications for pandemic preparedness, the tool enables remote patient monitoring, ensuring timely and precise healthcare responses. Quality and patient safety are enhanced through comprehensive 3D patient representations, while healthcare operations benefit from improved resource allocation. The project aligns with data analytics and health informatics by generating rich datasets for insightful analysis. Rooted in diversity and inclusion principles, this interdisciplinary approach pioneers the future of patient-centric, technologically advanced healthcare.",Simulation Models in Health Systems,206,331
Role of Aritificial Inteligence in Automobile Industry," The rapid development in technology with Artificial Intelligence (AI) leads to transform the automotive industry significantly. This section explores the multi-dimensional role of AI to revolutionize the automobile sector, in accordance with diverse aspects like autonomous vehicles, predictive preservation, user experience improvement, and supply chain optimization. Autonomous driving is a major factor of AI which is incorporated in the motorized sector. The AI algorithms, machine learning (ML), and sensor technologies are significantly employed to develop the self-driving vehicles. These systems assist automobiles in perceiving their ambiances, making realistic decisions, directing complicated settings accurately and efficiently, and surpassing the human potentials. The involvement of AI in autonomous vehicles is found effective for augmenting the road security as well as redefining the urban mobility, mitigating the traffic congestion, and making the transportation more accessible for different populations. Predictive maintenance is another factor at which AI is utilized in the automotive industry. The data is retrieved from sensors, vehicle diagnostics, and historical performance records, and feed into AI algorithms for predicting potential issues prior to their growth. Hence, proactive maintenance actions are taken. It results in alleviating the downtime and preservation expenses as well as making the overall vehicle more reliable and durable. Thus, AI-driven predictive maintenance is presented as a basis of recent convoy management mechanisms to ensure precise operational efficacy and consumer fulfilment.",Manufacturing III,137,332
Enhancing customers loyalty programs at Aeroplan by using artificial intelligence," Customer Loyalty programs are essential in the realm of brand management, facilitating the cultivation of brand recognition and fostering long-lasting relationships between brands and their customer base. Aeroplan, frequent flyer program, is strategically employed by Air Canada to both retain existing customers and stimulate member loyalty. Aeroplan can access flight distressed inventory which is a category of seats that are difficult to sell and show low demand, in most cases since they present a combination of features not preferred by members such as long travel duration, late departure time and high number of stopovers. The main challenge for the loyalty program is to understand the factors that make this type of inventory more probable to be booked. By knowing this information Aeroplan can improve its marketing strategy and increase profitability for the company. This paper presents a quantitative assessment model that calculates the probability of booking distressed inventory in diverse scenarios, thereby providing valuable insights for decision-making within Aeroplan. Our research explores the impact of several critical factors, including booking window, origin, destination and departure month, on the probability of booking distressed inventory. To achieve these goals, a combination of statistical inference and machine learning methods is employed. A comprehensive exploratory data analysis is conducted, culminating in the development of predictive models that elucidate the probability of booking distressed inventory. This research contributes to the enhancement of decision-making processes and offers valuable insights into the dynamics of marketing strategies for customer satisfaction at Aeroplan.",Logistics I,122,333
FRAM Effectiveness in the Era of Industry 4.0: A Dual Perspective," The advent of Industry 4.0 has ushered in a new era of greater system sophistication, which goes beyond the capabilities of traditional risk analysis methods. In response, researchers have turned to systemic methods that are more suitable. The Functional Resonance Analysis Method (FRAM), along with other systemic methods, stands out for its ability to analyze accidents, regular performance, and risks by considering the entire system as the unit of analysis. FRAM's unique focus on understanding how everyday variability combines to produce unexpected results distinguishes it from conventional methods as well as its focus on what went wrong and analysis capacity of what went right. In this regard, there are two opposing perspectives regarding FRAM's applicability to Industry 4.0. While the first focuses on the advantages of this method, the second argues that FRAM may not align well with industry 4.0 systems. This study delves into the performance of FRAM within the context of Industry 4.0. This investigation examines the advantages and disadvantages of FRAM in the dynamic landscape of Industry 4.0, leveraging a comprehensive literature analysis to provide an in-depth understanding of the method's strengths and limitations in contemporary industrial systems. Drawing on evidence from successful documented applications, this study argues that FRAM can be effectively utilized in complex systems employing Industry 4.0 applications, countering claims of misalignment and emphasizing FRAM's applicability for Industry 4.0 contexts. The comprehensive evaluation of FRAM's pros and cons offers valuable insights for researchers, practitioners, and decision-makers navigating the complicated challenges associated with Industry 4.0.",Digital Transformation,50,334
An Integrated Uncertainty Quantification Model for Longitudinal and Time-to-event Data," We present a novel joint prognostic framework for the integrated analysis and uncertainty quantification of longitudinal (i.e., multi-sensor degradation signals) data and time-to-event data. Specifically, the proposed method models longitudinal data using a functional principal component analysis (FPCA), while the time-to-event data is characterized by a Bayesian neural network-based Cox (BNN-Cox) model. The proposed method delivers several advantages: 1) Providing accurate remaining useful life (RUL) predictions while seamlessly integrating the uncertainties of both the longitudinal and time-to-event sub-models; 2) Demonstrating great flexibility in modeling both data types; 3) Allowing online, real-time updates of the RUL distribution as new measurements are collected; 4) Making reliable predictions under limited data availability. The numerical evaluations on simulated and real-world data suggest that the proposed method achieves outstanding performance compared with existing benchmarks.",Statistical Learning and Artificial Intelligence for Quality Control III,213,335
Detection and Prediction of Soiling in Solar Photovoltaic Systems Using Machine Learning," The increasing worldwide adoption of solar energy motivates the need for innovative solutions to optimize the operations and maintenance of solar energy systems. Soiling, i.e., the accumulation of material like dust on solar photovoltaic arrays, poses a key challenge for solar operators as it gradually degrades the performance and reliability of the solar system. To address this challenge, we leverage a newly installed optical sensing technology on the solar energy testbed in the Energy Lab at Rutgers University in order to effectively monitor the soiling condition of the solar system over time. Our research develops a tailored machine-learning-based solution that can digest multiple sources of time series data in order to timely detect, and accurately predict, the occurrence of soling events, thereby alerting operators to take necessary mitigation measures to ensure cost-effective operations and maintenance (O&M) of their solar systems.",Unique directions in Energy Research,234,336
What Leaders Look For In Promoting IE’s Into Management," Are you an engineer that wonders why you have not being considered for promotion into management? Or are you a leader of engineers and find yourself recruiting externally because you feel that your own engineering team lacks the qualities to have them considered for promotion? This panel discussion is focused to address these questions by having high level leaders within service, manufacturing and knowledge management industries speak to their experiences on this topic. Past panel members included C-Level, VP and Director level leaders from Disney, Boeing, FedEx, UPS, Accenture, Tesla, Hersey’s and Health Care organizations along with several past IISE Presidents and Keynote speakers. Within this panel session, these leaders will share what they look for when promoting engineers along with describing examples of what they find in coaching opportunities to help their own team improve chances to be considered for promotion. Speakers are often from a broad demographic range to enhance a connection with the audience and will take questions as the end of the session.",What Leaders Look For In Promoting IE’s Into Management,239,337
Contemporary Work Design & Ergonomic Education - Theory and Practice," Industrial and System Engineering (ISE) programs are increasingly prioritizing quantitative skills which often places pressure on the amount of remaining curriculum to cover traditional topics such as work design and ergonomics. At the same time the need to provide students with a current and relevant education in work design and ergonomics has never been greater. Our paper introduces significant improvements to the Work Design and Ergonomics course, transforming it into a highly effective and efficient first course in engineering to ISE students that optimizes curriculum time while ensuring the content remains up-to-date and relevant. To meet the practical educational needs of today’s engineers and employers the improvements include new content, lectures, assignments, and laboratory exercises, complemented by new learning objectives that emphasize hands-on experiments to demonstrate work design and ergonomic principles in complex, human-centered systems. Our approach includes team projects that enhance learning through social and human interactions, along with the deployment of new assessment tools for continuous feedback and improvement. Course content is augmented to keep the material fresh and engaging, while striving to retain the essential core topics of traditional industrial engineering. The effectiveness of our improvements is measured by monitoring student developments later in the curriculum as they independently select elements of work design and ergonomics in their senior projects. The improvements incorporate student and employer feedback to make sure the course not only meets program objectives but is also at the forefront of contemporary work design and ergonomic education.",Innovative Learning Approaches in ISE Education,111,338
Global warming and choking of heat exchanger pump; Burden of our deeds.GLOBAL WARMING AND CHOKING OF HEAT EXCHANGER AND AUXILIARIES; BURDEN OF OUR DEEDS.," Introduction; A heat exchanger facilitates heat transfer between two mediums.Specifically, a plate heat exchanger has plates prone to obstruction by marine debris. Global warming correlates with severe flooding, leading to increased sea pollution. This pollution contributes to higher machinery failure rates in various systems. Case; After 2022 flooding, we received multiple requests for cleaning and servicing of ship's heat exchanger. Plate blockage was primarily caused by the presence of large debris. Interestingly, incidents of blockage had surged in the aftermath of recent massive floods. In response to these findings, we implemented strategic modifications to mitigate the risk of future failures. This involved incorporating a 5mm hole plate into the primary sea chest strainer and introducing a 3mm hole plate before the inlet of the heat exchangers.We also recommended measures to minimize operational risks, such as restricting the use of essential machinery during low-water periods and favoring machinery with suction away from the jetty increasing the reliability of the systems while reducing operational costs. This approach is particularly impactful in environments with poor resources. Discussion; Ship's heat exchanger is prone to sea debris blockage, a known issue. Recent severe flooding in Pakistan, worsened by global warming, heightened this concern, imperiling marine life and increasing machinery failures, especially in Plate Heat Exchangers (PHE). Such failures burden economically disadvantaged nations despite their lower carbon emissions. A paradigm shift in practices and a global effort to reduce emissions are essential to address these challenges, safeguarding marine ecosystems and ship components amid escalating environmental threats.","Innovating for Impact: Exploring Interdisciplinary Collaboration, Sustainability Challenges, and Indigenous Design (SDG 9)",107,339
Analyzing Real-time Delivery Policies with Non-Linear Holding Costs," We consider a delivery-dispatch system where orders arrive one by one, they are accumulated for a while and then dispatched as a batch, and get delivered one by one. There is a fixed cost to dispatch and a variable delivery cost that is incurred per unit time spent in delivery. In addition, there is a holding cost which is a non-linear function of the time from when an order is placed until it is delivered. Analyzing such a non-linear cost, especially when the orders arrive and depart sequentially, is challenging. However, such a non-linear holding cost structure is realistic as it captures customers' ability to wait a little but the cost significantly increases with longer waits. The key idea is convert the non-linear holding cost into a state-dependent holding cost, i.e. as a function of the number of jobs in hand at a given time, and time-averaged across the delivery process. The equivalence of the modified holding cost to the original non-linear holding cost is similar to the results for the generalized Little's law in M/G/1 queues. In a stable M/G/1 queue, the kth factorial moment of the time-averaged number in the system is related to the kth moment of the time spent in the system. We illustrate the equivalence in our setting using numerical examples through simulations. We also obtain the optimal dispatch policies for such systems. We compare policies where full delivery information is known against those that only consider the time or number in the batch.",Policy-driven Decision Making,168,340
Modeling Behavioral Dynamics in Epidemics: A Framework for Incorporating Human Behavior in Mathematical Epidemiological Models," Public health interventions, including those implemented during the recent COVID-19 pandemic, focus on modifying or supporting individual behavior, promoting practices like mask-wearing, vaccination, and adherence to quarantines. However, establishing a policy alone isn't sufficient for driving behavioral change. Multiple internal and external factors influence individual decisions in this regard. The identification and characterization of these factors is important to model people’s response to interventions. Hence, we aim to contribute to the enhancement of mathematical epidemiological models by introducing a framework designed to incorporate behavioral change mechanisms. Our approach involves identifying and defining key factors shaping behavior through a comprehensive review of diverse behavior change theories from psychology. Furthermore, we explore the integration of these factors based on these theories to provide a comprehensive classification that can serve as a structured guide to model behavior. The resulting framework can inform the development of epidemiological models that aim to incorporate individual-level behavior to support decision-making during public crises.",Modeling Human Behavior,148,341
Federated Transfer Learning in Predictive Maintenance: Unveiling the Power of Collaboration Across Heterogeneous Conditions," Federated learning, a decentralized machine learning approach, presents a suitable environment for heterogeneous and dispersed data sets to per- form collaborative training. Likewise, transfer learning has emerged as an important paradigm that employs fine-tuning and model adaptabil- ity to overcome the differences in data distribution, domain shift, and model architecture. There exists a lack of comprehensive investigations in domains, notably those encompassing raw signals analysis and model performance over heterogeneous conditions. This research seeks to redress this gap by conducting an empirical examination of transfer learning ca- pabilities and their effect under federated learning conditions within the context of predictive maintenance. We aim to utilize motor sleeve bearings and shaft misalignment of varied horsepower levels and multiple layered neural network models consisting of paired 1D-CNN, TCN, and LSTM models. The study is conducted, by pitting transfer learning techniques against baseline deep learning procedures, to analyze the overall efficacy and feasibility of federated transfer learning.",Reliability I,187,342
AMED: Unveiling Complex Relationships in Manufacturing Processes through Attention-based Modeling of Deviant Events," In the realm of advanced manufacturing, deciphering the intricate relationships between numerous process-structure-property (PSP) variables is pivotal for enhancing process performance, quality control, and predictive maintenance. Particularly in complex fields with a multitude of variables exceeding a hundred, such as superconductor manufacturing, traditional regression methods fall short. These methods primarily capture relationships based on mean shifts, often overlooking crucial patterns such as deviant events in time series data. Deviant events, significant anomalies diverging from expected patterns, are the key for understanding actual process dynamics and identifying issues. To bridge this gap, this paper introduces an innovative method named the Attention-based Multiple-Encoder-Decoder (AMED) to capture the complex interactions among multivariate time series in terms of their deviant events. AMED employs Inverse Normal Transformation (INT) and Symbolic Aggregate approXimation (SAX) to normalize variable distributions and convert multivariate time series into symbolic sequences. This transformation enables the extraction of ""symbol baskets"" representing deviant events, facilitating an event-centric analysis that traditional numerical approaches overlook. Using a novel attention-based embedding model, AMED decodes complex relationships among these events, presenting them in a comprehensible relationship network graph. Our methodology not only counters the limitations of standard linear models in handling high-dimensional, dynamically changing data, but also provides deeper insights into the non-linear interdependencies among manufacturing variables. Empirical analysis of superconductor manufacturing datasets validates the effectiveness of AMED in providing a more accurate and nuanced understanding of process dynamics. This study offers promising pathways for incorporating machine learning into manufacturing, augmenting real-time monitoring, control, and decision-making processes.",Manufacturing II,136,343
Optimizing Food Bank Logistics: A synchronized Approach to Mobile Food Pantry Routing," Food insecurity is a global challenge affecting nations across different economic spectrums, from underdeveloped to developed regions. Food banks play a crucial role in collecting food from individuals and government entities to store and then distributed to local partner agencies, such as food pantries and soup kitchens, which, in turn, provide assistance to individuals facing food insecurity. Food banks, driven by a humanitarian mission, strive to achieve a delicate balance between ensuring equitable distribution among areas in need and increasing the number of individuals served within the constraints of limited resources. This research introduces a Mixed Integer Programming (MIP) model specifically crafted to address the coordinated routing of Mobile Food Pantry Trucks (MFPT) for food distribution. These trucks enable food banks to deliver food directly to those in need by dispatching their vehicles and personnel to locations where the demand is most significant. Our optimization approach places a substantial emphasis on minimizing routing costs, managing MFPTs efficiently, and ensuring fair food allocation to the food-insecure population while reducing waste. The primary objective is to enhance the operational efficiency of MFPTs. We design a matheuristic to solve large instances of the problem, conducting a comprehensive numerical analysis using real-world data to showcase the efficacy of our proposed approach. Results indicate that our matheuristic exhibits fast and efficient performance in terms of solution quality and computational time compared to the Gurobi MIP solver.",Logistics & Supply Chain Best Paper Competition,121,344
Self-supervised 6-DoF Robot Grasping by Demonstration via Augmented Reality Teleoperation System," Existing robot grasping problems are mainly solved by large-scale supervised models based on large-scale 6-DoF robot trajectory datasets. It is laborious to collect robot data in some restricted areas, and it is impractical to learn a new grasping skill without 6-DoF robot data. To this end, we propose a self-supervised 6-DoF grasp pose detection framework via an Augmented Reality (AR) teleoperation system that can efficiently learn new human demonstrations and provide 6-DoF grasp pose without grasp pose annotations. The overall system consists of a user interaction system and a remote robot control system. The user interaction system is mainly based on the Unity AR software to display the AR environment and enable human-robot interaction in the AR environment. The remote robot system includes a general grasping generator and a new grasping strategy learning component to control a xArm 6-DoF robot. The system utilizes a Realsense RGB-D camera to detect the objects and a Zed camera to stream the video in the AR software. Specifically, the system collects the human demonstration from the AR environment. The collected human demonstrations include demonstrated trajectories and the RGB-D images from the robot arm end-effector. The grasping strategy for new objects is learned contrastively from the demonstration. In the real-world experiment, the proposed system leads to satisfactory grasping abilities and learning to grasp unknown objects within three demonstrations.",Digital Manufacturing and Industry 4.0-IV,48,345
Primary Health Care Facilities in Developing Countries: A Location-Allocation Simulation Framework," In developing countries, the geographical accessibility to primary health care (PHC) attention is a significant challenge to overcome. Either a lack of mobility options (e.g., limited public transportation lines) or long distances to the closest PHC facilities could be the leading causes of this accessibility problem, preventing the population from getting adequate health services promptly. In this study, we develop a simulation framework to evaluate the level of accessibility to PHC services of the population in developing countries. The PHC facility location problem was formulated as a p-median problem, along with a simulation model, to obtain a set of feasible PHC locations. Furthermore, a spatial efficiency evaluation was conducted based on socioeconomic and equity metrics to ensure the viability of the framework using the country of Panama (4.41 million inhabitants and around 901 PHC) as a case study. Overall, the PHC facilities framework is an assessment tool of the level of health care service in developing countries, generating insights for a satisfactory administration of resources, which leads to improving the quality of life of individuals.",Healthcare Applications,82,346
Modeling Critical Mineral Supply Chains: The Role of Unconventional Sources," Critical minerals such as lithium are essential for modern technology and the clean energy transition. However, most critical minerals are processed outside of the United States and increasingly in China. Securing a critical mineral supply chain is essential to ensuring our technological advantage and for making a timely energy transition. This work explores how much lithium is needed for electric vehicles and what role recycling has to play in securing our energy transition. It uses a simulation approach to provide a baseline and an optimization approach under a variety of different scenarios to determine what the optimal strategy should be to secure the critical mineral supply chain.",Supply chain design 1,221,347
Ingenious Solutions in Resource Depletion: Enhancing Productivity and Repair Efficiency through Innovative Problem-Solving," Introduction; A centrifugal pump, utilizing rotational energy from impellers moves fluids mechanically. Mechanical seals, crucial for leakage control in rotating equipment like pumps, often incur extended repair times and high costs, particularly in economically constrained situations. In a specific case, we successfully replaced the mechanical seals of multiple pumps with locally sourced materials, significantly reducing costs and the overall repair time.  Background; Our company specializes in repairing and overhauling marine machinery, particularly pumps and heat exchangers. Operating in a resource-depleted environment, we face challenges in maintenance due to lengthy hauls and high freight costs. Acquiring materials from international Original Equipment Manufacturers (OEMs) is difficult, given limited local representatives and economic instability. To address these issues, we proposed unconventional solutions. With the approval of our client, we replaced the mechanical seals in various pumps with locally sourced alternatives, aiming to reduce reliability issues and enhance mean time to repair while maintaining previous operational parameters  Case; Our customer encountered recurrent failures in a horizontally oriented fire main pump with a Chesterton (split-type seal) due to plastic debris from the harbor. Challenges in replacing the seal, attributed to the absence of a local OEM representative and high costs, led us to modify the seal housing and shaft sleeve. The retrofit with a simpler, single spring-loaded mechanical seal not only saved costs in spares and pump replacement, but also enhanced the reliability of the system and platform.",Manufacturing process improvement,141,348
Enhancing Material Discovery with Reinforcement Learning-Driven Bayesian Optimization: A Cross-Material Dataset Perspective," In the dynamic field of material science, the quest for discovering novel materials with optimal properties is both critical and challenging. Traditional approaches often encounter limitations in efficiently navigating the vast experimental space, primarily due to the high cost and complexity associated with material experimentation. This paper introduces a novel methodology that synergizes Reinforcement Learning (RL) with Bayesian Optimization (BO), fundamentally transforming the landscape of material discovery. Our approach, Reinforcement Learning-Driven Bayesian Optimization (RL-BO), intelligently adapts acquisition functions to optimize the sequential sampling process, thereby significantly enhancing the process of material discovery. Distinct from previous studies that primarily focused on optimizing benchmark functions, RL-BO is applied to a variety of material datasets, encompassing a wide range of material properties and complexities. This cross-material dataset application not only serves as a robust testbed but also showcases the versatility and adaptability of the proposed method. The RL component dynamically selects and tunes the acquisition functions, specifically Upper Confidence Bound (UCB) and Expected Improvement (EI), in response to the evolving state of the optimization process. This adaptive approach ensures a more nuanced balance between exploration and exploitation, a critical aspect often overlooked in conventional optimization strategies. Compared to traditional BO methods, RL-BO demonstrates superior performance in terms of faster convergence, higher accuracy, and improved consistency in reaching optimal material properties. The empirical findings underscore the potential of RL-BO as a powerful tool for accelerated material discovery, paving the way for its application in other domains where optimization plays a pivotal role.",Deep Learning I,40,349
Initial investigation into design best practices of wire arc additive manufacturing," Wire arc additive manufacturing (AM) has garnered attention in recent research, yet a comprehensive set of ""best practices"" for design remains notably absent in the literature. This research initiative, conducted at Mississippi State University and funded through the US Army Corp of Engineers Engineering Research and Development Center, sought to address this gap by exploring the wire arc AM process's intricacies. Focusing on the inter-relationships between machine parameters, geometric outcomes, and overall build quality, our team utilized ES 120S-G steel to print six distinct geometric shapes. These shapes, including a single thin wall, cylinder, S-wall, rectangular block, ramp, and block figure 8, were chosen for their simplicity in programming the wire arc AM robot and their coverage of essential geometric variables such as overall weld bead thickness, sharpness of corners, edge smoothness, straightness, and concentricity. By employing various machine parameters, our study aimed to uncover insights that contribute to the identification of overarching design rules or ""best practices"" for wire arc AM. In this presentation, we delve into the lessons learned from these six simple builds, showcasing the iterative process of refining machine parameters and extracting knowledge from each geometric shape. Our goal is to advance the understanding of ES 120S-G steel behavior during wire arc welding, ultimately establishing guidelines for optimizing machine parameters. Beyond contributing to the ongoing refinement of wire arc AM processes, these findings set the groundwork for informed design considerations, thereby fostering advancements in additive manufacturing and elevating the overall quality of wire arc AM designs.",Directed Energy Deposition Additive Manufacturing Processes,52,350
Computational Fluid Dynamics Of A Bubbling Fluidized Bed In Wood Pellets," In comparison to conventional combustion technologies, fluidized bed combustion has several advantages, such as superior heat transfer characteristics due to homogeneous particle mixing, lower temperature needs, nearly isothermal process conditions, and the ability to operate continuously. Computational fluid dynamics (CFD) can help anticipate the intricate combustion process and the hydrodynamics of a fluidized bed thoroughly by using CFD techniques. Bubbling Fluidized bed was model using the Eulerian-Eulerian model including the kinetic theory of the flow. The model was validated by comparing it with other simulation of the fluidized bed. The effects of operational gas velocity, volume fraction, and feed rate were also investigated numerically. A higher gas velocity and feed rate cause an increase in fluidization of the bed.",Manufacturing process improvement,141,351
"Safety in Systems: A Comprehensive Literature Review of PHA, FMEA, HAZOP, and Fault Tree Analysis"," Objective: This review aims to evaluate the practical application of four pivotal safety engineering methods—Preliminary Hazard Analysis (PHA), Failure Modes and Effects Analysis (FMEA), Hazard and Operability Study (HAZOP), and Fault Tree Analysis (FTA). This review focuses specifically on the real-life application of the methods. Background: Work-related accidents caused 5,190 fatal and 2.6 million non-fatal injuries in the US in 2021. The cost of these accidents was estimated to be around $167 billion. We must learn from previous studies that applied the above-mentioned methods to successfully improve workplace safety. Method: Conducted a comprehensive literature review from Web of Science and UTA Library to understand, assess strengths and weaknesses, explore applications, and identify improvement areas across diverse industries. Results: The findings reveal that while each method has its unique advantages and specific applications, there is a significant overlap in their ability to identify and mitigate risks. However, the review also uncovers potential areas for optimization in their application, particularly in adapting to the specific needs of different industries and integrating technological advancements. Conclusion: This review offers valuable insights into state-of-the-art safety engineering methods. It underscores the importance of continuous improvement and adaptation of these methods to ensure the safety and reliability of industrial systems. Application: This review will be a practical resource for researchers and industry professionals, guiding the selection of suitable safety engineering approaches for specific industrial contexts. Additionally, it pinpoints areas for further refinement or integration with emerging technologies to support safety measures across sectors.",Diverse Topics for Human Factors and Ergonomics 2,56,352
Manufacturability Characterization of Digital Light Processing of Bone Scaffolds," In recent years, additive manufacturing has been used in the biomedical field to manufacture biocompatible medical implants. One such application is the manufacturing of bone scaffolds to encourage the growth of bone cells in damaged bone areas. Additive manufacturing (AM) processes used to manufacture bone scaffolds include stereolithography and digital light processing (DLP). Both AM technologies can print biocompatible bone scaffolds by using compatible resin materials but DLP has better prospects for developments of biocompatible AM bone scaffolds because of short printing duration and higher quality prints of smaller objects. Prior research has focused on exploring printer settings, scaffold structure, and biocompatibility, but more research on scaffold quality and process yield is needed as this application moves towards commercialization. This study characterizes changes of DLP-printed bone scaffolds made with hydroxyapatite to observe the relationship between process inputs (exposure time and layer thickness) and output measurements (dimensional error and yield) using a design of experiment process. The data is analyzed using the analysis of variance method to observe the relationship between the controlled variables and the resultant changes in the printability of the bone scaffolds.The study provides a better understanding on how changes in process parameters can affect the quality of DLP-printed scaffolds to enable further improvements in scaffold manufacturability.",Bioprinting and Biomedical Manufacturing Processes-I,19,353
Neural Embedded Optimization over Sets," This talk introduces Neural Embedded Optimization over Sets, a novel framework for solving optimization problems whose objectives are set functions. The proposed framework is particularly suited for objective functions that are either computationally expensive to evaluate, or only available via black-box function calls, or only observable via a finite number of prior evaluations, such as historical data. Notably, these functions are not required to be submodular and their domains may be finite or even infinite sets. Central to our approach is the learning and subsequent embedding of a permutationally invariant but sparse neural network that serves as an efficient surrogate for such functions. Specifically, we solve a modified optimization problem whose objective is the output of a trained neural network. This problem is then reformulated as a mixed-integer linear program and solved with off-the-shelf solvers. This allows for the computationally efficient solution of an otherwise intractable problem while also accommodating additional decision variables and side constraints, thus broadening its applicability. Computational experiments on a data-driven problem in last-mile delivery and a continuous location allocation problem confirm the efficiency, versatility, and robustness of the framework across different problem classes.","Machine Learning and AI, Part 1",128,354
Competitive Optimization for Resilient Cyber-Physical System Design," Cyber-physical systems (CPS) play a pivotal role in manufacturing, industrial control processes, power grids, and critical infrastructures. Recent research highlights the susceptibility of CPS to stealthy attacks, wherein attackers possess comprehensive knowledge of the system's configuration. In response to this vulnerability, we leverage insights into stealthy attacks and propose a competitive optimization framework. This framework considers the objectives of both attackers and defenders within a CPS, facilitating the numerical computation of Nash equilibria in this competitive two-player game. Through simulation and case studies, we demonstrate how this approach allows the design of more resilient and robust CPS. By treating the system design stage as a computational game, operators can automatically assess CPS vulnerabilities and strategically inform their actions. In the face of dynamically evolving attacks, this proactive approach ensures secure operations in scenarios where traditional, static detection methods may face difficulties.",Advanced Topics of QCRE IV,10,355
Enhancing Resource Allocation for Alzheimer's Diagnostic Process in North Dakota: An Application of the Maximal Coverage Location Problem," Alzheimer’s disease is a brain disorder that leads to the shrinkage of the brain and eventual death of brain cells. Memory loss is a key symptom, often first appearing after the age of 60. However, the chances of developing Alzheimer's increase significantly after the age of 65. Currently, about 6.5 million people in the U.S. live with this disease, and in North Dakota (ND), the number of deaths has increased by 90% in the past 20 years. Recent studies indicate that an early diagnosis can significantly improve the quality of life for patients. This paper aims to assist decision-makers in maximizing the quality of life for Alzheimer's patients. To achieve this, a maximal covering location problem is employed to maximize the diagnosis of Alzheimer's within the population of North Dakota constrained to limited resources. Different scenarios are analyzed and compared. Results for each scenario are presented.",Resource Allocation and Workforce Planning in Health Systems,193,356
Advancing 4D Printing: Analyzing and Optimizing Process Parameters for Enhanced 3D Shape Accuracy," Additive manufacturing (AM), commonly referred to as 3D printing, has undergone significant advancements, particularly in the realm of stimuli-responsive 3D printable materials. This progress has led to the emergence of 4D printing, a fabrication technique that integrates AM capabilities with intelligent materials, introducing dynamic functionality as the fourth dimension. Among the stimuli-responsive materials, Shape Memory Polymers (SMPs) have gained prominence, notably for their crucial applications in stress-absorbing components. This study employs Fused Deposition Modeling (FDM) utilizing PLA and Thermoplastic Polyurethane (TPU) filaments to investigate the impact of process parameters and activation temperature on the 3D shape properties of 4D printed components. To understand the dynamic shape evolution of the components, we introduce a novel machine learning approach. This method not only enables the modeling of the ultimate 3D shape accuracy but also provides interpretability for the intermediate transformation process. This research contributes to a deeper understanding of the nuanced interplay between process parameters and the dynamic 3D shape transformation process in 4D printing.",Fused Deposition Modeling Additive Manufacturing Processes,76,357
Domain-Aware Machine Learning for Precision Coaxial 3D Bioprinting of Liver Tissues," The success of 3D bioprinting for liver tissue engineering depends on identifying and controlling process parameters that influence hepatocyte viability and liver-specific function. Overcoming the challenge of shear forces during extrusion bioprinting, which can compromise cell viability and the structural fidelity of printed constructs, is critical. While promising, traditional machine learning (ML) models in this space lack domain-specific knowledge, leading to suboptimal parameter control and predictive accuracy. Our study presents a domain-aware machine learning (DA-ML) framework tailored to expedite the design and manufacturing of multicellular in-vitro liver tissue models. Utilizing a dual experimental approach, we first employed coaxial 3D bioprinting techniques using human hepatic progenitor cells (HepaRGs) for the shell and human umbilical vein endothelial cells (HUVECs) for the core. Through cellular assays, we established quantitative correlations between process parameters and key cellular functions such as viability, albumin secretion, urea synthesis, and CYP enzyme activity. Complementing these assays, we performed physics-based transient numerical simulations to characterize the causal link between bioprinting parameters and flow phenomena within the co-axial printhead. Together, these results allowed us to map and encode the process-flow-function relationship into the DA-ML framework as domain constraints. The framework's data-driven sequential experimentation strategy adapts to this domain knowledge, enabling rapid tuning of 3D bioprinting conditions to achieve desired cellular outcomes. Employing the developed DA-ML framework, we demonstrated successful coaxial 3D bioprinting of multicellular liver models that exhibit high cell viability and liver-specific function. This approach significantly reduces experimental iterations, time, and costs, marking a substantial improvement in tissue engineering.","Advancements in Bioprinting: Techniques, Materials, and Applications",12,358
Bayesian Regularized Post-hoc Local Explanations with Uncertainty Quantification," We propose a method to explain black-box machine learning models and obtain the distribution of feature importance using Bayesian ridge regression models. The method aims to improve the accuracy and consistency of estimating the feature importance, as well as quantify the associated uncertainty. We provide mathematical expressions of the Bayesian framework and theoretical outcomes including the significance of ridge parameter. Case studies were conducted on benchmark datasets and a real-world industrial application of locating internal defects in manufactured products. The results suggest that our method can outperform the state-of-the-art methods by providing more accurate posterior distribution and consistent rankings of the feature importance.",Machine Learning I,125,359
"Optimizing facilities, time, and productivity in an innovative small business located in Puerto Rico."," Operational efficiency at Vía Láctea: Optimization of facilities, time, and productivity. For my course of Facilities Design, I took the opportunity to help small businesses grow while innovating at the same time. As Engineering students, we are accustomed to work alongside big manufacturing companies when it comes to investigations. Having a small business, myself, I reached out to colleagues who are talented small business owners. For insights, we are talking about an All-Vegan Ice Cream Brand based in Puerto Rico. They are known for their wide variety of flavors and excellent service. When we had our first meeting, they presented me with their short and long-term goals. Including saving money, opening more space for production, and selling wholesale. I saw an astounding opportunity for a Facilities Design Project. We went through the DEFINE phase making a time study in the facility and then establishing our root causes.The Vía Láctea company wants to reduce the cost of pints by 5%. In order not to affect the quality of ingredients, we will be carrying out a re-establishing of the facilities. We need to increase productivity in the process from 47% to 70%. At the end of my research, I met with both owners/executive chefs, I shared my process time analysis results along with possible improvements. The team is willing to make the investments that will allow them to take their production to the big leagues. We discussed opportunities for new achievements like Walk-In-Freezers and opening second locations.",Facilities Design & Planning IV,74,360
"End-Of-Life Strategies for Battery Electric Vehicles, Managing and Collecting Lithium-Ion Batteries, A Comprehensive Framework"," This research addresses the urgent need for effective collection and management solutions for end-of-life lithium-ion batteries from electric vehicles (EVs), focusing on the automotive and battery manufacturing perspective. Despite the global push to reduce carbon emissions by adopting battery electric vehicles, the environmental impact of their life cycle, particularly in mining and production, currently surpasses that of conventional gasoline vehicles. With the exponential growth of discarded EV batteries, the United States faces a mounting challenge in managing the waste stream. We highlight the increasing demand for EVs and the importance of second-life lithium-ion batteries. The research explores the motivations behind repurposing, remanufacturing, and recycling batteries from both government and manufacturer standpoints. Emphasizing the significance of regulatory frameworks and economic incentives, the study underscores the critical role of end-of-life strategies in establishing a circular economy for lithium-ion batteries. A key issue is identified as the absence of a universal system for collecting and managing discarded batteries. The research evaluates existing systems, analyzes successful case studies, and extracts best practices to enhance efficiency. It delves into global policies promoting sustainable battery management, offering insights applicable to the United States. The study concludes by providing guidance for policymakers and battery manufacturers, presenting a comprehensive framework to refine collection systems and contribute to a more sustainable circular economy. By examining successful practices and technological advancements, this study aims to influence future policies and encourage original equipment manufacturers to adopt more environmentally responsible practices.",Poster Presentations,169,361
Leveraging Sensor Data Repository in IoT-Enabled Lean Manufacturing: A Window Manufacturer Case Study," The integration of IoT (Internet of Things) technologies and Lean principles is essential to obtaining operational excellence in a competitive manufacturing landscape. This paper presents a comprehensive schema for sensor implementation to create a data repository system in a manufacturing industry leveraging IoT and Lean methodologies. The proposed framework is applied to an industrial-grade semi-automatic PVC cutting machine tailored for window manufacturing. The process begins with the identification of machine variables that need to be measured, offering a comprehensive view of the production process. This system enables real-time data acquisition from the sensors strategically placed on the machine, capturing critical process variables. It involves breaking down the various aspects of the process into more detailed elements. This data is then stored in a robust repository, ensuring its integrity and accessibility for further analysis through data dashboarding. The real-time monitoring enables agile responses to changing conditions on the shop floor. The centralization of this information serves as a foundation for comprehensive analysis, empowering decision-makers with insights to drive continuous improvement. The study highlights how this integration aids in minimizing downtime, improving overall equipment efficiency, and ensuring the delivery of high-quality window products. Implementing this synergistic approach leveraging IoT and Lean principles promises substantial gains in overall output, waste reduction, and operational efficiency, paving the way for sustainable, data-driven excellence in the industry.",Digital Manufacturing and Industry 4.0-I,45,362
"Flexible Hybrid Digital Toolchain for Robotic Additive Manufacturing using Industry 4.0, and Industrial Robot and PLC systems"," This paper proposes the development of a flexible hybrid digital toolchain aiming to facilitate the integration of reliable industrial robots and Programmable Logic Controllers (PLCs) into adaptable Additive Manufacturing (AM) solutions. This approach involves the fusion of Industry 4.0 principles with the capabilities of the Robot Operating System (ROS) in conjunction with Allen Bradley PLC and FANUC robot manipulator for Wire and Arc metal 3D printing. The integration utilizes the ROS Additive Manufacturing toolchain for trajectory planning, seamlessly linking with an AB PLC via EtherNet/IP (EIP) protocol using the Pylogix Python library, and the PLC also establishes communication with the FANUC Robot Controller through EIP. For the simulation and testing of trajectories, FANUC’s Roboguide simulation software is used. This work results in an end-to-end PLC-based industrially compliant robotic solution for additive manufacturing capable of utilizing ROS capabilities including kinematics, motion planning, simulation, and visualization, and PLC demonstrated reliability. The Simulation and testing in Roboguide serve to demonstrate the functionality of the system and the overall outcome is to leverage existing industrial manipulators and PLCs as dynamic AM solution through the convergence of Industry 4.0 concepts and ROS capabilities.",M&D Best Student Paper Competition,124,363
A Simulation Model Analysis in the US-Mexico Border," New or innovative strategies in Supply Chains (SC) have been researched or developed to deal with disruptive events, such as Covid-19, hurricanes, geopolitical, or even climate change. SC deal with demand and supply imbalances, different logistical challenges, and policy restrictions for transborder commerce. In both, the US-Mexico and US-Canada border, Free and Secure Trade (FAST) lanes are dedicated lanes for commercial vehicles. In 2022, the government of Nuevo León, México, opened a dedicated lane just for Tesla´s northbound commercial traffic. There has been no prior knowledge of a dedicated lane for a single company at a US Port of Entry (POE). Dedicated lanes in queueing systems are novel methods of improving performance measures by allocating resources to prioritize the needs of a set of companies. This paper extends previous research of a cost-comparison model developed to analyze the benefits of this innovative strategy. The paper will test whether the innovation on the queuing system actually saves time, saves money, and benefits the SC. A simulation model will be validated and will use POE data from Mexican Customs, and it will analyze different scenarios for the traffic flow of the dedicated lane compared to the normal lanes in the Colombia-Solidarity Port of Entry. This model will also compute other measures to compare the system in different scenarios with different congestion situations. The analysis will show if the reduction in the wait time improves the resilience in the supply chain, or if different strategies should be considered.",Modeling Environments,147,364
Pattern-Based Autonomous Recovery Approach for Quality Assurance at a Specific Stage in Multistage Manufacturing Systems," In Multistage Manufacturing Systems (MMS), ensuring the quality of the final products is challenging due to the propagation of intermediate product variations along the manufacturing process, potentially leading to nonconforming products. This paper proposes an autonomous recovery approach to address quality issues at a specific stage in the MMS without input variables. The approach utilizes Logical Analysis of Data (LAD), a Machine Learning technique, to monitor the output characteristics of the specific stage and identify patterns that are associated with conforming and nonconforming states. These patterns serve as recovery patterns, guiding the system towards conforming states. The selection of the appropriate recovery pattern is based on the nearest recovery pattern to the current nonconforming state. The applicability of this approach is demonstrated through a real-world case study, where the results of generating recovery patterns have the potential to enhance product quality and reduce resource waste.",Advanced Topics of QCRE IV,10,365
A Food Bank’s Network Resilience in The Face of Disaster," A food insecure person is one who lacks consistent access to enough food for an active and healthy lifestyle. When disasters due to weather and climate or human-related activities occur, chaos ensues, leaving people jobless, homeless, and hungry. This abrupt disruption to everyday life generally increases food insecurity in that area. However, food banks, which typically cater to the needs of the food insecure, are also adversely impacted by the disaster despite the surge in food insecurity. The disruption to the food bank’s supply and capacity reduces its capability to meet this drastic surge in demand. To curb potential food crises after the disaster, food banks need to better prepare by evaluating network vulnerabilities beforehand. Recognizing the magnitude of the disaster, social vulnerability and resilience indices of the affected area aids the utilization of optimal distribution methods to meet demand effectively and on time. A quantitative approach is employed to enable food bank managers to make informed decisions in the advent of a disaster and use the best alternatives available to them. This ensures that the food bank still meets its core goal of serving the food insecure population despite limitations induced on its network by the disaster. Findings from this work can be adapted to fit food banks of various sizes with a comparable network structure. It can further be adapted to account for varying disaster types.",OR for a Resilient Future,152,366
Clustering Insights in Highly Customized Manufacturing: A Digital Twin Approach with Sensor Fusion and Machine Learning," A digital twin serves as a real-time virtual representation of a physical system, achieved by identifying and capturing critical process parameters through sensor fusion. In a conventional production line, efficiency is typically calculated by comparing actual production data with the production plan. However, in the case of highly customized products, production processes may significantly vary based on product variations, rendering it challenging to predict system behavior during the planning stage. As a result, the actual capacity of the production system will vary with each product variation. To enable a digital twin to distinguish individual products, a proper product architecture is essential. This architecture assigns a unique identity to each product based on specific product variables. This study focuses on sensor fusion in a highly customized windows manufacturing facility. The real-time process variables, captured through sensors, facilitate the creation of a dynamic value stream map (DVSM) for the assembly line. These process variables, combined with the product architecture, reveal the actual variation in the process corresponding to product differences. Drawing insights from historical data, machine learning techniques will be employed to establish connections between process variables captured through sensors and the product architecture. To achieve this, product clusters will be developed using partitional (k-means) and density-based (Gaussian mixture model) clustering techniques based on product variables. The machine learning algorithm should adeptly predict the process variation for any newly introduced product, as well as anticipate and plan for future changes and their impact on the production line.",Manufacturing & Design Best Track Paper,133,367
Project Management Information Systems: Helping or Hindering?," Project Management Information Systems (PMIS) are software programs that organize and control project data and information flow. Is your Project Management Information System working for you, or are you working for it? Are you pushing static “updates” or showing “dynamic” progress? How are you sharing and celebrating the value EPMO and Operational Excellence bring to the organization? Does everyone in your organization know if you are winning or losing? What's the score? This session will focus on how Ballad Health utilizes its Project Management Information System to create transparency, and build efficiencies.",Problem Solving and Decision Making I,175,368
Hansei: Reflections from a Japan Lean Study Trip," I have dreamed of going on this bucket list Japan trip since my time as an entry-level Production Control Engineer at Toyota. I never had the opportunity to go during my time at Toyota, but I have studied the Toyota Production System (TPS) and Lean for the past 20 years. Some may call it an obsession. Many questioned the need to go to Japan, but I felt it was time to go to Gemba and see with my own two eyes. More than anything, I want to learn from other Lean Geeks on Katie Andersion's Japan Study Trip, which is a proper mix of learning about TPS’s origins and experiencing Japanese business culture, history, food, and environment. So as a 40th birthday present (two years late) to myself, I took the plunge and am heading to Japan. Join me, as I share my experience, my insights into the Toyota Production System learned firsthand from a Toyota Leader, learnings of true Lean culture, humorous cultural difference, learning to be comfortable in the buff, and more. Would I do it again? Spoiler alert: I would answer that with an ecstatic yes! See more at www.leangeek.blog.",Continuous Improvement Tools and Methodologies II,34,369
Predicting Usability of Prosthetic Devices in a Virtual Reality Setting," Virtual reality (VR) simulations can be used for prosthetic device training and patient rehabilitation. Prior studies found that using VR simulations can reduce mental workload and increase perceived usability of prosthetic devices. Although previous studies have evaluated the usability of prostheses in VR settings, they mainly relied on user-testing which require a functional device or prototype. However, assessing the usability of prosthetic devices in early stages of the design process can be cost effective and help device developers design a more usable prosthetic device. This study developed a usability evaluation tool based on a human performance modeling approach to predict the usability of prosthetic devices in the early stages of the design process. Five usability dimensions were formulated including learnability, efficiency, error rate, memorability, and satisfaction. A human-subject study with 30 participants was conducted. Three device configurations (i.e., direct control, pattern recognition, and continuous control) and two activities of daily living tasks (i.e., clothespin relocation test and Southampton Hand Assessment Procedure) were simulated in a VR setting. The results suggested that the model outcomes were similar to the results of the human-subject experiment. The tool was able to predict the usability dimensions based on a few input parameters (e.g., device calibration quality, first impression of the device) and using a graphical user interface. The findings provided a quick and practical tool for a prototype-level usability and cognitive workload assessment of prostheses. Furthermore, the tool could help clinicians find, test, and recommend prosthetic devices that better fit the needs of patients.",Work systems and services for Human Factors and Ergonomics,242,370
Development and Validation of the Perceived Usefulness of Feedback Characteristics Questionnaire in Engineering Education," Instructional feedback is crucial in education, but the exploration and measurement of student perceptions of feedback characteristics remain overlooked. This study introduces and validates a novel Perceived Usefulness of Feedback Characteristics Questionnaire, tailored for the context of engineering education. The validation process includes establishing face validity through expert reviews, a pilot test with 30 participants for initial refinement, followed by data cleaning. Principal Components Analysis ensures the instrument accurately measures the intended constructs, while Cronbach’s Alpha evaluates the internal consistency of the items, leading to any necessary adjustments. This validated instrument provides valuable insights into students' perceptions of feedback usefulness, paving the way for enhancing feedback strategies in educational research, particularly within engineering education.",Operations Research and Modeling in Education,153,371
Enhancing procurement efficiency of collaborative supply networks using multi-agent actor- critic algorithm," Organizations strive for profitability while balancing economic, environmental, and social factors, with the procurement function playing a pivotal role. The key goal for supply organizations is to reduce the cost of products while maintaining other performance metrics. This paper introduces a novel approach to negotiate costs through iterative procurement auction, leveraging multi-agent actor-critic algorithms. Our study focuses on buyers, financial and risk impact assessors, and other key entities within the procurement ecosystem, each equipped with actor and critic components. The actor component takes the decisions, while the critic component evaluates choices based on financial metrics. The primary objective is to source products with minimal cost so that the profit margin is improved. This multi-agent system forms an adaptive decision-making framework which learns from historical data and dynamically interacts within the procurement environment. By decentralizing the decision-making, the collaborative efforts of individual agents contribute to the overarching goal of minimizing cost. Through this iterative process, we demonstrate that the application of the algorithm enhances the procurement efficiency, achieving lower costs and satisfying performance metrics. This innovative approach minimizes the need for extensive input from procurement managers, presenting a promising advancement in optimizing the intricate landscape of procurement decision making",Supply chain design 1,221,372
Detection of Stencil Printing Directions in PCB Assembly UsingSolder Paste Inspection Data," Traditional Solder Paste Inspection (SPI) systems, pivotal in quality control, focus on assessing solder paste attributes such as volume, area, height, and positional offset, but do not address the determination of printing direction. This study addresses this gap by harnessing SPI data to detect the printing direction, a factor significantly impacting solder paste deposition quality and the efficiency of the Surface Mount Technology (SMT) line. Despite advancements in Artificial Intelligence and Machine Learning, existing Convolutional Neural Networks, based on camera vision data, exhibit limitations in discerning printing directions due to the challenge in identifying unique geometric patterns. We propose an innovative method, integrating Long Short-Term Memory (LSTM) networks and Machine Learning techniques, to extract and analyze printing direction information from SPI data. This approach significantly extends the utility of SPI data, transitioning from mere defect detection to a comprehensive control mechanism in stencil printing processes. Our model, tested on two distinct board designs—Jabil and MOM4—demonstrated remarkable accuracy in classifying printing directions, achieving successful results with only two PCBs for training data. This promising development suggests the potential for integrating this model into inspection machines for inline production, enhancing quality control and aligning with the objectives of data-driven manufacturing in Industry 4.0. This novel methodology marks a substantial advancement in smart factory operations, offering a more efficient, reliable, and data-driven production process.",Machine Learning in Manufacturing I,129,373
Scheduling and Resource Allocation for Cyber-Physical Systems: A Multi-Agent Reinforcement Learning Model," In cyber-physical systems, achieving optimal resource allocation and crew assignments for desirable long-term system behavior is a critical research goal. Traditional models presume knowledge of probabilities and steady-state distributions for random variables, utilizing centralized approaches for policy optimization. However, not all stochastic and dynamic characteristics of the sequential decision-making process can be captured this way. We, thus propose a model-based reinforcement learning methodology for decentralized crew scheduling and resource allocation. A hybrid simulation model captures organizational and network evolution dynamics. Crew agents learn adaptive maintenance scheduling and a fictitious agent learns resource allocation policies via multi-agent reinforcement learning. Dynamic graph state representations that updates depending on the system evolution will help improve learning and stability. To address non-stationarity and partial observability, latent insights from past experiences are incorporated into reward signals, enabling nested learning. The proposed approach is applied to an interconnected multi-infrastructure network in the City of Tampa, FL. Findings will aid municipal leaders in assessing resilient strategies by learning from simulated disruptions.",Integrating AI/ML in Simulation II,115,374
Exploring Consumers' Panic Buying Behavior: An Agent-Based Model for Supply Chain Management in Crisis Situations," Title: Exploring Consumers' Panic Buying Behavior: An Agent-Based Model for Supply Chain Management in Crisis Situations Panic buying is a common response to crisis situations, leading to sudden surges in consumer demand and supply chain disruptions. Numerous incidents of panic buying in various countries at the onset of the Covid19 pandemic, resulting in stockouts and supply chain disruptions, exemplify this phenomenon. Such behavior arises as consumers strive to mitigate the unfavorable effects of supply disruptions. This research aims to comprehend how individuals respond to uncertainties concerning supply chain inventory levels. The objective is to unravel the complex interplay of psychological, social, and environmental factors that contribute to panic buying phenomena. An Agent Based Model (ABM) is used to capture interactions between customers and simulate the complex dynamics of consumer panic buying behavior. This study explores the impact of different factors such as inventory levels, perceptions of scarcity, fear of shortage, media coverage, and the social network of individuals on consumers' purchasing choices. By developing an Agent-Based Model that integrates these factors, this study seeks to improve our comprehension of panic buying in supply chains, thereby offering valuable insights for supply chain managers and policymakers to better manage and lessen the impact of such phenomena in future. By simulating and analyzing panic buying behaviors, the aim is to guide the development of more resilient supply chain strategies.",Agent-Based Modeling,14,375
Guided Active Learning Sampling Approach for Large Data: A Case Study on Printed Circuit Board Inspection," In the era of big data, efficiently managing and analyzing vast datasets has become a critical challenge, particularly in fields where precision and rapid processing are paramount. This study addresses the substantial challenge of handling and interpreting over 1 million testing data points. These data points, characterized by their volume and complexity, pose significant computational and logistical difficulties. The primary objectives of this research are to extract a statistically representative sample that focuses on defective regions, optimize high-quality data points for AI analysis, and achieve these goals within a time frame ranging from a few seconds to minutes, depending on the sample size. To meet these objectives, we employed the ""Batch-wise Uncertainty and Representativeness Guided Active Learning"" (BURGAL) methodology. This approach combines systematic weighted random sampling (SWRS) for initial data selection with an active learning process that iteratively updates the sample pool. The results demonstrate the feasibility of obtaining a representative sample from large datasets in a matter of seconds to minutes with maximum Cohen’s d of 0.2, depending on the sample size. This study contributes to the field by providing a scalable and efficient approach for data sampling in large datasets, facilitating rapid and accurate data analysis suitable for AI applications.",Digital Manufacturing and Industry 4.0-III,47,376
Identifying Key Factors and Predicting Product Obsolescence in Critical Supply Chains," Obsolescence management is critical in determining the continuous supply of products and services within a supply chain. Quantifying the probability that a product or supplier will become obsolete is a critical input for many companies in the design, procurement, and supplier selection processes. The defense industry is particularly susceptible to risks associated with product obsolescence since many products are purchased in lower volumes, have specific requirements, and have irregular buying patterns. Furthermore, because of the long design, testing, and deployment timeframes, the technology of components and systems that comprise the products used in defense applications may become obsolete within the product's intended life. Such situations create maintenance and repair challenges in the future. In this work, we demonstrate a lifecycle model to predict the lifespan of base items as a function of key factors that affect obsolescence to solve this obsolescence management problem. Our model has practical applications for designers and purchasers when selecting from a portfolio of substitution choices among parts and suppliers.",Supply chain Risk & resilience 1,219,377
Costing A Special Emergency Health Service Facility Design," A special emergency health service facility design is generally created in addition to the normal emergency service facility available in hospitals to cater to the specific needs arising out of the sudden emergency situation (For example, Covid 19, war, earth quack, flooding etc.) to meet the specific needs of affected people. The main components of a health service facility design are in the form of space (Land, building, and its internal layout), utilities (Water, gas, electricity etc.), machinery, fixtures (Tables, chairs, beds etc.), direct material supplies (Medicines, and chemicals etc.), and staff (Doctors, nurses, pharmacists etc.) to provide specific emergency services to the affected people. Studies reviewed related to cost estimation for admitted patients in emergency health service facilities, indicates that those are generally based on the direct medical and material supplies related expenses only. The cost of other indirect resources uses, such as special facility space, machinery and equipment used, and medical staff providing emergency health services to patients (Contributing significant part of the total cost) is not included in cost estimation. In this paper, a generic costing methodology is proposed to help estimate the cost of indirect resources along with direct medical supplies for estimation of cost per patient more accurately. This methodology could be useful to researchers, practitioners, entrepreneurs and policy makers in health services, to assess the cost of indirect resources along with direct resources per patients for purpose of accurate cost estimation for strategic as well as day to day decision making.",Resource and Asset Management,194,378
Volume Estimation for Dump Trucks in Earthmoving Operations Using Vision-Based Deep Learning Algorithms," In the rapidly evolving field of construction, earthmoving operations are paramount for optimizing efficiency and productivity. Traditionally, loaded trucks are counted manually and weighted on scale. Due to the physical limitations, these methods are error-prone, time-consuming, and expensive. To prevent such inconveniences, we suggest using more efficient methods by taking advantage of today’s technology. Our vision-based deep learning methods introduce a novel approach to earthmoving load estimation using advanced neural network algorithms integrated with Generative Adversarial Networks (GAN) from images of loaded trucks. In this study using scaled-down model dump truck images with different amounts of earth ranging between 0 and 1000ml at 200ml intervals up to six classes, we trained the deep convolutional neural network classifier, then we applied transfer learning to a pre-trained deep learning neural network to improve classification accuracy. The experimental results showed that the pre-trained deep neural network with a transfer learning approach achieved 96% accuracy. To achieve a remarkably better result, we need a large volume of data to train. To be able to achieve that goal, we proposed a GAN methodology which consists of two types of neural networks including a generator and discriminator. Based on a GAN-based framework, we generate new data from a given training set. The proposed algorithm provides a cost-effective and time-efficient solution for optimizing the dump truck allocation. The results show that our approach has the potential to increase the accuracy of deep learning models for estimating the volume of material transported by dump trucks in earthmoving operations.",Logistics I,122,379
Optimizing Automated Optical Inspection: Enhancing Precision and Efficiency through Adaptive Tolerance Limits with the Find Plane Algorithm," Automated Optical Inspection (AOI) systems are indispensable for ensuring the quality of electronic components in modern manufacturing. The Find Plane Algorithm stands out as a key element dedicated to verifying component presence in AOI inspection.The algorithm scrutinizes the height of each Surface Mount Technology (SMT) component, confirming their adherence to predefined tolerance ranges while flagging those that deviate significantly as potential defects during the inspection process. This is a common occurrence in SMT assembly after completing one side of a double-sided assembly. To combat the false call issue, the fine plane algorithm offers the flexibility to adjust tolerance limits, which is a critical feature in AOI inspection. This effort has been explored in the context of Mini-Dual Inline Memory Modules (MiniDIMM) and DIMM modules. This research presents a detailed analysis of the Find Plane Algorithm's application, emphasizing its role in reducing false calls and enhancing the overall effectiveness and dependability of the inspection process. The inferences derived from experimentation demonstrate the adaptability of the algorithm, allowing it to effectively address distinct LinkIDs, various component types, and tolerance limits. By strategically modifying these limits, substantial reductions in false calls are achieved, paralleled with improvements in yield, defect detection precision, and a reduction in the Defects Per Million Opportunities and Parts Per Million metrics. This algorithm enhance the AOI inspection program in terms of authenticity of the program as well as false call reduction during inspection of SMT manufacturing process.",Optimization,154,380
Nature's Navigators: Emulating Slime Mold Behavior in Algorithmic Design," This project explores the remarkable pathfinding abilities of slime molds, organisms known for their efficient network optimization. Our study involves observing slime mold behavior within specially designed 3D printed grids of varying shapes, aiming to understand how these organisms navigate complex environments towards food sources. The core of our investigation revolves around meticulously analyzing the movement patterns and decision-making processes of the slime molds as they traverse these grids. By leveraging these biological insights, we have developed a Python algorithm that replicates the slime mold's natural pathfinding strategies. This algorithm is grounded in the probabilistic models derived from our grid experiments, translating biological intelligence into a computational framework. The purpose is to harness the inherent optimization capabilities of slime molds for potential applications in network design, resource allocation, and route optimization problems. The fusion of biological observation and algorithmic modeling in this project not only highlights the efficiency of slime mold navigation but also opens new avenues for bio-inspired computational techniques. Our findings contribute to a deeper understanding of natural optimization processes and demonstrate the practical potential of biomimicry in algorithmic development.",Algorithmic Approaches,15,381
Connection of Heterogeneous Simulations based on ISO 23247," A manufacturing site is comprised of diverse production lines, each housing several machines and processes. While digital twin research focusing on individual objects like machines or production lines is gaining traction for the implementation of smart factories, it has limitations in addressing real-world problems that are intricate and stem from diverse causes. This underscores the necessity for federated digital twin technology which is capable of integrating seamlessly and working harmoniously for numerous individual digital twins within a manufacturing site. This study introduces an architecture for heterogeneous simulation connection based on the ISO 23247 standard, aiming to establish federated digital twins. Material flow within and between production lines, as well as among machines in factories, is observable through factory and logistics simulation models. Changes in working hours or conflicts with the surroundings within machines and processes constituting the production line are analyzable through machine and process simulation models. The scenario verification of this study demonstrates the viability of the design and operation of a federated digital twin in accordance with ISO standards, by aligning and correlating results from both factory/logistics simulation and machine/process simulation. This research anticipates broadening the application scope of digital twins across various levels within manufacturing sites and ensuring the adoption of standards-based, highly reliable digital twin technology.",Manufacturing & Design Best Track Paper,133,382
Sustainability of Manufacturing Enterprises: a Psychological Perspective of Linking Manufacturing Layers," As sustainability/sustainable development (S/SD) is still considered the buzzword in manufacturing environments, particularly after showing up and joining Industry 4.0 (I4.0), S/SD is prescribed to be embraced as one of the major perspectives of actualizing I4.0. Manufacturing, in common, is separated into three primary streams and/or layers. These layers are represented by machine design (MD), manufacturing processes (MP), and manufacturing systems (MS). All these layers constitute manufacturing enterprises. Although these layers coincide and/or overlap at one point, there's a psychological link between them. The primary layer is called the core and is dependable for designing machine components. The second layer is called the chosen layer, and it is represented by the manufacturing process with which generation operations will be adopted. The final layer could be a given one and is utilized to demonstrate which manufacturing system can be chosen. The objective of this paper is to discover sustainable development for these layers and the psychological interface between them. In this paper, elements, and components of these three layers will be distinguished and analyzed, and the S/SD index of linking these layers through a psychological perspective will be proposed and outlined independently and universally.",Process Planning-II,181,383
Solving Cold rolling scheduling problem based on Lagrangian relaxation heuristic algorithm," The cold rolling process is essential in modern steel production, encompassing large-scale, multi-unit, and multi-stage characteristics. Owing to the complexities involved in the cold rolling process, effective scheduling of coils presents a pivotal challenge for steel plants. In this paper, we address this challenge by studying a two-stage hybrid flow shop problem in the cold rolling process. We formulate a mixed integer programming model to minimize completion time and tardiness. The model considers the parallel machines in each stage production with different production batching rules. We propose an algorithmic framework based on Lagrangian relaxation. The original problem is decomposed into subproblems, which are solved by a heuristic algorithm. We perform experiments using both simulated and real-world cold rolling plant data. The experimental results demonstrate that our algorithm has a better performance both in efficiency and solution gaps than commercial solvers.",Planning and Scheduling,165,384
Comparative Analysis of Resampling Techniques on Predictive Model Performance for Lung Cancer Prognosis," : Lung cancer has the highest mortality rates among both men and women, making it the leading cause of cancer-related deaths worldwide. Lung cancer is often detected at an advanced stage when treatment options are limited. An earlier diagnosis can increase the chances of recovery and restrict the spread of the disease throughout the body. Machine learning is increasingly utilized to predict the likelihood and presence of cancer in patients based on various factors. Predictive model performance can be affected by class imbalance in datasets, particularly when the target variable has an unequal representation of classes. This paper examines different techniques to balance data, such as Random Oversampling, SMOTE (Synthetic Minority Over-sampling Technique), Random Undersampling, and SMOTE with Tomek Links, and assesses their impact on the predictive models used for lung cancer prognosis, which include Random Forest, XGBoost, SVM, Neural Network, and Logistic Regression. It can be concluded that SVM exhibit superior performance in lung cancer diagnosis, achieving overall accuracy of 97.8%. with no significant difference between the various balancing techniques employed across all models.",Predictive Models in Health Systems,170,385
Factory Layout Design and Optimization using Production Simulation and Reinforcement Learning," Designing the factory layout is important process that has a significant impact on productivity, logistics and manufacturing costs. The design of factory layout require careful consideration of the various factors mentioned above, and the relationships between them become more complex as the scale of the factory expands Implementing a new production line or making layout changes due to process redesign, such as adjustments in equipment count, process, and logistics, demands considerable investment of time and resources for design. However, it is difficult to know if the layout is optimal. It is necessary to find methods to reduce the costs and discover the optimal layout. This study explores the method of determining optimal factory layouts, considering productivity and logistics, using digital twin and reinforcement learning algorithms. Through this methodology, the research deviates from conventional rules traditionally considered optimal in existing layouts. The study focuses on finding an optimal layout that maximizes performance metrics(productivity, logistics) while satisfying given conditions. Utilizing design data containing information about the equipment, a digital twin model is automatically generated and the results are predicted through simulation. The predicted outcomes are evaluated and updated by the reinforcement learning algorithm, iterating the process of creating a digital twin model and predicting results based on the updated design data. Through this iterative process, the study gradually identifies layout with better performance metrics. This study demonstrates the possibility of deriving optimal layouts under complex layout design conditions. The proposed methodology is expected to the identifying optimal layouts for the varying conditions.",Digital Manufacturing and Industry 4.0-II,46,386
Investigating the Needs of Informal Caregivers to Inform the Design of Digital Technologies for Caregiving," In Puerto Rico, there is an insufficient number of formal caregivers to meet the growing demands for caregiving, highlighting the need to provide support for the expanding elderly population from informal caregivers. The fundamental challenge driving this research is the fact that, in most cases, informal caregivers lack prior experience and training to effectively provide care. Notably in Puerto Rico, elderly individuals are often caring for other seniors, further complicating the situation as informal caregivers typically lack the necessary support to allocate time for self-care and attend to their well-being. Thus, the critical question arises: how can we support informal caregivers? To address this challenge, we have undertaken a literature review to identify the specific needs, barriers, and limitations faced by informal caregivers, with a particular focus on those caring for patients living with dementia. Preliminary results show that the needs, barriers, and limitations faced by caregivers are related to six main categories: mental health aspects, social aspects, lack of education/training, lack of information, lack of resources, and condition-related challenges. Building upon this knowledge, we have also conducted a comprehensive analysis aimed at determining whether digital technologies available for caregiver support effectively address the identified needs, barriers, and limitations. This approach has assisted in the identification of areas of opportunity for the potential design and development of a new digital solution to provide technology-driven support to assist informal caregivers in caring for their patients and, crucially, in caring for themselves as well.",Information and Digital Systems in Health,105,387
Optimization of Worker Assignment for a Manual Assembly Production Lines using Reinforcement Learning," In the technological advancement known as Industry 4.0, the strategic implementation of flow production lines is essential for mass customization. As manual assembly production lines rely on the high flexibility and adaptability of human workers, it is important to consider human-centric, a key value of Industry 5.0, in addition to improving production efficiency. Worker assignment in manual assembly production lines is crucial, as it directly influences both the efficiency of the line and the workload of the workers. However, it is difficult to derive the optimal worker assignment by considering a number of complex factors. Therefore, we propose a data-driven worker assignment methodology using reinforcement learning for multi-objective optimization in manual assembly production lines. A case study is conducted in a laboratory environment that mimics a manufacturing site, and the proposed methodology is validated by comparing it with existing worker assignment methods. It is expected that future research on data-driven multi-objective optimization problems for manual assembly production lines will be diversified based on this paper.",Digital Manufacturing and Industry 4.0-III,47,388
Improvement of productivity and efficiency in cutting line using Lean Manufacturing tools.," This was a company-wide project, my area ""packing"" was the principal cause of delays and waste time that impeding to obtain the desired productivity. In this project I lead a team to improve the efficiency of this cutting line, the team and I worked on implement Lean Manufacturing tools and other innovative ideas to reduce the delays, improve the process control and use the most of resources, at the same time that reducing safety risks and environmental problems. Now the project is in the follow up phase giving very positive results.",Manufacturing Organizations I,139,389
A Heuristic Algorithm for Determining Order-up-to Level in a Multi-echelon Inventory System Under Lead Time Approximation," We introduce a new heuristic for determining the order-up-to level for each stage in a general multi-echelon inventory system using dynamic programming. Dynamic programming (DP) has mostly been used in single-stage or serial inventory systems considering deterministic lead times. The complexity increases in a general multi-echelon inventory system where the lead time is stochastic. The proposed heuristic algorithm implements DP to determine the order-up-to level considering stochastic demand and lead time. The distribution of the lead time is approximated by simulating the base stock levels of each stage in the inventory system. Ultimately, the DP algorithm uses this approximate lead time to determine the demand distribution, which facilitates the convergence of the order-up-to levels for each stage. We provide a numerical example to illustrate the computational results for the proposed heuristic.",Supply chain design 2,222,390
Decomposition for Stochastic Mixed-Integer Programs with Endogenous Uncertainty Arising in Wildfire Management," In this work, we consider decomposition for stochastic mixed-integer programs (SMIP) with endogenous uncertainty arising in wildfire management. Specifically, we devise models and decomposition algorithms for fuel treatment planning and wildfire response problems in which the first stage decisions (fuel treatment and resource deployment) influence uncertain future outcomes, which include fire behavior and impact. Fuel treatment decisions include prescribed burning, mowing, mechanical thinning, and grazing. Subsequent operational decisions in the second stage include dispatching of firefighting resources to multiple fires needing a standard response. The uncertainty stems from vegetation growth, fire occurrence, and weather conditions. We implemented the decomposition algorithms and report on a computational study for a fire planning unit in Texas.",Large-scale Integer Programming,118,391
Data-Driven Decision Making in eCommerce: Enhancing Profitability through Price Optimization," In the dynamic landscape of eCommerce, accurately pricing products is crucial for competitive advantage and profitability. With markets constantly evolving and data availability increasing, leveraging data-driven approaches for pricing decisions has become imperative. An online office supplies retailer confronts the challenge of optimally pricing a vast product range in a market with frequently fluctuating prices. Traditional manual methods, although functional, are time-intensive and lack efficiency. The primary challenge is determining the optimal selling price for the retailer's products to maximize profit in a highly competitive and dynamic market. The objective of this study is to develop a data-driven model to predict optimal daily market prices for eCommerce products, thereby enhancing profitability. We employed machine learning techniques, specifically the Random Forest algorithm, to analyze historical sales data. The model was trained on features including competitor prices, historical sales, and internal cost factors, and was evaluated using R² and MAPE metrics. The model demonstrated robust predictive capabilities, with an average R² score of 0.91 across k-fold cross-validation, indicating a high level of accuracy in price and profit prediction. The developed model significantly outperforms traditional manual methods in predicting product prices and estimating profits. The retailer should integrate this data-driven approach into their pricing strategy to enable quicker, more profitable decisions, and continuously refine the model with new data for sustained effectiveness.",Business Analytics,23,392
Depth Perception and Task Performance in Robotic Teleoperation," Accuracy in depth perception is critical for robotic teleoperation. This is especially true for tasks involving grasping, relocating, manipulation, etc. This study aims to improve human operators’ depth perception and task performance using 3D visual cues. The working hypothesis is that providing 360-degree (3D) video as visual cues would significantly improve depth perception compared to a traditional 2D video. To view the 3D video, a virtual reality (VR) headset will be used. On the other hand, 2D video will be shown on a 50-inch TV. This study will answer two research questions: (1) Does providing a 3D video improve operator depth perception and task performance in a simulated teleoperation? (2) How does wearing a VR headset affect operator comfort and mental workload? Thirty human subjects will be recruited to perform five teleoperation tasks. Depth perception is affected by an object's size, shape, and distance in consideration. Hence, the tasks involve grasping objects (different sizes and shapes) from one location and placing them in another location. Depth perception will be measured by the operator’s ability to grasp and place the object on the first try. Task performance will be measured with the total time to complete the task and the number of errors in each task. This study contributes to the current literature on depth perception in teleoperation. Future efforts will find real-world applications for the teleoperation approach; for example, an ARC Mate 100iB Fanuc Robotic arm will be used to perform welding operations from a remote location.",Digital Transformation,50,393
"Sensor Network-Based Optimization of Energy Consumption, Health, and Productivity in Office Buildings"," This research focuses on optimizing energy consumption and improving occupant health and productivity in office buildings through the integration of a sensor network. Initially, a detailed building geometry model, inclusive of the HVAC system, is developed using OpenStudio. Subsequently, a sensor network is employed to gather real-world performance data from the building. This data is crucial for calibrating the developed model, ensuring that the simulations accurately reflect the building's actual energy consumption and performance characteristics. The study then conducts a series of experiments aimed at enhancing Indoor Air Quality (IAQ) and, by extension, occupant well-being and productivity. These experiments involve fine-tuning various parameters, including indoor air intake and occupant density, to find their impact on the indoor environment. Finally, the research seeks to find an equilibrium between minimizing energy usage and maximizing occupant health and productivity. This is achieved through the optimization of the HVAC system, focusing on temperature and lighting setpoints, air filtration, and fan power levels, alongside refining occupancy schedules. Overall, this study provides actionable insights and practical strategies in enhancing building efficiency while simultaneously ensuring occupant health and productivity are maintained at optimal levels.",Resilience and State Estimation,191,394
Planning for Net-Zero Electric Vehicle Charging Infrastructure in Texas through 2040," The deployment of a comprehensive charging infrastructure that ensures efficient and sustainable electrification of transportation is urgently needed. It aims to reduce the fossil fuel dependence, enhance the grid resilience, and reverse the climate change. This research focuses on the planning for net-zero energy electric vehicle (EV) charging infrastructure in Texas in response to growing environmental concerns as well as to boost domestic energy security. It is projected that in Texas 45 million EV will need to access ubiquitous and reliable charging networks by 2040. The research objective is to support and facilitate Texas’ transition to a net-zero transportation paradigm. First, the number of battery-powered EV and plug-in hybrid EV is forecasted through 2040. Second, based on the expected EV fleet size, we use the EVI-Projection Tool to determine the required chargers of three different power levels. Finally, the sizing and siting of solar- and wind-based microgrid generation to power the individual stations as well as the entire infrastructure is obtained. We choose 54 cities whose population exceeding 100,000 to allocate stations and chargers within cities and across highways and major intersections between adjacent cities. Reducing emissions, minimizing charging congestion, and enhancing user experience are the design criteria when integrating renewable energy and positioning state-wide charging stations. We propose two scenarios of charging infrastructure solutions by varying fleet composition, charging demand, and the cost of distributed energy storage.",Decarbonizing Mobility,37,395
How the COVID-19 Pandemic Affected Spatio-Temporal Usage Patterns in a Bikesharing System," Bicycle sharing quickly became a popular mode of transportation in urban environments in the United States until the COVID-19 pandemic was officially announced. System providers then faced a severe loss in ridership level, although cycling was recommended to encourage social distancing. While other bicycle sharing systems (BSS) met the ridership level of the previous year in the short term, the BSS Capital Bikeshare (CaBi) did not build on prior-year numbers. Because today´s bicycle-sharing business is fiercely competitive, a high service level and customer satisfaction are keys to achieving a sustainable operation. This research aims to understand how usage patterns of the CaBi system changed in spatial and temporal aspects before and after the first twelve months of the COVID-19 pandemic outbreak on March 7th, 2020. First, raw data was analyzed with basic statistical metrics to distinguish the number of trips and trip duration for both periods of publicly available trip history. Second, the member type of riders was analyzed, as well as the temporal distribution of trips. Applying the k-means clustering algorithm, stations with similar rental activities corresponding to the hour of the day and trip duration were categorized in the third step. Overall, it can be said that a significant change in temporal usage patterns of the stations has been noticed, whereas the spatial clusters did not change much during the pandemic. Bicycle-sharing operators and urban planners can use those insights and the aggregated list of factors influencing BSS use to enhance their operations.",Healthcare III,85,396
Neural Network Structure Optimization using Dandelion Algorithm," Neural networks are powerful tools for solving complex problems across various domains. However, designing the optimal structure of a neural network remains challenging, especially with backpropagation which can get stuck in local optima. This paper proposes using the Dandelion algorithm, a recently developed nature-inspired meta heuristic optimization algorithm, instead of backpropagation for neural network structure optimization. The Dandelion algorithm mimics the natural rising and spreading of dandelion seeds to effectively explore the search space. The Dandelion algorithm will be used to optimize the weights in an artificial neural network trained on the MNIST dataset. The efficiency of Dandelion for weight optimization will be tested against standard backpropagation algorithm.",Deep Learning III,42,397
Towards Personalized 3D Bioprinting: Leveraging Cluster-based Machine Learning for Mass Customization," 3D bioprinting emerged as a potential technology for biomedical and tissue engineering. Mass customization in terms of material selection, cell types, fabrication techniques, along with shortened fabrication time made 3D bioprinting very attractive in medical-related applications. However, the bioprinting process remains challenging in two folds: finding optimal process parameters for desired mechanical properties of scaffolds and obtaining cell type-based microenvironment into fabricated scaffolds. Getting both the personalized mechanical properties and microenvironment of 3D bioprinted scaffolds simultaneously sometimes even inversely related. In this work, we adopted the clustering-based machine learning technique to understand both the mechanical and microenvironment of scaffolds. The K-means clustering would apply to obtain an optimal number of clusters for the bioprinting experimental dataset. Each cluster obtained from cluster-based machine learning technique will be analyzed and rated based on the patterns toward bioprinting of scaffold ensuring user defined mechanical properties and personalized microenvironment. This new approach would help 3D bioprinting practitioners to address the dual challenge of achieving desired properties and microenvironment in printed scaffolds.",Bioprinting and Biomedical Manufacturing Processes-II,20,398
Point A to P.E.: Professional Licensure for ISEs, This presentation will provide an overview of the process to become a licensed professional engineer. ISE professional engineers will share their experience with licensure and answer questions about the process.,Point A to P.E.: Professional Licensure for ISEs,167,399
Explainable Parameter Calibration in Building Energy Computer Models via Gaussian Process-Based Sliced Sequential Design," A building energy model is a physics-based computer model that can simulate building energy use under various scenarios. For accurate simulations, calibrating simulation parameters necessary for pre-configuration is essential. While Bayesian optimization has recently gained attention in calibration, it encounters a challenge when dealing with a large number of parameters. This study devises a novel calibration approach that effectively identifies important parameters and explains their importance in simulation. A case study with real-world data demonstrates the superiority of our approach.",Facility Design,75,400
Cockpit Environment Effects on Pilot Operational Speed," Piloting airplanes can require lightning-fast reactions with pinpoint precision. To understand how to help pilots accomplish this, we must first understand how the different factors experienced in a cockpit affect performance. While some elements have been investigated, they have yet to be distilled to such a level of focus. In this study, we utilized a custom cockpit simulator to investigate how Display Orientation and Seat Location strongly impacted speed by returning p-values of p<0.0001 each. This communicated that a portrait orientation for the touchscreen display and the Pilot-side (left side of cockpit) seat were significantly faster than their counterparts (landscape and Co-pilot-side). We also found that Glove Type is nearly significant when considering speed, with a p-value of p=0.0558, showing that the errors induced by the less communicative gloves didn’t necessarily doom speed. We also are able to show that the level of Vibration does not have a significant effect on speed with a p-value of p=0.6943, demonstrating that the stress induced by vibration may counteract the decrease in speed caused by the vibration.",Cognitive Ergonomics,27,401
Enhancing Socio-economical System Resilience via Generative AI-Driven Simulations and Reinforcement Learning Framework," Contemporary society confronts a range of systemic disruptions, including pandemics, natural disasters, economic crises, social unrest, and cyber-attacks. Addressing these challenges necessitates predicting social system dynamics to enhance societal resilience. This study leverages Artificial Intelligence(AI), particularly generative AI, to simulate societal environments and deploy autonomous agent-based simulations. We employ Large Language Models to initiate these agents, each possessing daily routines, preferences, and purchasing satisfaction levels. These agents, with diverse psychological profiles, reflect the complexity of actual societies. A crucial aspect of this research is human purchasing decision-making behavior, which is pivotal for tracking socio-economic systems. We develop a human decision-making behavior reinforcement learning framework for agent-based learning, enabling agents to emulate human purchasing behaviors. This framework integrates utility theory and decision field theory under uncertainty, formulating rewards for purchasing decision-making behaviors. Through continuously learning from the simulated world’s daily routines, human-like agents are able to more accurately reflect human purchasing behaviors. By conducting multi-agent simulations, we observe the dynamics of the socio-economic system under various scenarios. These simulation scenarios are differentiated by the demographic characteristics of the agents involved in the society. This research includes market trend analysis, pattern recognition in market dynamics, and supply and stock level assessment, using simulated data to forecast societal outcomes of the system. This novel approach offers meaningful insights into the complex contemporary society. The potential of AI would allow us to enhance society's resiliency by predicting systemic societal disruptions and evaluating various effective mitigation strategies.",Integrating AI/ML in Simulation II,115,402
A Comparison of Trust and Slip and Fall Events for Various Roofing Materials," Industrial rooftops are a workspace that is infrequently considered for how risk-prone an area is, exposed to the elements dozens of feet off the ground, with many tasks that need to be done on them. Slips and falls in such an environment can be catastrophic, and even the average slip or fall incident in 2019-2020 was found to cost $48,575 by the National Council on Compensation Insurance. This paper investigates four common industrial roofing materials and how people of different anthropometric morphologies experience those materials differently regarding trust and slip-or-fall events. This information demonstrates a statistically significant difference in the comfort and safety of people walking on different roofing materials. These findings can aid designers and employers by serving as a guide for which material to select to keep their employees and technicians safe.",Organizational Ergonomics and Engineering Education,158,403
Process optimization of spinning processes in textile manufacturing using reinforcement learning," In the domain of smart manufacturing, the integration of data-driven reinforcement learning algorithms assumes a critical role in enhancing decision-making processes for the optimization of manufacturing within production systems. The textile industry, characterized by its dynamic quality-affecting parameters, demands the seamless assimilation of smart manufacturing technologies. This study contributes to academia and the field through the introduction of a reinforcement learning algorithm. This algorithm provides valuable insights and recommendations for optimization of spinning processes, ensuring quality of textiles characterized by enhanced toughness and elasticity. The Q-learning algorithm, uniquely devised by leveraging insights from a previously established regression model for predicting textile toughness and elasticity, serves as the foundational element for reward calculation within the Q-learning framework. Departing from conventional experimental methods, this study adopts a data-driven approach that not only reduces production costs and time but also cultivates an enhanced understanding and application of intelligent manufacturing techniques in both academic and industrial settings.",Manufacturing & Design Best Track Paper,133,404
Survival Signature Estimation for All -Terminal Networks by Solving the Multi Objective Bottleneck Spanning Tree Problem," This research examines the problem of estimating the survival signature of all-terminal networks using Monte Carlo (MC) simulation. Following a recent similar result for two-terminal networks, we show that the work required within each MC replication corresponds to solving a multi-objective bottleneck spanning tree (MOBST) problem. We implement the resulting MC procedure using a “block” algorithm from the literature to solve the MOBST in each replication by identifying its minimal set of non-dominated points. We compare this implementation against intuitive benchmark procedures for completing the work within an MC replication. We conduct numerical experiments to assess the efficacy of multi-objective optimization algorithms in expediting survival signature estimation for network structures. Our focus is to determine if these advanced computational strategies can significantly reduce the time complexity inherent in large-scale network analyses.",Supply Chain Management,215,405
Peer Effects and Safety Culture," Peer effects refer to impacts on a focal person’s behavior from another reference person or group without any evidence to suggest intentional influence from the reference person or group. Peer effects occur naturally in the workplace and can impact an organization's overall performance and culture by affecting employees' decision-making and behaviors. Within the study of safety management, peer effects have not yet been considered in the conceptualization of safety culture. Safety culture refers to the assembly of organizational attitudes and behaviors that prioritize safety. Factors that impact safety culture include management behaviors and commitment to safety, employee behaviors and commitment to safety, and safety management systems. The objective of this study is to identify and operationalize the impact of peer effects on the factors of safety culture through a systemic perspective that is informed by peer effects and safety culture literature synthesis. This study proposes that management’s behaviors and commitment to safety can moderate peer effects on employees’ safety behaviors through their safety management systems. As peer effects directly impact employee safety behaviors as well as their spread, this can affect the management’s behaviors and the design and implementation of their safety management systems.",Economics and Strategy,59,406
The Art of the AIW: How to Rapidly Improve Your Production System," In this presentation, I will discuss how to use well-known Lean techniques to rapidly improve a production system using an Accelerated Improvement Workshop (AIW). In my role as an industrial engineer for the last 2 years, I became certified in the Lean AIW and led multiple workshops to identify waste in various production processes and implement solutions to see significant improvements within a week. In my presentation, I will discuss what an AIW is and which Lean techniques are used in the workshop. I will then walk through how to run a workshop and gather the necessary stakeholders to propose and simulate solutions as well as how to implement and sustain the solutions to build a culture of standardized repeatability. Afterward, I will discuss how to tailor the AIW approach to any industry as well as steps anyone can take to identify wastes in their workplace.",Continuous Improvement Tools and Methodologies I,33,407
Unlocking Renewable Energy Market Opportunities: Analyzing Day-Ahead vs. Real-Time Price Mismatches and Mitigating Risks," Day-ahead markets for electrical power allow participants to reserve capacity for the following day, while real-time markets provide immediate pricing based on real-time supply and demand conditions. Renewable energy sources such as wind and solar have injected substantial uncertainty and complexity into energy markets because of their dependence on unpredictable weather and environmental factors. This dynamic has given rise to apparent arbitrage opportunities resulting from differences between day-ahead and real-time prices. Market participants are increasingly seeking to harness these opportunities to optimize energy storage and trading strategies, but the inherent risks associated with these strategies are not well understood. We analyze prior industry data and characterize the degree of mismatch between day-ahead and real-time prices. We then propose a model that uses risk measures to explain price differences and quantify risk-related costs. By investigating the dynamics of day-ahead and real-time prices, we propose strategies that may help market participants navigate the inherent uncertainties stemming from renewable energy variations and the associated system disruptions.",Energy Markets,64,408
A Temporal Evidential Filtering Approach to Dynamic Reliability Assessment of Multi-State Systems by Aggregating Multi-Level Imprecise Observations," Dynamic reliability assessment has offered a new paradigm for hierarchical systems to integrate multi-level observations to update system’s reliability measures. The existent work on dynamic reliability assessment can only leverage precise observations for state updating. In this article, a novel temporal evidential filtering (TEF) approach is put forth for dynamic reliability assessment of hierarchical multistate systems (HMSSs) by aggregating multi-level imprecise observations under the belief function framework. The imprecise observation matrices are defined to quantify the stochastic relationship between the imprecise observations and the actual states of the observed entities (components, subsystems, and the system). Based on the imprecise observation matrix, the TEF approach updates the system states with the following two pillars: (1) The evidential prediction stage aims at inferring the mass function of the system current state given the historical observations till current time and (2) The evidential updating stage that updating the current system state given the current imprecise observations via an orthogonal combination rule. Based on the updated mass distribution of the system states, the system’s reliability measure and its mean residual life can be updated in a dynamic fashion. The TEF approach is implemented to a flow transmission system and a control rod drive mechanism in nuclear reactors, and the results show that: (1) the proposed TEF approach covers the traditional Bayesian filtering methods when the observations are precise, i.e., Bayesian masses; (2) the epistemic uncertainty of the updated quantities decreases despite with imprecise observations. The computational complexity of the TEF approach is also articulated.",Advanced Topics of QCRE II,8,409
Automatic Glottic Opening Segmentation in Endotracheal Intubation Using Deep Learning," Endotracheal intubation (ETI) is a vital medical procedure employed in a wide range of clinical settings, from emergency/intensive care to operating rooms, to ensure adequate ventilation and oxygenation in patients with compromised airways. The accurate placement of an endotracheal tube within the trachea, precisely at the glottis, is essential for successful intubation and patient safety. However, the process of identifying and locating the glottis, often performed manually in a rush during emergency situations (such as cardiac arrest or trauma), can be subject to a lot of human errors, resulting into complications and adverse outcomes for the patient. In this study, we design and evaluate a deep learning model to automatically segment the glottic opening from clinical ETI images and videos. The model aims at helping medical practitioners in identify the glottic opening with high precision and reliability during ETI.",Teaming in Work Systems,229,410
Feature-Based Predictive Maintenance Scheduling under Data Heteroscedasticity," In this work, we consider a maintenance scheduling problem for a single-component system to determine the optimal maintenance time that minimizes cost rate in a replacement cycle of the system. We apply predictive maintenance strategy which leverages the prediction of the remaining useful life by data-driven methods. The distribution of component remaining useful lifes is firstly estimated using weighted least squares to handle the data heteroscedasticity. Then the distribution estimation is applied to the maintenance optimization problem and we analyze the effect of heteroscedasticity on the maintenance time decisions. Finally,the computational experiments positively demonstrate the performance of applying predictive maintenance strategy and considering data heteroscedasticity when estimating the remaining useful lifetime.",Advanced Data Analytics for Quality Control and Reliability,2,411
Predictive Modeling of Hospital Outpatient No-show Using Machine Learning and Bayesian Networks," Background: Patient no-shows present a multifaceted challenge for hospitals, significantly disrupting service quality, extending waiting times, and resulting in resource wastage. The substantial financial repercussions, amounting to billions annually, underscore the pressing need to address this issue promptly. The urgency lies in mitigating the adverse effects on patient care and healthcare institutions' overall operational efficiency. Objective: The primary objective is to enhance the accuracy of outpatient no-show predictions by employing various machine learning algorithms and Bayesian networks. The model seeks to ultimately contribute to optimizing resource allocation, enhancing operational workflows, and creating a more effective and responsive healthcare system. Methodology: The study utilizes open-source datasets, including patients' electronic health records and historical appointment data, to train various Machine learning algorithms and integrate them with Bayesian networks to infer complex relationships among predictor variables, to uncover nuanced patterns, providing a deeper understanding of the complex dynamics of the no-show reasons. Results: The predictive model performs better in forecasting outpatient attendance, outperforming traditional methods. Bayesian network analysis reveals key predictors, highlighting factors influencing patient attendance patterns. Conclusion: In conclusion, integrating machine learning and Bayesian networks provides a powerful framework for predicting hospital outpatient attendance. This approach improves prediction accuracy and provides valuable insights into the intricate dynamics shaping outpatient engagement, offering a comprehensive solution for optimizing the healthcare system, thus improving patient satisfaction and operational efficiency.",Machine learning in health systems,131,412
A data-driven process parameter selection approach to material extrusion of CFR-PEEK for energy consumption and dimensional accuracy," Material extrusion using carbon fiber-reinforced poly-ether-ether-ketone (CFR-PEEK) has received attention for industrial applications due to its superior mechanical and chemical performance. For the effective applications of CFR-PEEK in material extrusion, process parameters should be carefully determined by considering operational performance measures, which may be in trade-off relationships. This study aims to provide a data-driven decision making approach to process parameter selection that simultaneously considers energy consumption and dimensional accuracy in the material extrusion of CFR-PEEK. First of all, a full factorial design of experiments for material extrusion using CFR-PEEK is performed by varying major process parameters (i.e., layer thickness, infill density, and printing speed) to collect energy consumption and dimensional accuracy data from experimental samples. Then, prediction models for energy consumption and dimensional accuracy based on process parameter combinations are obtained by linear regression and extreme gradient boosting (XGBoost), respectively. Finally, non-dominated soring genetic algorithm II (NSGA-II) is applied to search for the best (pareto optimal) process parameter combination set under a bi-criteria decision making problem of minimization for predicted energy consumption and maximization for predicted dimensional accuracy. The results show that the trained prediction models can accurately predict energy consumption and dimensional accuracy. In addition, the NSGA-II approach shows pareto optimal process parameter combinations that the decision maker can flexibly select depending on relative importance between energy consumption and dimensional accuracy for the material extrusion of CFR-PEEK. The proposed approach provides a practical decision making process for process parameter selection to achieve effective additive manufacturing.",Poster Presentations,169,413
Predicting change success: the Six Batteries Framework in Corporate Transformation," This paper focuses on the validation of the 'Six Batteries of Change' framework, a model that aims to provide a clear, empirically-based approach to understanding change management. Amidst a landscape of often conflicting theories, this framework stands out for its simplicity and holistic view, correlating change drivers—categorized as energy gainers and drainers—with organizational change success. Whereas the foundational study for this model included data from 111 organizations, the core objective of this paper is to extend the validation of this framework within a large corporate entity. Over four years, data was collected from selected Business Units within this organization, focusing on their change capabilities. This study correlates the outcomes from the 'Six Batteries of Change' questionnaire with two critical measures: the success of change management initiatives and the performance of the Business Units. Key findings emerge from the analysis of both quantitative and qualitative data. First, the study provides insights into the effects of Covid-19 on the units evaluated in 2021. Second, it uncovers the benefits derived from focusing on cultural transformation within the organization. However, it also points to potential areas for improvement, particularly in enhancing rational change capabilities in the Business Units. The paper concludes by proposing future research avenues. These include further empirical testing to substantiate the initial hypotheses, thereby contributing to a deeper understanding and application of the 'Six Batteries of Change' model. This research contributes significantly to both academic and practical realms, offering a valuable tool for organizations navigating the complexities of change.",Problem Solving and Decision Making I,175,414
Design of a manufacturing system using the customer journey mapping method: Hybrid solar panel assembly(manual - automated - 5.0)," The customer journey mapping (CJM) method allows to visualize and structure manual assembly processes, as well as to evaluate the interactions, requirements and information needed in the assembly process. This article presents the results of the application of the CJM method to a real manual solar panel assembly case study. It identifies digital aids for manual assembly during the design phase of a manufacturing system. A total of four major tasks and 16 sub-tasks were identified from the assembly structure tree, and five scenarios were identified to establish the risk portrait. The HAZOP method was used to draw up a risk portrait, highlighting the potential problems associated with solar panel assembly, as well as the levels of risk and consequences for operators as they carry out their tasks. The application of the CJM method to resolve the potential challenges and risks encountered in the solar panel assembly case study enabled us to model customer and business needs and identify potential digital assistance systems that could be integrated into the manual solar panel assembly process. The present study shows that the CJM method can be adapted and used during the early manufacturing system design phases.",Smart Manufacturing and Design,207,415
Distributed scenario generation for stochastic power systems optimization problems," With the rise of renewable energy resources, quantifying and calibrating power systems' operational planning against uncertainties in supply and demand is becoming more critical. Stochastic optimization forms an important paradigm for uncertainty-led, data-driven operational decision-making in large-scale power systems. However, the inaccessibility of relevant data due to privacy or computational reasons could present a critical roadblock for solving stochastic optimization problems in energy. In this talk, we present distributed scenario-generation techniques that rely on variational auto-encoders. We demonstrate that variational autoencoders can be trained with siloed datasets belonging to different power systems stakeholders without the need to move data. Using open-sourced demand and renewable energy datasets such as wind and solar, we show that our method is able to capture the spatiotemporal interdependencies associated with such datasets distributed across multiple stakeholders.",Privacy and Security in Power Systems,173,416
An explainable machine learning approach to aid MDS-UPDRS Part III diagnosis using kinematic data of Parkinsonian gait," The Movement Disorder Society-sponsored revision of the Unified Parkinson's Disease Rating Scale (MDS-UPDRS) Part III is widely used to examine gait abnormalities in Parkinson's disease (PD). However, employing the MDS-UPDRS scheme for PD diagnosis requires significant time and effort, which impose physical and cognitive burdens during PD examinations. To tackle this challenge, this study proposes an explainable machine learning approach to automate PD diagnosis by predicting the total MDS-UPDRS Part III score based on a patient’s motion capture data during gait. First, MDS-UPDRS Part III examinations for 30 patients with early PD symptoms were performed by a neurologist. Next, gait experiments using a motion capture system were conducted to track the ankle, knee, and hip joint angles of the patients at each gait cycle. The obtained joint angle data were transformed into joint angle matrices for gait cycles to represent gait patterns based on ankle, knee, and hip joint movements. Then, a two-dimensional convolutional neural network (2D-CNN) model was trained using the joint angle matrices to estimate the total MDS-UPDRS Part III score. In addition, the gradient-weighted class activation mapping (Grad-CAM) method was employed to extract plausible gait characteristics for the obtained MDS-UPDRS score. The proposed approach not only accurately predicts the total MDS-UPDRS Part III score but also reveals that significant features for predicting the MDS-UPDRS score are linked to imbalanced and inconsistent gait patterns.",Machine learning in health systems,131,417
Musculoskeletal Injuries Among Healthcare Workers: A Call to Action to Design for Safe Patient Handling," Nonfatal occupational injuries among US healthcare workers have continued to increase. The Bureau of Labor Statistics reported 453, 200 compensable healthcare worker injuries in 2021 resulting in days away from work. These numbers surpass the magnitude of injuries in every other occupation, including manufacturing, construction, and service sectors. Furthermore, these injuries primarily impact the musculoskeletal system in healthcare workers. The most common load handling tasks leading to MSDs are transferring, lifting, and repositioning patients, usually performed in awkward postures. The healthcare professional cannot get too close to the patient, so extended reaches would be a risk factor. Unpredictable patient movements, uncooperative patients, and patient characteristics such as their physical and medical conditions also add to the risk of injury. Researchers have experimented with engineering and administrative interventions to reduce MSDs with varying degrees of success. The use of ceiling lifts, team lifts, air-assisted devices, and patient transferring devices reduce injuries. Training in safe handling and promoting a safety culture also help. But ongoing implementation of engineering and administrative interventions for patient handling remains challenging because of resource constraints such as a lack of equipment. In this work, we amplify NIOSH’s call for evaluating exoskeletons to reduce MSD risk during patient handling, and for conducting interventional research for addressing barriers to safe patient handling, and present a framework and a roadmap for evaluating and implementing exoskeletons for safe patient handling among healthcare workers.",Health Systems for Human Factors and Ergonomics 2,80,418
Occupational Exoskeletons: A Scientometric analysis," Non-fatal occupational musculoskeletal disorders in the United States have recently increased in many industrial sectors. According to the most recent survey of employer-reported nonfatal workplace injuries in the United States, the total reported injury cases increased by nearly 6.3% to 2.2 million in 2021, up from 2.1 million cases in 2020. Industrial exoskeletons have emerged as a promising solution to alleviate the injury problem and maintain worker productivity and safety. Market analysts predict that the exoskeleton market will reach $ 1.62 billion by year 2027. But there is a lack of knowledge on how exoskeletons can impact worker safety, productivity, and worker comfort in the long term, particularly because workers must wear them over prolonged periods of time to realize any benefits from these devices. Furthermore, exoskeletons are designed and built to be application-specific, so their effectiveness depends upon testing and evaluating them in diverse industries. Unless exoskeletons can be deeply integrated into work contexts, their full potential may not be realized. Worker training in donning and doffing devices and their acceptance of the technology based on usability and comfort pose implementation barriers. To fill this knowledge gap, we conducted a scientometric analysis of the industrial and occupational exoskeleton research domain. In this work, we present the temporal publication trends, authorship and collaboration networks, keyword and thematic analyses, citation network analyses and international network analyses for understanding the global nature of research in industrial and occupational exoskeletons.",Health Systems for Human Factors and Ergonomics 2,80,419
Estimating Propensity Score from Electronic Health Records using Deep Learning," Propensity score is the probability of an individual being assigned to study exposure or treatment given the observed covariates of the individual. Propensity score has played a central role in observational studies for accurate estimation of treatment effect. Despite the recent grow of available electronic health records (EHR) in observational studies, accurately estimating propensity score only using billing code records in EHR is often difficult. This is mainly due to the complicated data structure and incompleteness of the data. Previous studies employed machine learning and deep learning models to estimate propensity score for accurate treatment effect estimation using EHR. However, there has been a lack of research evaluating these models in settings where only billing code records are available. In this study, we assess the performance of deep learning models in accurately estimating propensity scores for treatment effect estimation using synthetic and semi-synthetic data. We specifically selected the two most commonly used deep learning architectures for sequential data: Long-Short Term Memory networks (LSTM) and stacked Transformer encoder (BERT). Our findings demonstrate the superior performance of deep learning models over shallow models, regardless of whether manual covariate selection is involved. This shows the utility of deep learning models in estimating accurate propensity scores for better treatment effect estimation.",Information and Digital Systems in Health,105,420
Design and Manufacture of Innovative Canine trochlear Groove Prosthesis Using Medical Images and 3D Printing Technology," Patello-femoral degenerative joint disease is a kind of chronic arthritis pathology frequently found in cats and dogs. Although it is often ignored, it is one of the most common conditions of canine osteoarthritis, such as patellar dislocation or degeneration and rupture of the cruciate ligament. When the patellar sulcus (groove) is severely affected and/or worn, one of the surgical treatments that attempt to restore the joint stability is the replacement by a trochlear sulcus (groove) prosthesis. The implants are generally made with conventional manufacturing techniques and in massive series with a standard designed according to the average patient. Problems during the surgery are recurrent since it requires the surgeon to adapt the clinical case to the available prosthesis. To overcome the complication associate with the traditional method, this study proposes the use of additive manufacturing technology. For this reason, it is also necessary to generate 3D anatomic model using medical images and its digital reconstruction technique associated with the customized prosthesis design for each specific clinical case. This technology brings some benefits such as in the cost and mainly in the surgery time, which suggests lower infections incidences, pain in the treated area, and other common problems post-surgery.",Bioprinting and Biomedical Manufacturing Processes-I,19,421
A Production System Analysis to Reduce the Cost of Non- Conformity in a Paper Bag Process using Six Sigma DMAIC Methodology," A systematic way of assessing and analyzing the process helps effectively identify the right problem that leads to establishing appropriate and cost-justified solutions to the root causes of the problem. The current study focuses on a local manufacturing firm that produces different paper bags commonly used for packaging consumer products. Other types of defects occur at each stage of the paper bag production. The study intends to meet the company’s allowable rejection rate of 1.00% for the entire production process and reduce the cost of non-conformity. The study applies a Six Sigma DMAIC approach which involves various tools and techniques such as Process Map, Non- conformity Analysis, Pareto Diagram, Fishbone Diagram, 5-Whys Analysis, FMEA, and Cost-Benefit Analysis. Based on the significant findings of the system analysis, the study generates alternative solutions to reduce the rate of defects in the production process. The results show a 27% reduction in defect rate, which may give the company significant annual savings from the cost of non-conformity.",Manufacturing Organizations I,139,422
Sustainable Practices in Aerospace: A Circular Economy Perspective," This study thoroughly examines the integration of circular economy principles in the aerospace manufacturing and aviation industry. Utilizing a robust research methodology, the study conducts a comprehensive analysis of scholarly articles on circular economy practices within aerospace manufacturing. Identifying key performance indicators (KPIs) is crucial, encompassing a mix of quantitative and qualitative data, ranging from customer metrics to environmental impact assessments. The analysis revolves around the meticulous definition, measurement, and alignment of KPIs with the 6Rs of the circular economy, classifying impacts as social, environmental, or economic. The foundational aspect addresses the dual challenge confronting the aviation industry—balancing environmental impact mitigation and operational efficiency amid escalating emissions. Furthermore, the study explores strategies employed by aerospace companies to address sustainability challenges, including considerations for material recycling in design, implementing component repair and reuse practices, and a commitment to ongoing research and innovation. Each company demonstrates a dedicated commitment to circular economy principles through active engagement in continuous improvement initiatives. Following an exhaustive exploration of these strategies, the study validates the efficacy of each strategy. This involves a meticulous examination to ascertain alignment with established KPIs. The outcome is articulated through the development of a decision matrix and a tiered system, categorizing companies based on their adherence to criteria and emphasizing the extent to which they embody and prioritize each KPI. The study concludes by providing final recommendations derived from the decision matrix, proposing a new circular economy approach for sustainable aerospace manufacturing and a resilient future for the aviation industry.",Closing the Loop: Advancements in Circular Economy and Responsible Production (SDG 12),26,423
Multi-objective Neural Architecture Search for Energy-Efficient Spiking Neural Networks," Spiking Neural Networks (SNNs) are gaining attention as an energy-efficient and more biologically plausible alternative to Artificial Neural Networks (ANNs). SNNs process asynchronous and sparse spike information, which reduces expensive operations and energy consumption. However, more suitable architectures for SNNs are yet to be discovered due to the inherent challenges of SNNs including the non-differentiable spiking dynamics. This has led to SNNs not yet achieving their full potential as manually searching for the best network architecture for a particular problem is a very difficult and time-consuming process. While Neural Architecture Search (NAS) techniques have been proposed to automate the search for network architectures for ANNs, few studies have explored NAS for SNNs. In this study, we propose a multi-objective NAS technique to automate the design of SNNs and identify the best architecture based on both accuracy and energy efficiency. The proposed technique searches for the best micro-level neural block, which includes the identification of relevant components to SNNs like connectivity patterns, and feed-forward and backward connections. We eliminate the need for network training during the search by scoring candidate architectures based on their predicted performance and spike activation patterns. The proposed technique is evaluated on different image classification benchmarks. Our results highlight the important role of architectural configurations on both the performance and number of generated spikes for SNNs. The insights from this work are expected to assist in the discovery of more effective and energy-efficient architectures for SNNs.",Deep Learning II,41,424
Giving Manufacturing Engineers the tools to catch and fix Ergonomics issues in 3D," The Case Study Paper describes the application of Dassault System's Ergonomic Workplace Design (EWD) app by a team of process engineers at the Alstom site in Barcelona. The app was tested through two half-day training sessions. Inside the app EWD, Ergo4all technology helps to anticipate ergonomic risks and detect them early in the design phase, mainly by non-ergonomists, specifically for process engineers. This solution was a significant improvement over previous methods, such as ergonomic assessment checklists and VR devices that were difficult to use and required high levels of expertise. However, the challenge for Alstom is to define how to deploy and utilize the EWD app through process engineers during the design phase. One of the difficulties is reconciling the capacity of the app with the added value of the ergonomics assessments concerning working situations that are currently unknown. Using this app allowed the team to assess ergonomic risks factors in an objective way, determining if there were any potential issues with product and process compatibility without any ergonomic issues. The ability to detect risks and evaluate design acceptability early in the design process greatly reduces project costs and cycle times, while increasing the ability to design safer and more efficient workspaces. By using Smart Posture Engine technology, included in EWD app, they were able to achieve repeatability, accuracy and objectivity during the ergonomic assessment process, and the ability to see the 4 anthropometric sizes of workers allowed them to cover all the assumptions during the assembly process.",Digital Manufacturing and Industry 4.0-II,46,425
Social determinants of health impacting informal caregivers and their work for Hispanic people with dementia: A work systems view.," According to the World Health Organization, more than 55 million people worldwide live with dementia. This number is expected to get worse with the aging of the baby Boomer generation. Dementia is the seventh leading cause of death, and a major cause of disability and dependence among adults. Because of this dependence, informal and unpaid caregivers such as family and friends perform the bulk of the care work, estimated to total 18 billion unpaid hours, valued at 340 billion dollars in 2022. The problem is worse among Hispanic adults – they are more than twice as likely than White adults to have dementia, a major health disparity. From a work systems analysis perspective, informal caregiving work from family and friends is a complex, multifaceted, multidimensional problem that cannot be reduced to only an analysis of the daily care tasks and outcomes. The caregiver and the cared-for are a dyad, and their successful interaction depends upon an understanding of social determinants of health such as availability of access to financial resources such as insurance, cultural practices in the community, the built environment and access to facilities, employer work policies, access to timely and credible information, and support from familial units, among others. Hispanic informal caregivers report greater care demands, less outside help and formal service use, and more depression. They also report poorer health and physical well-being. In this work, we present a work systems framework incorporating important social determinants of informal caregiving work for Hispanic adults with dementia.",Healthcare Work Systems,90,426
Reducing Waiting Time in Local Diagnostic Clinics: An Application of Queueing Theory," Long waiting time has been observed to be one of the problems that exist in the process of the different establishments – including in healthcare services. In the local diagnostic clinic that offers Laboratory Tests, X-rays, and ECG, a long queue of outpatients is observed. This also resulted in a long waiting time. Through the application of queuing theory, the study will help this kind of healthcare setting to analyze the waiting lines of outpatients. This study also shows the evaluation of the system of the local diagnostic clinic to find the bottlenecks that affect the waiting time of the outpatients. With the use of Arena Simulation Software (ASS), constraints in the system and specific system conditions were identified. Through analysis and interpretation of the results of ASS, the primary problem of having a long waiting time is also discussed in this study – the lack of number of stations and personnel in some services. With that, proposed recommendations are elucidated to solve the bottlenecks in reducing the waiting time of outpatients in the local diagnostic clinic.",Healthcare Work Systems,90,427
Optimization of the Measurement System for Variability Reduction and Process Improvement through Six Sigma," For Outokumpu, YIELD stands as the paramount indicator, quantifying process efficiency and organizational performance. Its purpose is to assess improvement opportunities and guide actions toward achieving maximum effectiveness, thereby fulfilling internal objectives. Interdepartmental collaboration and the promotion of a culture of change and innovation are fundamental commitments that involve all process areas. The project at hand aims to rectify the measurement system in a specific section of the material processing process through the Bright Annealing Line (BAL), responsible for executing the cut-offs at the beginning and end of the line. The implementation of the Six Sigma methodology aims to reduce the variability of cut meters, standardize the cutting process, and decrease cycle times. The baseline has been defined as the time span between January and October 2023. Through an analysis of information, scope, and costs, the intention is to establish ideal conditions for the new measurement system, seeking tangible benefits for the process line, enhancing performance, and consequently, increasing company profits. The information reveals a comprehensive and strategic approach to addressing identified challenges in the process. The combination of the Six Sigma methodology, interdepartmental collaboration, and a focus on organizational performance suggests a strong commitment to continuous improvement.",Advanced Topics of QCRE II,8,428
A closed-loop supply chain network design with different levels of production technologies," In recent years, the globalization of economic activity, coupled with the rapid growth of information technology, has resulted in shorter product lifecycles, reduced transport capacity, and dynamic changes in customer behaviors in terms of preferences and expectations. These factors have led to uncertain demand, highlighting the increased importance of supply chain design. Decisions regarding the design of the supply chain network are among the most critical in supply chain management, significantly influencing the efficiency and effectiveness of the chain for years to come. In this paper, a two-objective mixed-integer linear programming model (MILP) is developed to design and optimize a closed-loop green supply chain network. The model incorporates real-world assumptions, including a multi-level supply chain, a variety of production technologies, and multiple transportation modes, aiming to minimize both the total cost of the chain (first objective) and the total emissions (second objective).To validate and address the problem as a single-objective, the precise ε-constraint method and the CPLEX Solver are employed. Finally, through sensitivity analysis, the study explores the behavior of objective functions in response to changes in real-world parameters. Optimal management suggestions and policies are then presented, offering practical insights for businesses and policymakers seeking to enhance the efficiency and sustainability of their supply chain networks.",Supply chain design 2,222,429
Simulations of Annual Medical Payments and CMS Reimbursements," In the United States healthcare system, the Centers for Medicare and Medicaid Services (CMS) administers the Medicare health insurance program. Within this program, insurers form risk-bearing contracts with physician practices. In the past, many physician practices failed financially under these types of contracts. Research is needed to investigate the financial rewards and risks between physician practices and insurance companies. In this study, we evaluate three methods to simulate annual medical payments and CMS reimbursements. This is an integral step to simulate the financial results of risk-bearing contracts. We evaluate three simulation methods to simulate annual medical payments: cumulative empirical distributions of annual medical payments, theoretical probability distributions of annual medical payments, and simulating individual patient visits then simulating the cost for each visit. We perform these analyses for both traditional Medicare patients and Medicare Advantage patients. For this analysis, we use the annual insurance records of one million Medicare patients in the state of Missouri. The data contains medical visit details for both traditional Medicare and Medicare Advantage patients. We present tradeoffs between the different approaches and present methods to evaluate the accuracy and variation generated by each approach.",Simulation Models in Health Systems,206,430
Circular economy-based closed-loop supply chain for sustainable winter road maintenance: A case study in Trois Rivières," This research addresses the environmental challenges posed by the disposal of winter road abrasives in regions with severe winters, such as Quebec. Road authorities apply abrasives like sand and crushed stones for safety during winter, leading to the collection of residual materials known as street sweeps in spring. Currently, a significant portion of these sweeps is disposed of through burial, prompting the need for a sustainable solution. The study focuses on a closed-loop supply chain (CLSC) model for abrasive management, introducing the concept of the circular economy to evolve residual materials. Two main actors, the Trois Rivières municipality and the Québec Ministry of Transportation, play the roles of both suppliers and customers. They contribute to a recycling center where the sweeps are processed, reusable abrasives are separated, and applied to producing recycled abrasive. A Mixed-Integer Linear Programming (MILP) model is developed for CLSC optimization. The model considers key components including quarries supplying sand and crushed stones, a winter maintenance center for mixing and storage, a customer zone offering a free market, road abrasive spreading, and road infrastructure construction/repair. The recycling center employs sorting and mixing processes, directing the recycled abrasives to either the winter maintenance center or landfill. This research emphasizes the potential of the CLSC model to not only reduce operational costs but also provide environmental advantages by diverting materials away from landfills. The MILP model serves as a strategic tool for optimizing the entire process, contributing to a more sustainable approach in winter road maintenance practices.","Smart and Sustainable Maintenance: Machine Learning, Blockchain and Circular Economy Approaches",208,431
Task-aware Privacy-preserving Dataset Valuation for Dataset Exchange in Manufacturing Industrial Internet," A Manufacturing Industrial Internet (MII) enables the collection of high-speed and large-volume data for manufacturing systems and thus, advances the data-driven decision by artificial intelligence (AI) methods. However, it takes a long time and intensive efforts for a single manufacturing entity to collect sufficient data from rich modalities in the manufacturing process to support the incubation of advanced AI models such as deep neural networks. Additionally, the discrepancies between the design feasibility and manufacturability may lead to suboptimal designs or manufacturing process settings by the AI models due to the lack of shared information from both design and manufacturing phases. Hence, it is important to valuate the dataset to enable the effective exchange between trusted partners (i.e., manufacturers in similar processes, designers and manufacturers) in MII such that high-quality datasets with complementary information can be shared to improve the target AI task. Existing approaches on data valuation focus on valuating each sample based on the marginal contribution coupled with the training and testing of one learning task, which renders them inflexible for different input modalities, tasks, and datasets. To address this, we propose a dataset valuation framework which distills meta data for both the raw datasets and the target tasks by attention-based generative model under privacy constraints and integrates both information with their correlation to enable effective estimation of the value by a Graph Neural Network. The effectiveness of the work is validated by a case study in the design and manufacturing network of Microbial Fuel Cell (MFC) anodes.",Cybersecurity in Manufacturing,35,432
Privacy-preserving information sharing among competing suppliers," Information sharing among suppliers can enable effective response in the face of demand fluctuations, major disruptions, and disasters. Manufacturers, distributors, suppliers, and retailers can share information about their inventory levels, production capacity, sales, demand forecasts and other supply statistics to have a more informed way to evaluate the current market status and make supply decisions, such as investing in more capacity, building up inventory, or contracting new providers. However, competition over a limited, shared demand and privacy concerns pose significant barriers to information exchange. We propose new methods for competing and privacy-aware suppliers to share their information with each other to collectively improve their responses in the face of disruption and demand fluctuations. Differential privacy helps us to not only satisfy the privacy requirements of individual sellers but also alleviate information asymmetries and competitive concerns that prevent information exchange in game-theoretic equilibria. Our results address the variety of tradeoffs that arise in the design of information exchange mechanisms with privacy guarantees for the participants. These include the choice of local or central privacy protection, as well as centralized or decentralized information aggregation, with implications on privacy, trust, communication complexity, accuracy, and decision quality.","Privacy, security, and resilience",174,433
Thermal Simulation for Metal Additive Manufacturing: Traditional Numerical Simulations vs Physics-informed Neural Networks," The use of additive manufacturing a.k.a. 3D printing is ubiquitous due to its flexibility of producing novel designs. Despite the extensive advantages, there are several limitations in qualifying an additively manufactured component, particularly while using metals for critical applications. The quality of a component depends excessively on the thermal history of the build. An ideal thermal history results in the desired microstructure that determines the bulk properties of the concerned part, typically known by the process-structure-property relationships. To determine the ideal thermal history for the required properties, numerical simulations are typically used for visualizing and analyzing thermal behavior to optimize the process parameters. Traditional numerical simulations, like Finite Element Methods (FEM), solve Partial Differential Equations (PDEs) through a discretization procedure well known as meshing. Meshing, apart from being expensive for complex geometries, limits the modeling capabilities to a few types of process conditions. Physics-informed Neural Networks are numerical methods that forgo the meshing procedure to solve a PDE system with typically a simple fully connected neural network. Recent advancements in PINNs provide a robust way to model thermal history for metal additive manufacturing processes. This work provides a comprehensive comparison between the traditional numerical simulations and the PINNs for thermal modeling in metal additive manufacturing. In addition to being faster in certain cases, the PINNs can embed process conditions, like a highly non-stationary laser power in a Laser Powder bed Fusion (shown in the figure), that are traditionally impossible to model with numerical simulations.",Advanced Topics in Smart Manufacturing I,4,434
Assessing Safety Programs and Strategies to Prevent of Heavy Equipment Struck-by Incidents in Construction.," The co-existence of human operators and machines at the construction site requires a sufficient balance between achieving desired productivity and ensuring worker safety. The U.S. Bureau of Labor Statistics (BLS) data indicates an average of 200 annual fatalities caused by non-transport-powered vehicle strikes for the year for the past ten years. While advancements in sensing technologies, such as wearable sensors, Internet of Things (IoT), artificial intelligence, and virtual/augmented/mixed reality, allow us to facilitate remote control or enhanced training programs, a significant reduction in serious injuries and fatalities remains unrealized. This study conducts a systematic review of the key safety elements or pillars that provide a robust framework for integrating technology. These foundational elements for preventing struck-by incidents encompass OSHA regulations, compliance-based and augmented safety programs, optimum man-machine ergonomics, cultural considerations, effective organizational and multi-employer worksite structures, and adaptation to environmental conditions. The findings of this study will contribute to providing safety professionals and researchers with a foundational knowledge of struck-by safety practices, crucial for the effective deployment of new technologies and innovations. Subsequently, a targeted survey among construction managers will be conducted to collate further data on the prevalence and needs of current struck-by safety programs, thereby identifying areas where technological enhancements are most required.",Public Health,183,435
Prototype of a bidirectional digital twin for an industry 4.0 smart manufacturing facility," We present a prototype Digital Twin environment that can be used for scalable remote training for Industry 4.0 smart manufacturing (I4.0SM). In the I4.0SM realm, a major research challenge is the paradigm of bi-directional digital twins (BiDDT). The BiDDT establishes an interactive bridge between the physical and virtual domains. The categorization of digital twin concepts into models, shadows, and twins serves as a foundational framework, with an emphasis on the facilitation of bidirectional communication. The objective is to amplify training efficacy by introducing a real-time feedback between the physical and virtual domains. This innovation enables assessments of user interactions and adaptive teaching methodologies, and facilitates proactive instruction and error correction. The amalgamation of a true-to-life virtual model, developed in Unity physics engine, a physical setup comprising integral components such as feeder mechanism, vacuum suction arm, and horizontal traversing piston, forms the basis of the proposed system. The integration of Siemens TIA portal, a digitalized automation service simulating a PLC, enables the digital model to mirror the functionality of its physical counterpart. This integration allows the digital model to operate analogously to a physical system with a real PLC. To resolve interoperability hurdles, the research adopts the Open Platform Configuration Unified Architecture (OPC-UA), ensuring seamless communication between disparate systems. The capture of a digital shadow, realized through OPC-UA, synchronizes the physical and virtual systems in near real-time, encapsulating the essence of bidirectional communication. This comprehensive approach demonstrates the potential of BiDDT in industrial training and envisions transformative applications in smart manufacturing.",Digital Manufacturing and Industry 4.0-II,46,436
Identification and Categorization of Building Damage using GPT-4 Vision," Quickly and accurately identifying and categorizing building damage through crowd-sourced photographs offers vital insight into the aftermath of natural disasters. It offers crucial information for emergency response teams, allowing them to prioritize their efforts by allocating resources more effectively and responding to the most urgent cases first. Additionally, these images provide valuable data for engineers and urban planners to analyze the causes of damage and improve building standards and urban planning to mitigate future risks. Recent developments in GPT-4 now allow for multimodal analysis, combining image analysis with human language to allow images to not only be labeled, but also providing detailed description and analysis of the image. This work harnesses GPT-4 with Vision to identify damaged buildings, and categorize them according to types or levels of damage.",Resilience in Construction,192,437
Planning Decentralized Electricity Systems under Uncertain Central Grid Conditions," Electricity is forecasted to play a leading role in the final energy consumption of the future. Yet, many developing countries suffer from limited access to electricity and poor reliability of fragmented national grid infrastructure. In this context, a large body of research has investigated the development and optimization of household-level and microgrid off-grid and on-grid systems powered by a combination of various renewable and non-renewable electricity generation sources. Yet, from the perspective of the households and communities without access to a reliable central grid, investments in decentralized solutions happen under one major uncertainty: (i) Will the reliable central grid become available at any point in time; and if so, when will that happen? To complete the picture, two secondary uncertainties follow the first one necessarily: if the reliable central grid becomes available, what will be (ii) the price of the centralized electricity, and (iii) the feed-in tariff for purchasing the renewable electricity that is generated by decentralized agents? We develop an optimization-based decision analysis framework that addresses the decision context that such households and communities face while considering these three important uncertainties. We illustrate our methodology by applying it to a case from Lebanon: a country that witnessed a quick drop in the centralized electricity generation due to the ongoing economic crisis and the development of various distributed improvised solutions at household and community levels. We discuss practical and policy implications that are relevant to Lebanon and to other similar developing countries.",Privacy and Security in Power Systems,173,438
Eliciting and integrating a broader range of information from human subject matter experts into optimization models," This work explores the opportunities and challenges associated with creating human-in-the-loop methods to synergistically combine the strengths of a human subject matter expert with the strengths of two-stage stochastic mixed integer linear programs. The goal is to create higher fidelity models that reduce the so-called “reality gap” and can recommend design solutions with a higher chance of implementation. While there is rich literature on interactive optimization approaches, most focus on eliciting an extremely narrow range of human knowledge, typically in the context of refining preference weights across multiple objectives. In contrast, formal methods of statistical expert elicitation have been successfully deployed to elicit a wide range of human knowledge and their uncertainty in these estimates. Yet, such approaches have not been integrated into optimization models. In this work we compare and contrast these two fields of literature and explore the opportunities and challenges associated with eliciting a broader range of information from the human user and integrating it into optimization models.",Policy-driven Decision Making,168,439
Development of a Structured Approach to Teaching Inventory Models," Inventory Analysis and Modeling is an important prerequisite knowledge for many other IE courses. Inventory models are usually presented to students in a production analysis/modeling course from deterministic to more complicated stochastic models, and build on the skills and concepts from previous simpler models. Based on course assessments from the past few years, once all models were covered, students have difficulty selecting the correct model and understanding the inputs needed to build the correct inventory model for a given situation. To bridge this gap, an overarching framework on how to build inventory models is needed. In this paper, we have developed a structured approach that presents a framework for presenting the concepts on inventory models such that students gain a systemic view of the models – the eventual goal being better retention and proper use of these models by IE students.",Innovations in Teaching and Learning Technologies,109,440
A Framework for a Short-Term Client-based International Systems Practicum," The need for globally competent practitioners able to take a systems approach to problem solving on interdisciplinary teams is well established. The most pressing problems of today span both national and disciplinary boundaries. To address this need, we created a faculty-led, short-term international practicum where students work on interdisciplinary teams to apply a systems approach to client problems. Two principles form the framework for this program. Principle 1 is to focus fully on delivering impactful, actionable results to clients. This is in contrast to traditional classes as the evaluator of quality is the client, not the instructor. The rationale supporting Principle 1 is that authentic work better engages students. Principle 2 is to prioritize depth over breadth. The programs stay in one city. Each team works on one client project. This is in contrast to short-term study abroad programs that serve students a sampler platter of experiences, going on different excursions every day. The reasoning behind Principle 2 is that this depth allows students to form relationships and experience cultural context more richly. Over 550 students have worked on over 100 projects for nearly 50 unique clients in three countries since the first program in 2009. Evaluation data shows that students see the client experience as central to their cultural and professional experience, that the authentic nature of the projects makes students feel like their work is truly valued, and that the experience measurably deepens students’ cultural knowledge despite the short program length.",Engineering Identity & Global Engineering Education,68,441
A Simulation Approach for Assessing Energy Efficiency in Unmanned Aerial Vehicle (UAV) Last-mile Delivery Systems," Undoubtedly, last-mile delivery is the most time-consuming and expensive component of any supply chain. The growing cost of fossil fuel and the need to decrease the carbon footprint left by traditional last-mile delivery methods motivate companies to look for new technologies. One solution that is becoming increasingly popular in literature is the use of unmanned aerial vehicles (UAVs) or drones. However, determining if drones are more energy-efficient than traditional last-mile delivery methods can be difficult and depends on many factors. In this study, we develop a simulation model to determine the energy consumption of last-mile delivery using drones. The objective of the model is to minimize energy consumption while fulfilling all orders from a single fulfillment center within a reasonable set of time to determine the most energy-efficient delivery method for each customer. The model considers multiple direct delivery methods, including drones, trucks, and drones during specified weather conditions. The results of the simulation model provide logistical support to minimize regional energy consumption from a single fulfillment center as well as provide projected required quantities of delivery vehicles.",Poster Presentations,169,442
AI-Assisted Acceleration of Catalytic Materials Design/Discovery: Towards achieving zero emissions," The discovery of innovative materials holds high potential for societal and technological advancement. In this context, the discovery of novel catalysts emerges as a prioritized need within many industrial applications to expedite the adoption of renewable energy sources, thereby contributing to mitigating global warming. Exploring the whole chemical space for potential catalysts is computationally challenging. In addition, the design of a catalyst involves a highly interdisciplinary technology that requires simultaneous control and understanding of many interacting and conflicting design variables. The key limitation of traditional trial-and-error methods lies in their inefficiency and time-consuming nature, while computational quantum mechanical modeling methods incur substantial computational costs. An increasingly important domain involves the adoption of Artificial Intelligence (AI) and its related generative Machine Learning (ML) technologies as a groundbreaking paradigm in materials science research. This paradigm aims to facilitate the efficient exploration of material relevance space, to enhance knowledge about materials, to understand material properties and to accelerate the material discovery process through parallel, automated and iterative procedures. This review paper conducts a comprehensive analysis of ML-driven catalyst design research, explores the applications and approaches within this field and describes how these new capabilities facilitate the acceleration and enhancement of each stage in the discovery cycle. The paper also delves into the main challenges in AI-based material design/discovery and gives some recommendations for future research directions.",Unique directions in Energy Research,234,443
Minimizing Uncovered Triples in College Football Conference Scheduling," Collegiate football teams often compete in groups of 8-20 teams known as conferences. One such conference, the Atlantic Coastal Conference (ACC), is adding three new schools this coming season bringing their total to 17 total teams. Currently, each ACC team plays eight games against others within the ACC. At the season’s conclusion, the two ACC teams with the best intraconference record compete in a conference championship game. With 17 total teams each playing eight games, the ACC could have a three-way tie for the best record where none of top the three teams play one another. To avoid this situation, we introduce the Minimizing Uncovered Triples (MUT) problem, in which we build a conference schedule for all teams that minimizes the number of uncovered triples in which none of the three teams in the triple play one another. To solve the MUT, we present two mixed-integer programs (MIPs). The first MIP is a straightforward approach the determines each team’s opponents individually while the second MIP is a clique-based approach that forms groups of teams as cliques and determines games between teams within separate cliques. We first explore the computational efficacy of each approach for the 17-team and 8-game conference scenario and extend our models to larger examples with more teams and games.",Planning and Scheduling,165,444
A Bibliometric Analysis of Power System Resilience and Recovery Subject to Extreme Events.," Research on power system failures and recovery after high-impact low-probability (HILP) events, like hurricanes, has become more prominent recently. Better understanding these complexities is crucial due to the pivotal role power systems play in modern society. This study aims to comprehensively explore existing approaches to identify interconnections, and create building blocks for addressing existing gaps and enhancing societal quality of life. The methodology includes (1) Aggregating recent pertinent research. (2) Categorizing collected research by subheads including author names, publication sources, and recovery-based keywords. (3) Analysing and visualizing segmented research and data clusters using VOSViewer, illustrating the relationship strength among subheads. (4) Identifying novel research directions based on these observed interconnections and gaps. By uncovering deeper insights into power system recovery and gaps, this study will contribute to heightened situational awareness among stakeholders, facilitating better-informed decision-making related to the construction and management of power systems in the face of future HILPs.",Resilience and State Estimation,191,445
Development and Application of A Systems Engineering Framework and Tools to Model Food Insecurity," As systems, technology and design become more complex, systems engineering design and modeling principles, tools and methods become more important. This study provides a framework for applying systems engineering tools and methods. The framework illustrates the systems engineering models, activities, tools and principles that integrate knowledge across the framework. There are three dimensions of integration in the framework models, between phases of the life cycle, between levels of detail, and integration between elements within the system. The presentation will include an application modeling food insecurity across multiple concepts that were designed to reduce food insecurity. This presentation will give the participants an appreciation of how difficult it can be to understand these concepts and to apply them to a real-world problem in community service environments. The model used the Vee life cycle model phases to demonstrate how critical systems engineering tools were applied in each phase as well as the connectivity and integration of the information derived through application of each tool.",Systems Engineering & Life Cycle Management I,225,446
Community Ergonomics 4.0: A vision for a new engagement with ergonomics in the community," This paper presents a vision for a reconsideration of community ergonomics considering advances in information technology to examine the Community-Environment fit to support diversity, equity, and inclusion. Community Ergonomics (CE) emerged in the late 1990’s from an educational quality problem [1]. Solutions were proposed including human factors and ergonomic (HFE) approaches to community-based assessments and contexts to address problems present in urban educational environments. Existing theories in HFE were considered alongside Behavioral Cybernetics, which is the assessing of situations and finding solutions at a macroergononic level [2], [3], [4]. There was an increasing engagement of sociotechnical theories with specific case studies of communities [5], [6], which led to additional principles with more contextual relevance [7], [8]. The integration of macroergonomic concepts and CE is proposed here to help educators deliver quality services to support the educational system and its impact on work in STEM fields [9], [10], [11]. This paper offers a vision of a conceptual framework, bolstered by empirical evidence, for two conclusions: (1) the overreliance on big data fails to capture the expertise and nuisances of inclusive educational environments; and (2) a systems approach of learning environments is required to support student engagement. The paper showcases recommendations for closer integration between school system operations and the surrounding community, with a goal of upgrading community design conditions to improve student learning performance. This work is critical to help education policy experts address these dire outcomes which are often independent of socio-economic class, education levels and even residential zip codes.",Work systems and services for Human Factors and Ergonomics,242,447
Predicting Management Skills of Undergraduate Students by Leveraging Different Machine Learning Classifiers," In today's dynamic and competitive environment, the need for effective management skills among engineering undergraduate students is pivotal for their success in various professional domains. These skills lay the groundwork for future leadership roles in various professional settings. Whether in business, healthcare, education, or technology, the ability to manage oneself, teams, projects, and resources efficiently is fundamental for career advancement. Moreover, possessing strong management skills fosters effective decision-making, problem-solving, and communication abilities, which are highly sought-after qualities in today's competitive job market. The objective is to leverage machine learning techniques to analyze data sets encompassing six underlying dimensions of management skills namely management planning and control, risk management, configuration management, decision management, project management, quality management, and information management to build predictive models. These models aim to assess and forecast the potential management capabilities of undergraduate students. This study will utilize four popular machine learning algorithms: Logistic Regression, Random Forest, K-Nearest Neighbors, and Naïve Bayes to develop a model based on a set of predictors, tune and cross-validate them, and select the best model that can accurately predict effective management skills of engineering undergraduate students. The proposed models will provide trustworthy and precise forecasts and will empower engineering students to navigate complexities, adapt to changes, and lead initiatives, contributing to their personal and professional growth.",Leadership and Teamwork Development in Engineering Education,119,448
On the Dynamics of Stochastic Multiplicative Weights," In this talk, we study the dynamics of online optimization in multiagent systems. Specifically, this talk focuses on the stochastic multiplicative weight update rule in the setting of network zero-sum games. We show that when using fixed step-sizes, that this systems forms an irreducible Markov chain where all steady state distributions correspond to a mixture of extreme points. Further, using theory developed by Feller, we show that this systems converges to a state where all agents play pure strategies with probability 1 in the limit. Finally, we show that that this divergence guarantee actually is sufficient to prove fast time-average convergence when using fixed learning rates -- a result that was previously believed to be impossible. This result emphasizes that an understanding of the dynamics of optimization provides stronger understanding that what is typically gained through standard approaches that rely on regret or contraction maps.",Algorithmic Approaches,15,449
Challenges and Innovations in Healthcare Fraud and Waste Detection Systems: A Systematic Review and Proposed Framework," Fraud and abuse in the healthcare sector cause considerable financial losses to public and private entities. This article carried out a systematic literature review intending to identify fraud and waste detection systems challenges. Furthermore, it sought to understand how these identified challenges are being addressed. Healthcare fraud and waste detection systems require constant efforts and evolution as they face challenges related to the significant increase in data volume. The challenges identified are dimensionality reduction, conceptual deviation due to changes in fraudsters' behaviors to circumvent audit systems, and support for real-time detection. Approaches that used unsupervised techniques to detect fraud and waste in healthcare were defined. Ten articles were identified in the review that covered the IEEE, PubMed, Scopus and Web of Science bases in the period from 2018 to 2023. We classify the studies according to the challenges and techniques used. Only one work used dimensionality reduction techniques. Usually, the works use datasets with reduced dimensions and already pre-processed to test the algorithms. Two articles present proposals for concept deviation, and no real-time detection approaches were identified. Recent advances point to innovative techniques, but testing on real databases is needed. We have proposed a framework to direct techniques according to the problem. The main gap identified refers to using unsupervised techniques for real-time evaluation.",Healthcare III,85,450
Rewriting capstone: The unexpected solution to our assessment problem," We describe an effort to improve communication and assessment of student learning in an undergraduate IE capstone course. Student teams work on real client-driven unstructured problems that often require Non-Disclosure Agreements (NDAs). Because instructors neither sign NDAs nor attend client meetings, students must communicate the problem, analysis, and solution to instructors sufficiently to allow them to evaluate course learning outcomes. In response to assessment challenges, several changes were made to the curriculum over a four-year period, including development of a comprehensive course guide, updated rubrics, project charter discussions, teamwork assessments, and structured midterm reviews. Despite these changes, assessment of student learning outcomes remained elusive as most of their analysis and understanding was conveyed through written deliverables. For teams that struggled with written communication, we could never quite understand their work, let alone whether they were doing it well. In 2023, a writing instructor was integrated into the class to help students better communicate their understanding of the problem, methods, and solutions. The contribution of the writing instructor has addressed several of the communication challenges that other innovations were attempting to solve. Moreover, and to our surprise, our assessment issues began to improve. Preliminary results indicate that student communication of the problem and solution to a wider audience has improved, both in written assignments and in final presentations. We present these early results as well as feedback from former students. We also describe a revised instructional model that incorporates writing and communication into the capstone course, along with future evaluation plans.",Engineering Education Pedagogy and Assessment,67,451
Improving wisdom of crowd effects on ordering tasks by eliciting and aggregating multiple modalities of estimates," We present a wisdom of crowds study where participants are asked to order a subset of images based on a quantifiable characteristic (e.g., by increasing number of dots) and then to submit numerical estimates of said quantity on each image from the set. The two input modalities are then aggregated via optimization and voting-rule based methods to estimate the true ordering of a larger universal set of images. We tested two input elicitation interfaces --- one elicits the two types of estimates jointly and the other separately. We show that the latter interface yields higher quality estimates, although the multimodal estimates tend to be more self-contradictory. We also show that improved crowd wisdom from aggregating multiple modalities of estimates is attainable with a variety of computationally-efficient methods. Lastly, we find that using the coupled modalities from each participant results in better estimates from smaller groups compared to mixing numerical estimates from one group with the ordinal estimates from a different group.",Social Media & Information Analytics,210,452
System-Based Methodology for Accurate Problem Definition," The implementation of Lean philosophy is a practice that has become more intense over the recent decades. Through this practice, it is envisioned to solve problems in order to reduce waste and, in general, optimize process or system operations. Despite its widespread use, Lean implementation often falls short of expected outcomes. A significant contributing factor to these shortcomings is the lack of clarity in the problem definition step. This challenge is not unique to Lean; it also impacts the Six Sigma methodology, which is a globally used data-driven approach for process improvement through defect reduction. This paper proposes alternate innovative methodology for accurately defining problem, aiming to enhance the input integrity of critical problem-solving processes. It introduces the Sawhney Model as an effective system-based approach to improve the formulation of problem definition for Lean and Six Sigma implementations. The model relies on the modularity of steps and reliability of the process. Concepts of process variation, disruption, and flow are integrated to identify uncertainty levels inherent in processes and systems. The proposed method is applied to define a problem in a manufacturing system through a case study. from the Sawhney model, traditional Lean, and the Six Sigma methodology provides valuable insights. Based on this, the comparison between the solutions yielded by the Sawhney model, traditional Lean and the six sigma methodology will be provided.",Continuous Improvement Tools and Methodologies I,33,453
A protocol to create an anthropometric database applicable to any population," Anthropometric data are used for a range of applications, from product design for customers to layout and tool design for workers. Anthropometric dimensions are integral in developing digital human models. Population-specific and updated anthropometric databases can reduce errors associated with biomechanical modeling. Unfortunately, data collection methods to create anthropometric databases are different across sources. Despite the existence of the International Organization for Standardization and the International Society for the Advancement of Kinanthropometry, many databases neither followed guidelines and nor represented the population diversity. Through a literature review, we create an anthropometric database protocol that includes stages before, during and after data acquisition. This protocol starts with the description of factors that should be considered, namely age, sex/gender, ethnicity, geographical location, and occupation. This protocol covers sample size calculation and recruitment strategies. Afterwards, the equipment for manual measurements and 3D/4D scanners as well as the layout and personnel are detailed. The description of the measurements and how to take them are also thoroughly explained to maintain a high accuracy and consistency. As a final step, we discuss data storage, processing, and presentation recommendations. Ethical considerations are embedded in all the steps. This protocol consolidates the ideas from standards and common practices in different empirical studies, facilitating the construction of an anthropometric database of a specific population. The recommendations are to ensure the representativeness of the sample, an adequate sample size, best practices on equipment and procedures, standard reporting using tables to describe the 5th, 50th and 95th percentiles, and ethical considerations.",Physical Ergonomics,164,454
3D Anomaly Detection for Complex Manufacturing Parts with Single Sample," The surface quality inspection of manufacturing parts based on 3D point cloud data has attracted increasing attention in recent years. The reason is that the 3D point cloud can capture the entire surface of manufacturing parts, unlike the previous practices that focus on some key product characteristics. However, achieving accurate 3D anomaly detection is a challenging task, due to the complex surfaces of manufacturing parts and the difficulty to collect sufficient anomaly samples. To address these challenges, we propose a novel anomaly detection method based on 3D point cloud data for complex manufacturing parts, which can achieve accurate anomaly detection in a single sample. In the proposed framework, we transform the input sample into multiple similar row profiles and devise a new column profile-based segmentation module, to enable the complex sample to be simple components, which can be modeled as low-rank matrices mathematically. Furthermore, accurate 3D anomaly detection can be achieved by using robust principal component analysis (RPCA) on these low-rank matrices. Extensive numerical experiments on different types of parts show that our method achieves promising results compared with the competitors.",Process Monitoring and Anomaly Detection,179,455
Fusing Natural Language Processing and Econometrics: Predicting Federal Funds Rates," With recent economic situations being turbulent, it becomes harder for businesses and investors to gauge their prospects and predict the direction of the economy. Traditional econometrics methods can come up short in predicting various changes brought on by policy or news. This research proposes a predictive model for federal funds rate by integrating sentiment analysis from Federal Open Market Committee (FOMC) minutes with quantitative economic factors. We specifically consider FOMC minutes, as potential news or policy affecting our target can be captured by the former. This reduces the number of qualitative factors we take into consideration. The study utilizes Natural Language Processing (NLP) techniques and Large Language Models (LLM) to extract sentiment from the textual content of FOMC minutes. We will look at a mix between aspect and sentence sentiment to generate metrics to embed them with other factors. It combines qualitative data with quantitative economic indicators, such as existing federal funds rates, inflation, unemployment rates, GDP growth, and stock market trends, to construct a predictive framework. The model’s performance, based on machine learning algorithms, will be back tested with historical federal funds rate. We expect this hybrid model to demonstrate a more accurate prediction as compared to models using quantitative or sentiment data in isolation. Sentiment analysis could add depth to the understanding of the FOMC’s outlook and decision-making process, which, when aligned with economic indicators, provides a more nuanced forecast of federal fund rate movements.",Technology and Digital Economy,230,456
Applying Bayesian Network to Determine Causes of Delayed Graduation: The Graduate On-Time Analysis and Lessons (GOAL) Model," : Four-year graduation rate is a measure of higher education success in general, and at Virginia Tech (VT), it is a Key Performance Indicator aligning with strategic plan objectives. At VT, the 4-year graduation rate for all students was 68.9% in 2023, with a goal of 73% by 2028. This metric is particularly important for underrepresented minorities (URM) and underserved students (USS) whose rates are lower, at 62% and 65% respectively. Additionally, VT is aiming for at least 40% of the students entering class through 2028 to be from URM and USS, increasing the difficulty in achieving the 4-year graduation rate goal. Therefore, the long-term aim of this project is to improve the 4-year graduation rate through data analysis and machine learning to identify potential causes of delays to graduation. At this stage, we developed the GOAL model, which is a Bayesian Network that incorporates student data on courses and other academic decisions. We combine structure learning, domain expert knowledge, and interviews with students to construct the Bayesian Network. Our initial target student population is the undergraduate students of the Grado’s Department of Industrial and Systems Engineering at VT. Future directions include expanding the model to capture a broader range of student experiences or expanding to other programs; potential use cases are to support departmental, college, and university leadership in improving student retention and graduation.",Operations Research and Modeling in Education,153,457
MOLECULAR CHARACTERIZATION OF HUMAN INDUCED PLURIPOTENT STEM CELL DIFFERENTIATION INTO CARDIOMYOCYTES," Heart diseases are the most common and leading cause of death with approximately 19.05 million deaths globally in 2020. Although heart disease is treatable, it cannot be permanently cured. Therefore, researchers have studied heart disease for years in search of a permanent cure, and in 2007 Human Induced Pluripotent Stem Cells (hiPSCs) were discovered by Shinya Yamanaka showcasing promising results in regenerative medicine in particularly for the generation of cardiomyocytes due to its non-human-rejection, simplicity, and reproducibility. These hiPSCs are derived from skin or blood cells reprogrammed back into a pluripotent state, allowing them to develop into any type of human cell needed for therapeutic purposes. Many studies have been performed to understand the mechanisms and attributes required to ensure the mature differentiation of these cells into cardiomyocytes to be used as a regenerative tissue therapy. Still, there is a need to better characterize these cells to monitor their effectiveness for approval. Hence, we aim to extract genomic differences between undifferentiated and differentiated hiPSCs and provide a comparable framework to model cardiomyocytes using publicly available genomic datasets. Differentially expressed genes (DEG) across different time points of the cell differentiation process were extracted using an empirical Bayes approach. Then these DEGs were compared with a landmark of expression profiles modelling normal heart tissues from two donors. The intersection of features between these two sets resulted in a list with putative markers of cardiomyocyte differentiation revealing enriched pathways such as adrenergic signaling known to be highly active in cardiac cells.",Healthcare III,85,458
A Comprehensive Leadership Development and Assessment System for Engineering Students," In this paper, we describe the development, testing, and scaling of a leadership development program specifically designed for engineering students. Program design, content, and process are described. The program combines a system thinking approach, visual models, and principle-based leadership to grow leaders and systems thinking ability concurrently. The program has been tested in small group cohorts, an engineering undergraduate program, and a college-wide co-curricular offering. A process for training faculty is described. The program layers development in learning, practice, and mastery levels similar to Six Sigma programs. Techniques for student retention and assessment are detailed at each level. The program is organized to allow student leaders to perform program assessment, improvement and sustainment. Program expansion to faculty and staff is described in order to facilitate college-wide leadership culture.",Leadership and Teamwork Development in Engineering Education,119,459
Enhancing Microgreen Supply Chain Efficiency Using Discrete Event Simulation," Microgreens are an emerging specialty food product that is gaining popularity due to their higher concentrations of bioactive components such as vitamins, minerals, and antioxidants than adult greens, all of which are beneficial to human health. Common microgreens are broccoli, red cabbage, radish, buckwheat, spinach, lettuce, which are a part of the following plant families respectively, Brassicaceae, Polygonaceae, Amaranthaceae, and Daisy. This research explores the intricate connections throughout the supply chain, considering variables such as crop growth, harvesting, packaging, transportation, and demand changes. A discrete event simulation (DES) model is used to capture the pre and post harvest stages of a calabrese broccoli microgreen supply chain. This study emphasizes the importance of DES as a strategic decision-support tool in improving the flexibility and responsiveness of supply chain and production systems for microgreens, ultimately leading to more efficient and sustainable agricultural practices. The findings indicate that DES can provide useful insights into efficient transportation and production, resulting in increased operational efficiencies.",Discrete Event Simulation,53,460
A Scientometric Exploration of Physical Fatigue and Risk Management in Construction," Continued exposure to physically demanding construction tasks leads to physical fatigue, which is a key contributor in increasing workplace injury risks, reduced productivity, and declined work quality. Consequently, the monitoring and early detection of physical fatigue during strenuous work is crucial in mitigating these risks. While several previous studies have investigated methods for continuous physical fatigue evaluation for practical application, a comprehensive exploration of physical fatigue assessment strategies in the construction industry remains critical. Such exploration should particularly address the mitigation of ergonomic risks, alongside examining the bibliometric relationship within the literature and the influence of research themes in the domain. This study conducted a scientometric analysis on bibliometric data concerning physical fatigue assessment research spanning from 1999 to 2023, using techniques such as co-occurrence of keywords, co-authorships, and co-citations. This study initially collected 132 articles from Scopus, Web of Science, and PubMed databases using keyword search. Following duplicate screening, 88 papers were selected for scientometric visualization analysis. Findings revealed an escalation in research activities related to physical fatigue assessment within the construction industry over the past four years. Major contributions to this research stem from the United States, Hong Kong, and the United Kingdom. Predominant areas of focus included occupational safety and health, risk assessment, and wearable sensors. This study contributes to the current body of knowledge on construction workers’ safety and productivity by providing an extensive understanding of the key research themes, trends, and pattern in physical fatigue assessment.",Construction Safety,31,461
Robotics Assembly by Demonstration via Augmented Reality without Real Demonstration," In response to challenges in high-mix low-volume manufacturing, we present RADAR—an integrated human-robot collaboration system for Robotic Assembly by Demonstration via Augmented Reality. Addressing the limitations of existing works, we propose a 5-layer Digital Twin model to seamlessly integrate human input into automated robotic assembly. Our Augmented Reality interface simplifies robot programming and boosts interaction efficiency. Additionally, a human-informed task planner dynamically adjusts human-robot collaborative assembly tasks, enhancing precision and success rates. Practical validation using the RAMP assembly benchmark confirms the system's effectiveness in augmenting human-robot collaborative assembly.",Digital Manufacturing and Industry 4.0-IV,48,462
A Novel Representation of Periodic Pattern and Its Application to Untrained Anomaly Detection," There are variety industrial products that possess periodic textures or surfaces, such as carbon fiber textiles and display panels. Traditional image-based quality inspection methods for these products require to identify the periodic patterns from normal images (anomaly-free and noiseless), and subsequently detect anomalies with the inconsistent pixels on a defective image. However, it remains challenging to accurately extract the periodic pattern from a single image in the presence of unknown anomalies and significant measurement noise. To deal with this challenge, this paper proposes a novel self-representation of the periodic image. By this way, the periodic pattern learning can be embedded into a joint optimization framework by simultaneously modeling the assumed sparse anomalies and Gaussian noise. Finally, for the real-world industrial images that may not strictly satisfy the periodic assumption, we propose a novel pixel-level anomaly scoring strategy based on z-score to enhance the performance of anomaly detection. Both simulated and real-world case studies demonstrate the effectiveness of the proposed methodology for periodic pattern learning and anomaly detection.",Process Monitoring and Anomaly Detection,179,463
Multi-period Stochastic Planning of Logistics Hub Capacities for Relay Transportation," The rapid growth of e-commerce brings formidable challenges to transport carriers with increased logistics demands and introduces more uncertainties into the system. This study specifically focuses on relay transport carriers that contract with logistics hub providers to reserve hub space and utilize relay transportation via hubs, promoting a driver-friendly approach to better serve their customers. In this context, our paper addresses the multi-period capacity planning of logistics hubs within hub relay networks, accounting for uncertainty in demand and travel times, to enable carriers to reserve sufficient hub capacity cost-effectively and conducting delivery with optimal efficiency and reliability. We model the problem as a two-stage stochastic optimization to strategically determine the logistics hub throughput capacities for each planning period, ensuring the fulfillment of logistics requirements while simultaneously minimizing both hub and transportation costs. Notably, this optimization problem falls within the NP-hard complexity class. To alleviate the inherent challenges in solving this problem, we employ an accelerated Benders decomposition utilizing Pareto-optimal cuts within a branch and bound framework. Additionally, a scenario reduction algorithm based on fast fast-forward selection method is performed to deduct computational effort while preserving the quality of the approximation. We conduct a case study for an automotive relay transport carrier operating in the Southeastern United States. The results show that our algorithm is highly efficient in solving large-scale instances. The resulting stochastic capacity planning outperforms the deterministic capacity planning, proving that considering uncertainty improves economic and social performance in terms of service reliability, network robustness, delivery efficiency, and cost-effectiveness.",Supply chain design 2,222,464
Every Data Point Counts: Iterating Dashboard Solutions to Meaningfully Measure Perinatal Morbidity and Mortality," In the United States, birthing people face a higher risk of death than in any other industrialized country, and the United States is the only one of these countries with a rising birthing mortality ratio. However, it is estimated that over 60% of these deaths are preventable. Despite this crisis in care, there has been no nationwide, standardized, comprehensive data-driven approach to address the evidence-based drivers of this issue. This gap has led to the creation of the Premier Perinatal Improvement Collaborative – a cohort of over 240 hospitals across the country focused on improving healthcare for birthing people and their infants. In line with the data-centered solutions focus of this collaborative, Premier has rolled out a suite of tools capable of taking on such a complex problem by integrating data across settings, connecting outcomes between birthing people and their babies, and addressing health equity by identifying social drivers of health. During this session, attendees will learn about how the Women & Infants team at Premier began this process with a small-scale collaborative to hone the analytical solutions. Using competitive intelligence, user testing, and effective data architecture to provide analysis of hospital- and system-level performance, patient detail, racial and ethnic disparities, and national benchmarking, the team developed then scaled dashboard solutions to expand these efforts to encompass the current cohort of 240+ hospitals. Over 2 million deliveries drive the data for this project, yet each data point represents a life, a person, their family, and community: every data point counts.",Process Improvement in Health Systems,178,465
Prediction of Service Utilization and Related Financial Risk for Healthcare of Medicare Beneficiaries," Primary-care practice groups negotiate contracts with healthcare insurers under Medicare with reimbursement from combinations of capitation payments, fees for services, incentives related to “best practices”, and patient co-payments. Lacking the scale and diversity upon which insurers rely to mitigate related financial risk, practitioner groups must carefully consider medical services that will be required for the pool of patients under their care. We address the challenge of estimating the frequency with which different healthcare services will be received by individuals and determining related costs and financial risks. Usage of services and related financial costs do not conform well to standard theoretical distributions – especially for cases with highest financial risk. With diagnostic and treatment microdata for individual patient encounters, we construct Poisson regression models to estimate the frequencies with which individual Medicare beneficiaries are expected to receive particular medical services over the course of a calendar year. Segmented regression models are used to estimate the costs of individual visits. Predictive variables include patient characteristics (demographic variables, indicators of health status, and socio-economic indicators), indication of the health plan to which individuals subscribed, and availability of medical services where the individuals reside. To deal with irregularities in the tails of frequency distributions for residual variation, we blend the statistical models with empirical distributions in a discrete-event simulation model for analyzing related risk. The simulation results discriminate well between high-risk and low-risk individuals, capture the behavior of high-risk cases better than standard theoretical forms, and properly reveal large differences among population segments.",Healthcare Applications,82,466
"Understanding the Adoption of Robotic-Assisted Surgery: A Focus on Human-Robot Interactions, Training, and Built Environments"," Despite the current technological advancements of robotic-assisted surgery (RAS) platforms, there is still limited understanding in the facilitators for adoption and integration of such systems in the operating room (OR). To understand the attitudes, barriers, and facilitators to current human-robot surgical work systems, an RAS stakeholder (clinicians, researchers, regulators, etc.) survey (n = 184 responses) and a crowdsourcing perception survey (n = 1069 responses) were disseminated. Adoption barriers included human-robot interaction challenges: 24% of respondents reported communication and teamwork barriers from environmental noise and from other staff. Surgeons and researchers reported the most common built environment challenges for adoption to be OR layout and size (28%). When considering automation, 59% of clinicians reported being uncomfortable with performing in a fully remote telesurgery scenario. Training limitations were also identified, where only half (out of 6) of hospital administrators use an accredited RAS training program. From the crowdsourcing survey, average responses of RAS were 3.5 and 3.3 for comfort and safety (out of 5, with 5 representing highest comfort and safety) and 2.1 for reliability (out of 3, with 3 representing highest reliability). Perspectives differences between income groups and races were identified. Individuals with an income over $100k reported higher scores for the comfortability and reliability of RAS. Significant differences were also found between self-reported races respective to safety (p < 0.03) and comfortability (p < 0.03). These findings highlight challenges in current RAS adoption and indicate opportunities to create future robotic surgery work systems.",Teaming in Work Systems,229,467
Machine Learning Enhanced High-Fidelity and High-Biocompatibility Bioprinting Using Rheological and Compositional Predictors," The rapidly evolving field of 3D bioprinting is undergoing transformative changes with the development of new materials and techniques. One of the primary challenges in this field is optimizing materials and processes to achieve high cellular viability and accurate structural replication in bioprinted constructs. A critical issue in this regard is formulating a bioink that addresses the inherent variability in fluid dynamics, rheology, and biocompatibility. Our study focuses on alginate-based bioinks, modified with Laponite nanoclay particles and Type-I collagen, aiming at creating a yield-stress bioink for extrusion-based printing. This bioink is specifically designed to meet the dual objectives of high cellular viability and structural fidelity in bioprinting. Utilizing a Design of Experiment (DoE) approach, we conducted a systematic study by varying the composition of the materials, thereby evaluating extrudability, printability, and viscoelastic properties. The gathered data was utilized to train a hyperparameter-tuned machine learning (ML) model. This model played a crucial role in predicting the interactions among various responses and pinpointing an optimal bioink composition. The chosen formulation effectively produced high-fidelity structures, while also significantly reducing shear-induced cell death, thereby ensuring a high level of cell viability in the final structure. Our findings demonstrate the power of a data-driven experimental approach in conjunction with ML techniques in advancing the field of high-resolution, high-viability 3D bioprinting. This integrated method presents a promising pathway to address current challenges and push the boundaries of precision in biofabrication.",M&D Best Student Paper Competition,124,468
A Conceptual Foundation for Asset-Based Systems Engineering," For decades, the discipline of system engineering has effectively integrated decision-making and processes across the system life cycle. Similarly, approaches such as Lean and Six Sigma have catalyzed systems improvement in a variety of environments. As systems increase in complexity, cyber and human integration, and need for resiliency, these past practices have limited usefulness. In this paper, we contrast traditional systems approaches with Asset-Based Community Development (ABCD), a sociological approach that has been transformational in community development. The paper presents a synergistic combination of traditional systems engineering with ABCD is what is termed Asset-Based Systems Engineering (ABSE). Both the philosophy and the application of ABSE is described. Philosophical elements include the systems view, nature of systems thinking, motivation, and orientation which inform application elements which include skills, methods, tools, and metrics.",SE Concepts and Theory,199,469
Developing a Hetero-functional Graph State Estimator of the American Multi-Modal Energy System," As one of the most pressing challenges of the 21st century, global climate change demands a host of changes across at least four critical energy infrastructures: the electric grid, the natural gas system, the oil system, and the coal system. In the context of the United States, this paper refers to this system-of-systems as ``The American Multi-Modal Energy System (AMES)"". These combined changes necessitate an understanding of the AMES interdependencies both structurally and behaviorally to develop and enact effective policies. This work focuses on behavioral analysis methods to provide examples of how to analyze system behavior and the crucial flows of energy through the system. Building upon past works, the AMES is modeled and its behavior is analyzed using Hetero-functional Graph Theory (HFGT). Specifically, the work presents a state estimation model of the AMES. This work brings the state estimation analysis out of the single-operand electric grid environment and into the heterogeneous environment that is the AMES. Employing a data-driven and model-based systems engineering approach in combination with HFGT a Hetero-functional Graph State Estimation optimization program was developed to optimize the flows of mass and energy through the AMES. This provides the first example of using a state estimator with HFGT to model the flows of mass and energy across multiple energy systems contained within the AMES.",Resilience and State Estimation,191,470
Profits or Loss: Installing Electric Vehicle Chargers on Public Parking Lots.," Electric vehicles (EVs) are key to sustainable transport systems and Texas’ current and future power grid supply because of tremendous powertrain efficiency gains. Limited public charging infrastructure and large investment requested could become a bottleneck in EV adoption and use. We propose a data-driven study to examine price elasticity of public parking lots where EV chargers will be allocated and determine optimal siting and sizing of EV charging stations to maximize profitability of EV charger investment. Specifically, we first study an open dataset of historical parking information for 18 public parking lots in Santa Monica, CA from 2014 to present to identify factors that affect parking demand, including time of year, traffic nearby, parking prices and the pandemic event. Then we figure out the best price policy for EV chargers installed in public parking lots, following the price elasticity resulting from the data. Next, we determine the optimal locations and sizes of EV chargers using a robust optimization model incorporating uncertain future demand. The approach of obtaining optimal charger allocations can be rolled out for multiple phrases in the next few decades.",Decarbonizing Mobility,37,471
A Generalized Quantitative Framework for Complex Adaptive Systems," A complex adaptive system is composed of interrelated, autonomous parts or agents which dynamically adjust based on internal performance and external environment. Such systems are inherently challenging to characterize and to predict. Quantitative characterization of systems is typically accomplished through a set of systems “metrics” with associated interrelationships. We propose a combination of this traditional practice with the concept of asset-based thinking from community development. This approach suggests characterization of system parts/assets, capabilities, relationships, groups, and needs leading to a diverse group of systems measure types geared toward long-term systems sustainability. In developing this framework, we seek to expand beyond the implicit and often unrecognized Newtonian-Cartesian system view of tradition systems metrics. The proposed framework is inspired by complex adaptive systems both in its structure/taxonomy and in its associated development process. The paper provides examples from literature supporting such integration of metrics and metric processes. Next, we share a community development-based analog that provides the context for creating the quantitative framework. Subsequently, the generalized quantitative framework is described in detail arranged according to a novel taxonomy. Example metrics are proposed to be purposefully abstract in order to be conceptually translated and adapted for a given practical context. A process to translate to dynamic computational models is described.",SE Concepts and Theory,199,472
Promoting Safe Use of AMRs Assessing their Residual Risks and Safety-Related Functions," With Autonomous Mobile Robots (AMRs), the usual risks are those of collision between a worker and the AMR, or a body part trapped between the AMR and a fixed or moving obstacle. To bypass obstacles (human or otherwise), AMRs feature autonomous control systems activating safety-related functions based on machine learning or optimization algorithms. This paper presents how assessing the residual risks of AMRs and their safety-related functions help promote their safe use. In order to do so, a risk assessment of the AMRs was performed, using ISO 12100, in a test bed consisting of an Intelligent Cyber-Physical Systems laboratory warehouse at Polytechnique Montreal. A safety checklist from the standard R15.08 was filled out to feed the risk assessment process and to help judge the efficiency of the technical preventive measures, namely the safety-related functions. Apart from the risks of collision and entrapment, the risk assessment highlighted other hazards stemming from the AMRs, such as intense light that can temporarily distort someone’s view, then potentially become a pitfall during human-robot interactions. Assessing the autonomous localization and mapping ability of the AMRs at their configuration phase highlighted the importance of a high quality and reliable Wi-Fi in order to detect obstacles on time and avoid unexpected movements. Consequently, the risks have started being addressed to use those AMRs safely. The study showed the gap between today’s safety-related state of the art and the manufacturer’s design choices. That gap will raise awareness amongst designers so they prioritize more inherently safe principles.",Emerging Technologies and Safety: From AMR Integration to Urban Air Mobility,61,473
Optimizing Coffee Waste Collection: A Discrete event Simulation Based on Consumption Patterns," Global coffee consumption has surpassed 10.7 million tons in 2022/23, leading to an increased production of spent coffee grounds (SCG), with 1 kg of soluble coffee yielding 2 kg of wet SCG. Additionally, SCGs are often sent to landfills, emitting a greenhouse gas 25 times more potent than carbon dioxide, called methane. This environmental’s impact entails the need for the development of an effective waste management system specifically designed for SCG. This conference paper introduces an integrated approach to optimizing coffee waste collection in urban areas by merging a Capacitated Vehicle Routing Problem (CVRP) mathematical programming model with a discrete event simulation model. The CVRP mathematical model aims at optimizing waste collection routes. The initial step is data collection, which involves using geolocation data from coffee shops' waste bins, identifying waste treatment facilities, and estimating coffee waste volume, Simultaneously, the discrete event simulation model acts as a visual representation of the outcomes derived from the CVRP mathematical model. It dynamically adapts to varying spent coffee grounds (SCG) quantities and the CVRP’s parameters. The quantities are estimated considering consumption per capita, temporal fluctuations, and employing local demographics and consumption data for precision. As a result, this simulation model serves as a tool to illustrate the dynamic aspect of the optimized waste collection routes generated by the mathematical model, which leads to the creation of the digital twin for the waste collection routes’s system.",Discrete Event Simulation,53,474
Stochastic Optimization of Intermodal Freight Transportation: A Case Study of the U.S. Southwest Supply Chain," We study a logistical challenge in the inbound supply chain within the U.S. Southwest region, focusing specifically on the network originating from the San Pedro Bay port complex. The primary goal is to minimize overall distribution costs. To tackle uncertainties in demand, we employ mixed-integer stochastic programming. In the main problem decision, we develop long-term strategies to identify the optimal locations for logistics centers equipped with intermodal facilities that would enhance accessibility to railroad systems. The subproblem stages are formulated as network flow problems, addressing transportation operations over a one-year period. This includes determining the most efficient routing and allocating the appropriate quantities of goods to be transported via railroads and trucks. The proposed supply chain system offers advantages such as mitigating traffic congestion in and around port areas and neighborhoods, alleviating bottlenecks, and enhancing the overall efficiency of freight throughput in the inbound supply chain.",Supply Chain Management,215,475
Time-series Analysis of Severe Weather Effects on Traffic and Mobility Patterns," Severe weather events can cause significant changes in traffic volume and pattern throughout the day, where certain routes may experience an increased traffic while others may see reduced use. Studying the impact of severe weather events on traffic volume and patterns aids in designing more resilient infrastructure and developing effective emergency response strategies. This research aims at analyzing the existing traffic data to identify disaster‐induced mobility and evacuation patterns in the State of Kansas. We examine the impact of historical severe-weather events in the region, obtained from the National Oceanic and Atmospheric Administration database, on hourly traffic data collected by the U.S. Department of Transportation Federal Highway Administration from 100 stations spread across the State of Kansas. We employ recurrent neural networks to determine if severe-weather events lead to statistical outliers in daily traffic patterns. The long-short-term-memory (LSTM) recurrent neural networks were used to develop a time-series model of hourly traffic flow at different stations. To enhance the goodness of fit, harmonic variables were added to the model to capture daily and weekly seasonality observed in the traffic data. Sensitivity analysis was performed to choose the ideal lag and LSTM network architecture. Outliers were then detected if the hourly forecast as determined by the LSTM network differs with statistical significance from the actual traffic volume. The proposed outlier detection approach was used to analyze the spatial impact of severe weather events on daily traffic patterns in different regions of the state.",Logistics I,122,476
Enhancing Supplier Selection and Order Allocation Processes with Machine Learning Clustering and Optimization Techniques," Optimizing supply chain management relies on effective Supplier Selection and Order Allocation (SS&OA). This study introduces a novel two-phase SS&OA framework. In the initial phase, K-means clustering, Gaussian Mixture Model, and Balance Iterative Reducing and Clustering techniques are utilized to identify and group suitable suppliers based on managerial preferences and specific requirements. The accuracy of the clustering models is assessed through the Silhouette Score technique. The second phase introduces a new multi-objective optimization model for SS&OA, using suppliers shortlisted from the best-performing Machine Learning (ML) clustering method in Phase 1. Validated with real historical contract data from Canada, this framework highlights ML clustering techniques' substantial impacts on decision accuracy, offering valuable insights for data-driven SS&OA decisions",Logistics II,123,477
Examining and Preventing Adverse Events in Automation Using a Combined HFACS/REDECA Framework," Automation and automated tools have become near ubiquitous in everyday life. Aviation has long used different levels of automation in aircraft. Still, near miss and adverse events have primarily been considered issues of automation addiction or automation atrophy. Little consideration has been given to considering how different levels of automation cause or contribute to human error in everyday life. This paper examines the interactions between humans and automated systems using the Human Factors Analysis and Classification System (HFACS) and Risk Evolution, Detection, Evaluation, and Control of Accidents (REDECA) Frameworks. Both extend Reason’s ""Swiss Cheese"" Model. The Swiss Cheese model considers error as the effect of multiple layers of defense, organizational to individual, inadequately preventing a near miss event from escalating to an adverse event. HFACS examines errors using four primary factors: 1) Unsafe Acts, 2) Preconditions for Unsafe Acts, 3) Unsafe Supervision, and 4) Organizational Influences. We will examine automation errors as primarily caused by unsafe supervision and organization influences. REDECA examines how automation risks escalate; and how AI can be used to detect, prevent, and/or mitigate these risks. By combining these two frameworks our goal is to develop a better understanding or automation errors and develop strategies to deal with them.","Systems Engineering, Logistics and Supply Chains for Human Factors and Ergonomics",228,478
Optimizing Pick Sequences Using Discrete-Event Simulation: A Warehouse Efficiency Case Study," In the fast-paced world of logistics and warehouse management, the optimization of pick sequences stands as a pivotal factor in enhancing operational efficiency. This study addresses this crucial aspect by critically analyzing traditional and proposed picking processes. The study challenges the conventional snake-like picking pattern, highlighting its inefficiencies, such as prolonged travel times, congestion, employee fatigue, and a heightened risk of collisions. Central to this paper is the introduction of an innovative zig-zag picking sequence, meticulously designed to significantly curtail travel distances, optimize congestion management, and reduce operator interactions. The foundation of this proposal is a robust modeling and simulation framework, employing Flexsim—a state-of-the-art simulation software. This tool was instrumental in creating a highly detailed and accurate model of the warehouse environment, allowing for a comprehensive comparison between the traditional snake-like sequence and the proposed zig-zag pattern. Simulations conducted using Flexsim revealed improvement in efficiency, with the new picking method projecting up to a 13% increase in operational efficacy for certain methods. The proposed implementation strategy is comprehensive, encompassing an initial assessment phase, systemic modifications, a phased implementation approach, and continuous performance evaluations. The expected outcomes of adopting this innovative picking sequence are multifaceted, including significantly enhanced efficiency, reduced picking times, a safer work environment, and augmented customer satisfaction. This presentation not only offers a blueprint for optimizing warehouse operations but also exemplifies the power of advanced simulation technologies like Flexsim in transforming supply chain and inventory management practices for the future.",Discrete Event Simulation,53,479
"Examining Caregiver Decision-Making using Human Factors Analysis and Classification System (HFACS), AcciMap, and Risk Evolution, Detection, Evaluation, and Control of Accidents (REDECA) Frameworks"," Pediatric caregivers are a critical part of chronic pediatric care. They are the first to observe, monitor, and act as their child’s medical condition progresses from benign to potentially life-threatening. Caregivers are thus in the unenviable position of being first responders without much formal training. Training, if any, is often truncated and limited to operating “therapy” devices like home mechanical ventilators (HMVs) or infusion pumps for home total parenteral nutrition (TPN). Little consideration is given to potential health risks, decision making, or even day to day activities like bathing. This paper examines caregiver errors using three frameworks derived from Reason’s Swiss Cheese Model: HFACS, AcciMap, and REDECA. The Swiss Cheese model considers error as the effect of multiple layers of defense, organizational to individual, inadequately preventing a near miss event from escalating to an adverse event. HFACS examines errors using four primary factors – 1) Unsafe Acts, 2) Preconditions for Unsafe Acts, 3) Unsafe Supervision, and 4) Organizational Influences. AcciMap considers errors a result of poor interactions across organizational boundaries. REDECA examines how automation risks escalate; and how AI can help detect, prevent, and/or mitigate these risks. Our goal is to study caregiver error using these three frameworks to develop methods to identifies sources of caregiver errors; then develop strategies to help caregivers integrate automation into their healthcare processes and inform them about escalating medical risks so as to reduce and/or prevent them.",Patient Care and Treatment II,161,480
A Temporal Convolutional Neural Network (TCNN) Approach to Predicting Capacitated Lot-Sizing Solutions," This study presents an innovative deep learning-optimization framework tailored for dynamic mixed-integer programs, featuring the integration of a Temporal Convolutional Neural Network (TCNN). The framework is applied to predict optimal decisions for the Single-item Capacitated Lot Sizing Problem (CLSP), where binary variables govern production feasibility within discrete periods, transforming it into a sequence-labeling task. Through the strategic integration of TCNN, our Optimization (Opt) framework achieves a remarkable factor of 10 reduction in solution time compared to MIP solver CPLEX, while deviating from the optimality with a small gap. This positions the framework as a promising solution for the efficient resolution of sequential decision-making problems in repetitive scenarios. We conduct a comparative performance analysis utilizing CPLEX as a Mixed-Integer Programming (MIP) solver with and without machine learning augmentation. The research introduces a TCNN-based machine learning model that demonstrates efficiency gains through its integration compared to the traditional CPLEX approach. The evaluation provides valuable insights into computational approaches combining optimization solvers with machine learning techniques for effective problem-solving in the combinatorial optimization domain.","Machine Learning and AI, Part 1",128,481
Towards a predictive prognosis and a personalized follow-up of breast cancer patients," This ongoing research work, which involves artificial intelligence experts and medical oncologists is about the development of an intelligent system for a predictive prognosis and a personalized surveillance/follow-up of breast cancer patients. The system would save lives, lower the cost of treatment and follow-up and relieve the capacity of the oncology treatment centers for better management of new and old cases of breast cancer. The targeted intelligent decision support system will guide the practitioner in the surveillance of patients with breast cancer based on the risk of relapse specific to each patient.It will enable the oncologist or general practitioner to introduce several attributes relative to the patient's history and condition, and in return obtain a personalized proposal for a follow-up plan for the patient, depending on the risk of relapse and the history of the patient. Follow-ups will vary in rhythm/frequency and also in tests to be prescribed. The resulting system will, make it possible to optimize the surveillance of former patients and to propose a personalized monitoring plan instead of a systematic monitoring frequency as recommended by the current guidelines (every three months) . This will help avoid inappropriate monitoring that is either too heavy or too light and will allow better management of hospital capacity. Furthermore, a better prediction of the risk of relapse will make it possible to intervene more quickly for cases at high risk of relapse. The system will make it possible to delegate the surveillance task to non-specialist doctors.",Predictive Models in Health Systems,170,482
Sparse Learning and Bayesian Sequential Inference of Network Connectivity," While significant efforts have been attempted in the design, control, and optimization of a complex network, most existing works assume the network structure is known or can be readily available. However, the network topology can be radically recast after an adversarial attack and remain unknown for subsequent analysis. In this work, we propose a novel Bayesian sequential learning to reconstruct network connectivity adaptively: A sparse Spike and Slab prior are placed on connectivity for all edges, and connectivity learned from reconstructed nodes will be incorporated to select the next node and update the prior knowledge. Central to our approach is that most realistic networks are sparse, in that the connectivity degree of each node is much smaller compared to the total number of nodes in the network. A sophisticated sequential selection of the nodes is implemented using the between-node expected improvement. The performance is compared against a random node selection. We use two different network structures: Barabsi-Albert network with and IEEE-118 bus network. Our algorithm improves traditional reconstruction when faced with limited data and robust with different noise levels. Our algorithm accurately reconstructs the network with just fewer nodes without having to explore the whole network structure.",Information Systems & Software,104,483
Predictive Analytics via a Stochastically-Informed Variational Autoencoder," The heightened complexity and inherent uncertainty in contemporary sensor-intensive systems pose a formidable challenge in capturing the latent dynamics essential for effective control and decision-making. Existing uncertainty quantification (UQ) methods predominantly rely on state-space models, encompassing a spectrum from physics-based to data-driven and hybrid combinations thereof. However, these methodologies encounter notable constraints due to the frequently unrealistic parametric assumptions inherent in their design, the substantial computational complexity associated with latent state estimation, and the imperative for substantial volumes of training data, which are not always readily obtainable. Regardless of the method used, calculation of the remaining useful life (RUL) implicitly depends on the, usually assumed to be decreasing, trend of the latent states. While this is a reasonable assumption, such enforced monotonicity posits hard constraints on the model that are unrealistic and sometimes not interpretable. In this work, we suggest a stochastically-informed variational autoencoder (SI-VAE) that approaches RUL estimation from a different perspective than previous models. Our method introduces custom-made code layers for modeling the stochastic ordering between successive latent states based on the likelihood ratio concept, which provides a more natural and probabilistic way of modeling degradation and RUL. More specifically, the code layer outputs fuse both degradation and RUL estimates into a single value, while at the same time discarding the necessity for a predefined monotonic trend of the latent states. Numerical experiments using 10-minute wind turbine SCADA data were conducted to prove the validity of the proposed method.",Advanced Topics of QCRE V,11,484
Human Factors Issues in Augmented Reality Assisted Manual Order Picking: A Systematic Literature Review," Objective: Identify cognitive and physiological human factors issues in manual order-picking tasks assisted with augmented reality technology. Background: Augmented reality (AR) has gained popularity as an assistive technology for providing cognitive support during warehousing operations such as order picking. Several research studies have explored the use of AR in manual order picking and found mixed outcomes in terms of both cognitive and physiological human factor aspects. Methods: This study is part of a larger systematic review assessing the use of AR, which aimed to identify the current body of knowledge relevant to the effectiveness of AR technology in enhancing safety, performance, and user satisfaction for order-picking tasks. The literature search was done following the PRISMA methodology. After the search, 26 studies were found to be eligible for the full-text analysis. Results: The results of the review showed that AR gadgets had both beneficial and detrimental effects on order pickers' cognitive and physiological systems. Several concerning issues are reported: visual fatigue, headaches, dizziness, discomfort, and cause of distraction. On the other hand, the benefits reported are increased speed, reduced error, flexibility, adaptability, safety, and new technology. Conclusion: The use of AR in manual order picking has benefits that can reduce overall warehousing costs and improve order picking performance. However, some ergonomic concerns need to be addressed to improve user comfort and acceptance. Application: The outcome of this review will help researchers and practitioners find the current status and future direction of the use of AR in manual order picking.","Systems Engineering, Logistics and Supply Chains for Human Factors and Ergonomics",228,485
Where has the power gone? A five-year review of rigid powered exoskeletons.," Powered rigid exoskeletons have existed since General Electric’s Hardiman model in 1965. While work on them surged in the early 2000s, there has been a reduction in the work done on new models, while investigations of soft and/or passive exoskeletons have exploded through the field. Rigid exoskeletons have the benefits of providing greater support for users and having greater options for mounting equipment. This is a literature review sets to capture a snapshot of the last five years of the work into rigid, powered exoskeletons to provide insight into the current work and what future work could explore.",Physical Ergonomics,164,486
Utilizing Agent-based Simulation and Game Theory to Enhance Decision-making on Cancer Detection Methods," Cancer poses a significant global health challenge. Early detection and treatment play crucial roles in improving patient survival rates and extending lifespans. Biomarker tests are vital for cancer detection, with hospitals offering a variety of these tests. One particular test, Whole Genome Sequencing (WGS), is a costly method dedicated to analyzing the entire genome. Only specialized centers and academic hospitals provide WGS, while others must refer patients to facilities offering this costly method. Given the limited availability of WGS in many hospitals, our objective is to create tailored scenarios for each institution in order to ascertain whether it would be more advantageous for them to either send patients for WGS or utilize the standard biomarker tests available within their own institution. We have employed the use of agent-based simulation (ABS) and game theory to identify the optimal scenario for each hospital. In this study, hospitals will be regarded as individual entities (agents), each possessing its own set of parameters and attributes such as the distance from WGS centers, set of biomarker tests available to them, and patient volume. Game theory model is used to illustrate the choices made by hospitals considering the cost and wait time for WGS results. If many hospitals refer patients for WGS, this could lead to longer wait times for all hospitals. Our simulation model incorporates several key parameters, including testing costs, test success rates, and the time required to complete the diagnostic pathway.",Agent-Based Modeling,14,487
Navigating Success: Validating and Optimizing Throughput Capacity in a Novel Marine Fuel Operation Through Discrete Event Simulation," A marine fuel provider in the process of launching and operating a new marine fuel business in Canada wanted to validate the projected throughout capacity of their marine operations. Confirming the throughput capacity of the marine operations system was complex for the following reasons: Brand new operation with no historical actual data. Patented, unique and purpose-built infrastructure and equipment. Demand, supply, and capacity constraints within the system. Blending requirements to produce a finished marine fuel product. Tide cycles, seasonality, daylight hours, and weather patterns that impact operating parameters. The interarrival variability of vessels and limited berth durations. Consistently meeting customer demand within operational constraints amongst many external, uncontrollable, random events and variables was critical to the success of the new marine fuel operation. A discrete event simulation model was offered as a solution to stress test the maximum volume throughput of the entire system. The simulation model not only validated the throughput capacity, but it also became a tool for the team to: Understand system constraints and identify bottlenecks. Test potential what if scenarios and impacts to various KPIs. Assess ROI on incremental investments. Prioritize operation efforts on efficiency gains.",Simulating Transportation,205,488
Empirical Cross-Modal Wasserstein Distance (ECM-Wasserstein)," Cross-modal learning is ubiquitous is engineering systems. Advancements in imaging and sensor technologies motivate researchers to investigate connections between different data modalities. From a probability theory perspective, it is equivalent to studying the connections between two probability measures. However, all existing framework that studies such subject requires either paired sampling (mutual information) or same support dimension (distance metric/divergence). In this work, we investigate a cross-modal Wasserstein distance defined as the shortest Wasserstein distance between one probability measure and the set of orthogonal projections of another cross-modal measure. The constraints of orthogonal projections on Stiefel manifold allow the preservation of important properties of distance metric. We derive the Kantorovich-Rubinstein Duality of this cross-modal distance formulation, which enables empirical estimation of cross-modal Wasserstein distance (ECM-Wasserstein) between arbitrary modalities with different support dimension. This derivation opens up the opportunity to compare and correlate any cross-modal datasets without any pair information. We demonstrate how ECM-Wasserstein is able to identify similarities across a suite of real-world datasets. We also show the benefits of ECM-Wasserstein in supervised learning across different engineering applications.",Machine Learning I,125,489
An overview of the literature on decision-making support models and techniques used for circular construction and deconstruction," The construction sector is not only a major consumer of virgin materials, but also a major contributor to waste generation. Therefore, it is essential to rethink current waste management practices in the sector, for example by applying circular economy principles to building demolition such as deconstruction. Considered as a more-resource-friendly alternative compared to standard demolition, deconstruction involves dismantling a building with the aim of maintaining the highest possible value for its materials and maximize their recovery potential. This study reviews the literature in the construction sector to identify and analyze recent studies reporting on deconstruction optimization problems. It describes the decision and planning problems related to deconstruction practice discussed in the literature and highlights the main particularities of these problems, the models proposed to address them as well as the solving techniques used. Finally, it identifies the limitations of current research in the field and suggests perspectives for future research.",Construction Performance,30,490
Pediatric vaccine tender scheduling in low- and middle-income countries," Effective and efficient scheduling of vaccine distribution can significantly impact vaccine uptake, which is critical to controlling the spread of infectious diseases. Ineffective scheduling can lead to waste, delays, and low vaccine coverage, potentially weakening the efforts to protect the public by controlling the spread of diseases. Organizations such as UNICEF (United Nations Children’s Fund), PAHO (Pan American Health Organization), and GAVI (Gavi, the Vaccine Alliance) coordinate vaccine tenders to ensure that enough supply is available in the market at the lowest possible prices. Scheduling vaccine tenders over a planning horizon in a way that is equitable, efficient, and accessible is a complex problem that involves trade-offs between multiple objectives while ensuring that vaccine availability, demand, and logistical constraints are met. The problem is aggravated by the uncertain nature of vaccine demand, year-to-year supply changes, and vaccine options available over time. We propose a multi-stage stochastic optimization model to capture the dynamics of decision making in a stochastic environment. This model helps us address the following research questions: What should the optimal sequencing and scheduling of vaccine tenders be to enhance affordability and profit? How does the number of products in a tender affect the optimal tender procurement schedule? What is the optimal tender procurement schedule for single/multiple antigen(s) scenario? We use several sources of real-life data to validate the model and address our research questions. Results from our analysis are expected to show how, and when vaccine tenders should be scheduled, to optimize affordability, and maximize vaccination coverage.",Public Health,183,491
Bitcoin Mining with Renewable Energy and Flared Methane (CH4) has a Potential Solution for Global Climate Change.," This study evaluates Bitcoin mining's sustainability features in detail, with a focus on how different renewable energy sources can be integrated. An in-depth analysis of hydroelectric, wind, solar, and geothermal energy systems is provided, along with an assessment of how well-suited and potentially beneficial they are for Bitcoin mining. Considering energy efficiency, environmental impact, and economic viability, a detailed understanding of the benefits and challenges associated with incorporating hydro, wind, solar, and geothermal resources into sustainable Bitcoin mining techniques is offered. The study adds to the ongoing discussion about how to create a sustainable future for digital currency ecosystems by revealing deep links between renewable energy technologies and the cryptocurrency sector. This research, which focuses on Bitcoin mining from Methane (CH4) flares, aims to build a more resilient and sustainable society while also promoting positive environmental reforms. It highlights the effectiveness of Bitcoin mining from flares as a means of turning methane emissions into electricity, therefore preventing an imminent climate catastrophe. This strategy connects economic incentives with climate action, creating an advantageous scenario for Bitcoin enthusiasts and advocates of a sustainable future.",Unique directions in Energy Research,234,492
Bridging the Intangible: A Review of Measurement Approaches in Advanced Manufacturing," This review article examines a range of methodologies for measuring and managing intangible assets in business and project environments, with a focus on their application in advanced manufacturing. Drawing from a collection of academic and professional literature, it highlights key strategies for quantifying non-physical assets like intellectual capital, organizational knowledge, and innovation potential. The article synthesizes these diverse approaches to present an integrated framework suitable for the dynamic nature of advanced manufacturing. It underscores the significance of intangibles in enhancing technological innovation and competitive advantage, advocating for their inclusion in strategic decision-making processes. This review serves as a comprehensive guide for researchers and practitioners seeking to understand and implement intangible asset measurement in the context of modern manufacturing industries.",Energy and Infrastructure,66,493
Best Practices in the development of Effective AR/VR Instructional Technologies," Augmented and Virtual Reality are increasing being used in the development of key stills across a wide variety of domains. This work details data collected in four studies, including both medical and industrial training. All the studies included common measures that were linked to training outcomes/ accuracy of participant learning. All the studies indicated a strong impact for not only content but also the physical nuance and temporal accuracy of the systems they were using. This papers offers a number of best practices for future instructional technology development in the area of AR/VR Technologies.",Organizational Ergonomics and Engineering Education,158,494
Securing Democracy: Evaluating Threat Countermeasures in Mail Voting Processes," The COVID-19 pandemic brought about sudden process changes to how United States citizens voted in the 2020 Primary and General Elections as there was a desire to allow for social distancing to prevent the further spread of the novel coronavirus. To do so, many states significantly increased the availability of mail voting to allow citizens to exercise their voting rights while protecting themselves, and others. As a result, and despite the pandemic, the 2020 U.S. General Election saw record voter participation with 46% of all voters indicating that they voted by absentee or via a mail-in ballot. While the U.S. Department of Homeland Security and the Cybersecurity and Infrastructure Security Agency praised the election as the “most secure in American history” in a joint statement and there was no evidence of widespread election fraud or that any voting system was compromised, public discourse continued to question the security and integrity of continuing to allow mail-based voting as a modality to vote in future elections. Building upon prior work that analyzed and updated the threats to the mail-based voting processes, this work leverages identified threat countermeasures to general election processes to assess their suitability to mail voting to better understand how to: 1. protect this critical democratic process; 2. enhance the threat and mitigation training of the poll workers that administer this election process; and, 3. educate the public on the ways to reduce threats to the mail voting process to ensure its continued security and integrity.",Problem Solving and Decision Making II,176,495
"Analyzing Multiple Source Water Usage Patterns, Affordability, and Quality in Appalachia"," Due to unavailable or unsafe in-home drinking water, an increasing number of Americans are choosing to rely on more expensive, less regulated, and potentially environmentally destructive water sources, such as bottled water and roadside springs. There is increasing concern that traditionally disadvantaged populations are bearing greater and poorly characterized economic and health impacts associated with bottled water reliance and roadside spring use. This study: 1) characterizes common water quality concerns and usage patterns between multiple water sources (e.g. municipal in-home piped, roadside spring, bottled water) in rural Appalachian communities; 2) assesses water affordability by creating models that consider the full economic burden (direct, financial costs and indirect costs (e.g. transportation, productivity lost, health)) associated with each source; and 3) compares drinking water quality to Safe Drinking Water Act standards and guidelines. Twenty-four households were recruited via community partnerships in Letcher County, Kentucky; Harlan County, Kentucky; and McDowell County, West Virginia—the third poorest county in the US. We found that bottled water reliance is extremely prevalent among participants and is associated with large direct economic and time costs; however, it is not surprising that residents are choosing to rely on bottled water rather than their in-home water, due to high rates of health-related and aesthetic contaminants. Findings on water usage patterns and results from our economic analyses are informing further research on alternative infrastructure and innovative solutions to help combat the water crisis in Appalachia and support the United Nations Sustainable Development Goal 6 on clean water and sanitation worldwide.",Aligning Profit and Planet and Addressing Water Challenges (SDG 6/SDG 12),16,496
Proposing a Design Science Research Framework for Developing Lean Six Sigma Solutions in the Service Sector," While Lean Six Sigma has proven effective in improving manufacturing processes, its application in the service sector faces more challenges due to the unique characteristics of service processes. The intangible nature of services, simultaneous production and consumption, and heterogeneity of demand make it difficult to fully replicate the Lean Six Sigma approach used in manufacturing. Operational excellence tools like Lean Six Sigma can significantly benefit the service sector by improving efficiency, quality, and customer satisfaction. However, as per the authors’ knowledge, there is no comprehensive framework to guide the development of Lean Six Sigma solutions tailored for the service sector. Design science research is proposed as an approach to address this gap. The proposed design science research framework has the potential to fill current gaps by guiding the contextualization, iterative design, and evaluation of Lean Six Sigma solutions for the service sector. The framework incorporates problem investigation through literature review to identify gaps and challenges specific to service processes. Iterative solution design allows for incorporating feedback and improving solutions to address the unique needs of service customers. Rigorous evaluation demonstrates the effectiveness and utility of the proposed solutions. The framework's applicability and effectiveness will be assessed qualitatively with Lean Six Sigma experts in the service field through semi-structured interviews to evaluate its potential in developing Lean Six Sigma solutions that specifically address the challenges of service processes and realize the potential benefits.",Service Organizations,204,497
Enhancing Engineering Education Through Virtual Reality Tools: A Comprehensive Review," This review examines the impact of virtual reality (VR) tools on engineering education, synthesizing literature. Virtual reality emerges as a transformative force, offering immersive and interactive learning experiences across diverse engineering disciplines. By simulating real-world scenarios, VR enhances spatial understanding and fosters hands-on, problem-solving skills. Key findings highlight the effectiveness of VR in promoting collaborative learning and improving retention of complex engineering concepts. The review underscores the potential of VR to bridge the gap between theoretical knowledge and practical application. While acknowledging the benefits, it also addresses challenges, including technical constraints, cost considerations, and the need for faculty training. In conclusion, the synthesis of current research emphasizes the pedagogical advantages of integrating VR into the engineering curriculum. Recommendations for future research and practical considerations for educators aim to guide the seamless adoption of virtual reality tools. This review contributes to the ongoing discourse on preparing future engineers for the dynamic challenges of the industry through the strategic incorporation of immersive technologies in education.",Innovations in Engineering Education,108,498
Simulation Analysis of Risk of Job Tardiness as a Measure of Manufacturing System Resilience," Resilience in the context of a manufacturing system is the ability to adjust, bounce back, and continue when challenged from unexpected occurrences, uncertainties, and disturbances. Manufacturing systems face a range of challenges: such as equipment malfunctions, supply chain disruption, changes in demand, and external events like natural catastrophes. The interrelationship between risks and system resilience is of dynamic nature, successful risk mitigation will result in increased system resilience, promoting sustainability and adaptability in challenging situations. In this paper a simulation model of a manufacturing system using Simio software was developed and Simio’s scheduling features were utilized to quantify the risk of job tardiness. Different case studies were performed on the simulation model with established due dates of job orders. Alternative routes from process planning task for jobs were used, containing scenarios as best, medium, and worst routes. The results obtained from the simulation model were analyzed and risk associated with different jobs routings corresponding to their due dates are quantified. The resilience of the manufacturing systems was assessed from two perspectives: using better routes to decrease risk and using alternate routes to reduce the risk of equipment malfunction.",Process Planning-I,180,499
Design of a Self-Starting Combined Shewhart-CUSUM Chart for Short Run Scenarios," The Combined Shewhart-CUSUM (CSC) chart is a mixed method Statistical Process Control/Monitoring (SPC/M) scheme that combines the Shewhart chart’s capability to effectively detect large transient shifts with the cumulative sum chart’s capability to detect small to medium sized persistent shifts in a process parameter’s underlying distribution. The CSC chart has received moderate attention in the literature, lately primarily in context of monitoring discrete data. However, research into a CSC chart that relies on on-line estimated parameters, i.e., that is self-starting, is nonexistent. In this paper, the results of recent research into the performance of a self-starting CSC chart for individual continuous observations in short run scenarios is presented. It shows that at a fixed false alarm rate, the self-starting CSC chart performs only marginally below the SS-CUSUM chart in terms of probability to detect small to medium sized persistent location shifts, while at same time providing significant improvement to the probability of detecting large transient shifts, making it an attractive tool in various short-run scenarios. This paper is considered of interest to industrial and systems researchers, as well as engineers with interest in SPC/M.",Statistical Learning and Artificial Intelligence for Quality Control III,213,500
The psychosocial work environment and its association with psychological incidents among pediatric healthcare providers.," Objective: The goal of this study was to examine the association between psychosocial factors and psychological incidents (e.g., stress, burnout) among pediatric healthcare providers. Background: The psychosocial work environment may increase the risk of psychological incidents among pediatric healthcare providers. The dearth of research in this area contributes to our lack of understanding this relationship. Methods: Randomly selected behavioral health specialists, patient care assistants, and registered nurses recorded psychological incidents using a digital voice recorder during their shift over a 2-week period. Participants completed the Nurses’ Worklife and Health Study survey that assessed work-related psychosocial factors. The association between psychological incidents and demographics, employment characteristics, psychosocial factors, and physical injuries was examined using Fischer’s exact test, Wilcoxon rank sum test, and logistic regression. Results: Pediatric healthcare providers who experienced psychological incidents were older, heavier, and worked fewer hours. Pediatric healthcare providers who experienced a physical injury during the 2-week period experienced a higher risk for psychological incidents. Conclusion: The psychosocial factors we examined are not associated with risk of psychological incidents among pediatric healthcare providers, but experiencing a physical injury greatly increases the risk of experiencing psychological incidents.",Work environment in health systems,241,501
Improving Post-disasters Heterogeneous Multicrew Assignment Policies in Infrastructure Networks," An infrastructure network consists of independent man-made systems that collaborate and rely on each other to provide communities with a continuous flow of goods and services. The impact of disasters on infrastructure networks, such as communication, transportation, and healthcare systems, necessitates the understanding of network behavior and the level of communication between service providers, to enhance resilience and performance. This study concerns the assignment of heterogeneous multicrew to serve the impacted nodes in the network. Each node may require a repair visit from one or more service providers, and the job completion time for a crew may depend on the availability and work completion time of the other crew. We represent this assignment problem as a multi-server queueing system with stochastic demand arrival for each node and stochastic service time for each work crew. We analyze the system in an agent-based simulation environment and conduct extensive sensitivity analysis around model assumptions to enhance the understanding of the structure of critical infrastructure systems within the context of disaster resilience and to provide insights for improving multicrew assignment policies in post-disaster scenarios.",Resilience & Hazard Analysis,190,502
Advancing Anomaly Detection in Critical Infrastructure: A Comprehensive Review of Computer Vision Algorithms and Their Applications," This paper presents an overview of various computer vision algorithms and their applications in anomaly detection within critical infrastructure sectors. Our focus is on examining the potential of techniques like convolutional neural networks (CNNs), feature extraction methods, object detection models, and advanced deep learning approaches. We aim to highlight the adaptability of these technologies in monitoring and safeguarding essential systems, discussing their real-world implementations and effectiveness. The review will also touch upon the integration of computer vision with other technologies, such as drones and thermal imaging, and the challenges encountered in practical applications. Our goal is to provide a synthesized perspective on the role of computer vision in enhancing the resilience and security of critical infrastructure, offering insights for researchers and practitioners in the field.",Reliability II,188,503
Improving customer demand forecasts in Solid State Drive (SSD) supply chain under the constraint of low quantity and quality of available data," Customer demand forecasts are critical to business planning, specifically for supply and operations related tasks. Due to the short-range of available data and varying market conditions, it is often challenging to accurately forecast demand across multiple Solid State Drive (SSD) product SKUs in Solidigm's (former Intel NAND business) supply chain. In this work, I propose a time-series based model that leverages vector similarity metrics, such as cosine-similarity, to identify patterns in customer demand historically. The goal is to learn the time periods that best predict customer behavior in the future and other patterns such as a demand shift from low to high density SSDs. This approach is best for short-range time-series data with a continuous dependent variable, such as Solidigm's supply chain which captures only 4 demand values per-year (on a quarterly basis). The model is currently in a proof-of-concept stage and will be implemented in the strategic forecasting process-flow in the coming months.",Manufacturing III,137,504
Simple Strategic Tweaks to Warehouse Management Yields Significant Results," A $6B company warehouse handling 30K SKUs was struggling to meet flow demands to and from the production unit. The leaders were considering adding more personnel and equipment to the warehouse, quality and assembly. With a one-week material flow workshop and 24 days of coaching, the constraints were alleviated without adding people or equipment, the lead time halved and the output doubled. In this session, we will present an industry-independent and methodology-agnostic approach to the strategic application of continuous improvement, Industrial Engineering, Six Sigma, Theory of Constraints (TOC) and Lean methodologies to analyze the flow of materials from warehouse to production. The approach used quick mapping of the workflow, direct observation of the work, questioning the policies governing the work, and using simple tools to perform data analytics. Rapid, significant and sustainable gains included reducing the Service Level Agreement to 2 days from 7 days, reducing several weeks of quality and Material Review Board backlogs to a 2-day cadence, improving the on-time shipment to 100% from 0%, and enabling the implementation of the Warehouse Management System (WMS).",Manufacturing Organizations II,140,505
Wood Flow Management for Reduced Lead time and better Delivery Precision," In the forest industry, the challenge of harmonizing raw-material supply with market demand persists due to fluctuating customer orders and the inability of the producers to adapt production in a timely manner. For supply managers, producing wood efficiently and cost-effectively while simultaneously satisfying the orders in a short lead time is challenging. The Wood Supply Chain (WSC) comprises four core activities, including procurement, production, distribution, and sales. These principal activities are often carried out by separate business units. Wood procurement involves purchasing, harvesting, transportation, and inventory functions. Wood flow management starts with fiber procurement, followed by harvesting, and ends with delivery to a mill yard. The main complexity lies in supply uncertainty arising from the natural diversity of forests, seasonality, and fluctuating market demand. This project focused on management, planning, and coordination strategies for adjusting the wood flow at the tactical and operational levels. We have identified strategies to improve supply visibility and traceability, facilitating the alignment of sales commitments with available wood supply to control lead times. Then, a conceptual framework that outlines a comprehensive scheme for deploying these strategies drawing from relevant concepts in the literature through a combination of hermeneutic and Systematic Literature Review (SLR) approaches, is developed. Subsequently, through a case study in Canada, a Discrete Event Simulation (DES) simulation model is implemented. Then, a simulation-based optimized solution that demonstrates the benefits of dynamically adjusting wood flow is generated. This research contributes valuable insights to the industry by optimizing wood flow to efficiently meet market demands.",Supply Chain Management and Transportation in Forestry,216,506
Matrix-Based Input-Output Process Modeling in Microsoft Excel," Matrix-based input-output methods are commonly used to model the economic linkages between industries within an economy. Effectively, they describe the flow of dollars or widgets between value-adding processes. This framework is also applicable to manufacturing processes. However, they have not been widely applied to model manufacturing or production processes within the industrial or systems engineering domain. Simulation techniques, specifically discrete-event simulation, are commonly employed to model complex manufacturing processes, but the creation of these models is time consuming and costly. In practice, there can be a gap between the need for quick model results and the effort required to build a discrete-event model. As an analytical solution, matrix-based input-output models present themselves as a quick and easy to implement alternative to simulation models. This work develops input-output production process models whose relationship between each step in the process is described by matrices. The effectiveness of this approach is demonstrated through a generic deterministic process flow that is then adapted to a stochastic case to indicate how variability can be incorporated within the model. Finally, implementation within Excel is shown to automate the process. The input-output framework can facilitate understanding of many metrics-of-interest, such as production capacity, utilization rates, waste generation, number of cycles need to complete a production run, and limiting factors.",Manufacturing,132,507
Tec Innovation District project a Sustainable Educational Ecosystem and Keystone University Cluster in Healthcare," Tec de Monterrey together with educational institutions, Healthcare providers, Medical Research Institutes as well as the mayor's office of Tlalpan, may be well in the position to create an innovation district in this geographic area of the he Southern Zone of Mexico city where innovative organizations converge. The purpose of this development is to create a cluster Dedicated to Research, Education and the practice of Healthcare, through the Tec Innovation District project, the urban and social environment of the southern area of Mexico City will be transformed. In addition to educational institutions, medical organizations such as the National Rehabilitation Institute have entered the discussion space to project the changes sought as well as the dynamics that the projected collaboration may create with the medical institutions in the nearby vicinity that already exist. Some of which are The Cardiology Institute, The National Center for Nutrition and the National Neurological Center as well as private top level healthcare providers. The project includes more than 400 hectares which will be used to generate housing without displacement, create a territorial balance, address water issues and improve mobility in the Southern Zone of CDMX. Analysis of common ground as the ‘traditional’ university is developed to an innovation ecosystem keystone with the changing role of universities in a regional context such as the Mexican arena for the potential benefits of University-Industry collaboration (UIC). According to Government officials, this UIC is an opportunity to create equitable, innovative, and sustainable spaces that involve the entire community.","Healthcare for a Sustainable Future: Innovations in Operations, Design, and Environmental Management (SDG 3)",91,508
Understanding the Impact of Poll Worker Cybersecurity Behaviors on U.S. Election Integrity," In 2017, the United States Department of Homeland Security designated U.S. elections equipment as critical infrastructure. Poll workers play a crucial role in safeguarding election security and integrity and are responsible for administering an election at the more than 100,000 polling places needed during an election cycle, oftentimes interacting with, and having unsupervised access to, elections equipment. This paper examines the utility of training poll workers to mitigate potential cyber, physical, and insider threats that may emerge during U.S. elections through an analysis of the relationship between poll worker training performance and their individual cybersecurity practices. Specifically, we measure a poll worker’s personal cybersecurity behavior using the Security Behaviors and Intentions Scale (SeBIS) and statistically examine this measure to performance on three training modules covering pollbooks, provisional voting, and scanning units, along with quizzes to assess poll workers' knowledge. The results indicate that security behaviors related to device securement, password generation, and proactive awareness have a positive relationship with poll workers' knowledge of threats. K-means analysis shows that highly-educated and device-secure poll workers tend to score better on the training quizzes; device securement was also the greatest driver of the relationship between security behaviors and poll worker threat knowledge. These findings have implications for election security policies, emphasizing the need for election officials and managers to prioritize device securement and proactive awareness in poll worker training initiatives to enhance election security.",Digital Excellence I,43,509
Data Fusion Optimization for Physiological Signals," Physiological signals include different types such as Electrocardiogram (ECG), Electromyography (EMG), Electrooculography (EOG), and Electroencephalogram (EEG). These signals play a crucial role in computer-aided diagnosis. However, the mechanism to fuse these signals is extremely critical to take advantage of the wealth information. This study aims to design a data fusion strategy for polysomnography (PSG) physiological signals collected from sleep centers. Channel attention weights are proposed and optimized to aggregate the information from different physiological aspects. The proposed approach was tested for sleep stage classification and validated the performance.",Healthcare II,84,510
Component-Wise Markov Decision Process for Solving Condition Based Maintenance of Large Multi-Component Systems," Condition-based maintenance of multi-component systems is a prevalent engineering problem due to its effectiveness in reducing operational and maintenance costs. However, developing the exact optimal maintenance decisions for the large multi-component system is computationally challenging due to the exponential state and action space size with the number of components. To address the scalability issue in CBM, we propose a Component-Wise Markov Decision Process(CW-MDP) and an Adjusted Component-Wise Markov Decision Process (ACW-MDP) to obtain an approximation of optimal system-level CBM decision policy for heterogeneous systems. The theoretical convergence and the relationship between ACW-MDP and CW-MDP are derived.",Industrial Prognostics and Decision-Making,102,511
A Transformer Deep Learning Model to Sequential Decision-Making under Constraints," In this study, we adapt an innovative deep-learning framework employing a transformer model to address the challenges of temporal mixed-integer programs, specifically focusing on the Capacitated Lot Sizing Problem (CLSP). Our approach utilizes the transformer’s ability to process sequential data, making it well-suited for predicting binary variables indicating production decisions in each period of the CLSP. This problem is inherently dynamic, with a need for handling sequential decision-making under constraints. Our transformer-based framework is distinct in its ability to capture the temporal dynamics and dependencies within the CLSP, treating it as a sequence prediction task. Through comprehensive computational experiments, we demonstrate that our model reduces solution times for benchmark CLSP instances down to 0.0016 seconds while maintaining high levels of feasibility and optimality.",Deep Learning II,41,512
Influence of Process Parameters on the Microstructure and Material Properties of Material Extruded (MEX) Three-Dimensional Steel Parts," Additive manufacturing of metal parts using Material Extrusion (MEX) is gaining popularity. During this process, a metal-polymer filament is extruded into a three-dimensional shape layer by layer, starting from a CAD model. This process implements traditional powder metallurgy manufacturing and applies it to additive manufacturing. In Metal MEX, a part is printed in the green state, washed to remove all of the polymer binder, and sintered to fuse the metal powder. Given the recent trends in the use of additively manufactured parts for end-use applications, more research needs to be done on the properties of the parts produced through the Metal MEX process, given its potential to print anisotropic parts. This study aimed to investigate the tensile strength and hardness of additive manufactured steel with different infills and print orientations. Microstructure analysis was also performed to analyze the porosity and layer adhesion. To accomplish this, tensile bars were prepared, filled with a solid infill, triangular infill, or gyroid infill, and printed in the horizontal or vertical orientation. Tensile testing, hardness testing, and microstructure examination were performed on the specimens. The test results displayed a significant effect of print orientation on the part strength, similar to the polymer material extrusion process, even though the parts were sintered fully to remove any anisotropy.",Mechanical Characterization in Additive Manufacturing Processes,143,513
Analysis of Security Behaviors of Supply Chain Professionals," Improvements in information technology and developments in AI enable supply chain professionals to improve efficiencies. The digitization of supply chains facilitates integration of upstream and downstream resources but also increases the likelihood of cyberattacks. Existing literature reflects a rapid rise in cyberattacks targeting supply chains, with a significant number of data breaches attributed to employee errors. Therefore, as supply chain professionals pose an insider risk to supply chain cybersecurity, this research delves into their information security behaviors. The objective is to assess the security practices of supply chain professionals and identify strategies for improvement. To that end, we conducted a survey using Amazon Mechanical Turk with 763 usable responses, including 167 individuals from the field of supply chain management. The survey consisted of 27 Likert scale questions, with 16 drawn from the Security Behavior Intentions Scale (SeBIS) and 11 from the Human Aspects of Information Security Questionnaire (HAIS-Q), supplemented by 11 demographic-related queries. Utilizing principles from information theory for analysis, results reveal significant inconsistency in information security behaviors among supply chain professionals, particularly in Password Setting, Device Securement, and Proactive Awareness. Finally, we compare and contrast with another large security behavior dataset in the literature to determine whether supply chain professionals from different disciplines exhibit comparable levels of security performance. Ultimately, this research seeks to provide recommendations for training programs aimed at reducing the risk of incidents or breaches stemming from trusted insider professionals within the supply chain.",Digital Excellence I,43,514
Thematic analysis of leaders’ perspectives on the barriers and enablers to Kaizen events in hospitals," A Kaizen Event (KE), also known as a Rapid Improvement Event (RIE), is a short-term improvement project usually lasting between 3-5 days using team collaboration to effect beneficial changes and improvements to a targeted workspace or process. Due to their expeditious, collaborative, and focused nature, this type of improvement project when applied to change initiatives within a hospital environment can meaningfully deliver desired outcomes. Identifying key mechanisms needed in hospital settings to achieve value-added socio-technical outcomes is an important imperative for hospital managers and change leaders. An empirical field study was conducted to determine the critical success factors (CSFs) for KEs in hospital environments. This investigation enabled the acquisition of descriptive textual evidence obtained from mainly senior KE hospital leaders and facilitators on their perspectives on the barriers and enablers for hospital KE success. Barriers deal with project-related, social, and organizational change inhibitors, while enablers refer to related aspects that are contributors. From the findings obtained from these experienced individuals, a thematic analysis was conducted to determine any common themes which can be considered as key mechanisms needed to ensure successful hospital KEs. The analysis resulted in the identification of important mechanisms that can be utilized to support KEs in hospitals. The findings imply that KE hospital leaders and facilitators agree on prioritizing key factors related to socio-technical aspects for ensuring successful KE project outcomes. Furthermore, the barriers and enablers defined in this publication are expected to increase healthcare managements’ confidence in the planning and execution of successful hospital KEs.",Problem Solving and Decision Making II,176,515
Resilient System Architecture for an Autonomous Robotic Patrol System," As research endeavors in autonomous robotics and multi-robot systems grow, more real-world applications of these technologies are identified. The coordination of multiple types of robots to achieve a common objective can increase the ability of the system. Defining resilience as the system's ability to absorb shocks, adapt, and restore following a disruption/disturbance, this study outlines a resilient system architecture for an autonomous robotic patrol system meant to utilize the various functions of current robotic platforms to act as surveillance and complete tasks in both military and industrial environments. Many existing multi-robot systems use a centralized control method which has a central compute system to coordinate the movement and actions of all robots within the system. Research and development of decentralized control methods exist where the robots have a certain degree of decision-making ability. The proposed system architecture allows the robotic fleet to operate under decentralized control with decision-making abilities while also having the ability to transfer over to a centralized control method under certain conditions. The architecting of this type of hybrid system is significant as it allows the robots to perform autonomous patrolling and other tasks entirely based on sensing the environment around them while automatically transitioning into a centralized control for more involved and significant tasks.",SE Methods and Applications,200,516
Assessing and Prediction of the Nutritional Value of Fast-Food Meals: Calories and Macronutrients," This comprehensive research delves into the nutritional intricacies of fast-food meals across eight prominent U.S. restaurant chains. Leveraging advanced machine learning techniques, including linear regression, classification tree, random forest, and KNN, the study aims to predict calorie content. The analysis uncovers the nuanced relationship between calories and nutrient profiles, offering a detailed panorama of nutrient values associated with consumer-purchased meals. The investigation expands its scope by employing clustering methods such as K-mean and hierarchical clustering, shedding light on macronutrient profiles within each cluster. Noteworthy findings highlight linear regression as the most accurate predictor, boasting a remarkable 98.6% R-squared value alongside minimal mean squared error. Crucially, the research identifies total fat, carbohydrates, and protein as pivotal factors influencing calorie predictions, providing indispensable insights for those navigating the complex landscape of informed dietary decision-making.",Public Health,183,517
Houston Methodist Operating Room and Procedural Area Supply Expiration Waste Reduction Kaizen," The First System Level Kaizen Catapults Houston Methodist to Prevent Millions of Dollars in Procedural Area Expiration Waste across seven hospitals in 2023. During FY 2022, there was $3.1 million in Operating Room expiration waste. The team strives to reduce 2023 OR Expiration Waste dollar value by 33% (Attainable Goal ≤ $168,338 per month) and/or 50% (Stretch Goal ≤ $125,625 per month). The team used a five-day Kaizen Event (March 20-24, 2023) with an A3 Problem Solving Approach framework. Post Go-LIVE findings (May–October 2023) indicate a $176,509 monthly AVG and just above target. Our Kaizen has been an effective and efficient approach for Subject Matter Experts to share best practices and develop ideal Standard Work Instructions, which includes: Overall Expiration Waste Reduction, Instant Adds, Inventory PAR Adjustments, and Inventory PAR Removal Processes. The team learned how to effectively use A3 problem solving and apply Lean tools to promote value-added activities. OR Inventory Coordinators execute their ideal processes with operational focus to prevent and reduce expiration waste. Engagement and ongoing success of this initiative requires buy-in from all levels of stakeholders (Executives, Surgeons, Directors, Managers, Inventory Coordinators from OR and Supply Chain, and Clinical Staff). Routine meetings and data transparency promote sustainment. The team expanded standard processes from ORs to all Procedural Areas (ORs, Interventional Radiology, Endoscopy, Cath Labs) and have prevented $4.3 million dollars (January – October 2023) and are on pace to prevent $5.2 million in expiration waste out of $8.8 million in forecasted waste to close out 2023.",Healthcare,81,518
The Manufacturing Production Game - Insights on Student Engagement," The Manufacturing Game is an experiential learning activity that requires students to develop a production plan, implement their plan in a simulated environment, and compete against other teams to earn the most profit. Students exercise their knowledge of production scheduling from aggregate planning to material requirements planning. While the Manufacturing Game was initially created in the 1990s as a physical game, recently, a web-based version was developed for students to be able to play virtually. This presentation will explain how to incorporate the game into a manufacturing course. In addition, we will discuss differences between students playing in-person versus virtually in terms of student engagement and learning outcomes.",Engineering Education Pedagogy and Assessment,67,519
Empowering Global Engineers: Facilitating International Engineering Design for Skill Enhancement," Industry employers need global engineers with the ability to interact in multicultural teams to solve complex problems. Sometimes, engineering students are not allowed to have international or professional experience to develop these kinds of skills. The collaboration between two international universities and a global industry partner addresses this crucial need for engineers with global competences. Recognizing the importance of multicultural teamwork in solving complex problems, this initiative enables engineering students to gain practical experience. By tackling a multi-site engineering design problem across different countries, students engage in real-world challenges with similar manufacturing processes. The structured approach involves forming teams comprising students from both universities guided by a team of teachers through a capstone course methodology. This ensures continuous support as students navigate industry-provided challenges. The outcomes include not only viable solutions to engineering problems but also the development of essential multicultural and engineering design skills. This innovative program provides students with a unique international experience, allowing them to work with a transnational industry partner. Facing a practical engineering design problem, students from two universities and different nationalities and backgrounds, can collaborate to solve an industry problem; dealing with several restrictions such as academic profile, language and communication issues students can build a viable solution to the problem. The result is the cultivation of well-rounded professionals with skills highly valued by employers.",Engineering Identity & Global Engineering Education,68,520
Hierarchical Model of Unreliable Systems in Comparison to an Anti-Fragile Replacement System," A hierarchical production mega-system is modeled with a pyramid architecture in which dependent systems on different levels experience stochastic partial failures, with faults below causing partial collapses of system integrity above. Time series process traces simulate the progressive degradation of the complete system. Various probability density functions are rotated as reliability functions, and alternative candidate inter-system dependency functions are utilized in the search for realistic modeling of hierarchical production mega-systems. Stochastic systemic behaviors are explored, in the search for viable models of progressive probabilistic degradation. Anti-fragile system substitutes are investigated as possible substitutes.",Advanced Topics of QCRE Applications II,6,521
Operational Excellence Systematic Layout Planning for a Boat Trailer Manufacturer," This study delves into the practical application of the Sawhney Model, a systematic methodology for driving operational excellence, within the context of a manufacturing challenge prevalent in the boat trailer industry. Specifically, this industry segment is engaged in the production of bespoke, high-quality trailers designed for recreational boating purposes. The focus of this problem lies in reducing production costs, increasing productivity, and fortifying reliability within the system responsible for fabricating small trailer components. Employing the Sawhney Model as a guiding framework, an assessment of the existing processes within this system was conducted. Subsequently, it was determined that establishing a novel small parts production line within a newly designated facility space would serve as a strategic recourse for the company. The paper delineates two distinct solutions intended to advance this overarching objective—one oriented towards process performance and the other centered on people. The former entails formulating a production plan and predictive schedule for a fresh production line, enabling the in-house manufacturing of previously outsourced materials. This strategic shift aims to diminish the inventory and associated holding costs significantly. The latter solution focuses on devising a revised layout design for the small parts division. This initiative is projected to optimize the movement of both personnel and materials, consequently trimming cycle time and lead time. This redesigned layout aims not only to streamline processes but also to enhance employee well-being. The culmination of these dual solutions is envisaged to elevate the productivity of the small parts system while concurrently bolstering employee retention.",Continuous Improvement Tools and Methodologies I,33,522
Enhancing Industrial & Systems Engineering Education with Smart Factory CPS Integration," This research investigates the utilization of a Smart Factory as an educational tool to enhance the learning experience of Industrial and Systems Engineering students. A Smart Factory contains Cyber-Physical Systems (CPS) which seamlessly integrate software, mechanics, and electronics, forming a dynamic environment where the physical and digital realms converge. Embedded systems and networks monitor and exert control over these physical processes and develop feedback loops where physical processes affect computations and vice versa. This technology has the potential to provide students with hands-on experience with automation and control systems, problem-solving skills within a manufacturing environment, and prepare students for future careers within industries embracing smart manufacturing technologies. Key learning objectives include understanding CPS components and interactions, highlighting the significance of CPS within Industry 4.0, examining CPS with embedded processes, and employing real-time monitoring for greater comprehension of manufacturing systems. The outcomes of this research have the potential to supplement the educational experience of students, preparing them for the evolving challenges and opportunities in the industrial landscape.",Innovations in Engineering Education,108,523
Using Artificial Intelligence Powered Teaching Assistant Tool to Enhance Student Learning in Engineering Economy Class," Providing timely feedback in large undergraduate courses such as Engineering Economy (about 200 students in each section at Purdue University), is both crucial and challenging. To enable real-time and individualized learning assistance to students, we developed an AI-powered “TA” tool – Arthur -- that includes a set of practice problems and can provide customized suggestions based on the answers submitted by students. The tool uses machine learning models that are trained using historical graded assignments to predict the cause of the incorrect answer and provide feedback accordingly. We have piloted using the tool for three semesters and surveyed students about their experience. Survey results show that the majority of students chose to use this optional tool and view it as helpful to improve their course performance.",Innovations in Engineering Education,108,524
Survey of Courses on Semiconductor Manufacturing at U.S. Universities," The significance of semiconductors became evident when manufacturing operations in various sectors nearly came to a standstill due to shortages of semiconductor chips. In response, the 2022 CHIPS Act offers a groundbreaking chance for the United States to regain its position as a leading force in modern semiconductor industry. This act aims at strengthening domestic semiconductor manufacturing, design and research, protecting the economy and national security, and reinforcing America’s chip supply chains. This push to re-shore semiconductor manufacturing in the U.S. has spurred massive investment but without talented STEM workforce, we'll lose the race. A survey on semiconductor manufacturing courses at more than 100 U.S. universities has been conducted. The survey encompasses an examination of course structures, curriculum frameworks, laboratory components, and emerging technologies in semiconductor manufacturing education. By synthesizing information from many U.S. institutions, this work aims to offer insights into the current state of semiconductor manufacturing education, identifying areas of strength and weakness, thereby contributing to the ongoing enhancement of workforce development in this critical area.",Industry-Academia Collaboration in Education,103,525
A Mixed Integer Programming Approach to Enhancing Throughput and Reducing Production Costs of Manufacturing Eco-Friendly Hair Extensions," With the global human hair extension market value exceeding $4 Billion in 2022, there is a growing concern about the environmental impact of traditional, plastic-based hair extensions. While the human hair extension market has thrived, in the past few years concerns surrounding the sustainability of the cheap plastic compositions used in these extensions have been raised. This has led to the emergence of environmentally friendly alternatives produced from vegetable fibers. The manufacturing process of these alternatives can be time consuming and requires substantial physical labor. Without proper material flow and scheduling, production costs of these sustainable extensions can skyrocket and lead to lack of market competitiveness. The objective of this research is to improve throughput while minimizing costs (labor and material) of producing eco-friendly hair extensions. A mixed integer programming model for optimizing workforce utilization, production targets, and material flow is developed. In addition, a simulation analysis is conducted to (i) verify the outcomes in the presence of uncertainty, and, (ii) explore alternative layouts and production settings for further improving the system efficiency. The results indicated a 50% improvement in throughput and $70,000 in annual cost savings as opposed to the current practice.",Production and Inventory Planning,182,526
A Comprehensive Characterization Study of Alginate-Gelatin-Tempo Mediated Nano Fibrillated Cellulose Composites for Extrusion-Based 3D Bioprinting Technique," Alginate's viscosity enhancement capacity by ionic crosslinking combined with Gelatin's cell-binding motifs, have elevated their role in extrusion-based 3D bioprinting. Gelatin shows improved cell functions due to the resemblance of collagen's structure, featuring RGD peptides. While pure gelatin faces temperature-related extrusion challenges, alginate supplementation helps. Even though Nano-fibrillated cellulose (NFC) augments hydrogel properties, it suffers due to uneven network entanglements. Surface modification via TEMPO oxidation produces TO-NFC, mitigating printability issues. TO-NFC's hydrogen-bonded crystallinity post-oxidation positions it as a robust bio-ink for 3D scaffold creation. In this paper, we will prepare a set of compositions using Alginate (2-5.25%), Gelatin (2-5.25%), and TO-NFC (0.5-1.0%) maintaining a total solid content of 8% to harness their combined benefits in the field of extrusion-based bio-printing process. We will identify the printability, shape fidelity, and biocompatibility of those compositions by conducting a series of characterization tests such as rheological test, scanning electronics microscopy (SEM), FTIR, thermal tests, and cytotoxicity encapsulating Human Mesenchymal Stem Cells (hMSCs). The outcome of those tests such as flow behavior, microporosity, chemical bonds, and cell viability will help identify the optimum composition/s for 3D bioprinting applications. The ability to control 3D printability and the favorable survival of cells make nano-fiber infused alginate-gelatin a promising option for creating precisely shaped scaffolds using the 3D bio-printing process.",Bioprinting and Biomedical Manufacturing Processes-II,20,527
Multilevel Neural Networks for Robust Learning," The growing size and availability of data in recent years has allowed machine learning models to become increasingly accurate and precise. Often however these datasets are extremely large, requiring a lot of time and computational resources to train successfully. Additionally, these datasets often contain significant amounts of noise and are extremely imbalanced. We address these problems by performing iterative graph coarsening in order to perform initial learning on a manageable size of the dataset. Once trained, the model is further refined by intelligently selecting datapoints from finer levels to ensure the model can generalize without being overwhelmed by noise in these levels.",Deep Learning II,41,528
Simulation and Digital Twin: Bridging the Gap," Modern industrial processes are being transformed by data-driven decision support tools like simulation, advanced data analytics, and Artificial Intelligence (AI). While Discrete Event Simulation (DES) accurately models manufacturing systems, it can be time-consuming and data-intensive. A Digital Twin (DT) can provide real-time insights and faithfully represent the system. DES and DT are different technologies with distinct capabilities. Therefore, this research aims to bridge the gap between DES and DT by demonstrating the steps to transform a fully capable DES model to a DT through a case study. Key transformation steps, challenges, and solutions are identified. This research concludes with lessons learned, critical success factors and recommendations for future studies.",Digital Twins,51,529
People-Centric Operational Excellence in Product Management for Small-Medium Manufacturing," Within small-medium sized niche manufacturing environments, project and product management structures that are commonplace in larger businesses are rare, causing disorganization. This disorganization is unreliable and increases stress on labor and professionals alike, limits capacity and improvement, and requires more resource allocation to accomplish tasks. In the business environment of manufacturing industries, project management is vital to driving and delivering value to the organization and its stakeholders. After a project is completed and begins to be manufactured, it becomes a product that exceeds the life cycle of the project it was once part of, and a team is set up to oversee the product management endeavor. However, the product may need to be overhauled, causing a new project to be set in motion by the product manager. This case study reviews a people-centric operational excellence (PCOEx) model to combat long lead times, high employee stress and reduce costs associated with product management operations, especially related to the research and development process. Entitled as the Sawhney model, this systems-thinking approach comprises four distinct modules, including a robust problem identification process, a hierarchical performance measurement system, a reliability-based platform, and a sustainability risk assessment, which focus is to improve company’s performance while enhancing employees’ quality of life. Reliability, retention, and human factor issues engendered by modern industry implored the implementation of the Sawhney model and proved to enhance the lead times of a new product engineering group while simultaneously decreasing their effort and stress levels.",Manufacturing Organizations II,140,530
Improving Medical Supply Chain in the Emergency Department – A Lean Framework," Shortages of essential medical supplies can compromise patient care and increase operational strain in the emergency department (ED). Despite restocking efforts by the central storage, the ED faces critical challenges. To address these challenges, this study employs the lean framework. From 6 AM to 10 PM, the ED employs two supply staff to fulfill nurses’ requests. However, between 6 PM and 6 AM, central storage remains closed, necessitating the forwarding of supply requests to the transport department. This redirection causes delays, requiring nurses to involve ED patient care technicians or supply coordinators in placing the orders. The approach begins with defining the problem with a process flow diagram and value stream map. Followed by the analysis of root causes and data including PAR levels of supplies that are frequently depleted. Solutions implemented include restructuring communication, optimizing PAR levels, bin sizes, 5S the supply rooms. Control plan will sustain the improvements over time resulting in streamlined process for timely access to essential medical supplies, enhancing patient care and operational effectiveness in the emergency department.",Process Improvement in Health Systems,178,531
"Development of a Customized, Modular Hydroponics Chamber"," In the changing world, agriculture is becoming increasingly difficult, with up to 70% of farmable land at risk of becoming unusable by the second half of the 21st century. Factors like this drive home a need to create innovating farming solutions, and one such method is hydroponics. This type of agriculture is characterized by growing plants without soil, and is generally conducted in an enclosed environment. There has been a significant amount of innovation since the hydroponics was invented in 600 BC Mesopotamia, and more recently with its reintroduction to modernity in the 1938. However, there is little published work on a single chamber conducting modular and customized investigations into the effectiveness of different features. This paper serves as a description of our process for constructing a custom hydroponics chamber and the potential for future work.",Harvesting Hope: Innovations in Food Security and Ending Hunger (SDG 2),77,532
A Simulated Annealing approach to Optimizing Cross-Docking Operations in Logistics," In logistics and supply chain management, cross-docking operations play a pivotal role in enhancing efficiency and reducing storage costs. This study introduces a novel application of Simulated Annealing (SA), a probabilistic technique for approximating the global optimum of a given function, to optimize the cross-docking process. The objective is to minimize the total operation time and enhance dock utilization under the constraints of truck schedules and loading times. Our approach adapts the SA algorithm to the unique context of cross-docking, involving a dynamic and complex coordination of inbound and outbound trucks. We meticulously tailor the cooling schedule and acceptance probabilities to suit the intricate nature of logistics operations. The efficacy of the SA method is demonstrated through a comparative analysis with traditional Integer Programming models, highlighting the advantages in terms of solution quality, computation time, and adaptability to varying scenarios. Preliminary results reveal that SA not only provides competitive solutions compared to conventional methods but also exhibits robustness across diverse logistical configurations. This research contributes to the field by offering a scalable and flexible optimization tool capable of handling the increasing complexity and variability inherent in modern logistics networks.",Warehousing,238,533
Renewable Hydrogen Generation: Environmental Implications and Supply Chain Analysis," Battery Electric Vehicles (BEVs) have emerged as environmentally friendly transportation solutions. Yet, challenges persist, particularly in the reliance on fossil fuel-derived electricity for charging and the inefficiency of building extensive charging infrastructure. To address these concerns, this research develops a hydrogen fuel supply chain as an alternative energy source for BEVs. Focusing on California, a state at the forefront of eco-conscious initiatives, this research aims to model a hydrogen fuel supply chain using existing infrastructure, offering a viable solution to the current environmental dilemma. Through the utilization of simulation software, we construct a detailed model of the California hydrogen fuel supply chain, drawing inspiration from the existing gasoline distribution network. The simulation will assess the environmental impact by quantifying carbon emissions saved compared to traditional Internal Combustion Engine (ICE) vehicles. This approach provides a comprehensive analysis of the potential benefits and challenges associated with implementing hydrogen fuel, contributing valuable insights for the transition to sustainable and efficient transportation systems. By showcasing the feasibility of a hydrogen fuel supply chain, our research not only addresses the environmental concerns of BEVs but also contributes to reducing overall fossil fuel reliance. This investigation offers a holistic perspective on the multifaceted implications of hydrogen fuel implementation, laying the foundation for informed decision-making in the development of future transportation ecosystems.",Supply Chain Sustainability 1,217,534
Predictive Maintenance Using Internet-of-Things: An Exploratory Case Study for Small and Medium Manufacturer Applications," Ensuring optimal equipment maintenance in industrial settings is still a challenge for manufacturers. Industry 4.0 and the Internet of Things (IoT) offer a platform to use digital technology to gather and analyze real-time data to address these challenges. However, small and medium manufacturers (SMM) still face difficulties with these technologies, despite the various applications documented in the literature. This research presents the development, testing, and implementation of an IoT-enabled predictive maintenance platform, focusing on SMM applications. The case study was conducted in a facility that contains additive and subtractive manufacturing equipment. The facility aims to implement real-time monitoring and a predictive maintenance program for an air compressor system using low-cost sensors to detect abnormal vibration patterns. Furthermore, this work makes the codes, sensor specifications, and equipment details available to facilitate SMMs' adoption of the proposed solutions.",Digital Manufacturing and Industry 4.0-I,45,535
Enterprise Valuation: A Method for Reducing Investment Risk," Asset diversification is a well-established strategy frequently introduced in engineering economy courses that can reduce the risk of loss and increase the likelihood of long-term wealth accumulation. However, identifying suitable assets to acquire in a portfolio of investments can be challenging for individual investors. In recent years, the stock prices of well-known companies have soared based on momentum investing, and brokerages tend to support this outlook by advocating unrealistically high 12-month future targets. Individual investors should not depend solely on these outlooks but rather perform some quantitative analysis of their own prior to acquiring an investment asset. However, the resources to perform this analysis are quite limited. Company Valuation is a methodology that attempts to quantify a company’s worth using time series evaluation. The value of a company involves assessing its operational (enterprise) and financial health. This paper presents a template that individuals can use to value a company using publicly available information to determine it’s worth and also it’s suitability for acquisition given the equity value to the shareholder versus current market share price. The paper presents findings for five publicly traded companies, which are compared to current marketplace conditions, and describes the strengths and weaknesses of the methodology. The template provides a useful tool for individuals to value a company using publicly available information. The strengths and weaknesses of the approach are discussed. The paper concludes that the approach provides a useful tool for individuals to make better decisions that will lead to reduced investment risk.",Decision Analysis and Economic Evaluation,38,536
Network Deployment for Electric Vehicle Battery Swapping and Charging Stations with Lateral Transshipments," The rapid proliferation of electric vehicles emphasizes the importance for logistics companies to strategically integrate electric vehicles into their freight transportation systems to optimize the environmental impact and efficiency of freight operations. Battery Swapping Stations (BSS) have been gaining attention and interest for the swift replacement of depleted battery with a charged battery, handling the obstacles regarding to the traditional charging methods. The discharged batteries will be charged at Battery Charging Stations (BCS), either at the service location or through central collections. Lateral transshipments between stations involve the redistribution of batteries and offering a solution to optimize resource utilization and enhance the overall efficiency of the charging network. To consider the integration of battery swapping and charging stations with hyperconnected logistic hub networks, this paper jointly determines station localization and sizing, freight consolidation and routing, and battery inventory and transshipment. We formulate the problem with a mixed integer programming model to optimize the total system cost, including site leasing cost, freight transportation cost, battery leasing, charging and transshipment cost over multiple time intervals. Through comprehensive mathematical modeling and analysis, we investigate the effects of deploying networks with lateral transshipment on network efficiency, cost-effectiveness, and other overall performance.",EV logistics,58,537
Modeling Panic Buying in Supply Chains: An Agent-Based Simulation Approach in a Game-Theoretic Framework for Decision-Making," Title: Modeling Panic Buying in Supply Chains: An Agent-Based Simulation Approach in a Game-Theoretic Framework for Decision-Making The phenomenon of panic buying in supply chains has become increasingly relevant, especially during times of crisis and uncertainty. This research study introduces a novel approach to comprehending panic buying behavior using an agent-based simulation within a game-theoretic decision-making framework. The proposed agent-based simulation model captures interactions between customers, modeling intricate decision-making processes and information flows within the supply chain. The game theory has been utilized to analyze how customers strategically adapt their purchasing behaviors in interaction with other players. This research aims to provide an in-depth understanding of panic buying dynamics and offer valuable insights for supply chain stakeholders. Through simulating and analyzing panic buying behaviors, the objective is to gain a better understanding of the panic buying dynamic and contribute to the development of more resilient supply chain strategies and crisis management protocols.",Innovative topics in supply chain 2,113,538
Advancing Quality Control in Printing: An Automated Image Processing Framework for Precision Defect Detection," : This study introduces a novel methodology for defect detection in the printing industry, enhancing quality control and process monitoring through advanced computer image processing. Our approach automates the identification and classification of defects by comparing the ideal and manufactured product images. Key to this process is the use of the Structural Similarity Index Measure (SSIM) and an algorithm that assesses pixel-wise differences between images. We employ the Canny edge detection algorithm to prepare the images for analysis. This well-known technique effectively highlights key features while minimizing false positives, which is crucial for accurate defect detection. The process involves steps like Gaussian smoothing to reduce noise, gradient calculations for intensity changes, and edge tracking to ensure clear edge delineation. The core of our methodology lies in using SSIM for making informed decisions about product conformity. We establish a threshold specific to each application to determine the acceptable level of deviation from the ideal image, ensuring non-defective items are correctly identified. The outcome is a comprehensive framework that identifies defects and provides insights into the quality control processes, promoting continuous improvement in the printing industry. This integrated, automated approach represents a significant advancement in quality assurance techniques. It offers the potential for more efficient, precise, and consistent defect detection, setting a new standard for quality assessment in the printing sector.",Statistical Learning and Artificial Intelligence for Quality Control I,211,539
"Wearable Technologies in Warehouse Logistics: Enhancing Productivity, Safety, and Decision-Making"," In today's logistics environment, operational inefficiencies and a lack of real-time information pose business challenges. These limitations result in limited asset visibility and difficulties in monitoring orders. In an era where data drives decision-making, wearable technologies, such as smartwatches, are gaining significance in workplaces. This research aims to assess the impact of these devices on warehouse logistics. It will discuss the impact of wearable device effectiveness on worker productivity, streamlining employee training, and enhancing overall well-being and safety. Our study explores the potential of measurable attributes such as location tracking and a hands-free ordering system. In addition, it will analyze the economic impact in terms of communication, information sharing, and safety. This research aims to illustrate that wearable technology serves not only as a valuable tool for enhancing productivity but also as a strategic investment within the logistics sector. By adopting and maximizing the benefits of wearable technology, companies will have valuable insights guiding them toward informed decisions.",Poster Presentations,169,540
A Comorbidity Network Analysis for Hospitalized Patients to Aid Early Pandemic Preparedness," The COVID-19 pandemic, caused by the new and deadly coronavirus SARS-CoV-2, emerged in late 2019 and then rapidly spread across the globe, leading to widespread illness, significant loss of life, strained healthcare systems, and profound socio-economic disruptions. Characterized by its high transmission rate and elusive nature, the pandemic prompted unprecedented public health measures, including lockdowns, vaccination campaigns, and extensive research efforts to combat and understand the virus. Early response and planning to a pandemic can help achieve efficient resource allocation, targeted public health interventions, accelerated research and vaccine development, informed economic and social planning, global collaboration, and the fostering of public trust, collectively minimizing the impact and facilitating a coordinated response. In this study, we employ a comorbidity network analysis (CNA) approach, which maps interconnections between diverse medical conditions within patient populations to uncover hidden associations and patterns among co-occurring diseases. We also compare the networks before and during the pandemic using the National (Nationwide) Inpatient Sample (NIS) data. NIS is an all-payer inpatient healthcare database designed to produce U.S. regional and national estimates of inpatient utilization, access, cost, quality, and outcomes. The results of this study can help enhance our understanding of complex health interactions and provide guidance for care planning upon a pandemic outbreak.",Emergency Response and Preparedness  in Health Systems,60,541
Evaluating the Impact of Vaccine Hesitancy on the Allocation of Vital Resources During COVID-19 Pandemic," The COVID-19 pandemic highlighted the significant challenges in healthcare resource allocation decisions. These decisions were impacted by the virus transmission rate, healthcare demands, and vaccine hesitancy. Operations research (OR) models were central in devising optimal strategies for resource distribution to contain the epidemic. Some OR models used offline the epidemiological compartmental models, specifically extensions of the Susceptible-Exposed-Infectious-Recovered (SEIR) model, to predict the spread of the COVID-19 virus. This study expands the SEIR model to integrate the distinctive attributes of COVID-19 and the impact of vaccine hesitancy on disease dynamics. We incorporate the proposed compartmental model into a multi-stage stochastic program (MSP). The MSP provides a dynamic framework for decision-making under uncertainty by capturing how the virus spreads over time. We apply this model to explore key research questions: What are effective resource allocation strategies at the onset of a pandemic? Specifically, how do the timing and scope of policies, like the Defense Production Act, influence the spread of the disease? What are the trade-offs between equity and effectiveness in resource allocation at the onset of a pandemic? We employ real-world data to validate our model and address these complex questions. Via our numerical analysis, we demonstrate the value of MSP over the deterministic counterpart. Our analysis also reveals that a strict focus on equity at the onset of a pandemic might lead to higher fatality rates, necessitating a careful evaluation of policy trade-offs.",Public Health,183,542
Integrated Modeling of Shared Mobility Systems and Their Sustainability Impact," Shared mobility, including bike-sharing, shared e-scooter, and ride-hailing, could improve transportation sustainability when substituting private car use and integrating with public transit. However, if shared mobility competes with other green modes, it cannot guarantee sustainability benefits. The competing and synergistic relationships between conventional modes and shared mobility are complex and not well-studied to date. We built a city-scale agent-based model that is supported by real-world mode choice survey and trip data to better study how different design and pricing of different mobility systems will lead to different competing and synergistic relationship among the shared mobility and conventional transportation systems. Using Indianapolis as the case study city, our results show that the current deployment of shared mobility systems (mainly in downtown area) does not help improve urban sustainability because the shared mobility is primarily competing with green travel modes such as walking and bus. To reduce transportation emissions, the shared micro-mobility vehicles need to be optimally deployed and rebalanced to areas that can supplement public transit network to enable multi-modal trips as an alternative to driving.",Modeling Environments,147,543
Enhancing Care Access through Process Improvement in a Pediatric Behavioral Health Facility," A mental and behavioral healthcare center in Northwestern Pennsylvania, dedicated to providing superior care to children, confronts challenges with its patient intake and referral processes. The center specializes in trauma-informed care and offers evidence-based treatments, clinical practices, and professional training. Yet, the inefficiency of its current intake and referral procedures impedes timely access to its services, particularly in outpatient and partial hospitalization programs. Currently, the intake process spans five and nineteen business days for outpatient and partial hospitalization services, respectively. This protracted duration falls short of the center’s service standards and patient expectations. The center aims to reduce these times to four and seven days, respectively, to enhance service efficiency and patient satisfaction. To achieve this, process improvement methods are used to propose an alternative process flow and a refinement to the referral documents and forms. Our approach focuses on eliminating process bottlenecks, reducing unnecessary steps and waste, and streamlining documentation. This redesign aims to address the key issues of excessive processing, protracted waiting times, and suboptimal process flow, which collectively hinder the center's capacity to fully utilize its services. The ultimate goal is to establish a centralized care access system, integrating billing and financial operations, within a six-month implementation period. This transformation is expected to significantly improve patient and family experiences, ensuring quicker and more seamless access to vital mental health services, thereby reinforcing the center’s commitment to delivering exceptional care.",Process Improvement in Health Systems,178,544
Extraction and Detection of Manufacturing Features using KAZE Descriptors," Manufacturing features are geometric volumes whose manufacturability is dependent on the type of machining operation, material composition, required tolerances, and available tooling. The automatic recognition of manufacturing features on parts is challenging as many manufacturing features exhibit high degrees of similarity and interact in complex ways that are difficult for traditional methods to identify. As a result, recognition is generally performed manually by human planners who are prone to error. This work uses KAZE descriptors to create a computer vision algorithm capable of automatically extracting and detecting manufacturing features on digital CAD models using a reference image library. Results indicate that the proposed computer vision algorithm is able to recognize manufacturing features in a way that is accurate, precise, and reliable. This is demonstrated through the detection of a singular manufacturing feature located on a part and the detection of interacting manufacturing features on a part. Once identified, manufacturing features can be used to simplify downstream planning by mapping part characteristics to machining capabilities.",Manufacturing III,137,545
Leveraging on Immersive Technologies to Develop a Framework to Assess Worker Training in Reverse Logistics," The widespread integration of technology is a contemporary reality in all industries, where it acts as a major disruptor and contributes to the creation of competitive advantages. A compelling illustration of this phenomenon is the application of immersive technologies, such as Virtual Reality (VR), Augmented Reality (AR), or Extended Reality (XR), for corporate training purposes. While immersive training has been extensively reviewed in high-risk domains, including the military, surgery, and aircraft maintenance, its potential in other industries has remained unexplored. For example, sectors characterized by elevated workplace injury rates like transportation, warehousing, construction, and manufacturing, are excellent candidates for the adoption of new training methods. These industries require a paradigm shift to ensure that new workers receive training in a safe environment, mitigating the risk of more accidents. Simultaneously, this new training context must guarantee that, upon completion, workers not only possess the requisite skills, but also feel confident and comfortable executing learned tasks.This paper contributes by presenting a methodological framework that companies in the pallet repair business can employ to gauge the potential advantages derived from integrating immersive technologies into their training processes, in contrast to conventional methods such as handbook reviews, video training, and on-site training. This framework proposes that benefits can be evaluated through a two-dimensional analysis. The first dimension encompasses core productivity metrics, while the second dimension assesses how an immersive and secure environment impacts the learning experience and workers' confidence when completing a new task.",Manufacturing & Design for Human Factors and Ergonomics,134,546
Design of Experiments for Artificial Neural Network Architecture," Artificial Neural Networks are nonlinear multivariable models that link input-output data as an adaptive learning process that is meant to mimic pattern recognition in human brains. The construction of neural network models has been described as an artform owing to the number of input nodes, the number of hidden layers, the number of epochs, the learning rate, and the choice of activation functions. The use of design of experiments to identify appropriate factor settings that increase neural network accuracy is an attractive solution as opposed to an ad-hoc or naïve approach. This work develops a simulation metamodel that accurately represents the input-output relationship of a discrete-event model using an artificial neural network that has been constructed using design of experiments to reduce predictive loss and increase accuracy of the network. Using the output of the discrete-event simulation as labeled ground truth data allows backpropagation of the neural network where different architectures are evaluated using design of experiments to select parameters such that overfitting is avoided. The use of simulation metamodels as an analytic solution to discrete-event models reduces the computational cost and runtime associated with execution.",Integrating AI/ML in Simulation I,114,547
Hiatal Hernia Detection Using Novel End-to-End Deep Learning Model with Explainable AI," Hiatal hernia is a condition where the stomach or other internal organs push through the diaphragm into the chest. It is still relatively unexplored area with scanty research making it crucial to enhance the efficiency of detecting this condition by automating the task and providing preliminary diagnosis. Hence, this paper proposes a novel approach to detect hiatal hernias using Deep Learning and Python. This model seeks to increase the accuracy of hiatal hernia detection using explainable AI technology. Compared to existing pretrained models, creating a custom model reduces training time. The model also facilitates integrated preprocessing, which enhances image contrast and provides more information for the learning procedure. This paper presents an innovative methodology for the detection of Hiatal Hernia leveraging Deep Learning and Explainable AI techniques. We achieved a robust classification of positive and negative cases of Hiatal Hernia using ChestX-rays, attaining a notably high level of accuracy. To provide transparency and interpretability in our model's predictions, we employed LIME, an Explainable AI method. This approach facilitated a deeper understanding of the influential features that contributed to the prediction outcomes. These findings collectively demonstrate the efficacy of our approach, offering a promising avenue for more accurate and expedited Hiatal Hernia detection, while also providing valuable insights into the diagnostic process.",AI in Health Systems,1,548
Blockchain Platform Selection for Sustainable Supply Chains: Integrating a Causal-Based Model with TOE Theoretical Framework," Due to the digitization phenomenon, conventional Supply Chain Management (SCM) systems are being replaced by data-driven and information-based alternatives. Some organizations seek to adopt emerging digital technologies, especially Blockchain Technology (BT), because of its inherent features (e.g., decentralization and traceability) to support real-time information sharing and enhance socio-environmental responsibility. As various platforms (e.g., Hyperledger and Quorum) have been introduced to provide supportive BT-based solutions for Sustainable Supply Chains (SSCs), there is a need to choose a feasible and effective BT platform to guarantee beneficial utilization. This study aims to bridge the gap between theory and practice to support SSCs to benefit from BT practices. Accordingly, we propose a decision support approach to select the best-fitting BT platform by analyzing a trade-off between the BT features (e.g., scalability and reliability) and adoption requirements (e.g., implementation cost) to ensure SSC’s success. The proposed approach is developed by integrating the extended version of a causal-based model in an uncertain environment and the Technology-Organization-Environment (TOE) framework to explore evaluation criteria and model the potential causal relationships among them. The TOE-based model is followed by the implementation of a hybrid learning algorithm and an outranking technique to determine the importance of each criterion and prioritize BT platforms. The proposed approach reflects the impacts of multiple aspects on adoption decisions and introduces the best-fitting platform to address the specific needs of an SSC network.",Supply Chain Sustainability 2,218,549
Exploring Nutritional Equity in Foodbank Supply Chains," Food insecurity, defined as insufficient access to food for a healthy and active life, affected approximately 10.2% of U.S. households in 2021. A concerted effort from both the government and non-government organizations is underway to address this challenge in the United States. This study centers on the Foodbank of Eastern and Central North Carolina (FBCENC), a nonprofit hunger relief organization pivotal in collecting and distributing food donations to local agencies serving individuals in need. However, despite the critical role of food banks, nutritional considerations are often overlooked. To address this gap, the study employs the Healthy Eating Research (HER) Nutrition Guideline, categorizing nutrition types (Red, Yellow, and Green) to assess and enhance the nutritional equity of the current distribution system. A linear programming model is proposed and equity is adopted as the performance measure. The study aims to develop a model that strategically reduces nutritional disparities across the network. By incorporating HER guidelines and emphasizing equity in distribution, this research contributes to the broader objective of creating a more nutritionally equitable response to food insecurity within the non-profit sector.",Sustainability and equitable Operations,224,550
Data-Driven Patient Allocation for Healthcare Facility Optimization Under Uncertainty with SIR Dynamics," This paper addressed the formidable challenge of Covid-19 patient allocation in regions with limited healthcare facilities. A nonlinear mathematical model with two integral components was proposed. First, data on hospital capacities was gathered, and using time series modeling patient-to-bed ratios and emergency treatment needs are estimated. Next, a Susceptible, Infected, Removed (SIR) model was integrated to understand disease dynamics with consideration of within and between county healthcare facility transfers. The aim was to minimize unmet demand for beds while considering disease spread within a stochastic setting, where the uncertainties could be observed in both supply and demand sides as reflected in hospital capacities and in disease spread rates respectively The model was employed to assign patients across regions, accounting for disease transmission implications. This study, based on the data of Florida's 67 counties during Covid-19 pandemic, would deepen our understanding of disease transmission and patient assignment dynamics by the analysis of efficient patient allocation in resource-limited settings with uncertainty.",Healthcare Supply Chain,88,551
Evaluating the potential of disparate sensing systems for machine learning-based in-situ microstructure defect detection in direct energy deposition," The utilization of machine learning (ML) models in metal additive manufacturing (AM) has demonstrated significant promise in overcoming key quality concerns. Recent research on the topic highlights the importance of using process and melt pool signatures in deep temporal and spatiotemporal models to predict defects on-the-fly. While the potential of these models to predict defects has been evaluated in different studies, hardly any work exists on evaluating the potential of different sensing systems for these models. Moreover, the existing studies focus mostly on visual concerns and process anomalies, while leaving the microstructural defects to post-process destructive evaluation systems. Direct energy deposition (DED) AM process has the potential to build and repair complex geometries. However, the development of the deposition process is challenging due to a lack of understanding of the complex relationship between process parameters and the resulting microstructure. This work evaluates the potential of different sensing systems to perform in-situ microstructural defect detection using temporal and spatiotemporal models to support DED process development. Specifically, a pyrometer, a visible light-based camera system, and two mid-wave infrared camera systems are used to monitor the process. Owing to its popularity, a CNN-LSTM architecture called Long-term Recurrent Convolutional Network is used for spatiotemporal modeling whereas a vanilla LSTM architecture is used for temporal modeling. The systems are compared in terms of prediction accuracy, implementation effort & cost, inference efficiency, and data fidelity. The work is expected to guide industrial implementation of ML-based in-situ defect detection systems for AM processes.",Directed Energy Deposition Additive Manufacturing Processes,52,552
Experimenting with ChatGPT in STEM Courses: Faculty and Students' Perspectives.," We describe an experiment using ChatGPT in an Engineering Economics course at Texas Tech University - Costa Rica. Two of the authors participated in the experiment as students. Students must write two essays on important societal economic topics. One of the topics was on the effectiveness of raising the Federal Reserve Bank minimum wage. There is always a guarded suspicion from the faculty perspective that students will attempt to cheat to avoid doing the necessary background material reading, and in the actual writing of the essays, the latter being perhaps an activity that is perceived as falling in lesser favor among STEM students, and thus the value of this type of assignments. The experiment consisted in “relaxing the rules” that students had to follow. The use of ChatGPT was allowed at the student’s discretion, but if chosen it should be clearly stated, and the student’s opinion and perspective on the validity and correctness of the ChatGPT generated essay should be added. Poor use of the AI tool was evidenced in some cases by the perfunctory use of, e.g., “I agree with what ChatGPT wrote”. Other cases showed a more pedagogical use, where students would state reasons and disagree with ChatGPT, and others would use it as an additional aid to comprehend better the issue to arrive at a personal position on it. From the student's perspective, in the best of cases ChatGPT is viewed as just another useful tool to help them learn faster and more effectively.",Innovations in Teaching and Learning Technologies,109,553
FMEA - Risk Assessment of Destination Dispatch Software for an Elevator Bank in a Hospital Setting," As a major hospital system expanded its facilities to meet increased patient demand, one of its busiest employee elevator banks (Elevator GB) required updated software to address the resulting increase in daily usage (average 12,000 requests) and unsatisfactory wait times (average 50 seconds). Therefore, the institution invested $1.5 million in Destination Dispatch/Agile software to improve Elevator GB wait times to maximize patient-related staff flow. Of concern was that the new software would invite potential failure points that could cause major patient safety issues. To prepare for such events, the team created a process flow map incorporating all entities engaged in successful operation of the new software system. Then the team was guided through an FMEA (Failure Mode and Effect Analysis) to identify all possible failure modes and causes, existing controls, recommended actions, and responsible personnel. Based on RPN scores, the possible causes were prioritized for mitigation or elimination. The team identified 40 such causes and developed the following plans of action: Communication Plan, Disaster Recovery Plan, Business Continuity Plan, and Downtime Plan. For continuous monitoring of elevator functionality, there was also a Vulnerability Management Program handled by designated system owners. This project team met twice per week for two months to ensure the system would pass all Go-Live tests as scheduled. Every item on the check list operated optimally, and the new software system went live successfully.",Healthcare,81,554
Fulfilling Triple Bottom Line Objectives: A Mathematical Modeling-Based Approach for Designing a Sustainable Supply Chain," We propose a mathematical modeling-based approach for designing a sustainable supply chain (SC) that integrates lean tools and practices to facilitate fulfilling the triple bottom-line objectives. The proposed model aims to accomplish circular economy systems as much as possible. In the forward loop, the model plans to obtain new components from enlisted partner suppliers for manufacturing new products. In the reverse loop, the SC manages the collection of customer returns and transports them to recovery service-providing cooperatives (RSPCs) through a contractual arrangement with retailers. Customers are incentivized to return end-of-useful-life products through the retailers according to the product’s label which specifies the return condition. The SC maintains a collaborative relationship with retailers and could establish visibility between the retailers and their manufacturing by including advanced communication systems and maintaining mutual trust-based transactions. The recovery and disposal through the mentioned RSPCs include inspection of the returnable to decide whether to provide repair, refurbishment, or recycling of products, components, and packing materials as applicable. RSPCs are the cooperatives of small firms formed by interested community members around SC manufacturing. The SC supports them by providing training and advisory services for arranging bank loans for starting and running their business. RSPCs are also supported by SC manufacturing with technical training for repairing, refurbishing recovery, and recycling through environment-friendly practices. Circular economy loops are planned around the operations of partner suppliers, RSPCs, and the SC. The applicability of the model is illustrated in a numerical example.",Supply chain design 2,222,555
Immersive Digital-Twin Simulation-Driven Nursing Education and Job Training," We aim to establish the new simulation modality through the integration of immersive virtual reality (VR) simulation and digital twin (DT) toward transformative nursing education. This approach closes the loop with a care team, patients, and their dynamic health conditions in a shared care environment. DTs of the care environment, equipment, members of the care team, patients and their specific health conditions, are all developed into a generic system architecture. Our interactive immersive VR incorporates the DTs and allows a group of nurses to experience realistic care situations that involve patients, their electronic health records, and care contexts. Specifically, this new simulation architecture integrates client applications for running the VR, Cloud services for data processing, and tracking of a physical environment (i.e., physical twin [PT]) to model team interactions within DT. Through this simulation architecture, complex team-based dynamics for decision-making, behaviors, and communication, will be represented using a dynamic Bayesian network (DBN). Once implemented, the DT built here will become the first clinical “experiential learning” reference source for nurses, which allows a user in a virtual world to directly navigate through and learn from various instances of nursing process and clinical judgement.",Health Systems for Human Factors and Ergonomics 2,80,556
Physics-informed Weakly-Supervised Learning for Quality Prediction of Manufacturing Processes," In manufacturing processes, a multitude of sensors are typically deployed to collect data of process parameters. While this provides an opportunity to better predict and control the quality of the final product, the relationship between the process variables and the desired final quality is often not well-understood. To establish this relationship, machine learning (ML) models can be used. However, collecting large, labeled datasets to train the ML model can be difficult, as creating such datasets typically involves costly or destructive end-of-line quality testing of the products. To overcome this challenge, we propose a novel framework called Physics-informed Weakly-supervised Learning (PWL) that integrates physics-based models with data-driven ML models. By leveraging physical knowledge and using the outputs of physics-based models as weak labels, PWL offers an alternative to traditional methods that require large, labeled datasets. Our approach simultaneously optimizes the data-driven ML model, as well as the discrepancy and calibration parameters of the physics-based model, resulting in superior predictive performance compared to either model used alone. We demonstrate the effectiveness of PWL through simulation experiments, comparisons with existing methods, and two real-world case studies, highlighting its potential for improving quality prediction in various manufacturing systems.",Reliability II,188,557
Backpack selection: A human factors and engineering analysis detailing the impact of backpack selection.," The research presented was aimed to evaluate the differences between backpacks designed for travel and backpacks designed for recreation. A feature analysis of commercially available bags identified test cases for experimentation. Participants were asked to pack items and hike with various bags. The usage, advantages and disadvantages of various design features were determined. The results of this study indicate that recreational backpacks require additional exertion when compared to travel backpacks when walking at a moderate pace for thirty minutes over even terrain. Additionally, the results indicate that travel backpacks require less time to pack. The data further indicates travel backpacks require less time to find items in the bag, and result in increased postural stability when compared to recreational backpacks. Ultimately, the outcomes of this study provided both an efficiency and ergonomic justification for backpack selection.",Physical Ergonomics,164,558
Intelligent Decision Support System for Steel Market Analytics," The price of steel is set by multiple market factors as well as domestic and international events resulting in high price volatility. As such, understanding the trends in steel pricing is crucial for making profitable procurement decisions. Through correlation and covariance analysis we have identified several new critical economic predictors that impact the price of steel. This data is then used in an interactive decision support system utilizing a visualization dashboard as well as a predictive model to support making buy or no-buy decisions. Numerical experiments indicate our model, a blend of time series analysis, linear regression, and machine learning, can predict the price of steel with a high degree of accuracy up to 12 weeks in advance.",Center for Excellence in Logistics and Distribution (CELDi),25,559
Simulation-based analysis of rail network layouts in a seaport," Seaports serve a critical role beyond domestic trade and import and export facilitation, acting as vital hubs connecting various transportation modes, particularly land-based networks. Utilizing railways for cargo transport between seaports and hinterlands is a sustainable way to transport cargo. Enhancing the port performance mainly relies on the performance of the rail network within the seaport. Inefficient operation of the rail network in the terminal can generate congestion in the terminal, consequently negatively affecting port capacity and the amount of cargo handled in the port. This paper addresses congestion issues in the Trois-Rivieres port, presenting scenarios to alleviate congestion and enhance the rail network's performance to eliminate the bottleneck effect noted by port authorities. Proposed changes focus on altering the port current network layout to eliminate intersections and enhance wagon movement flexibility. Utilizing Civil3D, an extension of AutoCAD, ensures the feasibility of the new layout, while a simulation approach is used to model the rail network in the port and the movement of wagons on this network. Findings reveal existing congestion and bottlenecks, signaling an opportunity for performance improvement. Two scenarios were evaluated on their performance to address bottlenecks by using static criteria on the infrastructure-related modifications to the layout of the current rail network and dynamic criteria about the operations efficiency and capacity usage. These criteria are used to evaluate and compare the proposed solutions with the actual port operations. This research provides valuable insights for mitigating congestion within the rail network, offering practical solutions to optimize port performance.","Digital Innovation in Supply Chain Management: Simulation, Decision Support, and Shared Tools",44,560
Discrete-Continuous Gaussian Mixture Models for Wind Power Generation," Gaussian Mixture Models (GMM) are an effective representation of resource uncertainty in power systems planning, as they can be tractably incorporated within stochastic optimization models. However, the skewness, multimodality, and bounded physical support of long-term wind power forecasts can entail requiring a large number of mixture components to achieve a good fit, leading to complex optimization problems. We propose a probabilistic model for wind generation uncertainty to address this challenge, termed Discrete-Gaussian Mixture Model (DGMM), that combines continuous Gaussian components with discrete masses. The model generalizes classical GMMs that have been widely used to estimate wind power outputs. We employ a modified Expectation-Maximization algorithm (called FixedEM) to estimate the parameters of the DGMM. We provide empirical results on the ACTIVSg2000 synthetic wind generation dataset, where we demonstrate that the fitted DGMM is capable of capturing the high frequencies of time windows when wind generating units are either producing at maximum capacity or not producing any power at all. Furthermore, we find that the Bayesian Information Criterion of the DGMM is significantly lower compared to that of the classical GMM using the same number of Gaussian components. This improvement is particularly advantageous when the allowed number of Gaussian components is limited, facilitating the efficient solution to optimization problems for long-term planning.",Energy Systems Maintenance and Forecasting,65,561
A Cost-Sensitive BiLSTM Approach for Control Chart Pattern Recognition," The utilization of control chart pattern recognition (CCPR) algorithms in smart manufacturing is crucial for advanced fault detection systems. A significant challenge in CCPR models arises from class imbalance, a factor that can compromise the model's performance if not addressed. Furthermore, existing CCPR models often suffer from poor performance in early abnormality detection in real-time production environments due to the separation of abnormal patterns and signals during training on simulated data. To address these challenges, our approach involves developing a cost-sensitive, bi-directional long short-term memory neural network tailored for sequences with mixed normal and abnormal signals.",Statistical Learning and Artificial Intelligence for Quality Control II,212,562
Development a custom framework to assess and calculate physical infrastructure resilience index- Data-driven approach," Community resilience can be defined as a community’s capability to proactively anticipate, absorb, recover from, and adapt to actual or potential adverse events in a timely and efficient manner. This encompasses the restoration and enhancement of fundamental functions and structures. One of the most important dimensions in community resilience is Physical Infrastructure, which includes transportation systems, communication networks, utilities, and all physical systems of a region or nation that often produce goods and services. The aim of this study is to review physical infrastructure-based frameworks and propose a custom framework for Jefferson County, Texas, USA. The concept of resilience is heavily influenced by functionality and interdependency, which are critical in determining the resilience index. To achieve this at the beginning stage, variable assessment was done by expert perspective orientation. Then, using factor analysis and the weight entropy method, the resilience score was calculated. A significant consideration in this process is the availability of historical functionality data spanning several years. In this study, we use selected variables in the physical infrastructure dimension to create a model. Data for this study was collected from public sources and databases, which were prepared by experts. For calculations based on this data, Python was employed. By revealing the resilience score, decision-makers will be able to plan and implement practical solutions to increase total resilience in the communities that leads to decrease recovery time and costs on a disaster event.","Building Sustainable Communities: Enhancing Early Child Development, Infrastrucure, Park Access and Industrial Efficiency (SDG 11)",22,563
A Usability Study of a Virtual Reality-Based Manufacturing Digital Twin," With the fourth industrial revolution, the integration of Virtual Reality (VR) with Digital Twins (DTs) has shown promising prospects in smart systems. While much scientific and development work has focused on the technical feasibility and usefulness of DTs, very little attention is given to the usability of DTs and how they are perceived by the end-users. This study conducts a comprehensive usability analysis of VR-based DT which is used for monitoring, inspection, and control of manufacturing station consisting of 3D printers and collaborative robots. Through a structured methodology, including participant recruitment representing diverse user profiles, the study investigates usability aspects such as ease of use, learnability, and task efficiency within the VR environment. Tasks are defined and user interactions are observed while encouraging verbalized thoughts. Data collection encompasses qualitative feedback via observation and surveys, coupled with quantitative metrics such as task completion times and error rates. The analysis synthesizes these findings to identify usability issues and areas for enhancement, aiming to bridge the gap between the VR simulation and real manufacturing processes. The results outline actionable insights and recommendations to optimize the VR-based DT’s usability, ensuring it aligns more seamlessly with user needs and industry requirements.",Work systems and services for Human Factors and Ergonomics,242,564
Stress Analysis in Multi-head Large Scale Additive Manufacturing," Large-scale additive manufacturing is a rapidly evolving field that offers unique opportunities for manufacturing massive structures such as full-size prototypes of the submarine hull, wind turbine molds, and multi-story buildings. Commercially available large-scale 3D printers, such as big-area additive manufacturing or large-format additive manufacturing, can work with a wide range of materials, from metals and polymer/composites in the automotive and aerospace sectors to cementitious materials in the construction sector. Characterizing residual or yield stress development in these processes is key to understanding the part distortion during the print towards real-time quality monitoring, error compensation, and effective process control. This analysis would become further complicated as multiple heads are adopted for collaborative large scale printing either to enhance efficiency or facilitate multi-material or multi-resolution printing. The adoption of multiple printing heads introduces variables such as changes in interlayer gap or bonding time, affecting stress distribution in the final printed part, and eventually the deformation or structural integrity of the end product. To systematically investigate and characterize this intricate relationship, this study employs an analytical approach to explore the stress distribution in a wall constructed by a multi-head large-scale 3D printer. The maximum shear stress distribution of the wall from the equilibrium condition of forces is calculated to compare with the yield stress of material (i.e., concrete in this study) to ensure no failure takes place. This failure criterion is compared and evaluated for single-head and multi-head large-scale 3D printing for different print lengths, layer heights, and number of heads.",Mechanical Characterization in Additive Manufacturing Processes,143,565
Heterogeneous Recurrence Network Analysis: Unveiling Complex Dynamics for Emotion Recognition in EEG Signals," This study presents a novel approach for emotion recognition through the analysis of EEG signals, employing Heterogeneous Recurrence Network Analysis (HRNA). Recognizing the complex and dynamic nature of brain activities, HRNA is adept at capturing these intricacies using a sophisticated network topology that integrates both heterogeneous and homogeneous properties. This integration enhances the potential for machine learning applications in deciphering the brain's complex dynamics. We applied HRNA to the SJTU Emotion EEG dataset (SEED-IV), aiming to uncover the multifaceted temporal patterns associated with emotional states. Our methodology involved constructing advanced network features that reflect the heterogeneity of brain signals, thereby providing a more nuanced understanding of emotional responses. Our HRNA-based approach achieved an average AUC of 0.8, demonstrating its effectiveness in distinguishing diverse emotional features within EEG data. These results indicate HRNA's potential as a powerful tool for accurately measuring and categorizing emotional states through EEG. The implications of our findings extend to providing objective support for the clinical diagnosis and treatment of mental health disorders, highlighting HRNA's relevance in both research and clinical settings.",Healthcare II,84,566
Enhancing Wire Arc Additive Manufacturing (WAAM) with In-Situ Spectrometer Integration: Advancing Process Monitoring and Material Properties," Real-time monitoring techniques have emerged as promising tools to monitor the arc welding and additive manufacturing process. Integrating an optical spectrometer with Wire Arc Additive Manufacturing (WAAM) enables in-situ monitoring and control of the WAAM process by characterizing the plasma arc in variety of manufacturing process parameters such as wire feed speed, current, and torch travel speed. In this study, we aim to capture and analyze the emitted light to determine the presence and concentration of specific elements in the material being deposited. This information is essential for predicting potential microstructural features such as phase formations within the material and identifying any changes in the material's composition that might occur due to factors like evaporation and contamination , thereby providing an opportunity to optimize the quality and performance of the end product.",Advanced Topics in Smart Manufacturing I,4,567
Assessing Prevalence of Burnout Among Community Health Workers," Burnout is a condition resulting from prolonged exposure to workplace stress that has not been adequately managed. Scholars have established a relationship between burnout and adverse consequences within the healthcare industry including employee turnover, increased costs, and a decline in the quality of service provided. This research focuses on the study of burnout among community health workers in El Paso region who are trusted members of the community and serve as intermediaries between health services and the community. The Maslach Burnout Inventory, a tool consisting of a twenty-two-item survey about work attitudes and perceptions was utilized to measure burnout levels among community health workers. The survey assesses burnout among three dimensions: emotional exhaustion, depersonalization, and low sense of personal accomplishment. The results of this investigation provide valuable insights for future interventions to mitigate burnout and enhance the well-being of community healthcare professionals.",Work environment in health systems,241,568
Optimizing Protein Titer Production using Animal Cells: Predictive Modeling and Recommendations for Enhanced Yield," Current biomanufacturing processes rely heavily on human expertise, struggling to adapt to the growing complexity of bioprocessing. Decision support tools based on machine learning models play a vital role in optimizing the production and timely detection of anomalies in the production line and can save thousands of dollars and reduce quality control costs. We have performed a thorough analysis on a pharmaceutical dataset to identify significant variables that can affect protein titer production. Based on this analysis, we develop machine learning-based models for prediction of the protein titer production and detecting anomalous patterns in the biopharmaceutical/biotechnology-based manufacturing processes industry. We envision the practical applications of our models in other biopharmaceutical and biotechnology industries, leading to increased productivity and cost-effectiveness in protein production within animal cells.",Energy & Environment II,63,569
DISTRIBUTIONALLY ROBUST TWIN SUPPORT VECTOR MACHINES," In this presentation, we propose a distributionally robust twin support vector machine model to address the classification problems with uncertainty using the first and second-order information. The proposed model finds two nonparallel linear separation hyperplanes by solving two interconnected chance-constrained SVM models. Tractable SDP and SOCP reformulations are derived for efficient computations. Computational results on synthetic data and real-world benchmarks showcase superior performance of the proposed model compared with other established classification models, particularly for imbalanced datasets.","Machine Learning and AI, Part 1",128,570
EVERYDAY MANUFACTURING: IDENTIFYING FIRST-YEAR ENGINEERING STUDENTS’ MANUFACTURING-RELATED EXPERIENCES," For manufacturing education, introducing novel content or skills to beginner engineering students by establishing a link to their pre-existing knowledge or experiences could facilitate an enhanced and long-lasting understanding of the material. Manufacturing education in engineering programs often focuses on providing engineering students with manufacturing experiences in the form of labs, tours, and case studies, experiences that most first-year engineering students have little of. While this focus on providing new experiences certainly builds competence, it can be intimidating and may disadvantage students with little experience who may find the experience overwhelming or disconnected from any prior experiences. Education literature shows the importance of connecting new knowledge with existing knowledge, and we argue that presenting new manufacturing skills and experiences in the context of students’ prior experiences could promote better retention of information and more excitement toward manufacturing educational experiences. In this presentation, we share themes and stories of students’ past fabrication experiences derived from a set of 28 one-hour interviews with a diverse group of first-year engineering students. Students often had little experience with manufacturing prior to starting their engineering program but frequently identified manufacturing-related experiences from their hobbies, jobs, and day-to-day lives that they felt helped prepare them for engineering and fabrication activities. These themes can be used by other manufacturing educators to design activities and lectures that feel connected to students’ prior experiences to promote more engagement and retention of material.",Digital Manufacturing and Industry 4.0-II,46,571
Stakeholder Analysis Using a Problem Structuring Method (PSM) to Enhance Stakeholder Management in Ghana’s Artisanal Mining Problem," Mining plays a significant role in supporting and advancing both global and national economies. Africa's mining industry has historically been marked by a wide range of valuable mineral resources. Ghana is widely recognized as a significant contributor to the African mining industry. The country has experienced a notable increase in mining operations, making a substantial contribution to its economic growth. However, there exists a significant and intricate matter referred to as Artisanal and small-scale mining (ASM). The inherent challenges, with a specific focus on artisanal mining in Ghana, require a comprehension to develop effective and sustainable solutions. Effectively addressing these concerns requires proficient stakeholder management. This research project explores the use of a Problem Structuring Method (PSM) as a tool for comprehensively understanding and addressing the complex issues associated with artisanal mining in Ghana. This study aims to create a structured approach for identifying interdependencies, clarifying stakeholder interests, and promoting collaborative problem-solving to enhance stakeholder management. By embracing a PSM-driven approach, one of the goals is to catalyze positive change and promote effective stakeholder management as a cornerstone for addressing the challenges in Ghana's artisanal mining system. Also, this paper will discuss the development of a robust framework that enables stakeholders to work collaboratively toward sustainable artisanal mining practices in Ghana.",Engineering Management Best Student Papers,69,572
System-level factors associated with postpartum care after adverse maternal outcome," Postpartum care holds an important role in the health of the mother and the infant. The postpartum period is known as the 4th trimester and it is a critical time for the women and the family, especially after an adverse maternal outcome. Even though there are guidelines for follow-up care in general, the absence of guidelines specifically for adverse outcomes such as stillbirth and neonatal death, have a negative impact on women’s physical and mental health. The aim of this study is to identify system-level factors and barriers that hinder the effectiveness of communication and information exchange among providers and the potential consequences in postpartum care delivery using the SEIPS framework. The findings from this study contribute valuable insights to healthcare stakeholders, policymakers, and practitioners, providing a foundation for the development of targeted interventions and improvements in the systematic approach to postpartum care, particularly after adverse maternal outcomes. Addressing system factors can enhance the overall quality, safety, and patient satisfaction associated with postpartum care.",Patient Care and Treatment I,160,573
Integrating Sentiment Analysis and Community Detection in Long Short-Term Memory Time Series Predictions: The WGA Strike Case," Amidst the entertainment industry, disruptive events like the labor strike of 2023 impact the film industry and television. Our inquiry delves into this event, seeking to unravel its impact. This research intertwines media discourse, disruptive events, and financial market behaviors within the dynamic of the entertainment sector. This approach considers a vast corpus of over 13,000 news headlines from specialized entertainment industry sources. These headlines span diverse points of view, such as production studios, influential actors, and the dynamics of the labor strike. Employing natural language processing (NLP) techniques, we extract insights and patterns within the narrative. To capture the dynamics of media and financial markets during disruptive events, we implement a Long-Short Term Memory (LSTM) model. This model incorporates several variables, blending technical analysis, sentiment indicators, and categorical representations of the topics. Our hybrid model yields a mean average error (MAE) of less than 13\%, which shows the relationship between media discourse and market fluctuations.",Deep Learning III,42,574
"Scheduling a Two Stage Flow Shop with Batch Processing Machines,Limited Waiting Time Constraint and Makespan Objective"," This study focuses on optimizing the operation of a flow shop with two stages, each equipped with a batch processing machine capable of concurrently handling multiple jobs as long as their capacity is not exceeded. The goal is to minimize the makespan—the total time required to process a given set of jobs on these machines. The processing times and sizes of the jobs are predetermined, and once grouped into batches, the processing time for a batch is determined by the longest processing job within it. While forming batches, the total size of jobs in a batch must adhere to the machine capacity constraint. Traditionally, flow shop problems incorporate a buffer based on the number of waiting jobs. However, this research considers the maximum waiting time between the two stages. It is worth noting that minimizing makespan on a single batch processing machine, with makespan as the primary objective, is known to be NP-hard. Consequently, the problem addressed in this paper is also NP-hard. To tackle real-world scenarios efficiently, this paper proposes both a mathematical model and heuristics designed to solve industry-sized problems.",Manufacturing Optimization,138,575
Examination of Open-Source Software Capabilities for the Creation of 3D Binder Jet Printed Sand Casting Molds and Cores.," With the increasing use of 3D binder jet sand printers, both the core and sand mold making processes are being revolutionized in the foundry industry. As a result of the increased design freedom made possible by the layer by layer printing process, cleaning out unbonded sand from the hollow cavities, addressing solidification shrinkage, and creating an optimal metal flow path are the primary design considerations with 3D printed sand molds. 3D digital models are used for the core and mold designs. Utilizing open-source software and online models, accessibility is increased, allowing individuals to utilize 3D scanned meshes, or custom digitally sculpted models to design a casting while preparing it for pouring in the free software. Using Boolean commands on 3D based models, a 3D model of the gating system can be assembled and solidified as a single mesh. This mesh can then be subtracted from the mesh of the mold creating a cavity for casting. Utilizing free downloadable simulation packages in software such as Blender, the behavior of removing unbonded sand from the mold for cavity creation, addressing solidification shrinkage, and modeling metal flowing into the mold can be predicted. Through examination of current resources available, extensive testing of printed 3D models made with this technology and experimentation with simulation programs, the viability, and procedures for how users can go from the base digital model to the finalized mold most cost effectively and efficiently can be determined.",Directed Energy Deposition Additive Manufacturing Processes,52,576
Online Dynamic Dual Bin Packing with Lookahead for Production Scheduling in Computer Server Industry," Efficient production scheduling in the computer server industry remains a critical challenge due to the dynamic nature of incoming orders and the complex optimization requirements for resource allocation. This paper introduces an Online Dynamic Dual Bin Packing with Lookahead (OD-DBP-LA) specifically tailored for optimizing production scheduling in computer server industry. A binary integer linear programming model is proposed for OD-DBP-LA to maximize the number of assigned servers. To solve this model an algorithm is developed to decompose this highly uncertain problem over the planning horizon into a set of deterministic subproblems for a given length of the lookahead or decision-making window. Realizing that even these deterministic subproblems are hard to solve due to assignment constraints and problem size, a two-stage computational framework is proposed that seamlessly integrates mathematical programming with genetic algorithm (GA). A case study from a leading server manufacturing company is used to validate the proposed model. The results of our numerical study demonstrate the efficacy of the proposed decomposition approach in terms of solution quality and computational efficiency for solving large-scale instances. Furthermore, the relationship between the length of the lookahead and objective value is evaluated to derive an easy-to-use policy for computer server industry.",Facilities Design & Planning III,73,577
Taking stock of the best Human Factors / Ergonomics case: presence in undergraduate ISE programs," Professional engineers must “hold paramount the safety, health, and welfare of the public” and should “adhere to the principles of sustainable development”. Since Human Factors and Ergonomics (HFE) focuses holistically on wellness and productivity, and humans are involved in all engineering systems, HFE is integral to ensuring sustainability in design, and respecting ethical obligations. As a fundamental part of Industrial and Systems Engineering (ISE), this study quantifies HFE exposure of undergraduate engineers considering this “best case”. We searched for HFE keywords in course descriptions within 167 Canadian engineering in Canada including five of 10 ISE programs. On average, 2.5 required and 1.5 optional courses included HFE per ISE program, all having at least 1 required course. Internationally, 39 professors with “knowledge of undergraduate HFE teachings in engineering” (29 from Industrial and 10 from Systems programs) rated their program’s HFE course coverage as “good” or “excellent”, including between 3 and 37 courses (2021 questionnaire). This communication details the ISE program findings in Canada and compares these with international questionnaire respondents who rated their HFE as at least “good”. Although representing a limited sample, this ISE subset illustrates the “best case” of HFE presence in undergraduate engineering programs can be compared with other engineering fields which all require sensitivity to HFE to fulfill the ethical obligations of engineering professionals. Results raise questions about the adequacy of engineering training programs in giving new engineers the knowledge and skills needed to uphold the professional code of ethics in their work.",Innovations in Teaching and Learning Technologies,109,578
A Design Guide to Developing an ISS Inspired Long Duration Space Vehicle," Designing and developing a long duration space vehicle can be guided by the design and development of the International Space Station (ISS). Every new space vehicle development usually borrows from space vehicles development for endeavors that precede them (Gemini, Apollo, Shuttle/Mier, ISS). The vehicle development methodology involved can be outlined in a five-step process (1) Understanding Mission Requirements/Mission Planning, (2) reviewing available technology and their fitness for the mission, (3) understanding technology to be developed for the mission (4) development of derived vehicle requirements, (5) selecting subsystems of the vehicle design and trade studies for prototype vehicle development, testing and certification. This paper is particularly important for NASA’s space missions that are increasingly targeting beyond earth’s orbit into known and unknown destinations. A few examples will be used to illustrate the concepts and methodology for space vehicle development.",Systems Engineering & Life Cycle Management I,225,579
Advancing Data Augmentation with a Generative Adversarial Network (GAN)-Informed Denoising Diffusion Implicit Model (GAN-DDIM) in Manufacturing and Medical Applications," With the rapid advancements in deep learning, numerous studies have utilized its capability to address various challenges within their respective domains. In engineering applications, such as the quality control of additive manufacturing (AM) systems and the disease treatment monitoring using medical imaging systems, the understanding and augmentation of images play a crucial role in advancing the system’s capability and thereby broadening their applications. This study proposes an advanced diffusion-based generative model enhanced with a generative adversarial network (GAN) integration. In this proposed methodology, the diffusion model, a denoising diffusion implicit model (DDIM), is used to generate high-quality sampling images, thereby playing the role of the generator in the GAN. In this model, the GAN generator is used instead to condition the diffused noise injected into the input images, while the generated images try to pass the discriminator test of reality. The model also includes novel distance metrics to find an adequate balance between similarity and diversity for the generated samples. The proposed model has been tested on several case studies with application in both layer-wise AM images and tumor ultrasound medical images. Current results show the great potential of the proposed methodology to explore possible unseen pattern variations in real-world engineering applications.",Deep Learning I,40,580
Exploring Holistic Dimensions of Team Effectiveness in A Multiplayer Virtual Reality Simulation Study," Virtual Reality (VR) technology has revolutionized the study of team effectiveness, yet many studies in this domain lack a comprehensive approach, focusing narrowly on performance metrics. This study integrates traditional team effectiveness frameworks with VR-specific dynamics by utilizing Data Envelopment Analysis (DEA) and Group Styles Inventory (GSI) to assess teams within a multiplayer VR simulation. Fifteen groups of three, totaling 45 participants, participated in the VR simulation study while their self-reported and sensor-based data was collected and analyzed. This includes various survey-based assessments (demographics, system usability, simulator sickness, and team performance perception) and physiological measures (heart rate variability and electrodermal activity). The data was analyzed using DEA to evaluate team efficiency and GSI for team effectiveness. Efficiency and effectiveness were correlated with physiological and self-reported data. The findings demonstrate that team effectiveness in VR is a multifaceted construct, influenced by a combination of team inputs, processes, outputs, and dynamics specific to the VR environment. A cluster analysis of the efficiency and effectiveness of the 15 teams revealed insightful trends across various metrics.",Teaming in Work Systems,229,581
ADVANCING METAL ADDITIVE MANUFACTURING: DATA-DRIVEN SURROGATE MODEL FOR EFFICIENT DESIGN," Utilizing machine learning to analyze part geometry and predict manufacturability or quality is critical in advancing the rapid and efficient product design and development of additively manufactured products. The development of digital twins utilizing machine learning for the design of additive manufacturing parts is a dual-use technology applicable in both commercial and military contexts. A digital twin for additively manufactured part design can play a vital role in generating virtual prototypes; rapidly verifying the dimensional accuracy, functionality, and performance of those designs without the need for physical prototypes; and efficient design modifications accordingly. While process simulations offer a traditional approach for design verification in the virtual environment, they require significant time to solve. Data-driven machine learning surrogate models are an efficient alternative, providing rapid design performance predictions, which is imperative to minimize material wastage and optimize quality for metal additive manufacturing parts. This study presents a data-driven surrogate model trained from process simulation data for rapid prediction of part distortion in metal powder bed fusion, incorporating multiple shape descriptors from several hundreds of parts as model input and part distortion metrics as outputs. Emphasizing the significance of part geometry in additive manufacturing, this approach focuses on the dimensional accuracy or part distortion of additive manufacturing parts for diverse part geometries. Predicting distortion caused by complex additive manufacturing part geometry allows proactive adjustments to the part designs for minimum part distortion and thus is crucial for optimizing designs, ensuring quality, and reducing costs in the additive manufacturing process.",Digital Thread in Additive Manufacturing Processes,49,582
A Framework For Integrating Outsourcing Requirements With Product Portfolio Planning In New Product Development," Recent developments in the new product development (NPD) practice has witnessed the integration of various NPD strategies mainly for the purpose of improving operational efficiency and organizational competitiveness. The distributed product development (DPD) strategy which involves the inclusion of outsourcing requirements in NPD processes is one common integration that has gained wide research attention. Although the DPD-NPD integration has been statistically proven by researchers to improve the execution of NPD projects, the benefits of integrating DPD requirements with “product portfolio planning (PPP)” which involves determining the optimal product mix and optimal product launch portfolio in modular product development has been underexplored. In this work, we propose a framework for integrating DPD requirements with PPP. We begin by discussing key concepts and identifying key elements of the DPD and PPP strategies. We then proceed to develop a DPD-PPP construct. Our DPD-PPP construct takes into account the “degree of interaction between various components of product architecture” and the “degree of information sharing between product development teams” which are two implicit functions of the DPD-PPP problem. We identify relevant problem parameters and proceed to develop a multi-objective mixed integer linear programming (MOMILP) model to quantitatively define our proposed DPD-PPP construct. We present a realistic example to demonstrate the applicability of the model and then discuss the managerial implications of our findings. Our main contribution is to provide a framework for linking DPD requirements with PPP to enable firms determine the optimal product portfolio and product launch timing in a distributed product development environment.",Engineering Management Best Student Papers,69,583
Value Stream Mapping Approach to Redesign of Hospital Admission Workflows," Admission is an integral part of patient care processes in a hospital. To excel in a dynamic environment, provide excellent care efficiently, ensure quality and safety, and achieve patient and staff satisfaction, improving admission processes is essential. This paper describes an in-depth study of the admission workflows of three different care units in a midsize regional hospital. Through observation of the admission processes, time studies, and interviews with care unit personnel, current state process maps and value stream maps were prepared to portray a clear overview of how the processes work and identify problem areas. Root causes behind the problem areas were identified using ‘5 Whys’ technique during the interview sessions leading to future state value stream maps for the admission processes in these care units. Key recommendations emerged from this work include formation of a transfer team, written communication to avoid misconception, checklists to ensure that required information is shared, and uploading patient’s discharge related assessment reports immediately into patient charts to enable hospitalists to assess without coming to the floor. This research identifies various support activities for the admitting patient flow that directly impact care efficiency, which will facilitate the design of value-based admission processes and achieving efficiency and customer satisfaction. It will guide future researchers adopting integration of VSM and root cause analysis including recommendations for strategic healthcare process improvement. However, this study had several limitations pointing to further research which can be done on potential variations in admission processes among different care units.",Healthcare,81,584
A Simulation-Based Approach to Enhancing Preparedness and Reducing Traffic Risk at the Port of Anchorage," As Alaska’s largest and most versatile port, the Port of Anchorage plays a critical role in handling over 5.2 million tons of fuel and freight annually. While the impact of the port on the economy of Anchorage and its surrounding areas is well-documented, concerns have arisen from only having a single road as the main access point for both freight trucks and cars. Despite its economic significance, the port has identified the traffic redundancies associated with the single road as posing significant potential risk to local businesses in the event of an accident or long-term construction. The purpose of this project is to develop a discrete event simulation model that reflects the port’s operations and traffic patterns in order to inform the decision making of the port and provide best practices in the event of short-term or long-term disruptions to the port’s operations. The proposed model will allow port officials to simulate several types of short-term and long-term disruptions, as well as investigate the best course of action to handle such situations. By addressing the traffic concerns and providing best practices, this project enhances the Port of Anchorage’s preparedness in the case of potential disruptions, protecting its vital role in the local economy.",Resilience & Hazard Analysis,190,585
A Location-Allocation Model for Optimizing COVID-19 Vaccine Distribution with Equity Constraints," This study presents a maximal covering location problem that aims to minimize the total cost of vaccine distribution and maximize the total number of vaccines allocated to population blocks. Equity constraints are included in the proposed mixed-integer linear model considering age, race, and gender groups. A modified Voronoi diagram technique embedded in a Lagrangian relaxation framework is proposed to solve the problem. Moreover, an advanced column generation method embedded with a linear support vector machine (SVM) has been proposed in this study, which can improve the efficiency of the original column generation method. Empirical case studies in Pennsylvania are conducted based on the real-world data collected from the Centers for Disease Control and Prevention (CDC) and the health department. The numerical results indicate that the proposed model can effectively solve the problem and outperform a column generation-based benchmark.",Humanatarian logistics 2,95,586
An Efficient Algorithm to Optimize Vehicle Routings in Post-Disaster Humanitarian Logistics," In the aftermath of a disaster, ensuring the efficient delivery of essential supplies, particularly water, is of utmost importance. Various commodities, including water, rice, and fuel, can be transported in different ways. Bottled water offers the advantage of self-storage and easy distribution, but it necessitates transportation from external sources, incurring high logistics costs. On the other hand, bulk water can be sourced locally from streams and purification stations, though it requires survivors to have containers. The tradeoffs between logistics costs and transportation methods for these two water formats are often overlooked in existing literature. This study introduces the Social Cost Vehicle Routing Problem, presenting a mathematical optimization model to determine the optimal mix of water formats for transportation, routing, and delivery, taking into account social costs in the objective function. Given the NP-hard nature of the problem, a hyper metaheuristic algorithm with a unique local search is devised to address large instances of the problem. This algorithm integrates tabu search, simulated annealing, and variable neighborhood search in a cohesive manner. To demonstrate the model's practicality, it is applied to a case study involving post-disaster water distribution in Puerto Rico following Hurricanes Irma and Maria in 2017. The results from numerical experiments highlight that a combination of bottled and bulk water maximizes aid to survivors while minimizing response costs.",Urban Logistics,237,587
Quality Assurance Through Layered Process Audits in the Automotive Industry, Quality Assurance through Layered Process Audits in the Automotive Industry,"Data Analytics in Controls, Measurement, and Education",36,588
Uniform Concentration Inquality for MMD-related Statistics," Maximum Mean Discrepancy (MMD) is a distance in the space of probability measures; it has numerous applications in machine learning and hypotheses testing. This paper introduces a uniform concentration inequality for Maximum Mean Discrepancy (MMD)-related statistics. To elaborate further, let G = {g : g ∈ G} be a functional class, and let P and Q be a pair of probability distributions. For all functions g ∈ G, we provide a uniform deviation bound for the empirical MMDs between push-forward measures g#P and g#Q, which can be applied to compute the upper and lower confidence bounds in MMD-related optimization problems. We extend this inequality to other MMD-related statistics, including the Hilbert-Schmidt Independence Criterion (HSIC), energy distance, and distance covariance. By imposing Lipschitz conditions on the kernel function, this generalized bound improves the classical confidence bounds based on large deviation bounds and asymptotic distributions of MMD.",Machine Learning II,126,589
Evaluating Accessibility Conformance of State Public Health Agencies’ websites during the COVID-19 pandemic," The goal of our study was to evaluate and analyze conformance with accessibility guidelines of home pages and vaccine information pages of public health websites dedicated to COVID-19 information in the US. We used the Web Access Checker tool AChecker to assess the accessibility of 51 public health agency websites in 50 states and Washington, DC. We computed aggregated conformance counts at the guideline level. We evaluated violations of the WCAG 2.0 guidelines and collated all known WCAG 2.0 problems for each criterion at the A, AA, and AAA levels for each state, for the home pages and vaccine pages separately. Although violations were detected in all four POUR accessibility principles, the largest number of known violations occurred in meeting the perceivability and operability principles; in particular, problems in providing non-text content, contrast, and text resizing were prevalent. We found that accessibility violations were prevalent across states but to varying degrees for a specific accessibility criterion. Our evaluation indicates that state public health websites can improve support for non-text content, use of assistive technologies, contrast, and text resizing to offer accessible content for various needs.",Health Systems for Human Factors and Ergonomics 1,79,590
Addressing Barriers to Food Access: A Comprehensive Study of Fresh Mobile Market Distribution in Low-Income Communities," Food insecurity remains a global public health obstacle, highlighting inequalities vulnerable populations face. Using data collected from participants at several fresh mobile market (FMM) locations in a North Carolina (USA) county, combined with other US Census and geospatial datasets, we performed a case study examining FMMs' impact on their beneficiaries and serviced neighborhoods. More specifically, we examined the commute patterns of participants who visited FMMs and the sociodemographic characteristics of participants' residences and mobile market-serviced communities. Lastly, using contemporary spatial modeling, we enumerate the improvements in physical access to food assistance programs by looking at the impact of current FMM scheduling given the spatial distribution of existing food banks and pantries. To address remaining disparities in access to food assistance, we propose a spatial optimization approach for strategically positioning FMMs to minimize the travel burden to food assistance among vulnerable populations. The findings in this research can guide the strategic placement of FMMs in low-income communities tailored to their target communities' specific needs and constraints.",Humanatarian logistics 2,95,591
IAB/YP Career Development Panel Series," This Special Session will consist of four 20-minute panels spanning the most important career decisions engineers encounter, presented as a collaboration between the IAB and YP organizations. The first panel will include both early and late career professionals, with a focus on career planning and goal setting. The second panel will focus on the process of successfully executing the first job change after graduating. Topics will include “How to know when the time is right” and “How to job hunt with industry experience”. Panelists will be young professionals who have recently completed their first job after graduating. The third panel will consist of Directors and VPs who will give advice on transitioning into upper management roles. Topics will include “Building visibility” and “Pros/Cons of additional degrees and certifications”. The fourth and final panel will focus on the decision to retire. Panelists will discuss their late career journeys and the non-financial steps they took to successfully retire.","IAB/YP Career Development Panel Discussion on Career Planning, your first job change, transitioning to senior management and retirement",96,592
Horizontal Collaborative in Vehicle Routing Problem with Split Deliveries: A Genetic Algorithm Approach," The article presents a mixed-integer programming model to study a collaborative vehicle routing problem with split deliveries (CoVRPSD). In this model, suppliers are the service and product providers to fulfill less-than-truckload demand by horizontal collaboration. The goal is to minimize total traveled distance of all vehicle-routes, fixed costs of vehicles, and the penalty incurred by underutilization of vehicles. This model is an extended version of VRPSD; however, in VRPSD, the origin of all vehicle routes is the depot, while in our model, the origin of each vehicle route can be any of the suppliers. We utilize a genetic algorithm (GA) to solve large size problems. To minimize the size of the instances and prepare them for the GA, we use logistic regression to systematically select vehicle routes for direct transportation. Numerical analyses proves that the proposed solution approach is significantly more efficient that CPLEX.",Routing 2,198,593
Using Emerging Technologies to Accelerate Your Early Career," Geoff Dybicz will offer guidance to recent and soon-to-be graduates on how to leverage emerging technologies to kick start their careers. Attendees will first learn how to recognize and document opportunities that have a high likelihood of helping them stand out. Then, they will learn how to capitalize on those opportunities and connect them to career success. Topics covered include ""Writing proposals for management"", ""How to work well across diverse teams"", and ""How to network your ideas"". The format will be a mix of practical examples and general guidelines, with time left at the end for Q&A.",Personal Development I,162,594
An Analysis of Methods for Ergonomics Research in Sports," By conducting a meta-analysis of ergonomics papers across multiple athletic disciplines, a dichotomy of analysis lenses was deemed most effective for engineering research into sports: techniques and equipment. While ergonomic analysis of technique and equipment often involve similar types of data, most notably EMG data of relevant musculature and visual assessment of photo or video recordings, meaningfully different conclusions can be drawn and differing types of recommendations given for future improvements to human performance. Both technique and equipment analysis can provide valuable insight into discrepancies between novice and expert performance, and proper selection of a technique or equipment focus can highlight various desired aspects of these discrepancies. This paper will discuss the strengths and potential oversights of sports analysis with a technique versus equipment focus, as well as discuss successful methods of balancing technique and equipment analysis to produce holistic conclusions.",Physical Ergonomics,164,595
Optimal Allocation of Cross-Trained Nurses in a Surgical System," In response to the pressing nursing shortage, we model an inpatient surgical facility with cross-trained nurses that provide pre-operative, operative, and post operative care as a tandem clearing queueing system. We then formulate a Markov decision process to optimize the allocation of servers to workstations and tasks. The servers, workstations, and tasks are flexible to varying degrees; and the particular flexibility scheme we consider is designed based on the real-life business rules that govern the movements of nurses and patients. Optimal policies are obtained by minimizing the total holding costs. Focusing on systems with a small number of jobs, we study the optimal policy structure and identify optimal actions under some conditions. Our results show that the optimal movements of servers are determined by holding cost thresholds that are functions of the service rates. Subsequently, we extend our analysis to systems with an arbitrary number of jobs and thus arbitrarily large state spaces. Finally, we develop and evaluate a heuristic that can be used to obtain practical and well-performing server allocation policies for larger systems.",Resource Allocation and Workforce Planning in Health Systems,193,596
Optimizing Perishable Product Allocation at A Client Choice College Food Pantry," According to studies, approximately 40% of college students in the USA have experienced food insecurity at some point of their student life, which has the potential to negatively impact their academic performance. College food pantries aim to alleviate food insecurity by minimizing the food waste and maximizing the total number of people served. This poses a challenge for client choice food pantries distributing perishable food items because of variabilities in demand, storage space limitations and the possibility of spoilage. Optimizing limits of items based on the demand distribution and available inventory can help maintain equity as well as reduce the wastage. This study develops a finite time Markov Decision Dynamic Programming Model to optimize the distribution limits of perishable items for different days under variable demand conditions. We explore operational effectiveness of food pantries through the outputs of this model as well as develop policy insights.",Optimization in Transportation,156,597
Exploring the Robustness of Wilcoxon Signed Rank-based Control Charts when symmetry is misspecified," The Wilcoxon signed rank statistic is commonly used to build nonparametric control charts due to the unsensitivity of the statistic to deviations from the assumptions of normality. Initially used to test for symmetry, once symmetry can be assumed, it can also be employed to test for location changes. However, the performance of SR-based control charts may be severely affected when symmetry is incorrectly assumed at an early stage of analysis. This research explores the robustness and the effects of asymmetrical distributions and symmetry misspecification on the performances of a SR control chart for process monitoring. The results of this line of research will not only contribute to this area of research, but will assist working industrial and systems engineers make informed decision regarding the selection of nonparametric control charts in cases where symmetry is neither known or cannot be clearly identified.",Advanced Topics of QCRE Applications II,6,598
Development and Optimal Design of Electric Vehicle Charging Station Digital Twin," Electric vehicles (EVs) have contributed to reducing carbon emissions, promoting the advancement of sustainable transportation. However, a widespread adoption of EV is significantly impeded by the lack of charging stations and inefficient charging systems. To address these issues, we introduce a new Charging Optimization Framework (COF) based on quantitative modeling implemented in Anylogic simulation software. The COF aims to reduce the EV charging time while meeting customers’ demands. The methodology incorporates real-time stochastic simulation of EV arrival patterns using a non-homogeneous Poisson process. Computational results indicate a significant reduction (81.46%) in overall charging time over the baseline using the COF. Based on a new System Efficiency metric, the optimal number of charging stations and waiting stations were computed as 11 and 13, respectively, maximizing the average efficiency under the EV arrival and charging demand distribution considered. Simulation results highlight the optimal EV charging station design’s potential in helping reduce resource misutilization while fulfilling customers’ charging demands. These findings not only support the value of the simulation model for effective planning but also provides a forward-looking solution strategy for electric mobility.",Simulating Transportation,205,599
Enhancing Campus Mobility: A Set Covering Problem for Electric Scooter Charging Stations at Cal Poly Pomona," Cal Poly Pomona, spanning 1,438 acres with over 24,000 students and 2,600 faculty and staff, faces challenges in student mobility due to its expansive and dispersed campus layout. The limited 10-minute breaks between classes, combined with considerable distances between academic buildings and laboratories exceeding 3,500 ft, result in students feeling exhausted and stressed. While the Bronco Express Bus Shuttle exists, its designated routes and schedules are deemed insufficient. In response, this paper proposes the introduction of electric scooters on campus to complement existing transportation options, mitigating deficiencies and reducing student stress. Utilizing the Set Covering problem, this research formulates a mathematical model to determine the optimal placement of electric scooter charging stations. Cal Poly Pomona's campus map, class schedules, and bike rack station map for Fall Semester 2022 are integral to the model. The objective function aims to minimize the number of charging stations, taking into account the campus's unique layout. A numerical example which uses a portion of the campus map, effectively determines the optimal locations based on binary decision variables and evolutionary methods. The results demonstrate the feasibility of reducing the number of charging stations while ensuring convenient access for students. This innovative approach addresses campus transportation deficiencies, providing students with a sustainable and leisurely mode of mobility between classes and activities. The implementation of this solution not only improves efficiency but also contributes to a more sustainable and student-friendly campus environment.",Optimization in Transportation,156,600
"Risk-Informed Stochastic Programming for High-Impact, Low-Probability Events with Applications to Flash Flooding Climate Change Risk"," Traditional stochastic programming (SP) assumes either a known probability distribution or uncertainty set. Both risk-neutral (expected value) and risk-averse (chance-constrained or robust optimization) postures largely ignore low-probability, high-impact events. This work relaxes both assumptions while incorporating decision maker risk postures into a novel two-stage SP model for high-impact, low-probability events. This model is applied to the projected increase in flash flooding events due to the effects of climate change. The magnitude and location of this flooding is highly uncertain, meaning each road segment has a low flooding probability. However, these events have both short-term (traffic delays) and long-term (road degradation) effects that must be considered in investment planning.",Risk Management,195,601
Characterizing hydrodynamic shear stresses and their effects on algae cell fate during extrusion-based bioprinting," A disadvantage of extrusion-based bioprinting is the shear stress applied to cells during the printing process, which may negatively affect cell viability and function post-printing. Bioprinting has been most commonly used for fabricating mammalian cell scaffolds for tissue engineering applications, but has also been employed for microorganism-laden constructs. However, the acceptable limits of process conditions for extrusion-based bioprinting that ensure the maintenance of phenotypic behavior in algae cells laden constructs remain unknown. Here we report the cell viability and function when various nozzle types, nozzle sizes, and printing pressures are employed. An 8% alginate bioink containing Chlamydomonas reinhardtii at a concentration of 1x106 cells/mL and pre-crosslinked with 50 mM CaCl2 was used for printing. Scaffolds were fabricated with nozzle sizes 22G or 25G, conical or blunt needle nozzles, and high or low pneumatic pressures. Cell viability and function were measured at set time points after scaffold printing to determine the effects of printing pressure on cell health. Cell viability was determined by measuring cell growth rate and mobility. Cell function was studied by analyzing the photosynthetic pigments, chlorophyll-a, chlorophyll-b, and carotenoids, and measuring the electron transport rate of the cells. Experiments were supplemented with transient numerical models to characterize and quantify the shear stress limits required to maintain phenotypic behavior of algae cells. Viability results showed that printing pressure, and the resulting shear force, have an effect on cell health post printing.",Bioprinting and Biomedical Manufacturing Processes-III,21,602
Alignment of Carbon Fibers During 3D Printing of Carbon Fiber Reinforced Concrete," Concrete is the most widely used construction material in the world. Automating the fabrication of concrete components, through 3D printing (3DP), has the potential to dramatically reduce its associated carbon footprint by enabling the utilization of green mixes and advanced topologies. However, structural concrete components typically require steel reinforcement in order to provide appropriate tensile resistance. This dependence on steel reinforcement is a major obstacle impeding widespread acceptance of 3DP as an alternative. Of interest to this research is the utilization of carbon fibers obtained from decommissioned wind turbine blades to create stronger and greener cement paste mixes targeting the replacement of steel reinforcement. Early research efforts have demonstrated the potential of utilizing such carbon fibers to improve strength of cast cementitious materials. However, the amount of carbon fibers required to achieve strength similar to that provided by steel reinforcement is excessive, attributable to the randomness in the distribution of fibers within the cementitious matrix. Therefore, we are proposing to align the carbon fibers along the direction of the mechanical stress generated by the interaction of the nozzle geometry and the cementitious matrix during 3DP. We present a customized nozzle engineered to align fibers via a differential fluid flow speed caused by boundary flow on the walls of the orifices of an insert. We demonstrate the application by 3DP and testing small-scale specimens with aligned fibers and compare performance against specimens with randomly distributed fibers and controls (specimens without fibers). Results show the promise of the proposed fiber alignment method.",Composites in Additive Manufacturing,29,603
Efficient Approximation of Conformal Prediction using Surrogate Model," Accurate predictive modeling plays a crucial role in optimizing system performance, preventing failures, and refining maintenance strategies. While traditional modeling techniques, particularly black-box models, offer point predictions, the demand for predictions accompanied by measurable confidence has grown, particularly in high-risk scenarios. The Conformal Prediction (CP) framework provides a means to establish an error rate bound for predictions, but computational efficiency poses a challenge. In this research, we present a novel framework that combines surrogate modeling with conformal prediction to effectively address these challenges. Our method constructs conformal p-values directly from input data, bypassing the use of non-conformity scores by training the surrogate model to establish a direct relationship between input data and conformal p-values. This approach significantly enhances the model's computational efficiency, facilitating more informed decision-making. To validate the efficacy of our proposed method, we apply it to a numerical example. The results underscore its capability to reduce training time, pushing the boundaries of the field toward more efficient and precise uncertainty quantification.",Advanced Topics of QCRE IV,10,604
Integrating Neural Controlled Differential Equations and Neural Flow for Comprehensive Irregularly-sampled Time Series Analysis," Addressing the complexities of irregular and incomplete time series data, this paper presents a novel approach that utilizes Neural Controlled Differential Equations (Neural CDEs) and Neural Flow. Driven by the need for a comprehensive solution in the realm of time series analysis, our research introduces an advanced framework that is not limited to regression but also demonstrates proficiency in classification tasks. Central to our approach is an enhanced dual latent states architecture, meticulously designed for high precision in a variety of time series tasks. Through empirical analysis, our results showcase significant performance improvements compared to existing models. This work not only marks a significant advancement in the field of irregularly-sampled time series analysis but also stimulates innovative ideas in related areas, offering a versatile and effective tool for practical applications.",Machine Learning III,127,605
Enhancing Human Activity Recognition with Comparative Data Fusion and Learning Strategies," In the field of Human Activity Recognition (HAR), integrating multiple sensor inputs poses significant challenges, especially when dealing with heterogeneous feature sets. This study addresses these complexities with a novel approach aimed at enhancing prediction in HAR. The key motivation is to overcome the difficulties associated with the fusion of diverse data sources. This research introduces a unique comparative analysis of data fusion methods, viewed through the lens of learning strategies. By maintaining a consistent model architecture and varying the hierarchical sequence of optimization, the proposed method strategically navigates the intricacies of multimodal datasets. This innovative approach is validated through extensive testing on different real-world HAR datasets. The results underscore the critical role of learning strategies tailored to multimodal data, significantly impacting model performance. These findings offer valuable perspectives on the effectiveness of data fusion in sensor-based activity recognition and gently pave the way for novel approaches in HAR research, suggesting the potential for more sophisticated and efficient methodologies in this domain.",Advanced Topics of QCRE Applications I,5,606
Modeling and Assessing Capability-Based Planning for Emergency Preparedness, The Department of Homeland Security and the Federal Emergency Management Agency have identified 32 capabilities across 5 mission areas for preparing for and responding to emergencies. State and local agencies use capability-based planning to identify gaps in their capabilities and fund projects to sustain and improve their emergency preparedness. We worked with the Iowa Department of Homeland Security and Emergency Management to model and assess interdependencies among these 32 capabilities. A Bayesian belief network of the capabilities quantifies the effect of improving a capability and provides insight into how improving a capability can improve capabilities and mitigate impacts from threat scenarios. This model allows us to identify the most influential or important capabilities.,OR for a Resilient Future,152,607
Profit Maximization by Optimally Sizing of Photovoltaic and Battery Energy Storage System at a Point of Interconnection with Existing Gas-Power Generation," The paper proposes an optimization model to obtain the best combination of photovoltaic (PV) and battery energy storage systems (BESS) at a point of interconnection with existing gas-power generation in an electric power network system. The paper focuses on taking advantage of the economic benefits of renewable energy resources while reducing gas-powered plant operating and maintenance costs to maximize profitability. The model considers the uncertainty of solar energy generation resources, variability of locational marginal pricing (LMP) and the economically available battery storage systems. A Mixed Integer Linear Programming (MILP) technique was used on experimental IEEE bus systems to determine the optimal combination of PV and BESS to reduce gas-powered generation and to maximize profitability at a point of interconnection in an electric power network system. Academic researchers and utility owners would benefit from these experimental results to achieve their sustainable and economic goals over a planning horizon.",Energy and Infrastructure,66,608
Industry 4.0 Technologies and Lean Office: perspectives to Smart Office," Paper aims: Due to the scarcity of research that approaches the Lean Office in conjunction with Industry 4.0 Technologies, this article aims to discuss, understand and analyze the associations between these two concepts, as well as identify gaps to be explored. Originality: This research contributes with guidelines for applying Industry 4.0 Technologies in administrative areas and possibilities of an association with the Lean for the development of the Smart Office. Research method: Based on a systematic review of the literature, with a basic purpose, a descriptive objective, and qualitative data, a framework for developing the Smart Office is presented. Main findings: An association model between Lean Office tools and Industry 4.0 Technologies is provided. It even classifies and addresses the impact and trends in administrative environments so that managers can develop the Smart Office. Implications for theory and practice: Industry 4.0 technologies have been widely discussed in companies that seek to improve processes, mainly industries; however, there are still few applications in administrative environments. The applicability and association of new technologies for Smart Office can explore future studies and contribute to the growth of these areas in addition to the creation of new articles relating to technologies in this environments.",Service Organizations,204,609
Managing Inventory with Customizable Parts using Economic Order Quantity (EOQ) Modeling," The determination of Economic Order Quantities (EOQ) and Reorder Points (ROP) are essential for the minimization of inventory costs and reduction of waste within warehouses/ inventory storage. In the classic examples of EOQ modeling, parts are ordered/used at relatively constant rates with some variation due to seasonality and adjusting for trends. This works well with standard parts that are constantly being used; however, the issue arises when customization becomes involved. Customized parts are difficult to predict because certain finished products use various types of customized parts. This leads to overstocking all types of customized inventory in order to prevent any stockouts. This paper will research how to manage inventory with customized parts while preventing excess inventory (holding costs) and increasing warehouse aisle utilization.",Production and Inventory Planning,182,610
Identifying best practices in modern ICU design: A literature review and qualitative analysis of stakeholder priorities," Each year Canadian Intensive Care Units (ICUs) treat 250, 000 critically ill patients. In contrast to an extensive focus on the performance of ICUs for clinicians, ICU design has received limited attention as an integral influencer of stakeholder outcomes. Furthermore, there has been greater emphasis on the use of human-centered design for ICUs to reduce adverse incidents, to improve healthcare provider workflow, and support patient-centered care. The objective of the research was to identify high priority design implications to inform ICU design best practices. In order to synthesize the available evidence on ICU design, we completed a systematic literature search and conducted interviews with relevant stakeholders. The literature search generated 894 articles from Medline and Scopus. After the initial screening using Covidence, 158 articles from Medline and Scopus were deemed relevant. 47 articles were chosen for data extraction. Additionally, Ten Semi-structured interviews were conducted with healthcare providers and patients based on the design categories identified in the literature. Two reviewers categorized relevant themes based on the findings from the review and interviews. Key design categories elicited from the review and interviews included room and ICU layout, lighting, noise, family spaces, and privacy. Specifically, patients and providers preferred larger single occupancy rooms with large windows, freestanding beds, and comfortable family seating. An open floor plan and sound isolation were also recommended. The study found several intersections between the review and interviews for ICU design. Additional research is needed to assess the impact of these design features on provider and patient outcomes.",Diverse Topics for Human Factors and Ergonomics 1,55,611
A Multi-Criteria Model for Assessing Vendor Risk with a Supply Chain," The primary motivation behind this research is to evaluate the risk profiles associated with the significant number of vendors present in supply chains. To tackle the identification of supply chain risk in operational settings, the research adopts a multi-objective decision analysis approach. This approach utilizes a methodology based on risk and importance indices, which enables the development of a risk profile for vendors based on operational data. By employing the well-established theory of multi-objective decision analysis (MODA), risk indices are formulated in a manner that allows for meaningful comparisons and facilitates decision-making. By utilizing sampled data on items from a military supply chain, individual MODA models are created and demonstrated using a prototype tool.",Center for Excellence in Logistics and Distribution (CELDi),25,612
Exploring the tradeoff between transportation cost and risk for a vehicle delivering hazardous materials to customers," This talk will focus on the routing of a hazmat delivery vehicle. As the vehicle delivers product the amount of remaining product on the vehicle decreases and risk potential decreases. A mathematical model to explore the tradeoff between transportation cost and risk will be presented. Computational results will also be shared along with managerial insights. A case study will also be presented, along with a discussion of data sources and application potential.",Network Optimization,149,613
Single Product Known Time Varying Demand Produced on a Finite Capacity Single Machine," Inventory problems are typically separated into two classes of demands, deterministic and stochastic. In the realm of deterministic demands, the dominating assumption is that of uniform or constant demands. The EOQ formula (Harris, 1915) is the typical and much used prototype of the class of methods developed on the uniform demand assumption. The other extreme of discrete deterministic known demands can be solved by dynamic programming methods (Wagner and Whitten, 1958). The area that has had little attention is the more-realistic assumption of known but varying demand such as that which would be obtained from curve fitting historical demand data. This is the demand assumption considered in this analysis. The main basis of this work is the finite production model under the assumption of time varying known demand. We will illustrate how the time varying demand under instantaneous replenishment is readily solved via the proposed procedure. The general solution procedure is to fit the yearly time varying demands via a polynomial to any needed power. The function values, integrals of demand and expected inventory levels can then be solved efficiently and exactly based on this polynomial form and its integrals. Using Leibniz rule for the derivatives of integrals, the problems considered yield concise recursive relationships which can be solved numerically using most equation solvers for the optimal reorder points in time.",Facilities Design & Planning III,73,614
Multi-objective electric bus scheduling problem considering multi-vehicle types.," The electrification of public transportation, particularly the transition from diesel/gas to electric bus fleets, poses a unique set of challenges related to efficient scheduling and operational management. The Electric Bus Scheduling Problem (EBSP) is a critical aspect of this transition, as it involves optimizing the assignment of electric buses to predetermined timetable trips to minimize fleet size and operational costs. This paper presents a systematic approach to address the multi-depot and multi-vehicle type electric bus scheduling problem (MD-MVT-EBSP) within the complex framework of urban transportation systems. The problem is tackled by developing an optimization model, which, alongside the genetic algorithm, results in finding the optimal schedule and recharging trips while the total cost of using an electric bus fleet is minimized. The proposed method not only achieves the optimal schedule but also addresses the crucial aspects of determining the required number of each vehicle type and the associated charging specifications needed to fulfill the timetable trips. A rigorous investigation of a case study is performed by employing a real-world transit network dataset from Canadian cities.",OR for a Resilient Future,152,615
Reinventing Material Planning & Buying with Perfect Planner," Perfect Planner®, a cloud-based software, revolutionizes material planning and procurement processes. Unlike traditional MRP systems and current supply chain software solutions, it offers a standardized planning process and an intuitive interface that consolidates and prioritizes all tasks into a simplified ""to-do"" list. This eliminates the administrative and analytical burdens on Material Planners and Buyers which often consumes 75% of the work day. The platform excels in identifying short and long-term supply gaps, conducting comprehensive root-cause and Lean analyses, and enhancing productivity, visibility, and data-driven decision-making. Crafted by seasoned planners with 15 years of planning and supply chain expertise, Perfect Planner caters to Material Planners and Buyers across all industries. The Intelliplanning® Logic Engine (IPL Engine), the heart of the platform, employs advanced Artificial Intelligence with over 2,000 logic-driven planning algorithms per part. The IPL Engine has been meticulously refined for over a decade in industry, and it ensures an output of over 99% accuracy, providing valuable insights for both Material Planners and organizational leaders. For organizational leaders, Perfect Planner extends its impact, offering unprecedented transparency into planning and procurement. Innovative performance management dashboards facilitate performance tracking and measurement at all levels. With the opportunity of a 70% reduction in expedites, a 50% increase in productivity, and a 20% inventory reduction, Perfect Planner promises a robust return on investment. Positioned at the forefront of industry automation, its commitment to precision and analytics makes it a pivotal player in the journey toward complete automation in material planning and buying.",Innovative topics in supply chain 1,112,616
Physiological Sensing in Stressful Surgical Simulation Scenario for Non-technical (NT) Skills – A Pilot Study," Non-technical (NT) skills in surgery encompass communication and teamwork, decision-making, leadership, and situational awareness. Developing an intraoperative scenario with a controlled environment that challenges surgeons is useful for studying intraoperative NT skills. This study proposed and tested a scenario with physiological sensors to objectively identify moments when NT skills can be challenged due to heightened stress. This intraoperative pneumothorax simulation consists of a sudden deterioration in the patient's vital signs during laparotomy, requiring the surgeon to coordinate the embedded team to identify the problem and initiate a chest tube placement. 7 surgeons (practicing and residents) participated in the study wearing a commercial heart rate monitor and a wearable eye-tracker. Using paired sampled t-tests, heart rate metrics (RMSSD, Mean RR interval, and average heart rate) throughout the simulation were analyzed and reported a significantly heightened stress during the vital sign deterioration segment (p<0.05) with a large effect size. Compared to the initial takeover phase and the patient deterioration phase, a decrease in fixation to saccade ratio (0.64 vs. 0.64 vs. 0.55) and average fixation duration (0.42s vs. 0.43s vs. 0.30s) was observed during the phase when the problem was identified with chest tube inserted. The more saccadic gaze pattern and lower fixation duration both indicated a possible reduction in workload after the proper problem identification. The scenario can be further used to study the effect of stress on surgeons’ NT skills and surgical performance with validated NT skills ratings and their correlation to the sensor data for a more objective evaluation.",Teaming in Work Systems,229,617
Sustainability Reporting and Environmental Impacts: A review of the Oil and Gas Industry in the GCC," This research delves into sustainability reporting and environmental impacts within the Gulf Cooperation Council (GCC) oil and gas industry. Representing one-third of global oil reserves, the GCC nations play a pivotal role in the industry. Sustainability reporting, covering economic performance, social responsibility, ethical culture, environmental protection, and governance, has gained significance. It acts as a crucial bridge between companies and communities, providing stakeholders with essential information. However, the industry, vital for global development, poses environmental and societal challenges. Climate change threatens water scarcity, reduced agriculture, extreme temperatures, and health risks in the GCC. Oil spills cause pollution, habitat destruction, and health threats. Air pollution from industry emissions contributes to respiratory and cardiovascular problems. Coastal environments and marine life face risks from industrial activities, including petrochemical plants. Eutrophication from untreated waste discharge persists. Heavy tanker traffic endangers coastal livelihoods. Recognizing the global need to halt climate change, the paper underscores the need for the oil and gas sector to address operational emissions and align with climate objectives. The research highlights the crucial role of logistics performance in environmental sustainability. In conclusion, this paper advocates for prioritizing sustainability reporting and adopting green supply chain operations in the GCC oil and gas industry. By embracing sustainable practices, these nations can contribute significantly to global efforts to combat climate change and foster economic growth, crucial for building a sustainable future for the region and the planet.",Industrial Engineering Solutions for Sustainability Planning and Reporting,101,618
Modelling Component Hardening Strategy for Power Network Resilience Optimization Under Uncertain Disruptions: A Distributionally Robust Approach," Designing a resilient power network is paramount for a stable power supply. The component hardening strategy has been widely adopted in resilient power network design to mitigate the impact of massive natural disasters and malicious attacks. However, the uncertainties associated with natural disasters and deliberate attacks pose a significant challenge in making decisions for the component hardening strategy. In this article, we put forth a distributionally robust optimization (DRO) model incorporating the component hardening strategy to minimize the impact of uncertain disruptions. The decision-dependent ambiguity set of the DRO model and the binary decision variables in the post-disruption stage greatly increase the complexity of solving the DRO model. In this article, a cutting plane algorithm is tailored to solve the DRO model. We prove that the proposed cutting plane algorithm can exponentially converge for the master problem and linearly converge for the separate subproblem. The model is also extended to a general form to cover the existing post-disruption recovery models. The results from the case study of a 35 kV power network show that the proposed DRO model yields a high-quality component hardening strategy to enhance the resilience of the power network, comparing with the existing stochastic programming models. The convergence speed of the algorithm is also examined, and it is demonstrated to be effective.",Advanced Topics of QCRE IV,10,619
Special Session: Updating the Work Systems Body of Knowledge," This special session will start with a presentation with the current chapter of the Work Systems body of knowledge document available in the IISE website. The presentation will be followed by a discussion on each one of the topics included and the level of evidence available to support maintaining the topic or replacing it with the contemporary equivalent given today's work landscape. The last part of the discussion will focus on topics not currently in the body of knowledge that participants agree (through consensus) that should be added. The outcome of this session is an annotated, updated version of the Work Systems Body of Knowledge.",Updating the Work Systems Body of Knowledge,236,620
Critical analysis of digital supply chain twin concepts and technological requirements," Digital twins are a concept often reduced to simulation. While simulation has been used in logistics for a long time, digital twins extend the common notion of simulation through its capacity to support near real-time planning and decision-making. Digital twins enable a dynamic, detailed, and functional real-time representation of physical assets to monitor their performance, anticipate their future state, or control how their resources are used. Its approaches and methods to designing, developing, implementing, and updating digital models that allow modularity, reuse and evolution of their components have not yet been exhaustively developed. It is not the first time the simulation research community has attempted to create real-time simulation models and tools. However, it is the first time the technologies required to develop such advanced performance assessment and planning and control systems are available to enable the functions needed to support real-time adaptive planning and decision-making. Several conceptual frameworks have been done to build a coherent and common understanding of such systems, but its interpretation and adaptation to specific systems still require the development of dedicated methodological and technological architectures. By exploring the body of knowledge before the popularization of the term digital twins, this paper proposes a critical analysis of the technological requirements and methodological steps to implement a digital twin in logistics. Ultimately, the goal of this project is to proposes a conceptual and methodological framework dedicated to the design, development and operation of digital supply chain twins.",Digital Twins,51,621
Collaboration based forest resources-allocation mechanism," We design a mechanism that considers collaboration to allocate a limited amount of public owned forest resources to competing companies. To do this, we introduce a new cost savings game. Our approach considers that the strength of a company (player) depends on its contribution to the collaborative efforts in overlapping coalitions. Moreover, we consider collaboration in three forest operations: harvesting, road construction / upgrading, and transportation operations. The coalition configuration concept and its corresponding value, which is a generalization of Owen's value, are applied for the first time to a real case study in Canada. In particular, we propose a methodology for value estimation based on the collected data. We compare the allocations obtained by the coalition configuration value with those of least core value solution. From this comparison, we derive conclusions on the coalitional configuration stability. We show that the combination of cost savings game and goal programming is an interesting model for the public forest resources allocation problem. Our approach can be used to tackle more general versions of the problem.",Collaborative Utilization of Natural Resources,28,622
"Developing a decision-making tool for sustainable climate action while harmonizing economic, GHG, and ecosystem service indicators in local initiatives: A case study in Québec, Canada for buffer strip implementation in the agricultural sector."," In the global pursuit of climate change mitigation and biodiversity preservation, effective leadership from public decision-makers is paramount. Successful execution relies on local public authority initiatives promoting sustainable practices among local stakeholders.In rural areas, the agricultural sector is of a primary interest to contribute both to the climate and ecological emergency by adopting innovative agroenvironmentales practices such as extended riparian strip at the edge of crops field. Our research illustrates the core decision-making challenges that lie in arbitrating between the public cost of a buffer strip project lead by a municipality in collaboration with local farmers and the anticipated benefits, both environmental (riparian restauration, greenhouse gas emissions (GHG) reductions and others ecosystem services) and economics (harvested biomass revenues, carbon market). We first review the various assessment approaches of the expected benefits from similar conservation project with GHG protocols and ecosystem services valuation. Then, we introduce a case study of such municipal-farmers project and emphasize the existence of multiple scenarios, each influencing outcomes differently and the underline supply chain design and its operations. Specifically, two scenarios of buffer strip are explored: switchgrass crops for the energy market and willow towards the bioproducts market. We delve into the parameters of our assessment model of these two scenarios, including time horizon, costs, revenues, and conversion factors. Preliminary numerical results, such as breakeven analysis and the determination of the ecosystem service value, are presented, underscoring the complexity of decision-making in sustainable initiatives at the intersection of economic, environmental, and socio-ecological considerations.",Collaborative Utilization of Natural Resources,28,623
Increasing the Deposition Rate In Molten Metal Droplet Jetting, Molten metal droplet jetting is a very promising new metal additive manufacturing process in which droplets of molten metal are ejected from a nozzle onto a moving substrate where they spread and solidify to form 3D components. Present state-of-the-art metal droplet jetting machines are able to eject ~500 µm diameter molten aluminum droplets at a rate of approximately 400-450 Hz. This is in contrast to inkjet print heads used in document printers that jet droplets at >3 kHz. This paper will present research aimed at increasing the metal deposition rate without sacrificing on print resolution. The first research thrust involves multi-nozzle molten metal jetting. A novel multi-nozzle metal droplet jetting print head design will be presented along with initial demonstrations of the system that's under development. The second research thrust involves developing novel jetting actuator waveforms that control droplet ejection velocity as well as oscillation of the fluid meniscus at the nozzle following droplet ejection. Results from multi-physics modeling of actuator waveforms will be presented to explain how acceleration profiles influence achievable droplet jetting frequencies.,Inkjet Additive Manufacturing Processes,106,624
Analyzing electronic medical records (EMRs) use by midwives to support Black Women's birthing care.," Healthcare informatics as a field advanced as a result of the collaboration between engineers and clinicians over the last several decades, capitalizing on the possibilities that mobile devices, electronic medical records (EMRs) and other information and communications technologies (ICTs) bring to medical decision-making contexts. EMR use has been demonstrated to successfully communicate, create, disseminate, store and manage medical information. Overwhelming evidence exists that successfully implemented EMRs are a key component for improving health and healthcare management. The applications play a critical role in clinical information management, error mitigation, decision making and data collection. Specifically, this work is interested in EMRs utilization and their effects on the midwifery work environment and resulting birthing health outcomes (for mother and child) using a socio-technical systems approach. This work will report on a scoping review of literature identifying the use of EMRs by midwives as they care for Black women’s maternal birthing health and document that care. The maternal mortality rates among Black women are significantly higher than other US women in childbirth, regardless of income status. As a result of triangulating the review findings with focus groups with clinicians, midwives and potentially Black mothers, this work will present the perceived advantages, disadvantages and limitations to EMRs and their impacts on the work lives of midwives. These findings will inform the design of midwifery work as well as the design of EMRs in use.",Patient Care and Treatment I,160,625
Toward integrating decision theater into digital supply chain management: literature review and conceptualization," We first review the state-of-the-art conceptual research and industry applications in supply chain management with digital twin and decision theater, respectively. Then, the reviewing result discloses the challenges about lacking interrelated communications during complex decision-making processes involving multiple stakeholders participating in digital supply chain management. Transdisciplinary dialogue rooted in immersive environment of decision theater facilitates the communication process between scientific and nonscientific. Therefore, we discuss the opportunities on integrating decision theater into the decision-making process of digital supply chain management to increase and promote the sustainability of supply chain. Finally, conclusion remarks detail our future works.","Digital Innovation in Supply Chain Management: Simulation, Decision Support, and Shared Tools",44,626
IISE Chapter Bank Account learnings and best practices to keep a chapter bank account with todays US banking regulations," This session is intended for any USA chapter that has a dedicated checking or savings account under their name. If the Chapter is able to secure money from a 'parent' organization (e.g. requesting a check that is written on behalf of the chapter by their university or company), this session is not intended for you. The evolution of USA banking regulations has resulted in both Student and Professional Chapters bank accounts to be at risk. Current banking regulations require support documentation from the chapters that are often not done or are incomplete. This session will present what chapters need to understand and have in place as supporting documentation and processes to present to their local banks in order to protect their bank accounts.",Personal Development I,162,627
Noninvasive real-time zone-level determination of critical quality attributes for engineered tissues," Engineered Tissue (ET) are quickly becoming potential therapeutic alternatives for treating various medical conditions, and is also being used widely in drug testing, disease progression studies. Despite its significant potential; ET are hindered as mainstream alternative to animal models due the lack of scalable, non-invasive and non-destructive approach for real-time monitoring of cell health. Current quality evaluation techniques are inherently destructive in nature and involve immunostaining or biochemical assays originally designed for 2D cell environments, and may require microscopic examination. Dielectric impedance spectroscopy (IS) is an innovative, non-invasive, and non-destructive approach for evaluating the critical quality attributes of an ET. Existing research prove that impedance matrix recordings such as impedance (Z), relative permittivity (∆ε), Cole-Cole-alpha (α), and critical frequency (fc) can be used to estimate the critical quality attributes (CQA’s) such as cell viability, cellular functionality, and cell health of an ET in real-time. However, a notable gap exists in literature regarding the determination of CQA’s at a localized region within an ET. In this study, we conducted structured experiments to validate the hypothesis that IS matrices accurately identify localized region-level CQA’s of an ET. We developed 1D, 2D, & 3D sensing devices capable of real-time determination of cell count and cell type in localized regions. Additionally, we observed promising results in drug testing, particularly in the real-time assessment of cancer progression in triple negative breast cancer cells and pancreatic cells. Preliminary findings suggest that IS is a viable approach for monitoring an ET's CQA's in cancer research.",Composites in Additive Manufacturing,29,628
Towards a Robust Deep Reinforcement Learning for Optimization of Heating Setup in Thermoforming Process," Thermoforming, a commonly used method in thermoplastic and composites manufacturing, involves interaction of various components influencing the quality and efficiency of the final product. Among those, precise modification of heater settings plays a pivotal role in optimizing the process. While traditional control theories have been historically employed for process optimization, recent advancements in Artificial Intelligence (AI) have encouraged its widespread adoption across diverse manufacturing domains. However, AI application in thermoforming remains limited to date. This case study harnesses Deep Reinforcement Learning (DRL) to enhance thermoforming primary operations' effectiveness. Namely, the goal is to optimize the input heating settings of the process and reduce energy consumption, using a Multi-Agent Reinforcement Learning (MARL) integrated with Transfer Learning (TL). We show how the model can be employed for thermoplastic sheets of different properties. Finally, drawing knowledge from previous learning tasks, the robustness of the transferred multi-agent RL model is analysed against manufacturing uncertainty factors, such as the distance of the thermoplastic sheet from the heaters, initial temperature at the beginning of the process, and external disturbances including variations in heat convection coefficient.",Digital Manufacturing and Industry 4.0-I,45,629
"Towards Operational Excellence in data-challenged, small, family-owned manufacturing companies - Improving data workflows at shop level in an Mexican automotive company"," Nearshoring is creating many opportunities for Mexican companies; however, Mexican SMEs, family-owned, are facing tough challenges in reaching operational excellence due, among other reasons, to the overall lack of quality, reliable data to manage and improve operations. In an environment where data is becoming a competitive factor itself, these companies need to improve their data workflows with full, reliable, on-time information to drive operational excellence. This paper presents a medium, family-owned, Mexican company dedicated to manufacture drum brakes and kacing plates for heavy-duty trucks that is looking to improve its performance. A senior engineering class, dedicated to specializing in operation excellence, performed an integral OE + I40 assessment for one of the two main manufacturing process: machining. The main assessment outcome is the lack of adequate, reliable, on-time operational data to feed management and improvement processes. The assessment pointed out that processes need to be standardized, data need to be digitally collected and fed to management processes and production planning needs to be automated and monitored to identify real operation performance. Three projects were developed using a lean approach: 1. Design digital data workflows from shop level to cloud-based databases, 2. Calculate real production capacity per machine and per process, 3. Design an automated, data-driven production planning system fed by the other two projects. The resulting digital information processes were standardized, using visual management principles, and error-free by including poka-yokes to minimize unreliable data. Resulting data will be used to drive factual-based operations management and corresponding improvement projects",Manufacturing Organizations II,140,630
Exploring the Impact of Mechanical Properties on 3D Object Performance through SolidWorks Simulation," The continual advancements in 3D-modeling and simulation tools have significantly transformed the landscape of product design and development. This revolution enables the evaluation of object behavior and functionality through simulations before the commencement of physical prototyping. Despite these advancements, the optimization of design parameters remains a formidable challenge for those aiming to produce high-performing products within budgetary and time constraints. Simulation emerges as a potent tool, offering a means to assess and refine designs effectively. This process contributes to improved product performance, decreased manufacturing costs,and a faster time-to-market. This research utilizes the SolidWorks-Simulation to analyze the influence of mechanical properties on the performance of 3D-objects. The evaluation encompasses stress analysis, displacement, and deformation under various loading conditions, considering different materials. Following the ASTM-D628 standard for specimen design—a representation of real-world applications—ensures the findings' relevance and applicability. This study explores two primary parameters under static conditions: the mechanical properties of distinct polymer materials (ABS,PC,PMMA) and varying loading values (1000,3000,5000N). The results reveal that ABS absorbs the loading force and deforms with slightly higher values compared to PC and PMMA materials. Moreover, stress values across the proposed materials remain comparable under different loading conditions. As the load increases, ABS and PC materials exhibit a dramatic rise, while PMMA material shows a consistent incremental pattern. In essence, this investigation underscores the profound impact of mechanical properties on the behavior of 3D-objects. This insight enhances the fabrication process and contributes to the development of innovative products that align with customer expectations and industry standards.",Facility Design,75,631
Simulation based optimal insulin infusion pump controller design with reinforcement learning," The development of control systems to achieve desired responses from mathematical models representing the interaction between glucose and insulin within the human body are garnering attention to help with understanding this dynamic environment. These control systems have the main objective of controlling the injection of insulin to maintain plasma glucose concentrations within a healthy range, and reinforcement learning (RL) has emerged as a potential option. RL utilizes a continuously adapting learning agent to apply an action to an environment based on its current state that will induce change in the environment and lead to reinforcement by the environment onto the agent based on the result. RL is used in this study to achieve the purpose of producing an optimal insulin infusion profile in response to an increasing plasma glucose environment, such as seen after eating a meal. An optimal insulin infusion profile for this study is described as delivering the smallest total concentration of insulin while avoiding hyperglycemic and hypoglycemic states as well as stabilizing plasma glucose to basal levels in 90 minutes. Applying the minimal amount of insulin to effectively control plasma glucose concentrations is important to decrease potential insulin resistance from cells and allow for the effective treatment of diabetes for the duration of someone’s life. The RL insulin infusion profile will be compared to a profile produced from a Proportional-Integral-Derivative (PID) controller, which utilizes a Simulink autotuner, by analyzing the area under curve for each profile to determine if RL is appropriate for this situation.",Simulation Models in Health Systems,206,632
Privacy-Preserving Load Forecasting via Personalized Model Obfuscation," The widespread adoption of smart meters provides access to detailed and localized load consumption data, suitable for training building-level load forecasting models. To mitigate privacy concerns stemming from model-induced data leakage, federated learning (FL) has been proposed. This paper addresses the performance challenges of short-term load forecasting models trained with FL on heterogeneous data, emphasizing privacy preservation through model obfuscation. Our proposed algorithm, Privacy Preserving Federated Learning (PPFL), incorporates personalization layers for localized training at each smart meter. Additionally, we employ a differentially private mechanism to safeguard against data leakage from shared layers. Simulations on the NREL ComStock dataset corroborate the effectiveness of our approach.",Privacy and Security in Power Systems,173,633
Multimodal probabilistic modeling of COVID19 density map," Inspired by the physics of optimal imaging, this paper presents a novel approach to simulate the COVID19 cases for statistical estimation and modeling of the multimodal probability distribution function (PDF) of a COVID19 density map. First, we simulate a large number of COVID19 cases as independent and identically distributed (iid) random samples drawn from the multimodal PDF of a COVID19 density map. Second, we propose a new Gaussian mixture model to estimate the multimodal PDF of COVID19 cases via the expectation-maximization procedure. Third, we leverage the estimated Gaussian mixture model to investigate the geometric variations of COVID19 density maps.",Healthcare V,89,634
Spiking Neural Network for Identification of Future Influenza Strains in the United States," As influenza strains rapidly evolve, a spiked neural network perspective would be beneficial to identify which strains would be most prevalent among various locations. This allows for tracking strain development and prediction of strain prevalence along with the framework to predict strain morphology. Influenza accounts for significant deaths, sickness, and costs to both national and local governments year after year. Predicting incidences and strains will allow public health officials to better prepare for novel strains. The approach to use Spiking Neural Networks (SNN) on influenza data has yet to be attempted. SNNs allow for increased computational efficiency and more accurate prediction due to the nature of spiked neural networks. This leads to better prediction of certain strains along with computational efficiency of spiking neural networks.",Healthcare V,89,635
A Simulation Based Metaheuristic for Workforce Allocation in Airport Screening Facilities," This study introduces a simulation-based metaheuristic designed to enhance the efficiency of airport checkpoints. The utilization of simulation-optimization proves effective in addressing challenges associated with data uncertainties that unfold over time. This is particularly pertinent in the context of airport security checkpoints, where predicting passenger arrival times is challenging, necessitating advance scheduling of equipment and human resources. This work incorporates uncertainties related to future passenger arrivals, as well as the availability and performance levels of resources, into the computation of schedules and area assignments. A case study is presented for an airport with two security checkpoints. The computational results demonstrate the efficacy of the simulation-optimization strategy in optimizing resource allocation for airport checkpoints. By developing innovative decision-making models that leverage technology and knowledge, this research aims to enhance the overall operational effectiveness of airport security checkpoints.",Decision Support,39,636
Co-Simulation Model to Evaluate the Impact of Nudges on Occupant Behavior in Smart Buildings," This paper presents a co-simulation model that integrates EnergyPlus and AnyLogic as a testbed to investigate the nexus between energy use and occupant behavior in buildings. More specifically, this model proposes to simulate occupant behavior in terms of their environmental and demographic profiles, their indoor activities, their perception of thermal comfort, their ability to adjust the temperature setpoint (i.e., thermostat) and their clothing, as well as external incentives or nudges used to influence their energy consumption. Anylogic is used to simulate occupant behavior; EnergyPlus is used to simulate the building environment (thermal control and energy use); and Python is used to coordinate both simulation models. A key innovation of this project is the modeling of external interventions, such as an energy consumption ranking system, economic incentives, or energy management decisions, to balance occupant comfort with reduced energy consumption. Preliminary results show how these interventions can influence occupant behavior and energy use, highlighting the method's potential for real-time management, energy reduction, and applications in smart energy management and building automation systems. The long-term goal of this tool is to investigate the potential of nudges to smooth and reduce energy consumption in a multi-occupant building.",Modeling Human Behavior,148,637
Integrating UX Journey Mapping with Systems Theory Behavior Over Time Graphs to Explore the Complexities of Identity Formation.," Literature on professional identity formation is broad and complex. Currently, researcher identity development is an important topic that is beginning to be studied in different educational areas, including industrial and system engineering. Documenting researcher identity development is critical for designing student-centered programs. This is particularly crucial in doctoral students, as it may contribute to appropriate professional development support delivered by graduate programs. To properly analyze identity development, investigators have used tools from user experience (UX) methods such as journey mapping, which are invaluable. Journey maps document and visualize the steps that the “users” (in this case, novice researchers) take to achieve a goal, including the process that developing professionals undergo to become experts in their respective fields. Meanwhile, investigators have also used Behavior Over Time (BOT) Graphs in Systems Theory research, which assist in analyzing individual and organizational behavior trends over time. BOT graphs are also effective tools for tracking complex social behaviors. This paper proposes the potential to bridge gaps between UX and Systems Theory research methods, through their integrated application to understand researcher identity formation in doctoral engineering students. This integrated application offers a nuanced perspective on the formation of professional identity. This study benefits researchers by offering insights into new potential methodological approaches for mapping complex situations and behaviors. The examples provided in this paper focus on doctoral researcher identity formation but are not limited to this area of endeavor. Practitioners and researchers can apply the proposed approach in various contexts, within and outside of engineering.",Engineering Identity & Global Engineering Education,68,638
Improved Intel's Substrate Capacity Analysis and Future Substrate Factory Design and Decision using Capacity Equivalent Dashboard," Substrates, integral in linking the die to the motherboard, constitute the second most costly asset at Intel. Planning their capacity and future manufacturing sites is intricate: with over a hundred projected substrate products per cycle, each possessing distinct package design attributes influencing capacity and diverse capacity requisites. Distribution of manufacturing capacity for these substrates spans across multiple suppliers, each operating a network of factories tailored to specific product types and capacity levels. The establishment of a new factory embodies a substantial Intel capital investment, entailing a three-year lead time. Anticipated product mix and volume forecasts indicate a surge in capacity requirements, reflecting a 1.8x growth in necessary capacity since 2018. Numerous forthcoming factories are forecasted, with several already in the ramp-up phase. The preceding capacity analysis method lacked robustness to assess scaled data comprehensively, evaluate sensitivity factors impacting capacity demands, and often incurred lengthy processing times for simple requests. A prompt, consistent, and reliable methodology was imperative to analyze immediate capacity concerns, synchronize with supplier responses, and facilitate swift What-If simulations for assessing the impact of factory ramp-up and capacity scenarios with diverse product mixes and attributes.",Manufacturing I,135,639
Using living labs as a mean of IoT transfer of expertise.," This industry-academia transfer of expertise is very important, especially for front-end innovation projects. The aim of this work is to highlight effective practices for transferring IoT expertise and/or knowledge. In this context, our methodological approach is qualitative. We will mainly use Living Lab approach, in which users are no longer seen as an object of investigation but as key players in the innovation process. This approach which values open innovation, was highlighted by Thomas Edison, who said: ""the value of an idea lies in the using of it"". In this research approach characterized by “users as innovators” cooperating in an open and independent research environment we aim to envision, design, develop, test and validate emerging IoT applications – as well as build and transfer expertise and knowledge. Frameworks and procedures for teaching/learning IoT solutions are therefore important for users and learners. From a skills development perspective, we will leverage the infrastructure deployed at an IoT lab based at a university in Montréal and present a case study on the development of an innovative smart shelf solution using RFID technologies.","Internet of Things (IoT) Technology: Tools, Management & Applications",116,640
Bibliometric analysis of burnout studies before and after COVID-19 reveals themes and opportunities for interventions.," Recent reports suggest a relationship between COVID-19 and increasing rates of burnout among healthcare professionals, resulting in problems such as employee turnover, missed care, and societal costs. The purpose of our study is to determine if there are significant differences between the topics studied about burnout in the healthcare industry before and after the COVID-19 pandemic. The terms ""burnout"" and ""healthcare"" were used to perform a literature search in the Web of Science database. To facilitate comparison of themes, the search results were divided into two major time periods: before (1993-2019) and after (2020-2023) COVID-19. A bibliometric co-occurrence analysis of these publications was performed using VOSViewer. A sample of 1000 keywords were compared to identify similarities and differences in burnout related topics studied during the two time periods. Findings indicate that 64% of the articles were published during the COVID-19 period. Furthermore, 492 of the keywords presented in these studies were similar for both time periods, focusing on topics such as bullying, coping mechanisms, job demands, and workplace conditions. While Alzheimer's disease, substance use disorders, and workaholism dominated study topics from 1993 to 2019, the post-pandemic period saw an increase in research on workplace aggressions, emerging technologies such as telemedicine and virtual reality, and studies directly related to COVID-19. Our study findings indicate that there was awareness about burnout in healthcare professionals even prior to the pandemic. Although numerous studies have examined strategies for reducing burnout, the effectiveness of these strategies and barriers to implementing them needs further study.",Emergency Response and Preparedness  in Health Systems,60,641
Accessibility evaluation of state public health department dashboards during the COVID-19 pandemic," Dashboards became important during the COVID-19 pandemic. Given the significance of these dashboards to public health, ensuring their accessibility is crucial. The purpose of this study is to evaluate the accessibility of COVID-19 data dashboards on the websites of 51 public health agencies in the U.S. To assess the accessibility of the dashboards, we used the Web Access Checker tool AChecker. We evaluated violations of WCAG 2.0 guidelines at the A, AA and AAA levels in each of the 51 websites containing dashboards. The analyses show the extent to which the websites adhere to WCAG 2.0 guidelines at the A, AA, and AAA levels. The accessibility principles evaluated are known as POUR which stands for perceivable, operable, understandable, and robust. To differing degrees, all websites violated all four POUR accessibility principles, with the highest number of problems occurring in adhering to the perceivability and operability principles. At the lowest A level, most dashboards lacked alternative text, alternative ways of displaying content, and descriptions about the purpose of each link. Similarly, websites contained problems with language, user input labels, and resizing. At the AA level and AAA level, contrast ratio, resizing and navigational issues were prevalent on the websites.To ensure that all individuals can make more informed decisions without having to rely on unofficial or secondhand information, it is imperative that public health agencies make accessibility a priority when developing websites for disseminating public health information.",Work systems and services for Human Factors and Ergonomics,242,642
Design of Reliable Pricing in Residential Electricity Distribution," This talk presents studies of residential users' electricity consumption in response to time-of-day pricing under demand response in a smart grid. To provide a reliable pricing scheme, this study considered both rational and irrational human decision making. Multilevel optimization models are built to tackle this challenge, which comes with a catch, being difficult to solve. By leveraging hidden convexity, a Lagrangian cutting plane method is tested. Both computational and managerial insights have been drawn from this study for both academia and industry practitioners.",Policy-driven Decision Making,168,643
Using IoT technologies and simulation as building blocks for a Digital Twin in a clinical care environment," With the fast development of analytical capabilities as well as the Internet of Things (IoT) technologies and the potential of automated real-time data gathering, allowing decision makers to take advantage of real-time visibility on their processes, the rise of Digital Twins (DT) has attracted several research interests. Indeed, DT are listed among the highest technological trends managers and researchers cannot afford to ignore for the near future. While the application of DT in healthcare is mainly focused on the digital patient, our research project analyzes the impact of applying DTs for improving healthcare daily operations management. In this research paper, we analyze the impact of using a DT in a clinic that provides care and support services to marginalized people suffering from addiction. Following a ""design science"" research approach, we develop (i) an IoT prototype for real-time patient and resource tracking, (ii) a hybrid simulation model to represent clinic’s daily operations, and (iii) build our DT prototype. Our IoT Lab is used as a testbed research environment to develop the IoT infrastructure and simulate the implementation of the DT. While the prototype is developed for a specific clinic, the approach can be applied to any other healthcare operational environment where real-time visibility and decision support based on simulation is needed.","Internet of Things (IoT) Technology: Tools, Management & Applications",116,644
Weather Prediction using Machine Learning and Markov Chains," This research aims to apply machine learning and Markov chains in a novel way, and weather prediction is taken as a case. Through the use of historical weather data, precise machine learning models are created for each country, and the developed model provides a cutting-edge method for very accurate, real-time weather predictions. In addition to forecasting weather, the system also provides transition probabilities between different weather states. This system, which is easy to use and emphasizes accuracy and dependability, is a great resource for decision-making in areas such as transportation, agriculture, and emergency preparedness. Finally, this research addresses the drawbacks of conventional weather forecasting, making a substantial contribution to well-informed planning and the welfare of society.",Energy & Environment II,63,645
Pedestrians Interaction with Automated Driving Systems: Design of External Communication Interface," In 2022, over 40,000 pedestrians were killed in traffic accidents caused by human error (1). Level-5 Automated Driving Systems (ADSs) have the potential to create safer roads by eliminating human errors (2). However, this can only happen if they are well integrated in the transportation system. While the development and deployment of level-5 ADSs have been improved, the interactions between pedestrians and ADSs are not fully understood, despite pedestrians being the most vulnerable road users. This study investigated the factors that affect pedestrians' acceptance of level-5 ADSs and design features for safe and efficient external human-machine interfaces (eHMIs) to facilitate communication. A survey was conducted with 37 participants to investigate the impact of pedestrians’ background, behaviors, and personal innovativeness on ADS acceptance. A follow-up lab study was performed with 70 participants to determine effective eHMI design features. It was found that there was no effect of background information on the acceptance factors or behavioral intention to cross in front of level-5 ADSs, though pedestrian behaviors and personal innovativeness had a significant effect. In the eHMI lab study, both visual and auditory features were used to create eHMIs including external speedometers, audio cues giving advice to pedestrians, and a method of indicating the driving system was level-5 ADSs. This study gives recommendations about the effect of pedestrians’ background, behaviors, and personal innovativeness on eHMI acceptance and intention to cross the street in front of level-5 ADSs as well as several key visual and auditory features pedestrians included in eHMIs.",Diverse Topics for Human Factors and Ergonomics 2,56,646
Contribution of the Systems Approach to Quality Management in Manufacturing: The Case of Human Error Analysis in Complex Manual Assembly," Human error is considered one of the main causes of quality problems in complex manual assembly. The origin of human error is associated with various factors in the work environment that can influence workers' performance and increase the probability of errors, thus decreasing human reliability. Factors that influence human reliability have been studied by the discipline of ergonomics and human factors for at least 40 years, particularly in safety critical domains (nuclear, petrochemical, aviation). While human reliability methods can make an important contribution to the analysis of assembly errors in manufacturing, they primarily focus on factors directly influencing worker performance and do not include factors associated with the socio-technical system. Therefore, the use of systemic methods of human error analysis is a fundamental contribution to quality management in manufacturing. These methods can shed light on influencing factors at higher levels of the organizational structure, which can support decision-making by managers. In this paper, we present a reflection and comparison on the use of three systemic methods for the analysis of human error in manual assembly: AcciMap, STAMP, and HFACS.",Cognitive Ergonomics,27,647
Optimal and Personalized Dose Determination for Patients with Thyroid Hormone Disorders Using Deep Learning-Based Survival Analysis," This study introduces a new recommendation methodology for determining the initial medication dosages for hypothyroidism patients. While the significance of precise initial dosing cannot be overstated, the current practice for hyperthyroidism relies on simplistic formulas or physician expertise. Leveraging clinical trial data from 80 actual hyperthyroidism patients at Thyroscope Inc. and Seoul National University Bundang Hospital (SNUBH), we constructed a time-to-event dataset, defining recovery after medication initiation as an event. Building upon this dataset, we developed an innovative deep survival analysis methodology for determining initial medication dosages. Experimental results reveal an average 16% improvement in survival probability compared to conventional methods, showcasing the potential impact on enhancing treatment efficacy and patient outcomes.",Patient Care and Treatment II,161,648
Implementing the Hybrid Virtual Nursing Care Model in Acute Care Settings for Admission and Discharge Tasks," Nationwide, hospitals are grappling with a mounting nursing shortage, primarily fueled by burnout and the educational gap between seasoned nurses and recent graduates. This pilot study aims to introduce the hybrid virtual nursing care model with a focus on admission and discharge tasks. The hybrid virtual nursing care model was implemented on two units within a rural hospital in the southeastern United States. The study's core methodology involved conducting time studies to identify and measure various tasks performed by both virtual and bedside nurses. Detailed time-stamped flowcharts were developed based on observations, capturing the flow and duration of key tasks associated with admissions and discharges. The research findings indicate a reduction in the time required for admissions and discharges with the implementation of the hybrid virtual nursing care model. The choice of technology, whether tablets or TV kits, emerged as a critical factor influencing the time-saving aspect. Additionally, the study highlighted the importance of pre-existing workplace culture and the presence of project champions. Additionally, vital qualities for virtual nurses surfaced, including multitasking skills and effective communication, both emotionally and clearly, in conveying messages to patients and caregivers virtually. The impact of the hybrid virtual nursing care model is promising in healthcare. Beyond admissions and discharges, it could expedite medication confirmations and deliver comprehensive education to patients and caregivers without burdening bedside nurses. The model holds potential to revolutionize various aspects of healthcare delivery.",Home and Mobile Health Systems,92,649
Understanding and Identifying Pharmaceutical Supply Risks for the Department of Defense," This systematic literature review delves into the intricate dynamics of pharmaceutical supply chains (PSCs) to identify and evaluate risks across various stages of the supply chain. The paper aims to establish a comprehensive understanding of the challenges inherent in both military and civilian PSCs by comparing the unique challenges faced by each PSCs. While civilian pharmaceutical supply chains focus on commercial viability, regulatory compliance, and widespread distribution to healthcare facilities, military supply chains demand rapid response capabilities, stringent security measures, and adaptability in challenging environments. By highlighting similarities and differences between these sectors, the study aims to derive insights for developing strategies that enhance resilience and mitigate risks in both military and civilian pharmaceutical supply chains. The findings seek to offer actionable insights to policymakers, industry practitioners, and researchers, fostering improved decision-making and bolstering resilience against evolving challenges in pharmaceutical supply chains.",Healthcare Supply Chain,88,650
A Metrology Inspection Guide for Informed Decision-Making and Process Optimization in Small and Medium Manufacturers," In the context of modern manufacturing, the imperative need to ensure product quality and precision has driven the adoption of proactive in-process inspection, particularly through automated means like Coordinate Measurement Machines (CMMs) and Blue Light Scanning systems. However, understanding the capabilities and suitability of these systems for various part geometrical characteristics poses a challenge. This paper presents the concept of a ""Metrology Inspection Guide"" tailored for Small and Medium Manufacturers (SMMs) to facilitate informed decision-making, enhance data collection efficiency, and optimize manufacturing processes. By replacing trial-and-error approaches, this guide aims to boost productivity, reduce defects, minimize rework, and promote cost-effective manufacturing in the Industry 4.0 landscape. The project's scope involves creating a standardized framework for comparing CMMs and Blue Light Scanning systems across diverse part geometrical characteristics, offering clarity to SMMs, and providing comprehensive experiment notes and system recommendations based on part characteristics and volume.",Advanced Topics of QCRE III,9,651
Mixed-initiative system for combined planning and scheduling.," Creating a master production schedule is crucial since it outlines the timing of production activities, taking into account resource availability, capacity constraints, and dependencies. Generating a production schedule can be done using a constraint programming model that may identify multiple feasible solutions, not all of which consider the planner's preferences.This study is motivated by the need of an industrial partner to automatically schedule production activities, while enabling the user to reschedule some activities without compromising the solution’s validity. In pursuit of this goal, we propose to develop a Mixed-Initiative System to combine planning and scheduling. The mixed-initiative system enables the user to plan by testing various changes to the solution in what-if mode, while maintaining the validity of the schedule. First, a constraint programming model with a large neighborhood search heuristic is used to generate a first solution. If the solution does not satisfy the user’s requirements, a linear model is solved and returns a new solution within a reasonable time according to the user's preference. Interactions must not only meet the user's needs, but also be as fast as possible. Thus, a User Interface (UI) is designed to improve the user’s experience and remove usability barriers, relying on Human-Computer Interaction (HCI) and user experience (UX) designs as the fundamental aspects of the conception process. The Mixed-Initiative System developed is tested with the industrial partner and is considered quite satisfactory by different users and can be generalized to other operations scheduling and planning problems.","Digital Innovation in Supply Chain Management: Simulation, Decision Support, and Shared Tools",44,652
Bridging the Gap: Aligning Manufacturing Industry Recruitment Strategies with the Aspirations and Preferences of Generation Z," Over the past four decades, the manufacturing industry has experienced a prolonged decline, triggering widespread repercussions across various sectors. As the companies hope for an influx of new employees, and job vacancies continue to rise, it is imperative for manufacturing companies to actively engage Generation Z in pursuing careers within manufacturing. This research project aims to reveal the gap between the aspirations and expectations of these generations and the current recruitment strategies employed by the local manufacturing sector for talent attraction. Drawing upon insights from previous research that delves into the psychological nuances, communication preferences, habits, and attitudes of Generation Z, this study will juxtapose these findings with the existing efforts of the manufacturing industry in recruiting these cohorts. By analyzing the survey results conducted with small to medium-sized manufacturing companies in the Auburn, Alabama area, this paper seeks to identify any disparities between the industry’s practices and the preferences of the target demographic and provide data to help bridge the gap.",Industry-Academia Collaboration in Education,103,653
Linear Approximations for Stochastic Serial Network Performance," Many systems are characterized by the flow of entities through a network of servers. Systems may have random, nonstationary interarrival times and arrival group sizes, stochastic service times, parallel servers, and finite buffers that induce blocking. Representative systems include the flow of batches or material through a manufacturing system, the processing of paperwork through a service system, or passengers passing through a security screening checkpoint. In all cases, the flow is subject to conservation equations that can be used to develop deterministic approximations of the actual throughput rates, queue lengths, and throughput times associated with a particular network architecture and parameterization. In this paper, a computationally efficient, deterministic approximation of stochastic network performance is proposed and evaluated for serial systems. Nonstationary arrival rates and arrival rates that temporarily exceed service capacity are modeled with discrete periods. Arrival rates within each period are set equal to the distributional mean at that time. Throughput is limited by arrival rates at each stage from outside the system or prior stages, service capacity and possible blocking after service. Two stage and four stage systems are examined with balanced and unbalanced capacity, and with finite and infinite buffers. Queue lengths and throughput times are tracked by period. Performance of the approximation is compared to stochastic simulation for a variety of cases including constant and sinusoidal arrival patterns with various levels of average utilization. The approximations are shown to work well for estimating throughput times and, under certain conditions, queue lengths.",Risk Management,195,654
Identifying the Most Important Drivers of a Culture of Continuous Improvement via Regression Models," Ever since lean management was introduced, the topics of a culture of continuous improvement and lean management tools have been widely researched and implemented across various types of organizations. However, there is a lack of empirical studies that investigate the most important drivers for creating, growing, and sustaining a culture of continuous improvement. This paper will systematically investigate the significance of different potential drivers of a culture of continuous improvement using data from over 30 teams within the material handling industry. All these teams are supported by the organization’s lean management team and encompass various aspects of the company’s responsibilities, but are mostly based in the corporate office and not operations team. Potential factors or drivers of culture will be determined from pre-existing KPIs and through brainstorming sessions with the lean management team. To examine these factors, linear regression and pre-trained transformer models will be applied to calculate weights of significance or correlation for each factor in consideration of each team's overall grade. Grades will be determined from the average grades given by the five lean management experts. This paper will provide valuable insights backed by data into what the most important drivers of a culture of continuous improvement are, allowing people from any organization to take a targeted and effective approach into implementing and sustaining that culture.",Organizational Culture,157,655
"Home care work of partners and caregivers for Hispanic adults with dementia: A culturally informed model integrating work systems analyses, health disparities research framework, and life course perspectives."," Our study develops and evaluates an integrated, multi-layered, culturally informed, health disparities-sensitive model of care work home caregivers such as family of Hispanic adults with dementia perform by combining and integrating the SEIPS 3.0 model and the research framework of the National Institute on Minority Health and Health Disparities (NIMHD). We created three sets of “Caregiver-Hispanic adult with dementia” personas with the help of two experts in community health and dementia caregiving to generate journey maps at the most important intersects of care elements. The journey maps traverse several layers of our model including the behavioral, physical/built environment, sociocultural environment, and the healthcare system layers. At an individual level, the sociodemographic and cultural identities of both the caregiver and the cared for can tend to play prominent roles in the journey map. Our model identifies prominent emerging intersects between home care work tasks, tools, goals and outcomes intertwined with factors that influence health disparities in the care giving process for Hispanic adults with dementia. More than 55 million people worldwide live with dementia. Informal and unpaid caregivers perform the bulk of the care work, estimated to total 18 billion unpaid hours, valued at 340 billion dollars in 2022. Hispanic adults are more than twice as likely than White adults to have dementia. Hispanic caregivers report greater care demands, less outside help, and more depression. Hence, any model of care giving work must prioritize health disparities due to differences in life experiences, socioeconomics, and health and well-being of caregivers.",Home and Mobile Health Systems,92,656
Pandemic Wave-based Influence Analysis of Social Media Information," Social media platforms are ubiquitous in society today and consist of countless individual accounts. Each account wields varying levels of influence, and how the account attributes affect the influence has always been a subject of significant scholarly interest. Inspired by the proliferation of misinformation on social media during the pandemic, we use a X-sourced dataset and undertake a comprehensive examination of the factors that influence social media accounts in this paper. We propose a novel mechanism to perform time-series analysis based on COVID-19 waves. Our method combines regression statistics and machine learning techniques to better elucidate how an account's characteristics and the nature of its content can affect its influence score. Consequently, we discover a negative correlation between an account's influence and the linguistic complexity and rationality of the context during emergencies. Additionally, we determine that the size of an account influences the strategy requirement, with different sizes of follower accounts necessitating customized approaches.",Social Media & Information Analytics,210,657
Smart IoT System for Longitudinal Real-time Physiological Monitoring of Cancer Patients Undergoing Treatment," Cancer patients with comorbid conditions experience notably higher mortality rates shortly after diagnosis and treatment. Among these conditions, sleep-disordered breathing is a crucial yet often overlooked concern during cancer therapy. Conventional in-lab sleep diagnostic methods, such as polysomnography (PSG), present challenges in real-time monitoring capabilities and patient comfort. Meanwhile, existing at-home sleep monitoring devices exhibit limitations in edge computing capacity and the ability to collect longitudinal diagnostic signals in cancer patients. This paper introduces a smart IoT system designed to enhance real-time and longitudinal physiological monitoring. Our proposed physiological monitoring system integrates hardware and software components, featuring ESP32-based IoT devices tailored for the efficient and non-intrusive collection of vital bio-signals such as ECG and SpO2. The compact form factor takes into account the unique characteristics of cancer patients. The cloud-based system enables real-time data monitoring and analysis using Apache Spark and Kafka, providing immediate insights to healthcare professionals. Lab evaluations using bio-signal simulators and trials conducted on head and neck cancer patients demonstrate the system's capability for continuous, real-time monitoring, facilitating prompt identification of changes in patient conditions during cancer treatment. By enabling at-home real-time physiological monitoring, our system addresses existing limitations and advances the quality of care for cancer patients undergoing treatment.",Cancer Care,24,658
"""Feasibility Study for the Establishment of a Sargassum Algae Biofertilizer Production Plant in the Dominican Republic"""," In response to the global environmental concern, particularly ocean pollution and its devastating effects on marine ecosystems and tourism, this study proposes an innovative and sustainable solution. It focuses on sargassum algae, whose excessive proliferation in the oceans has been driven by industrial pollution and global warming, adversely affecting marine life and tourism in the Dominican Republic. To address this challenge, the establishment of Biorgazo S.R.L. plant is proposed, dedicated to the production of natural biofertilizers from sargassum. This biofertilizer, named Biorgazo, is presented as an ecological alternative to synthetic and chemical fertilizers. It is characterized by its high content of essential nutrients such as phosphorus, potassium, nitrogen, calcium, sulfur, and magnesium, and a moisture level beneficial to the soil. Strategically located in San Pedro de Macorís, the plant requires an initial investment of RD$50,348,444.32, including construction, machinery, transportation equipment, and other supplies. The financing is distributed between a loan from local bank, covering 70% at an interest of 15.95% annually for 12 years, and the remaining 30% by principal shareholders. The economic and financial viability of the project is confirmed with a Minimum Attractive Rate of Return (MARR) of 12% for 10 years, a Net Present Value (NPV) of RD$11,681,366.45, and a Payback Period (PP) of 4.20 years, ensuring a Return on Investment (ROI) of 23.78%. This project not only represents a promising solution to a critical environmental problem but also promises to revitalize the local economy and tourism, transforming an environmental issue into an opportunity for sustainable development.",Energy and Infrastructure,66,659
Models for scheduling charging tasks for electric vehicles," The problem of scheduling electric vehicle (EV) charging tasks on parallel chargers over time is considered. The decision time range is an interval or a circle. Each charging task has to be performed within its fixed time window. The charging tasks can be preemptive or not. Each charging preemption may imply a setup time or cost. Each task is associated with a given amount of energy that has to be received from the chargers, which determines the charging time requirement. The chargers are characterized by their electric power. The total power supply is limited and the limit can be time dependent. The objective is to minimize the total cost of the chargers, setups and received energy. In practice, this problem is part of a more general EV routing and charging scheduling problem. It appears when a routing decision precedes a charging decision and provides charging time windows and energy requirements for the latter. Various special cases of the charging scheduling problem have been studied in the literature, in the practical and theoretical contexts. We review and analyze these special cases using traditional scheduling terminology, thereby creating a bridge between practical charging scheduling models and theoretical scheduling models.",EV logistics,58,660
Modeling Infrastructure Vulnerabilities Using Attack Graphs," As infrastructures in our society become increasingly interdependent on one another, the possibility of attacks on these infrastructures utilizing these also increases. In this paper, we consider attacks from multiple attackers working cooperatively to reach their goals. Moreover, we model the possibility that multiple exploits must be used by an attacker to reach their objective. In this work, we propose modeling attacks using the notion of attack graphs, in which attack graph nodes represent states an attacker seeks to reach, and arcs represent exploits that must be completed in order to reach an attack state or move from one attack state to another. In this context, an attack state could correspond to an attacker compromising some portion of a network infrastructure, and an arc in an attack graph refers to an exploit that must be completed to compromise that portion of the infrastructure. Assuming each exploit requires some positive amount of time to complete, attackers seek to reach all attack states as quickly as possible. To solve this problem, we provide a mixed-integer programming model along with a set of valid inequalities. As an alternative, we present a decomposition-based algorithm in order to solve the problem faster. Furthermore, we provide computational results comparing the different methods and discuss future work.",Network Optimization,149,661
Energy by-product Exchanges Optimization in Industrial Parks: A case study of the Bécancour Industrial Park," Recently, there has been a growing interest in the use of quantitative tools for the optimization of industrial symbioses and by-product exchange networks. However, while there is a substantial literature on material exchanges, there is less literature on the optimization of energy exchanges. This project addresses this gap. The literature shows that existing models do not fully address all considerations, such as long-term investment and profitability for individual actors. To address this issue, we extended the capabilities of a model and validated the results for the specific case of the Bécancour industrial park, Québec, Canada. More specifically, we adapted a mixed-integer linear programming model (AnyMOD.jl) to optimize industrial symbiosis and energy by-product exchange. In particular, the proposed model now includes the forecasting of future energy outflows using time series analysis. In addition, constraints have been added and modified to reflect the characteristics of the physical infrastructure required to enable energy exchange. Furthermore, the model was adapted to account for the stochastic nature of some parameters. In order to identify the optimal network of economically viable energy by-product synergies between industrial companies, the optimization model considers various aspects such as the long-term energy consumption profile of companies, the supply and demand of energy by-products within the industrial park, and various economic factors of the energy exchange network. To account for the infrastructure required to enable these exchanges, this model considers energy conversion technologies, energy storage solutions, mutualizing infrastructure opportunities, energy by-product flow treatment, and the potential for adding complementary companies.","Building Sustainable Communities: Enhancing Early Child Development, Infrastrucure, Park Access and Industrial Efficiency (SDG 11)",22,662
Data-driven analysis to minimize downtime in an automated production line," This study presents a comprehensive, data-driven approach to minimize operational downtime, a crucial determinant of overall operational effectiveness (OEE) in manufacturing processes. Through an in-depth study of operational systems, employing innovative analytical tools such as mind maps, causal loops, and cause-effect diagrams, we identified and addressed the primary factors causing machine downtime. Our strategy included the implementation of crafted standard operating procedures (SOPs), which encompassed failure modes for each station, a refined data entry process, and targeted mechanical interventions, particularly at the bottleneck station: the bag welding station. Additionally, the integration of human elements through extensive workforce surveys ensured the alignment of solutions with employee dynamics and self-interest, contributing to sustainable changes. The proposed solution has been shown to increase OEE by more than 1.1% in all scenarios, leading to a revenue increase of over a million USD per year.",Manufacturing Organizations II,140,663
Robust design of an Industry 4.0 manufacturing platform for mass personalization," The manufacturing of customized items with personalized design features is a complex task, characterized by various sources of uncertainties. As opposed to standard products, the amount of design and manufacturing resources required to produce such items highly depends on the intricacy of their design specifications. This would significantly extend their manufacturing lead-time and consequently reduce service level and/or increase lost sales. This study develops a decision model facilitating the design of a reliable manufacturing platform that guarantees a high service level (low lost sale) under the most pessimistic circumstances in terms of suppliers’ production lead times. The goal is to alleviate the impact of reduced capacity of part and sub-assembly suppliers in manufacturing intricate products (e.g., lidars) that incorporate specialized, high-tech components (e.g., lasers) in their bill-of-material. An adjustable robust optimization (ARO) model is developed that determines the optimal choice of suppliers from a pool of entities all featured with uncertain capacity for the production of customized items. The uncertain capacities are modeled as intervals without emphasizing on a specific probability distribution. The objective is to maximize the platform profit under the worst-case capacity outcomes while imposing a budget of uncertainty. The latter controls the level of conservatism of the decisions by limiting the number of suppliers that might be confronted with maximum production capacity drifts. The AOR model is solved based on a Monte-Carlo sampling approach and its performance is compared with a deterministic model in terms of total lost sale cost under out-of-sample capacity scenarios.",Smart Manufacturing and Design,207,664
A Recruitment Game for ISE: Usability Feedback from ISE Faculty and Graduate Students," Engineering departments in the United States constantly look for creative approaches for their recruitment and outreach campaigns. Some engineering majors enjoy high visibility and don't require active recruitment, while others, like Industrial and Systems Engineering, are less widely known and need to be more proactive. Declining enrollment occurs when prospective students and their guardians lack awareness of the potential benefits associated with a specific college degree. Thus, outreach and information sessions are of higher importance for Industrial and Systems Engineering departments. This paper examines the educational content and usability of an Industrial and Systems Engineering (ISE) recruitment activity. The activity engages prospective students in a “simulation game” that is designed to allow them to utilize ISE ways of thinking to solve a problem. For the first part of a multi-step evaluation, ISE faculty members and graduate students at a mid-western university will participate in the activity and serve as expert evaluators. Using Neilsen’s usability heuristic principles (1994), experts will complete a questionnaire that assesses i) a layperson’s understandability of the ISE recruitment activity, ii) the activity’s ability to inform prospective students about industrial engineering, and iii) the activity’s ability to engage students in systems-level thinking. Based on expert feedback, we will appraise the effectiveness of the ISE recruitment activity to make further refinements before deploying it with prospective students. The ultimate goal of this evaluation work is to develop a more effective and robust ISE recruitment activity that can be adopted by other institutions.",Industry-Academia Collaboration in Education,103,665
Optimization of the Healthcare Infrastructure Planning in Guanajuato: A Comprehensive Primary Healthcare Units Planning Model," The planning of primary healthcare infrastructure is essential to improve access to healthcare services for the population, especially in developing countries where access to healthcare is limited. In this work, we propose the use of a bi-objective optimization problem to support the decision-making process related to the strategic decisions of locating new Primary Healthcare Units (PHUs), upgrading the installed capacity in the PHUs network, and allocating demand points to PHUs. We present a Case Study based on the State of Guanajuato, Mexico; a federal entity with more than 6 million inhabitants in 2020, where more than 21% of the population lacks formal healthcare insurance and the other 35% is affiliated to the public healthcare institution. The problem addressed was solved for each of the state's eight regions, with instances between 650 and 1,398 demand points, generating the Pareto set for five different budget scenarios. The problem minimizes the weighted total travel distance from demand points to PHUs for general medical consultation while maximizing the demand coverage for complementary services such as nutrition counseling, dental care, mental health, clinical analysis, and imaging. An augmented version of the epsilon constraint method is used to find the Pareto sets, and the Cplex solver is employed to solve all the generated problems. The model's usefulness is shown through its application in the Case Study of Guanajuato.",Healthcare Supply Chain,88,666
The path to Autonomous Mining: A Top-Down Digital Twin Strategy for Industry-Wide Interoperability," Industry 4.0, characterized by advanced interconnectivity, automation, and digitalization, introduces digital twins as a cornerstone of cyber-physical systems. Digital twins offer comprehensive virtual models of physical processes, essential for agile and responsive operations in complex environments. While the manufacturing industry has gradually embraced these technologies, the mining sector predominantly remains in the preliminary stages of digital integration. The solutions are primarily adaptations of models developed for manufacturing, which do not adequately cater to the specific complexities and requirements of mining operations. This study introduces a modular, and dual-level digital twin architecture, explicitly designed for the mining industry, and aims to comprehensively integrate and enhance operations throughout the mining value chain. It encompasses the entire mining process through a high-level architecture that systematically addresses lifecycle phases, physical assets, and operations across six distinct functional layers. This type of structured approach is instrumental in facilitating interoperability among Internet of Things (IoT) devices, data streams, and various modeling techniques to enable advanced planning and control solutions. The architecture adopts a service-oriented perspective, separating data and decision-making models for flexibility and expansion. Nine distinct service categories within the mining process are specified, each defined by its unique function. This enhances modularity and addresses interoperability issues, while also provides insights into their interdependencies, technological specifications, and stakeholder considerations. This architecture is poised to significantly transform mining processes, elevating operational efficiency, safety, and adaptability to unprecedented levels. It marks a strategic advancement in mining, aligning it with the digital transformation goals of Industry 4.0.","Internet of Things (IoT) Technology: Tools, Management & Applications",116,667
Game-Theoretic Integration of Red Team Survey Data in Multi-Layer Security Systems," With the rise of domestic terrorism and soft target attacks, it is crucial we optimally allocate defensive resources across multiple security layers in venues such as airports, subway stations, sports venues and houses of worship. By allocating resources across these security layers properly we will aim to minimize the damages caused by a potential attacker or even be able to deter them. The attacker on the other hand, has the ability to observe how the defender allocates their resources and tries to circumvent the defenses we have laid out in order to maximize their objective. Building upon previous research in game theoretic, resource allocation problems and sociological surveys of participants playing the role of strategic attackers, we look at methods of updating the defenders’ best response given updated attacker strategies. These attacker models have been built upon red teaming survey data collected from studies where participants played the role of an attacker. These attacker models not only take into account features within the game such as cost, payoffs, probability of success, etc. but also take into account characteristics of the attackers, such as numeracy skills and risk preferences. By utilizing game-theoretic principles and these updated attacker models to solve for better Nash equilibria we aim to provide defenders with better decision making tools that can deter or reduce the damages caused by soft target attacks",Risk Management,195,668
Predictive Models for Agency Dependency on Food Banks," In the quest for equitable resource distribution within the realm of food banks and partner agencies, understanding the dependencies of these agencies on food banks emerges as a critical factor. This study investigates the intricate dynamics influencing agency dependency ratios, exploring the complex factors that shape the demand for food resources. Leveraging historical self-reported dependency ratio data, the study employs predictive modeling to forecast agency dependencies on food banks. The primary objectives are to augment existing research on food bank supply chains and discern the underlying factors that significantly impact agency dependency ratios. Employing Principal Component Analysis (PCA) for feature reduction, the study identifies 10 key components that capture the essence of the dataset. These components, elucidating the variables contributing most to the model, pave the way for robust predictive modeling. The study introduces Support Vector Regression (SVR) as the primary predictive model, showcasing its superiority over alternative regression models. SVR's efficacy is underscored by its performance metrics, including Mean Squared Error, Mean Absolute Error, Root Mean Squared Error, and Mean Squared Logarithmic Error. This study offers a comprehensive approach to understanding and predicting agency dependencies on food banks, with SVR emerging as the model of choice. The findings hold significant implications for non-profit hunger relief organizations, aiding in strategic decision-making for equitable resource distribution. By providing predictive insights, this study contributes to the overarching mission of alleviating hunger and fostering community well-being.",Social Good Analytics,209,669
Reliability Analysis in Vehicle Routing Problem," Vehicle routing problem (VRP) involves identifying optimal routes for a fleet of vehicles to efficiently deliver products to multiple customers. The parameters of VRP are often subject to uncertainty in practical applications. For instance, travel times can be influenced by traffic conditions, and demand may be unknown or fluctuate due to customer behavior. Such uncertainties may lead to delivery delays or failures, resulting in increased costs or decreased service satisfaction. Therefore, decision-makers must evaluate a solution's effectiveness before implementing it. As a result, assessing VRP solutions under stochastic conditions has become an important research area. This study aims to develop a stochastic model and propose a mechanism for evaluating the cost and reliability of VRP solutions with stochastic customer demands by utilizing metaheuristic algorithms to generate high-quality solutions. Additionally, the performance of the proposed metaheuristic algorithms will be compared to the existing algorithms in the literature to demonstrate their effectiveness.",Routing 2,198,670
"A Review of the Performance Indicators, Key Factors, and Planning Strategies Developed for the Pulp and Paper Supply Chain"," The pulp and paper industry plays a pivotal role in meeting the global demand for essential products. Addressing the management and control of such a complex supply chain, especially when processing diverse feedstocks, is a significant operational challenge. Solutions that enhance overall supply chain resilience and streamline processes, ensuring optimal performance in the face of diverse raw materials, are needed. This review maps the multifaceted dimensions of measuring, evaluating, and enhancing the performance of the pulp and paper supply chain while identifying the research gaps in the current literature. Research questions (RQs) considered for conducting the review can be summarized as: 1) Which indicators should be used to measure the performance of the pulp and paper supply chain? 2) What are the key internal and external factors as well as the challenges having significant effects on the performance of the pulp and paper supply chain? 3) What are the advantages of the implementation of optimal strategies and techniques to enhance the performance of the pulp and paper supply chain? Our research process adheres to the Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines. The scope encompasses international, English-language, peer-reviewed research articles sourced from scientific databases, by systematically selecting over 70 relevant studies. Through a qualitative content analysis, we synthesize key insights related to central research themes at both firm and system levels. Furthermore, we propose a specialized framework aimed at discerning and reporting perspectives within this context.",Planning/Logistics in Forestry,166,671
A Statistical Online Inference Method for Batch-adaptive Q-Learning Algorithm," Reinforcement learning algorithms are widely used for decision-making tasks in various domains. However, the performance of these algorithms can be impacted by high variance and instability, particularly in environments with noise or sparse rewards. In this paper we propose a framework to perform statistical online inference for a adaptive-batch Q-learning approach. We adapt the functional central limit theorem (FCLT) for the modified algorithm under some regularity and moment conditions, and then construct confidence intervals for the Q-values via random scaling. We conduct experiments to perform inference on both the modified approach and its traditional counterpart,Q-learning using random scaling and report their coverage rates and confidence interval widths on a grid world problem for comparison.",Advanced Topics of QCRE II,8,672
Automation Assessment Approaches," Assessments play a critical role in all automation initiatives. Some assessments focus on maximizing automation while others aim at reducing cost and manpower. This presentation depicts why assessments geared towards automation maximization or cost/manpower reduction often results in little to no benefits for organizations. This broad-brush approach typically overlooks most significant location pain points in favor of following the latest trends, which may or may not be appropriate for an organization’s most significant business case. We have adopted a needs-based assessment to drive rapid, significant, and sustainable benefits. This presentation demonstrates the application of both types of assessments and their outcomes, demonstrating that needs-based assessments yield superior results.",Automation,18,673
Operationalize New Memorial Cancer Institute (MCI) Building," South Florida’s Memorial Healthcare System took on the project to construct a 4-story building that could integrate its four independent cancer treatment sites for patients on the West side of town to receive their cancer treatment and support under one roof. The Process Improvement (PI) team was asked to help identify risk areas and lead discussions for solutions. Observations of supporting staff and discussions with department leadership gave insight into patient flows at each location. With the understanding of where each department/service would be in the new building, alongside the MCI historical data, patient flows, based on their level of care, were developed using spaghetti maps on the floor plans of the new building. These helped identify potential bottlenecks, crowding, as well as queueing/staffing needs. Our focus then became the daily workflows to understand the interdependencies of departments and staff, and how the new building layout would affect future daily operations to circumvent issues once doors opened to the public. These deliberations led to future-state workflow planning and brainstorming to accommodate the needs of the day-to-day. This project helped identify and strategize for major operational obstacles for the opening of the new MCI building. The opportunities we identified can be summarized by the following categories: communication, patient queueing, wayfinding, load leveling, and resource allocation. The key takeaway has been the versatility of Lean Six Sigma tools and how vital they can be in setting a good foundation for operations.",Cancer Care,24,674
Evaluating Street Sweeping Operational Efficiency: A Simulation-based Study of a Traditional versus Novel Sweeping Systems," In Nordic country, the post-winter cleanup of roads is a significant challenge after the application of millions of tons of abrasive material in winter maintenance. The removal of this residual material earlier in spring is crucial for public health and environmental safety. This research undertakes a comparative analysis of a traditional mechanical broom and a novel broom street sweeping systems to ascertain their operational effectiveness. The study required the development of an approach for empirical data collection using an onboard system, complemented by an advanced data processing framework, reflecting the depth and significance of the research. A discrete event simulation model was developed for both systems, utilizing advanced simulation techniques. This model allowed for an exhaustive assessment of the operational performance of both systems across various scenarios, such as night or day shifts and in different settings like urban roads or highways. Key operational metrics, including the frequency and duration of states such as sweeping, moving, and waiting, and the causes of these delays, were rigorously evaluated. The findings are pivotal for decision-makers, pinpointing the more efficient system for effective street sweeping and reduced operational time. This study also enables street sweeping service providers to initiative a data-driven continuous improvement process, prioritizing the most promising improvement actions and recommendations are provided based on the results obtained. Furthermore, the research significantly enriches urban maintenance literature, providing insights to shape future strategies for improved urban cleanliness and environmental management.",Routing 1,197,675
Hard Disk Drive Failure Prediction with Explainable Time-series Characteristics Tree and Large Language Model Hyperparameter Optimizer," The Hard Disk Drives (HDDs) remain central to the infrastructure of information technology due to their cost-effectiveness. As the number of operational HDDs scales up dramatically with the surge of Artificial Intelligence (AI), the Internet of Things (IoT), and Industry 4.0 (I4.0), an increasing incidence of hard drive malfunctions raises concerns about their reliability. These malfunctions result in data loss, costing US corporations millions of dollars annually. To address this issue, state-of-the-art research has favored the accuracy of deep learning models in predicting hard drive failure. However, these models often obscure the underlying root causes of malfunctions in those complex ""black box"" algorithms. Our study tackles this challenge by enhancing the transparency of HDD failure prediction. Adopting the ""catch22"" feature extraction method, we extract interpretable time series features from S.M.A.R.T. signals and employ a decision tree classifier that not only predicts HDD failures with high accuracy but also provides understandable insights into the causes of failure. This method offers actionable intelligence for HDD structural improvements. A case study using an open-source dataset from the Center for Magnetic Recording Research at UCSD validates our approach, achieving a failure detection rate (FDR) of 97.73% and maintaining a false alarm rate (FAR) of 1.15%, as confirmed through ten-fold cross-validation. Future work will aim to integrate these interpretative diagnostics into manufacturing processes, thereby paving the way for more resilient data storage solutions.",Reliability I,187,676
AirScope: Autonomous Building Inspections Using Drones," This research proposal developed by AirScope is to automate the building inspection process with the use of a drone but more specifically, providing in depth thermal analysis, cost reports, deterioration identification, and roof inspection for buildings on Busch Campus at Rutgers University. The current state and situation among building efficiency and inspection is of concern: Building operations are responsible for 27% emissions per year which are key contributors to the rise in carbon emissions. In 2021 the American Society of Civil Engineers gave U.S. infrastructure a C- in structure integrity, safety, and cited more investments are needed to improve U.S. infrastructure. Infrastructure inspections are expensive as the risk involved in inspections determine how much it costs. This proposal takes a deeper look and evidently shows building inspections are in need of change to ensure efficiency standards and structural integrity guidelines are met. Research has shown that buildings in the US are aging as they were constructed in the 1900’s and are a leading cause for structural issues along with high operation and maintenance costs. In addition, the advancement of climate change is creating issues that have not been seen before, such as: expansion of underground hotspots, new energy demand, and the urban heat island effect. A model to help address each concern provided by AirScope will be implemented to combat rising energy costs for building along with structural integrity problems. The plan will focus on developing energy reports, thermal analysis, roof inspection, and identifying deteriorating conditions in buildings.",Contemporary Work Environments,32,677
Joint design and pricing problem for Symbiotic Bioethanol SupplyChain Network: Model and Resolution Approach," To fight climate change, the Province of Quebec, Canada, has set targets to reduce greenhouse gas emissions by reducing fossil fuel consumption and integrating biofuel content into gasoline and diesel fuel. Motivated by a real-world case study, this research project presents a novel distributed decision model for designing a symbiotic supply chain network and supporting pricing decisions. We formulate a distributed decision-making problem as a game theoretic approach considering a Stackelberg–Nash equilibrium. A novel mathematical model is proposed to support the decisions of four actors: corn farms, processing depots, pig farms, and biorefineries. In addition to the configuration of a biofuel-based industrial symbiosis, the model offers the possibility of setting purchase prices and supply levels for biomass (corn stover supplied by farms), as well as determining sales prices and production levels for the main product (the cellulosic sugar used for the bioethanol production) and a coproduct (pig feed sold to pig farmers). A three-step optimization process involving the user is proposed to address the computational challenges posed by large design problem instances. The Province of Quebec case study is used to evaluate the performance of the proposed resolution approach.","Unlocking the Potential of Clean Affordable Energy: Innovations in Biomass, Biofuels, and Offshore Wind (SDG 7)",235,678
Enhancing Tensile Properties in Additively Manufactured Parts: A Study on PETG and Continuous Carbon Fiber Composites," This study aims to investigate the tensile properties of parts additively manufactured using an Anisoprint Composer A4 printer. For this investigation, ASTM D638 I specimens printed with polyethylene terephthalate glycol (PETG) and continuous carbon fiber were tested in tension to failure. For the PETG specimens, triangular and line infill were used with 100% density. According to Table 1, it was found that the tensile strength and elastic modulus were 38.1 MPa and 2.1 GPa for the triangular and 48.4 MPa and 2.2 GPa for the line infill, respectively. This shows an increase in yield strength of slightly above 20%. In a honeycomb core structure (mostly hollow), a strength of 32.4-33.5 MPa and stiffness of 1.8-1.9 GPA were recorded, which indicates that the weight of the parts can be significantly reduced without compromising their strength. For the composite specimens, four cases were studied: A. Only one contour of continuous carbon fiber; B. 1 out of 3 layers were reinforced. For case A, the modulus and strength increased to 76.2 MPa and 5.2 GPa. Consequently, the mechanical properties almost doubled, and the behavior changed from ductile to brittle. For the other cases, the strength and modulus were 105.2 MPa and 8.2 GPa for case B, 135 MPa and 9.0 GPa for case C, and 193 MPa and 16.2 GPa for case D. This demonstrates that a significant increase in tensile performance can be achieved by co-extruding continuous carbon fibers with PETG.",Composites in Additive Manufacturing,29,679
Social Media Influencers- Methods to the Madness," I present a thorough exploration of Social Media Influencers (SMIs), particularly focusing on best industry practices for influencer marketing. I explore diverse areas, encompassing how to recruit the best influencers for a marketing campaign, how to use the seed set to spread a marketing message as widely and quickly as possible as well as broader applications of SMIs in society. My primary objective is to shed light on the methodologies and theories that underpin the current body of research, offering insights that can inform and enhance industry practices. This review synthesizes the findings and identifies gaps and unexplored territories within the existing literature. By delving into emerging areas and uncharted contexts, I aim to pave the way for future research that aligns with the dynamic evolution of social media and influencer marketing. Moreover, this deeper understanding facilitates more informed decision-making for practitioners and stakeholders when implementing influencer marketing strategies.` It was recognized that influencer selection involves distinct approaches, with high-status and high-indegree seeding being prominent. Success relies on understanding network structures, consumer traits, and the interplay between influencers and adopters. The widely embraced Independent Cascade (IC) model maximizes influence. The forefront integration of APIs in social media data capture enables real-time analysis of influencer activities. Additionally, text mining and machine learning prove versatile and effective across sectors, ranging from healthcare to crisis communication and operations and supply chain management, offering a comprehensive understanding of the multifaceted landscape of SMI marketing.",Optimization in Transportation,156,680
A Joint Industrial Engineering and Urban Planning Approach for Designing an Optimal Electric Vehicle Charging Network," This research aims to determine the optimal locations for electric vehicle (EV) charging stations in urban and suburban areas of Louisville, Kentucky. We apply a combined methodology integrating industrial engineering (IE) and urban planning approaches. The IE methodology is an optimization-simulation model that takes forecasted charging demands and provides the optimal strategic location and capacities of EV charging stations through solving a mixed integer linear problem (MILP). Subsequently, an agent-based simulation model is developed to study the behavior of the EV fleet to account for their dynamic and stochastic nature. It also allows monitoring of the charging stations' status (i.e., queue length and average waiting time) during the study period. In addition to operational efficiency, our network design also considers various community related factors such as population size, unemployment rate, traffic conditions, amenities, and economic growth projection often used by a location analysis approach in urban planning. A total of 11 factors are weighted by stakeholders and used to evaluate 560 Traffic Analysis Zones (TAZ) in Louisville. The final recommendations are the top five locations for EV charging stations based on the integrated outcome of engineering and urban planning analyses.",EV logistics,58,681
Hetero-functional Graph Theory Toolbox Visualization Module," Hetero-Function Graph Theory has emerged as a means to model the structure and function of highly interconnected and heterogeneous engineering systems. It reconciles the graphical (SysML) models used in Model-Based System Engineering (MBSE) with the quantitative models used in network science and allows for a straightforward translation between them. In order to support insightful quantitative analyses, HFGT relies on multiple graphs as data structures. It also explicitly incorporates the heterogeneity of conceptual and ontological constructs found in MBSE. Recently, a Python-based HFGT toolbox has been developed to facilitate the instantiation of HFGT's mathematical models from an XML input file. Despite this development, the calculation of multiple graph data structures provides limited conceptual insight to the human eye; especially for large datasets. Consequently, this paper extends the HFGT toolbox with graph-based visualization functionality that specifically draws the system concept, hetero-functional adjacency matrix, controller agency matrix, and controller adjacency matrix and any others. In so doing so, the visualization toolbox aids researchers' ability to detect input data errors and students' ability to learn MBSE from a quantitative, visual, and intuitive perspective.",Information Systems & Software,104,682
Demonstration-guided Reinforcement Learning for Outbound Container Stacking Problem," Outbound container stacking is an important operation in ports, significantly impacting later retrieval for vessel loading. Stacking refers to designing an optimal strategy for placing arriving containers in stacks with the aim of minimizing the retrieval time. Out of stability and safety concerns, heavier containers are often placed at the bottom of the vessels and thus should be retrieved earlier from the yard. Consequently, it requires prioritizing heavier containers on the top of lighter ones when stacking. The challenge for the problem lies in the undetermined sequence of arriving containers, making it difficult to achieve this desired layout. Dynamic programming is the most predominant approach for addressing the stacking problem in the literature. However, it bears the curse of dimensionality when incorporating more state-related information. To address this challenge, we employ the Dueling Double Deep Q Network (D3QN) algorithm, a kind of reinforcement learning approach. It can leverage all the state features and eliminate redundant information, enabling more informed and efficient decisions. Additionally, we find that some types of relocations can be limited within some certain stacks by adopting the categorizing policy. It is more evident in the case of two container weight groups, an optimal structural property can be identified. Moreover, we incorporate this idea as an expertise demonstration into the D3QN algorithm to further facilitate the training process. Finally, we validate the effectiveness of the proposed method based on the benchmark data, which shows the proposed demonstration-guided D3QN algorithm outperforms the existing methods for 89% of tested instances.","Machine learning and AI, Part 2",130,683
Redefining Value Creation: Assessing the Economic Impact of Digital Twin Technology Across Industries," This paper presents a comprehensive analysis of the economic impact of digital twin technology, an innovative digital modeling process that has become increasingly pivotal in various industries. As businesses strive for enhanced efficiency and innovation, understanding the financial implications of integrating digital twin technology is essential. This study delves into a detailed cost-benefit analysis, examining the return on investment (ROI) experienced by different sectors, including manufacturing, healthcare, and automotive. By analyzing case studies and industry reports, the paper highlights how digital twin technology contributes to operational efficiencies, reduces downtime, and enhances product development. Furthermore, it explores the technology's role in facilitating predictive maintenance and strategic planning, thereby leading to significant cost savings and improved resource allocation. The research also addresses the challenges and potential barriers to adoption, providing a balanced view of the technology's economic viability. Ultimately, the paper aims to elucidate how digital twin technology is not just a technological advancement, but a transformative tool for business innovation and economic growth, signaling a new era in digital-driven value creation.",Energy and Infrastructure,66,684
A Simulation-Driven Hospital Facility Design Optimization Using A Priority-based Heuristic Algorithm," The optimization of hospital facility design is a crucial aspect of enhancing the patient experience. This study employs a comprehensive, priority-based approach to redesign hospital layouts. Six department distribution designs were crafted to address specific goals, such as improving efficiency and maximizing space utilization. Within each design, five room assignment algorithms were strategically implemented. For both department distribution and room assignment strategies, heuristic algorithms are proposed based on the prioritization of multiple objectives. Different heuristic algorithms are implemented and evaluated in the simulation model of a hospital facility with 14 departments and 72 rooms, resulting in 143,489,070 unique scenarios. To evaluate near-optimal configurations, an Analytic Hierarchy Process (AHP) methodology was employed, incorporating four dimensions. Weightings for each dimension were derived from a survey involving medical professionals, ensuring a well-informed evaluation. The findings highlight the effectiveness of the proposed facility design, aligning with preferences elucidated by healthcare practitioners. This research not only provides valuable insights into optimizing hospital facilities but also emphasizes the significance of incorporating diverse perspectives from medical professionals in shaping the future of healthcare infrastructure.",Facility Design,75,685
Rule-based Automated Cancer Staging from Scanned Pathology Reports," Pathology reports provide detailed information regarding the patient’s cancer diagnosis and stage, which are not only critical for designing effective treatment plans, but also serve as a critical resource for various clinical research endeavors. However, pathology reports are represented in a narrative format with free texts, introducing significant challenges in abstracting critical information. Currently, registrars extract cancer stage information by manually sifting through voluminous amounts of text, which is labor-intensive and susceptible to errors. Thus, there is a need to develop cost-effective tools for automatic information extraction. Pathology reports are typically scanned into PDFs, which poses significant limitations on the machine’s ability to extract informative features. Additionally, the effectiveness of data-driven models hinges on the quality and quantity of training data available. Pathology reports associated with a specific clinic may not meet the requirement to sufficiently train large-scale artificial intelligence models. To cope with those challenges, this paper presents a rule-based cancer staging tool designed to automatically identify the cancer stages from scanned pathology reports. We first develop an effective process to accurately convert the PDF-based text into a machine-interpretable format through the combination of Optical Character Recognition and Bidirectional Encoder Representation from Transformers (BERT). Second, we incorporate the clinical rules for cancer staging, defined by the American Joint Committee on Cancer, into the automated process, avoiding the requirement of large data for training the model. Finally, we build a user-friendly interface for our developed method, allowing clinicians to easily perform the end-to-end automated cancer staging from the scanned reports.",Cancer Care,24,686
Application of Machine Learning Approaches to Minimize Defects in Thermal Energy Cutting Processes," Thermal energy cutting outperforms mechanical cutting processes and can cut a wide range of thicknesses. However, it also presents many issues such as meeting tight specifications and requiring post finishing in the application. The optimal parameter settings often are provided by the cutting equipment manufacturer, but there are still unpredictable variations due to parameter control drifting over the lifetime of the equipment and variations in the workpiece material in production. Those variations that happen locally at the production site could cause notable quality issues over time, and it is not economically feasible to manually tune the parameters periodically for every machine for all different material type and thickness combinations. After collecting samples of different material thicknesses, parameters used, and images, we developed several machine learning approaches to determine the best parameters that minimize defects in cut parts.",Machine Learning in Manufacturing I,129,687
Covering Routing Problem with Robots and Parcel Lockers: A Sustainable Last-Mile Delivery Approach," This study presents the Covering Routing Problem with Robots and Parcel Lockers (CRP-R-PL), a challenge arising in sustainable last-mile delivery context such as e-commerce and city distribution. In this problem, trucks depart from a central depot, delivering parcels directly to a subset of customers or a subset of parcel lockers. With these parcel lockers, the remaining customers could pick up items if they prefer the pick-up delivery method. In addition, each truck is equipped with a Sidewalk Autonomous Delivery Robots (SADR), zero-emission vehicles, which are deployed to get off from the truck, serve one or multiple customers, and then return to the same truck for both a battery swap and package retrieval. For the routing of SADRs, the trucks act as a moveable satellite depot to serve the remaining customers. The CRP-R-PL seeks cost-minimizing solutions by determining optimal parcel locker’s locations and routes of trucks and SADRs to serve all customers. We offer a mixed-integer programming formulation and an effective heuristic to solve large-size instances. The CRP-R-PL includes three decisions: 1) finding the location of parcel lockers, 2) routing the trucks to visit the customers and parcel lockers, and 3) routing the SADRs to serve the remaining customers. Since this problem has not been studied in the literature, a new set of benchmark instances is introduced for the CRP-R-PL. Also, managerial insights on the optimal use of trucks, SADRs, and parcel lockers are provided as the available delivery options for the customer.",Urban Logistics,237,688
Quantification of Human Health Externalities Associated with Power Grid Expansion Plans," Power grid expansion decisions are often made based on models which minimize market costs, ignoring externalities which may have significant harmful financial and societal impacts. Such approaches portray an incomplete assessment of the effects of potential electrification policies. This research effort evaluates New Jersey’s energy master plan which is designed to plan for essential energy resources, but also to achieve societal goal concerning air emissions and the health impacts of those emissions. We developed a generation expansion planning optimization model to determine least cost decisions for annual aggregate electrical generation, purchasing, and capacity investment given a modular set of economic, environmental, and policy constraints. We estimate the resulting pollutants from our optimal solutions to approximate the incurred health damages both as enumerated occurrences and as an aggregate financial burden. We also test several other less environmentally motivated expansion policies. These system-level simulation models of the electric power system serve as decision-support tools to help answer a variety of energy policy questions. This work specifically focuses on the negative human health consequences of electricity generation. Fossil fuel utilization contributes to a number of health conditions, which generally have negative impacts on quality of life and society as a whole, but more pragmatically cause significant financial healthcare burdens. Our findings show that there are significant abatements of all negative health occurrences. These include work loss days, hospital admittances, emergency room visits, and mortalities. Furthermore, there is an even more significant increase in these same factors in the environmentally unrestricted scenario.",Unique directions in Energy Research,234,689
ASSESSMENT OF IoT PROJECT MANAGEMENT CHALLENGES AND ISSUES," Many companies are planning to adopt IoT technologies over the next few years. While these technologies enable innovative business models, and despite all this excitement towards these technologies and applications, there is a high percentage of project failures. Although there is a great deal of research into why so many IoT projects are not successfully completed, there is a lack of consensus on IoT success factors. The aim of this work is therefore to contribute to a better understanding of the key success factors of IoT projects. To identify these factors, we adopted a two steps approach. The first part consisted of searching the academic and professional literature. A list of 20 key success factors was extracted. The second part consisted of semi-structured interviews with IoT project managers to corroborate information from practice (the field) and the scientific literature. Although practitioners and the literature identified the same factors, they did not agree on the importance of these factors. We therefore consolidated the results and proposed classification, which highlights factors such as IoT expertise, communication, project vision and goals, training and mentoring, project management and, not surprisingly, senior management support.","Internet of Things (IoT) Technology: Tools, Management & Applications",116,690
Federated Short-run Process Monitoring," Short-run productions are common in manufacturing systems which requires for customization and flexibility under limited demand and resources. However, traditional statistical process control charts cannot handle such scenarios, since they either asks for data transformation or have strict assumptions which misalign with real-world applications. To address these limitations, we propose a federated framework to collect process parameters across multiple distributed product lines and create process monitoring baseline models for each line. Specifically, a Gaussian Mixture Model uses the gathered local information to estimate each line’s parameters at the global server. By running the clustering algorithm, local sites receive the process parameters. Next, we personalize the local model based on the random effect model. Finally, we validate the model by using two simulations and a case study.",Statistical Learning and Artificial Intelligence for Quality Control III,213,691
Asset Management of Utility Poles Under Budget Limitation," As overhead transmission lines age through various abiotic and biotic factors, they require more frequent inspections and maintenance to ensure they operate reliably. With most transmission grids having hundreds of miles of lines to maintain, there needs to be an efficient way to budget for labor, materials, and time. Current practices typically put inspections on a calendar schedule for every few years, dependent on the environment, to check the status of transmission lines and decide if action needs to be taken. Wood poles serve as support structures for various overhead lines and utility equipment. Because of the invasive procedure required for a replacement, budgeting for thousands of poles for a single utility company needs to be conscientious of the lifespan of each of the poles and the total number of poles needing maintenance each year. This research offers analytical solutions to the maintenance planning challenges in industry by finding the optimal treatment and replacement strategies under budget constraints. An engineering-economy analysis was performed for wood-pole maintenance activities for a local utility company to analyze the required maintenance budget and the ideal target replacement ages. We also develop an optimization framework to schedule replacement and treatment of wood poles under budget limitations. We present the results obtained from applying the proposed framework to the wood-pole infrastructure of the local utility company.",Resource and Asset Management,194,692
Mathematical Modeling of Economic Impact of Solid-State Batteries Research To South Dakota state," Solid-state batteries signify a breakthrough in energy storage, providing enhanced safety, superior energy density, and extended longevity, addressing the escalating need for reliable, durable energy solutions. This study aims to comprehensively understand the dynamic of solid state batteries through advanced mathematical modeling, with the goal of creating cutting-edge energy storage solutions tailored to South Dakota's unique environmental conditions and energy needs (Ahmed & Maraz, 2023). By combining expertise from material science, electrochemistry, computer modeling, and mathematical modeling of economic impact, the research endeavors to not only enhance the state's role in pioneering global energy solutions but also to qualify the economic impact of this innovative research (Pomerantseva, Bonaccorso, Feng, Cui, & Gogotsi, 2019). The ultimate objectives are to strengthen the state's economy, industrial growth, create job opportunities and contribute to the global advancement of sustainable energy technologies. With significant economic ramifications, the study's emphasis on mathematical modeling of economic impact of solid state batteries research that are optimized is poised to impact development of new technology, advance knowledge ad catalyze economic development in South Dakota.",Driving Towards Clean Affordable Energy: Advances in Electric Vehicles and Battery Management (SDG 7),57,693
Exploring the Potential Adoption of Collaborative Autonomous Material Handling Vehicles/Robots in Non-Containerized Cargo Ports," Material-handling vehicles are increasingly being automated with varying levels of autonomy for various applications along the supply chain. In a port context, automation is typically associated with fully automated container terminals, requiring significant investments, extended installation times, and limited flexibility with dedicated workflow. However, partially automated solutions are now available, offering relatively affordable alternatives while remaining highly flexible and adaptable to various material flows through the port transit, such as collaborative Autonomous Mobile Robots (AMRs or Cobots) increasingly used in factories, warehouses, and distribution centers but less prevalent in port. This article discusses the potential adoption of these collaborative robotic systems in port handling non-containerized goods to improve productivity and operational flexibility. Specifically, these robots aim to minimize unproductive walking time and support human operators by autonomously handling and transporting goods from one position to another, making work easier and faster. Primarily carried out by humans using non-autonomous mechanical equipment, the potential horizontal movements of goods in the land area of a port is first explored in this research work. It then compares these processes with ports equipped with container terminals. Finally, it draws analogies with handling practices in factories, warehouses, and distribution centers using Cobots/AMR for intralogistics transportation. Based on the presented analysis and given the emission-free nature of these robots, decision-makers are encouraged to invest in partially autonomous solutions in the port sector to enhance operational and energy efficiency.",Emerging Technologies and Safety: From AMR Integration to Urban Air Mobility,61,694
Impacts of inter-firm collaboration for logistic activities in a specific forest network," Harvesting and transportation activities in the forest industry represent a major part of the logistics costs for wood processing companies. Although recent research has shown how collaboration partnerships among companies from the forest sector can bring significant benefits, the number of successful coalitions in the industry remain rare. This paper aims to study the effect of different collaboration scenarios for the forest logistic network of the Laurentides and Outaouais regions, in south-western Quebec, Canada. Considering the interdependence of wood processing companies in the network, caused by the presence of mixed species in the forest, scenarios are evaluated on their contribution to favor network-level synergies, logistics costs reduction, and value maximization from harvested forest. A Mixed-Integer Linear Programming (MILP) model is developed to guide tactical level decisions regarding transportation planning and inventory management. Scenarios are characterised by the integration of a logistic platform for storage and sorting, and improved coordination of transport activities. The results generated by the optimization model show logistic costs, distances travelled, and trucks used for each scenario. A sensitivity analysis also highlights the parameters with the highest impact on the output. For the industry, the project will provide a method for cost reduction in logistic activities achievable through collaboration alternatives. For the academic community, this research will represent a case study of collaboration among independent companies from the forest sector, faced with highly diversified forest stands. This research will therefore provide a new reference point and serve as a stepping stone for further research on the subject.",Planning/Logistics in Forestry,166,695
Human system integration challenges for spacesuit materials design," Space suits are spacecrafts in miniature, created to support and interface with a user when conducting activities in space. A variety of NASA and commercial spaceflight activities planned through the remainder of the 2020s significantly increase the demand for advances in suit designs and crew member performance monitoring and support. For many of these candidate space suits, concerns have arisen about the materials currently used in suits designed to conduct extravehicular activities (EVA). Many popular materials for current and proposed EVA suits include risks to human health, survival, and task performance. These risks limit the capabilities of the human users and human-system integration requirements for EVA suits. This renders more activities outside of controlled environments unviable, such as repairs, exploration, or manufacturing. Each excursion outside of a controlled environment confers significant hazards, limiting the degrees of performance freedom. This paper addresses challenges in design of EVA suit layers to utilize beneficial properties of novel materials, reviewing and updating design elements and requirements. Advances following the development of suits currently in use on orbit provide possibilities for applications and the limitations of candidate materials. Some candidate materials may also improve potential systems integration to support crew member health monitoring; multi-modal sensory feedback; and improved human-system interaction controls. Joint consideration of material, manufacturing, and multi-layer material integration processes can enable a greater performance envelope than each of these approached in isolation. This enhances crew member capability to perform in space with more finesse, which increases survivability and mission robustness.",SE Methods and Applications,200,696
Prediction of traffic incident hot-spot locations using long-short term memory network," Vehicle crashes are one of the major concerns related to the safety of humans as well as resources. Predicting the incident hot-spots will enable proactive and effective management of incidents. This study uses a deep learning algorithm, long-short term memory (LSTM) network, to predict incident hotspot locations. The model presents a predicted normalized density score which defines the hot-spots for a given time period of a date and for each identified block. The proposed model is validated using incident data obtained from North Carolina Department of Transportation along with other related variables such as holidays, annual average daily traffic (AADT) index, weather information, unusual events and road types. The performance of the prediction model is evaluated using three criteria, i.e., mean absolute error, mean squared error, and root mean squared error. The values of the error estimates are compared with two other machine learning techniques (i.e., decision tree regression and random forest) verifying that the proposed model using LSTM has higher prediction accuracy. The results of the study could be used to reduce the risk of potential crashes, better allocate resources in handling incidents, and implement warning mechanisms.",Logistics II,123,697
Harmonizing Urban Airspace: Autonomous Parking Lot Landings for Delivery Drones," Urban and suburban landscapes heavily rely on parking lots, occupying nearly 50% of commercial areas. Facilitating safe and socially acceptable autonomous landings for delivery drones within these spaces is pivotal for enhancing their safety, flexibility, and operational efficiency. We present a vision-learning-optimization framework to empower small delivery drones to autonomously land in urban parking lots during emergencies. This innovation introduces a paradigm of shared usage between ground and aerial vehicles, curtailing smart city carbon footprints. Using nVIDIA's ISAAC SIM framework, we showcase the development of drone landing algorithms, and the transition from digital simulation to physical implementation. We will also present outlooks at harmonizing ground and aerial mobility in urban settings, optimizing space and resources for sustainable city operations.",UAV logistics,233,698
Understanding DEI Initiatives and Performance Metrics in Food Bank Operations," Food banks provide services and food assistance to those facing food insecurity, a challenge that can affect families and individuals from various backgrounds and communities. Diversity, equity, and inclusion (DEI) are very important factors in food bank operations. This study focuses on diversity as measured by client ethnicities and the rurality of the counties served by the food banks. Over 44 food banks were interviewed to understand their operations. Key performance indicator (KPI) metrics in each organization were identified and classified as Community Focused (CF), involving tailored services based on community needs, and Organizational Focused (OE), involving processes and strategies to increase output and minimize resources. A clustering analysis was conducted to group these organizations depending on the percentage of rural counties served by the food banks and their respective z-score based on diversity index, so four clusters (tiers) were created (Tier 1 are highly rural and least diverse, while those in the fourth tier are highly urban and highly diverse). The KPIs in each tier organization were examined and results suggest that organizations in Tier 1 use more OE KPI metrics whereas those in Tier 4 use a more balanced combination of CF and OE metrics. Ultimately, this research provides hunger-relief organizations insights to adopt practices that acknowledge, accommodate, and celebrate the diverse needs and characteristics of the neighborhood they serve.",Continuous Improvement Tools and Methodologies II,34,699
Integrated Modeling for Predicting COVID-19 Outbreaks: Wastewater and Hospitalization Insights," Wastewater surveillance plays a pivotal role in early COVID-19 detection, fostering a proactive approach to public health. This study aims to establish a surveillance system utilizing wastewater data for forecasting COVID-19 outbreaks before their occurrence and understanding their implications for healthcare facilities. Additionally, it seeks to anticipate thehospitalization rates during outbreaks, enabling timely resource allocation and response. The system employs Vector Autoregression and Bootstrap Aggregation to predict COVID-19 surges based on SARS-CoV-2 concentrations in wastewater, which are obtained from the Centers for Disease Control and Prevention’s (CDC) National Wastewater Surveillance System. The model also integrates hospitalization data from New York State’s Daily Hospitalization Summary to calculate the correlation between COVID-19 outbreaks and hospitalization rates. Initial development using New York data is rationalized by its representative nature, with plans for nationwide expansion. This model's development aims to enhance public awareness of outbreaks, facilitating transmission precautions and motivating facilities to prepare resources based on predicted patient volumes.",Emergency Response and Preparedness  in Health Systems,60,700
To Security and Beyond: Cyber-physical Security for Manufacturing Utilizing a Digital Twin Ecosystem," Industry 4.0 has led to the development of many innovative technologies that manufacturers can utilize to make better decisions and improve their processes. Some of these advancements introduce security concerns that require innovative defense strategies. Cyber-physical systems (CPS) are a noteworthy example of these security concerns, as these systems can influence the physical and cyber domains. It is challenging to assess the vulnerabilities of cyber-physical manufacturing systems due to the complexity and cost of the machines used in manufacturing. Digital twins, another key Industry 4.0 technology, presents a unique opportunity to research potential attacks and defense mechanisms for Cyber-physical systems. Digital Twins are virtual replicas of physical systems that can be utilized to assess situations that are otherwise impossible to recreate in a real manufacturing setting without disrupting the production line or causing equipment damage. In this paper, we demonstrate the benefits of using a Digital Twin Ecosystem (DTE) to explore the security of manufacturing assets. We will also present a case study of a DTE for a desktop five-axis milling machine. This case study will focus on how a collision detection system is a necessary security feature that is nonexistent in current simulation software. The case study will reinforce how DTEs will help manufacturers tackle problems related to security and beyond.",Cybersecurity in Manufacturing,35,701
A System Approach to Peri-operative Informatics: Integrating a Dashboard to Improve Operational Excellence," Purpose: The primary objective was to create the ability to monitor and manage operational metrics in peri-operative suites across our system to increase efficiency. Methods/Approach: This dashboard was developed collaboratively between a team of performance improvement engineers and clinical experts, which was instrumental in curating actionable metrics. Extensive process mapping was conduction to determine the ""typical"" process of peri-op flow in each facility ensuring all non-value barriers were captured. Time studies (n=43) were conducted at the pilot site to perform comparative analysis of OR occurrence and data returned from EHR. Comprehensive literature reviews were conducted to determine best practice standards to set peri-op targets for facilities to achieve. Results/Findings: Implementation of this dashboard led to the discovery of wide range of variability within OR management (n=14 hospitals). This spurred a larger project focusing on metric and definition standardization across the system to create standard reportability cascading to our C-suite. The utilization at a facility level is monitored on a user basis to research causality between usage and metric improvement. The dashboard in prototype form had received extensive feedback from the test facilities and is has transitioned to a BI platform. Conclusion/Practical Implications: This project resulted in standardized metric monitoring across CHRISTUS system allowing facilities to be internally benchmarked for the first time while setting targets and calculation patterns consistent with best practices allowing the system to benchmark against other comparable facilities. Within the pilot site in the first 5 months, First Case on Time Starts increased from 41% to 75%.",Process Improvement in Health Systems,178,702
Building robust short-term and real-time schedules of underground mine operations," This presentation focuses on the development of a tool for robust short-term and real-time scheduling of mining operations. This tool first seeks to construct schedules for work shifts that take into account the operational constraints of underground mines. Given that the mining environment is very dynamic and generates a lot of variability over the duration of the different mining operations (drilling, ore transport, bolting, etc.), the models developed seek to produce robust schedules that will take this variability into account to avoid constantly rebuilding new schedules. These models are called proactive. Since mining is a highly dynamic environment, the solution proposed by proactive models may eventually deviate from reality and it is essential to modify this schedule. We then move to a reactive model or real-time scheduling. Tests carried out with different models demonstrate the effectiveness and robustness of the schedules produced by this new approach.",Scheduling/Real-Time Execution,201,703
Improving Barbershop Operational Efficiency using a Comprehensive Work Methods Analysis," For the Final Project in our Work Design and Ergonomics course at Rutgers University, students are tasked with conducting a comprehensive work methods study to improve efficiency and reduce waste at a local business or organization. Our group received permission to conduct this work design analysis at a popular local barber shop in New Brunswick called College Cuts. The study explored the following questions: “What percentage of time are barbers actively cutting hair at College Cuts? How can the current operations be revised so that the time cutting hair is maximized and customer wait time is minimized?” From extensive experience and customer feedback, our group noticed that haircuts would often be extended due to time spent on non-barber related activities. Potential examples involved engaging in prolonged conversations with other customers, searching for barber supplies, taking unnecessary phone calls, and ringing up other customers at the cash register. Over the course of a month, our group collected 80 hours of data observing barbershop operations. Metrics tracked included time spent by barbers on combing, changing tools, clipping hair, scissoring hair, blow drying, spraying, waxing, idling, and ringing up customers for each haircut. After compiling and analyzing the data, our group developed a collection of 20+ practical recommendations which were provided to College Cuts ownership. Specific suggestions were implemented and follow-up study demonstrated tangible improvement in barber efficiency and customer wait times. Recommendations can inform improvements to the operational efficiency at barber shops and similar small businesses.",Organizational Ergonomics and Engineering Education,158,704
Biofuel Supply Chain Design," As the world strives to transition from fossil fuels to renewable energy, biofuels such as bioethanol are emerging as promising energy sources. As a result, scholars have explored various aspects of biomass production, harvest, logistics, and production processes for obtaining bioethanol. Developing a supply chain network for bioethanol production is necessary to connect these stages. While the primary focus of research lies in a single-sourcing supply chain, this study presents an integrated multi-sourcing supply chain network for biomass procurement from diverse sources, such as switchgrass and agricultural residues. The mathematical model is structured to address the facility location-allocation and capacity expansion decision problem. Furthermore, we take into account the sustainability of the bioethanol supply chain and formulate a bio-objective optimization model that incorporates environmental factors while minimizing total costs. The model is applied to a real-world case study in North Dakota in the United States. According to the results and sensitivity analysis, the proposed model is economically and sustainably viable and provides novel insights into the design of bioethanol supply chains.",EV logistics,58,705
Modeling the Effects of Strain on a Network of Emergency Departments," Emergency Departments (EDs) are understaffed and overstrained. Although tightly optimized staffing may reduce costs, it may cause congestion in the ED when there are unexpected staff shortages. The purpose of this project is to develop a simulation model of the network of EDs in the Prisma Health-Upstate system to stress test the clinician staffing plan and improve the system’s resilience to strain. We present a discrete-event simulation model of the six, interrelated EDs. The locations are staffed by attending, advanced practice, and resident clinicians. Patient acuity is stratified by the Emergency Severity Index, and outcomes include length-of-stay. Analyses are conducted to evaluate the resilience to different types of strain (e.g., patient volume surge, staffing shortage, or COVID-19 peak). We discuss staffing fragility and how strain at one facility may propagate to others.",Work environment in health systems,241,706
Accelerating theme park management training leveraging a Management Flight Simulator (MFS)," This paper/session will be of interest to both students, faculty, and practitioners who have an interest in theme park management, training, and the use of synthetic training environments. This paper and the accompanying presentation will: Highlight the issues, information, and decisions that are routinely made by managers in a complex system environment known as a theme park. Provide a state of the current practice associated with theme park management training. Demonstrate a prototype MFS (Management Flight Simulator) to assist in reducing the time required to train theme park managers in their critical daily management decisions. Provide a set of recommendations for theme park administrators in their efforts to onboard and train managers within the context of a theme park. Theme park managers are routinely exposed to and are required to make decisions that have a significant impact on both theme park revenues and customer satisfaction. Theme parks constitute large complex systems and can be modeled in a variety of ways but revenue per customer and satisfaction per customer are clear indicators of success for all parties involved. This student-based research and development effort models key facets of a typical theme park using state of the art discrete event simulation modeling to provide an interactive tool for training managers. The objective of the training is to develop managers that are attuned to the interplay between revenue generation and customer satisfaction in a timely manner within a dynamic environment.",Problem Solving and Decision Making II,176,707
Group sparsity-based beam angle optimization in proton therapy: a comparison of two approaches," This research addresses Beam Angle Optimization (BAO) in Intensity-Modulated Proton Therapy (IMPT), a crucial component in radiation therapy. While traditional BAO algorithms are designed for Intensity-Modulated Radiation Therapy (IMRT), IMPT presents unique computational challenges due to its fewer beam requirements, demanding specific optimization techniques. The study explores and compares two Beam Angle Optimization (BAO) algorithms: FISTA and SGD. The simultaneous implementation of BCO and Fluence Map Optimization (FMO) is investigated to achieve optimal beamlet intensities and dose distributions. Particular focus is given to the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) and Stochastic Gradient Descent (SGD) for large-scale optimization problems in IMPT. The methods section elaborates on the optimization framework, highlighting hierarchical sparsity and group sparsity terms to address large-scale, non-differentiable optimization challenges in IMPT. Results demonstrate the effectiveness of FISTA and SGD algorithms in determining beam configurations and angles compared to clinical angles. This highlights the complexity of optimal beam orientation in IMPT and emphasizes the importance of computational time in selecting suitable optimization approaches for effective radiation therapy planning.",Patient Care and Treatment II,161,708
Quantitative Risk Assessment Model for Private Companies," This study introduces an innovative quantitative risk assessment model tailored for private companies, leveraging publicly available information including market indices, factory locations, and economic indicators. Employing advanced data analytics and financial modeling, our methodology incorporates sentiment analysis of positive and negative news articles, evaluating their potential impact on risk. Additionally, the model considers geographical risk factors and the current status of the industry to discern patterns and correlations. By integrating these diverse sources, our framework provides a comprehensive risk profile, addressing not only financial stability but also location-specific and industry-related risks. This approach equips us with a nuanced understanding of potential threats and opportunities, fostering informed decision-making amidst uncertainties. The model's adaptability and scalability make it a valuable tool for seeking a holistic view of the risks associated with supply chains that incorporate privately owned companies.",Technology and Digital Economy,230,709
Supplier Selection and Order Allocation in a Supply Chain considering Finite Production Rates," In this paper, we examine the implications of the well-known supplier selection and order allocation problem in a decentralized supply chain when production rates are finite, and demand is price sensitive. We propose a mixed integer nonlinear programming model with the objective of maximizing the overall profit within a profit-sharing mechanism that ensures a fair distribution of profit among all participating partners.",Facilities Design & Planning II,72,710
Using Machine Learning to Create a Hospital Revenue Prediction Model," In recent years, Artificial Intelligence (AI) has emerged as a transformative force with the potential to revolutionize industrial processes across various sectors. The research conducted in the AI applications has delivered promising outcomes that encouraged researchers to explore what more can it benefit each industry. In healthcare, AI applications has been an active research field. However, despite the increasing adoption of AI technologies in healthcare services on the financial side, there is a lack of a comprehensive research that can predict the revenue cycle by predicting the amount of collected payment along with the duration to complete the payment based on the submitted claims as well as investigating the factors that may cause claims denial and late submissions. The goal of this research is to build a comprehensive prediction machine learning model to predict hospital revenue based on the claims submitted. To do so, this paper will conduct a three-phase research plan. First, the probability of the claim’s denials will be studied along with the factors that contributes to it. Secondly, the student will study the duration of the claims collection and the prediction on the time it takes to collect the submitted claims. Finally, build a comprehensive accurate prediction model that will predict the revenues on the hospital each month based on claims submitted as well as providing insights to reduce claims denial and long reimbursements by identifying the factors that contributes to their occurrence.",AI in Health Systems,1,711
Big data reduction algorithms inspired by design of experiments: A critical comparison using real data science tasks," Modern companies use big datasets to answer business and research questions. However, the analysis of such datasets is computationally expensive or even infeasible. To overcome this issue, subsampling algorithms are being used to select a highly informative subsample of the big dataset, which can then be used as a surrogate for the analysis. Recent research has shown that subsampling algorithms rooted in design of experiments (DoE) can obtain statistically efficient subsamples. However, the computational performance of these algorithms has been assessed using simulated data and a few real datasets, as well as a few predictive models. In this presentation, we compare the performance of different DoE-rooted subsampling algorithms using real datasets that range from moderate to big. Moreover, we evaluate the quality of the subsamples obtained by the algorithms to build good parametric and non-parametric predictive models. We discuss the benefits and limitations of the subsampling algorithms and provide recommendations on their application to big datasets.",Machine Learning II,126,712
Volunteer management in non-profit settings with equity and efficiency measures," This paper presents a pioneering solution to the vehicle routing problem with pickups and deliveries with equity (VRPPD-e) within the realm of non-profit food distribution. With a focus on multiple volunteers at service centers helping with food deliveries to food-insecure households through food banks, our objective is to optimize volunteer assignments, plan cost-efficient routes for their pickups and drop-offs at service centers and back, and ensure equitable service distribution. Considering each volunteer's time window and vehicle capacity, we aim to maintain a balance among these key factors. We present a scalable solution utilizing a branch-and-price algorithm. This approach transforms the initially proposed mixed integer programming model into a set partitioning model, specifically a relaxed linear program. The algorithm dynamically refines solutions by iteratively introducing variables. Leveraging the power of branch and price, coupled with column generation, the proposed solution technique systematically enhances the linear programming relaxations. To further optimize the column generation process, we employ a labeling algorithm. This additional step contributes to the effectiveness of our approach, providing a comprehensive strategy for solving complex optimization problems efficiently. This integrated approach not only redefines the VRPPD paradigm but also provides a novel solution to workforce management challenges in the non-profit sector. The preliminary experiments highlight the algorithm's effectiveness in optimizing volunteer assignments and vehicle routing, emphasizing considerations of fairness and cost undertime-window constraints and vehicle capacity restrictions.",Innovative topics in supply chain 1,112,713
Unveiling Stress Responses through Heart Rate Variability Analysis: A Machine Learning Approach," Stress has been called the ""hidden epidemic"" since it affects every aspect of human life. A prerequisite for effective stress management is early detection. Advances in wearable sensor technologies have led to various approaches for detecting stress using physiological signals. In this study, we utilized a publicly available data set from PhysioNet which contains data collected from 10 participants during three exams (Midterm 1, Midterm 2, Final) using the Empatica E4 device. For each subject interbeat interval data recorded for each condition were converted into time domain and frequency domain heart rate variability features using Neurokit2, a Python package. We developed classification models using Support Vector Machines, Random Forests, and Artificial Neural Networks to classify participants’ data. For cross validation we implemented Leave-One-Subject-Out. Using F1-score as the performance metric, Artificial Neural Networks was the best of the three machine learning models.",Diverse Topics for Human Factors and Ergonomics 2,56,714
Timberwulf: Integrated Forest Intelligence Tool using Mobile Laser Scanning Technology and SLAM Algorithms," Utilizing Boston Dynamics' robotic dog, Spot, and a LiDAR sensor for mobile 3-D forest mapping, this project aims to optimize forest management by assessing lumber yield, fire risk, and carbon capture potential. This project serves as an automation proof of concept in forestry. The traditional process of obtaining an accurate forest inventory with high-quality tree-level data is time-consuming and labor-intensive. This project implements a systems-based approach to generate and evaluate high-level 3D maps of forests. A Light Detection and Ranging (LiDAR) sensor attachment has been added to Spot, the agile mobile robot. Data from the LiDAR sensor is used to create comprehensive 3D maps by applying a specialized Simultaneous Localization and Mapping algorithm. 3D maps are analyzed to determine tree yields, forest plot densities, forest structure, and other forest attributes for industrial and environmental purposes. Overall, Timberwulf demonstrates the application of mobile LiDAR technology in forest operations and would serve as a valuable tool for federal and state environmental and forest agencies.",Planning/Logistics in Forestry,166,715
Enhancing operational management of shared tools in a job shop with digital twins," Manufacturing companies often utilize shared tools for their production operations. This leads to flows of tools between the workstations and the tool store. It is observed that tooling management is often inadequately addressed in such a context, especially at the operational level with a lack of technology for efficient tool traceability. The initial symptoms of the absence of tool management include the search for tools, both on the production floor and at the tool store, an oversized tools inventory, and the waiting caused by the use of tools already in use. Technologies such as the digital twin can be employed to leverage traceability data, enhancing tool management in companies. However, the scientific literature does not delve into the use of digital twin in this specific context and there is also a lack of awareness in the industry regarding the potential of digital twin. Furthermore, the various levels of advancement in a digital twin implementation remain relatively unexplored. The aim of this article is to introduce the initial implementation of a digital twin, particularly a digital shadow designed for managing tool flows between workstations and the tool store in a job shop. The selected case study is an academic factory dedicated to providing technical training for students on specific manufacturing processes, operating without tool traceability technology. A discrete event simulation model was created to examine both context of tool flow management: one utilizing tool traceability technology and the other without. A comparison is conducted based on performance indicators.","Digital Innovation in Supply Chain Management: Simulation, Decision Support, and Shared Tools",44,716
Market-Ready: Boosting E-Commerce Logistics with Intelligent Decision Support System," This study presents a multi-stage stochastic dynamic risk-averse model for the last-mile delivery problem with online orders (dynamic orders-same-day deliveries) and offline orders (stochastic orders-regular deliveries), incorporating three innovative policies mobile depot, crowd-shippers, and hyper-local drivers. The aim is to identify mobile depot optimal locations prior to the full information about offline orders and the availability of delivery drivers (i.e., crowd-shippers and hyper-local drivers), resulting in optimal delivery schedule. The uncertain availability of crowd-shippers is estimated by developing a deep learning model, with features extracted from social exchange theory (SET). The most imperative features are identified by developing an ensemble model. To address dynamic offline scenarios, a Markov decision process model is developed, and an online reinforcement-driven adaptive optimization (ORDAO) is proposed to find optimal routing policies. To validate the proposed ORDAO, an interactive multi-agent simulation (IMAS) is developed to compare average delivery time and the generated tours by ORDAO and IMAS. According to the obtained results, by imposing on average \%2 more cost to the network, the risk-averse model can effectively handle high-risk scenarios, resulting in significant cost savings. The proposed ORDAO generates delivery tours to fulfill the same number of orders in almost \%11 less delivery time in comparison to the IMAS. The incorporation of the hyper-local drivers policy leads to a 12\% decrease in both total delivery time and distance, leading to lower CO2 emissions and reduced traffic congestion.",Innovative topics in supply chain 2,113,717
Police In-vehicle Technology Adaptation based on Officer Cognitive State," Law Enforcement Officers (LEOs) experience high level of workload and stress while on duty. LEO cognitive state varies under different driving conditions, such as patrol, pursuit, and emergency driving. In-vehicle interfaces further increase LEO workload, as LEOs need to process information from the mobile computer terminal and radio, creating a need for adapting information intake under high workload. To address this need, this study introduces a system designed for real-time adaptation of in-vehicle technology for LEOs based on their cognitive state. The system leverages real-time data to track and manage the workload of officers dynamically. Gaze behavior analysis is utilized to determine attention allocation during various driving scenarios. Sensory outputs are monitored to assess physiological measures of workload. Additionally, vehicle dynamics data provide insights into driving behavior under different driving conditions. Based on the live processing of these variables, the system adjusts the in-vehicle interface and information delivery based on the LEO’s cognitive state. The system is intended to optimize the interaction between the officer and in-vehicle technology, resulting in better performance and optimizing workload levels. The proposed system could offer a novel approach to integrate context-aware technology into police vehicles. This approach aims to contribute to the field of live information processing and human-system interaction, and more broadly contributes to the advancement of adaptive technologies in high-stress professional environments.",Transportation,232,718
AI and Dementia Diagnosis: Insights from Linguistic Patterns," The rise in dementia cases, combined with the aging U.S. population, signals a looming healthcare challenge. Early diagnosis of dementia allows for appropriate medical management and helps individuals to prepare for years of productive and meaningful life ahead. However, current diagnoses are largely based on clinical interviews and questionnaires, which are subjective and can lead to recalls and interviewer biases. This paper delves into the comparative efficacy of different Artificial Intelligence (AI) models, specifically Large Language Models (LLMs), Markov Chain models, and pre-trained language mechanisms such as Bidirectional Encoder Representations from Transformers (BERT), in the early detection of dementia for the analysis of linguistic cues in patients' speech. Through rigorous analysis, the Markov Chain model's capability to decipher linguistic anomalies using steady-state probabilities is assessed against BERT's nuanced pattern recognition capabilities and the innovative linguistic interpretations of LLMs. Preliminary evaluations shed light on the strengths and weaknesses of each model in distinguishing between neurotypical individuals and those manifesting early signs of dementia. BERT, with its remarkable accuracy of 91%, and LLaMa-2, with a notable accuracy of 80%, have emerged as frontrunners in this investigation. Envisioning a new horizon in dementia diagnostics, this comparative study serves as a pivotal reference for understanding the potential and limitations of contemporary AI-driven approaches in the early detection of dementia, highlighting the profound impact of AI technologies on medical practices.",Healthcare V,89,719
Multi-Material 3D Plate Lattice Structures Using Fused Filament Fabrication Technique," Plate lattice structures are a type of cellular solids made from three-dimensional intersections of plates to achieve theoretical upper bounds on the stiffness and strength at low densities. Manufacturing such structures can be complex and requires careful selection of materials to achieve the desired properties. In this work, we present multi-material plate lattices with at least one material composed of carbon fiber reinforced thermoplastic composite. The multi – material configuration enhances mechanical properties without compromising the density. A fused filament fabrication technique was used to fabricate the unit cell of the plate lattice. Material such as polylactic acid (PLA), carbon fiber reinforced PLA, polyethylene terephthalate glycol (PETG), and carbon fiber-reinforced polyethylene terephthalate were used. Different material configurations were investigated on the elementary BCC structure. The results of this study offer promising opportunities for lightweight and high-strength applications.",M&D Best Student Paper Competition,124,720
Image-Based Quality Control for Additive Manufacturing through Layer-by-Layer Analysis," Quality control for additive manufacturing is investigated by leveraging image segmentation techniques. In this study, we propose a novel approach incorporating Siamese networks, introducing innovative training methods. The state-of-the-art neural net architecture employed will feature in-network scaling for enhanced performance. Identifying gaps in existing methodologies, our method addresses unexplored avenues, specifically focusing on the in-situ quantification of measuring over and under extrusion. The envisioned experiments will compare material properties of printed parts to their nominal digital representations in a layer-by-layer fashion. This methodology, with its application to extrusion processes, is poised to offer valuable insights into material properties that are challenging to discern conventionally, thus driving advancements in quality control for additive manufacturing. By providing precise geometric or dimensional quality control, the proposed monitoring system represents a significant step towards ensuring quality control and process efficiency in additive manufacturing.",Sensing and Control in Additive Manufacturing Processes-II,203,721
Industrial Engineers Enhance Public Sector “Business”—It’s the People!," This presentation focuses on the many ways someone with an industrial engineering (IE) background can thrive in the public sector, drawing on the personal experiences of the speaker. Typical IE careers are often focused on “productivity improvement” and are found in production assembly lines, manufacturing, and even health care. According to Wikipedia, the profession is concerned with optimizing complex processes and systems by developing, improving and implementing integrated systems of people, money, knowledge, information and equipment. All of these skills can be put to great use in the public sector, where profit isn’t the only end-goal, and even in positions that aren’t titled “Industrial Engineer”. IE skills can be important in developing and managing contracts and agreements, including audits; environmental permit compliance processes/negotiations; development/implementation of software systems and new technology tools; staffing and equipment justifications, working with regulatory agencies to develop policy; emergency response activities; training; working with politicians; and effective communications within the respective agency and with its stakeholders. Focusing on the people aspect of IE is a critical component of our skill set and lends itself to significant personal career enhancement while furthering the goals of public sector agencies. The speaker will describe a variety of career experiences at the South Florida Water Management District (a regional water management agency), the U.S. Air Force, and also as a consultant to public sector agencies and how her IE background significantly contributed to personal career growth and that of others.",Process & Operational Improvement I,177,722
Interpretable Artificial Intelligence for Deciphering Dementia," The escalation of neurocognitive disorders such as Alzheimer's disease (AD) poses a significant global health challenge. Traditional diagnostic methods, including clinical interviews and paper-based assessments like the Mini-Mental State Examination (MMSE), Mini-Cog Test, and Montreal Cognitive Assessment (MoCA), are constrained by practical issues of subjectivity, recalls, and interviewer biases. In response to these limitations, there is a growing demand for noninvasive, real-time, and data-driven diagnostic methods. This paper presents an interpretable artificial intelligence (AI) approach to analyze speech signals for the early identification of dementia signs. First, we propose a new linguistic encoding technique to transform speech transcripts into numerical signals. These signals are then processed through recurrence analysis to extract salient features indicative of cognitive decline. Central to our methodology is an interpretable autoencoder, a type of neural network adept at compressing and reconstructing speech signals. Third, hidden neurons are interpreted in a way to highlight distinct representations of dementia and healthy subjects. This investigation focuses on the juxtaposition of autoencoder’s neuron activations with actual brain scans, correlating speech features with neurological changes in dementia. The proposed research thus not only contributes to a better dementia diagnosis but also offers novel insights into the neural correlates of speech and cognitive impairment. Our findings underscore the immense potential of AI for medical applications in dementia diagnosis, advocating for a shift towards non-invasive and data-driven diagnostic tools.",Healthcare II,84,723
Individual International Research Portfolios Design in Higher Education: Building a Management Model for Sustainable Global Research and Scholarship in Future Complex Systems," The importance of international research programs across the disciplines is becoming an ever-critical strategic endeavor for research universities in the U.S. and abroad. Research environments cross borders, engaging in complex project management practices, optimizing hyperconnected systems, and sequencing and balancing cultural value differences and similarities to avoid miscommunication. International research initiatives are not new, but the need to better plan, manage, and sustain long-term international research programs is novel for the modern university. Primary friction points center around the professional development of internationally competent faculty who must integrate their teaching, research, and service profiles strategically and tactically to focus on competitive funding demands. Initial inquiries show that while many emerging and experienced faculty are interested in developing an international research footprint, they are woefully unprepared to navigate the design of international research to meet the needs and expectations of diverse stakeholders and processes. For instance, the demands of tenure procedures systematically prioritize relatively less complex research trajectories. This paper develops a conceptual systemic model for individual international research portfolios in higher education to assist faculty in becoming more engaged international researchers while at the same time empower administrators to better service faculty interested in international research endeavors. Employing active network theory and user experience methodology, the research also examines ways to balance management interface design, tenure requirements, organizational cultures, and other institutional and professional expectations, with complex international infrastructural and logistical realities, to address this on-going challenge confronted by the modern research university.",Systems Engineering & Life Cycle Management II,226,724
Electrohydrodynamic Inkjet Printing of Neodymium Magnetic Powder towards Magneto-active Soft Robotics," Soft robotics has gained prominence due to its potential in various applications, such as medical devices, assistive technologies, and search and rescue operations. Electrohydrodynamic (EHD) inkjet printing, a novel 3D printing technique, offers promising avenues for creating soft robotic components by depositing shape-programmable materials into complex 3D architectures. The high resolution and precision control of EHD printing enables the creation of ultra-small soft robotics. This research aims to explore the application of EHD printing in the development of soft robotics. The feasibility and benefits of this technique for creating flexible actuators and structures for soft robots were investigated. A custom-designed EHD printing system was utilized to precisely deposit neodymium-iron-boron (NdFeB) magnet nanoparticles with fine features. By altering the concentration of magnet nanoparticles, we investigated the optimized ink composition to obtain the desired printing outcome. Multiple sets of printing parameters, including the voltage, standoff height, printing speed, etc. were attempted to realize the patterning of designed actuatable structures. In future work, we will conduct a series of magnetization and testing experiments to assess the performance of these printed components in soft robotic applications. We anticipate that the printed structures, when subjected to an external magnetic field, can exhibit controlled deformation and motion. Our experiments demonstrated the significant potential of EHD printing for actuatable soft materials as well as the feasibility of the printing of magnet nanoparticles as a valuable tool for the soft robotics community.",Inkjet Additive Manufacturing Processes,106,725
Dynamics Underlying the Six Pillars of Food Security," The World Food Summit defined food security as having access to sufficient,safe, and nutritious food to meet the dietary needs at all times. When one or more of the factors mentioned is not present, there is a risk for food insecurity. Food insecurity is a complex problem caused by many factors. To propose policies that can curb food insecurity, the first step is better understanding of this complex problem. In this study we used a system dynamics modeling approach to capture the mechanisms underlying the six pillars/dimensions of food insecurity, namely, food availability, food access, food utilization, food stability, agency, and sustainability. Food availability captures availability of sufficient quantities of food supplied through the food supply chain. Food accessibility captures access to food resources by individuals free from obstacles such as physical features of the area. Food utilization captures the nutritional adequacy and quality of the food used. The stability refers to the continued access to adequate food at all times, without the risk of economic/seasonal crisis.Agency refers to the capacity of individuals and communities to make meaningful decisions about the food systems in ways that allow them to be free from food insecurity. Sustainability refers to food system practices that contribute to long-term regeneration of the food needs of the present generations.In this paper we used system dynamics modeling to show how the interplay among all reinforcing and balancing feedback mechanisms underlying the six pillars of food insecurity has contributed to increase in food insecurity and propose policy interventions.",Harvesting Hope: Innovations in Food Security and Ending Hunger (SDG 2),77,726
Evaluating Risks in the Pharmaceutical Supply Chain utilizing the DELPHI method," These interviews and research contribute to the development of a robust risk assessment model. Our research involves the development of a scoring system for these identified risks utilizing the DELPHI method. We collaborated with PSC experts to assign scores to each risk factor based on its severity and likelihood. This scoring system serves as a benchmark to evaluate pharmaceutical companies supplying the military. By adapting these scores, our aim is to gauge the reliability of individual companies and, collectively, assess the resilience of the entire military PSC network. Ultimately, this research seeks to provide actionable insights for enhancing the resilience and reliability of military pharmaceutical supply chains, offering a valuable contribution to both academia and practitioners in the field.",Supply chain Risk & resilience 1,219,727
LLM Accuracy Detection for Operational Use in Healthcare - “Automated detection and continuous evaluation of hallucinations in purpose-built Large Language Models for Healthcare”," LLM Accuracy Detection for Operational Use in Healthcare “Automated detection and continuous evaluation of hallucinations in purpose-built Large Language Models for Healthcare” : As LLMs become more widely used, it's crucial to address potential risks and ensure high accuracy for decision-making, especially in healthcare. A major concern is 'hallucination', where LLM outputs diverge significantly from expected responses. The primary aim of our study is to evaluate, detect and analyze continuously the degree of hallucinations in responses from custom-built LLMs on patient treatment pathways. Hypothesis: Our hypothesis is that automating early-detection of deviations in LLM outputs can ensure continuous evaluation and reliability of LLMs during operational clinical use. We trained our custom-built LLM with trusted patient pathways, real-world data and procedure codes. Methodology: Our purpose-built LLMs utilize de-identified patient data to generate multiple pathway predictions from user-provided sequence of inputs. We enabled a hallucination detection algorithm that uses a decision-tree model to examine the LLM outputs based on the inputs (which are coded and structured procedure summaries and codes). We used random procedure codes to measure the rate of hallucinations by comparing the output of the LLMs to the training data using tree-based heuristics. In our observation, LLMs trained on external, untrusted data are prone to poor responses. Results: Our results showed that we can detect 90% of the LLM driven hallucinations using decision-tree based heuristics and N-gram models. To enable trustworthiness for decision-making, several metrics are needed to ensure high accuracy and low hallucination rates.",Healthcare I,83,728
Resilient Suppliers Selection in Pharmaceutical Industry – An International Perspective," This study intends to provide strategic insights for reducing disruptions and enhancing supplier networks by conducting a detailed evaluation of the industry's financial status. While successfully addressing supplier disruption assessment, this paper recognizes the need for a similarly comprehensive strategy to selecting resilient suppliers. The study used the Bayes' Theorem approach to determine disruption and resilience, concentrating on conditional probability. The study assesses the conditional elements of three companies from each nation, with a focus on India, China, and Singapore as important supplier countries to Bangladesh. The averages of these parameters establish probability for each country across several factors. These numbers are then integrated into Bayes' Theorem to determine the most dependable supplier according to the highest probability. This report will summarize the findings and recommendations, highlighting the crucial need for proactive actions to improve the resilience of supply chains in Bangladesh's pharmaceutical sector. The analysis of this paper can be applied with any available but comparable data volume for measuring resilient supplier. The paper will conclude with a set of particular suggestions for industry players, and policymakers to strengthen the sector in the face of future challenges.",Healthcare Supply Chain,88,729
Advanced Manufacturing Curriculum Development in Ohio High Schools and Community Colleges," There is a huge lack of qualified personnel in advanced manufacturing in the U.S. Midwest stemming from a lack of student interest compounded with a lack of experienced teachers who usually motivate students. This paper describes the findings of an NSF RET project at Bowling Green State University that successfully addresses the common need to produce STEM graduates in the advanced manufacturing area. The NSF-RET project’s unique hands-on research experience combined with local industry collaboration prepare future STEM teachers, who can interject research experience in a classroom learning and tie that with the real-world implementations. The project cements the partnership among BGSU, local high schools, and community colleges in Ohio to address the common need of producing STEM graduates in advanced manufacturing area. This project addresses the workforce needs by producing competent high schools and community college educators, who are capable to blend research with educational activities at their institutions, motivate students for STEM degrees, and build long-term collaborative partnerships in the region. This project focused on two goals: (1) explore a sustainable educational model that connects high schools, community colleges, university, and industry; and (2) play a transformational role in preparing future leaders in advanced manufacturing. This paper explains the need, scope, and nature of the curriculum development process through engaging K-14 educators. This paper will share some of their successful research projects, how they translated their research into actionable curriculum modules, and some lessons learned from implementations.",Innovations in Engineering Education,108,730
An Agent-Based Modeling Approach for Exploring Predictive Model Diffusion and Cryptocurrency Price Behavior," This study presents an innovative exploration into the dynamics of the Bitcoin markets, observed through the lens of an agent-based model (ABM). The research delves into how the spread of predictive models affects the behavior of diverse market actors, ultimately shaping the supply and demand forces that drive Bitcoin prices. In the rapidly evolving domain of cryptocurrencies, understanding the interplay between advanced predictive models and market flux is imperative for stakeholders like investors and regulatory authorities. The simulated market environment in this study is made up of diverse agents – from individual investors to algorithm-driven traders and institutional entities. Each category of agent is governed by distinct behavioral rules and decision-making processes. The core of this study is the mechanism through which agents discover and adopt various Machine Learning (ML) models, reflecting different levels of accuracy and market insight. The ABM simulates various scenarios to understand how the dissemination of superior ML forecasts among agents affects trading patterns, liquidity flow, price volatility, and overall market stability and efficiency. Furthermore, it delves into the ramifications of market saturation with highly accurate forecasts, potentially leading to conditions of extreme market positioning and liquidity crunches. This study contributes to the understanding of market efficiency in the context of high-frequency, algorithmic trading environments. It offers insightful perspectives on the limitations and potential risks associated with the widespread adoption of predictive models in financial markets. Finally, it underscores the necessity for robust regulatory frameworks in the face of rapidly advancing technological capabilities in finance.",Agent-Based Modeling,14,731
Study of dimensional accuracy and elastic properties of 3D printed Thermoplastic polyurethane (TPU) models with different infill patterns," Thermoplastic polyurethane (TPU) is a plastic with elastic properties and a good replacement for rubber. The material is often used in fused deposition modelling to create medical models, sporting goods. There has been research conducted on the effect of several parameter on the quality of a 3D printed model, however, the research on the dimensional accuracy of the 3D printed TPU models based on the infill patterns while maintaining the elastic properties has been limited. To better understand the effect, five infill patterns were tested: Gyroid, Grid, Triangle, Honeycomb and Cubic. The parameters measured as a quality index were: the gage width and overall width of the dog bone specimen; outer diameter and inner diameter of the ring specimen. Tensile tests were conducted on each of the dog bone specimens to understand the stress-strain relationship for each of the infill patterns. The Cubic infill pattern resulted in small deviation for the gage width and the inner diameter, however, triangle infill pattern resulted in small deviation for the overall width and outer diameter. The elongation at break however seems to be highest for Gyroid and lowest for Triangle. The discrepancy in the dimensional accuracy data suggests that a wider sample size need to be used in order to make a concrete conclusion for the effect of the infill pattern on the dimensional accuracy and selecting the optimal infill pattern based on the strain at break.",Mechanical Characterization in Additive Manufacturing Processes,143,732
Personal Branding 101: Positioning Oneself for Early Career Success," In the Professional Skills to Succeed course at Rutgers University, students are exposed to key strategies in order to prosper as they begin their career. Topics in this course include professional ethics, effective communication, evaluation of career options, and interviewing skills. This class highlighted the importance of collaboration and asking questions in the early career journey. An example of this is the Informational Interview assignment. By conducting informational interviews with industry professionals, students are able to obtain a better understanding of a company’s internal culture and how cross-functional teamwork is applied to real-world problems. Confidence and self-awareness are also valuable traits in career development. When discussing their experience, students should actively highlight their personal contributions, skills, and achievements. Recruiters often discuss being the ‘proper fit’ for a role. For a student to know if they are a proper fit, they must first take the time to fully understand their personal and professional strengths, goals, and values. Learn how a senior industrial engineering student was able to apply the topics in this course to improve their communication ability, secure multiple internship opportunities in program management and supply chain at Fortune 500 companies, and successfully expand their professional network of connections. This presentation will include multiple topics related to early career development: Crafting an Elevator Pitch, Resume Optimization, Writing a Standout Tailored Cover Letter, and Interview Advice. This practical and valuable information will be useful to all students on an industry path, especially those seeking guidance in obtaining internship and co-op opportunities.",Personal Development II,163,733
A Collaborative Truck-and-Drones Delivery for Humanitarian Relief Logistics," There has been an increased interest in utilizing drones in emergency management due to their mobility to access affected areas swiftly and safely through the sky. In the aftermath of natural disasters such as earthquakes, some road networks in the affected areas may be disrupted during relief logistics processes. Thus, in this study, we develop a mixed integer linear programming (MILP) model to minimize the total delivery time for a single truck and multiple drones to distribute humanitarian relief supplies to all citizens in the affected area. In our problem, the relief supplies are delivered by truck or drone. Drones can deliver supplies to an evacuee multiple times to meet the required quantity of relief supplies of the evacuee and then return to the truck after each delivery. More interestingly, in this study, we investigate the impact of a special type of node, which is called a parking node, on enhancing the drone utility; at the parking node, drones can be launched from and retrieved to a truck with no delivery. An adaptive large neighborhood search (ALNS) metaheuristic is exploited to address the challenges of solving the large-scale problems and the characteristics of our delivery system. Experimental results are expected to demonstrate that utilizing ALNS offers a more efficient solution in operating a single truck with multiple drones. This study contributes to the effective utilization of both a truck and drones in large-scale natural disaster situations, enhancing the efficiency and responsiveness of humanitarian relief logistics.",Humanatarian logistics 1,94,734
Technology Benchmarking-SWOT for eVTOLs and Vertiports based on literature review.," Advanced Air Mobility is a disruptive technology representing the next stage of transportation innovation and aims to improve and facilitate urban, suburban, and regional mobility. Through this project, we will focus on two key areas: Firstly, the eVTOL aircraft, which combines electric propulsion and vertical flight capability to provide fast and efficient transportation within and between cities. Secondly, the vertiports, a dedicated infrastructure that these aircrafts will operate from. To carry out our project, we will evaluate advanced air mobility as a new concept by studying its history, occurrence, and integration into the Québec market by gaining insights from comparable examples to collect essential information and data. Subsequently, we will conduct a SWOT analysis and a ""gap analysis”, two valuable tools for strategic planning and decision-making. First, we will start with a SWOT analysis by identifying the Strengths, Weaknesses, Opportunities, and Threats of both the eVTOLs and the vertiports. Then to achieve better observability, we will conduct a literature gap analysis, with a specific emphasis on batteries, a critical element for the eVTOL industry especially in the Québec market. This study will identify gaps in knowledge about battery technology, ensuring a comprehensive understanding of the challenges and opportunities essential to eVTOL functionality. Advanced Air Mobility aims to achieve quicker, more cost-effective, environmentally friendly, and less congested transit options. AAM can change our environments and make aerial mobility an essential part of our daily lives as technology advances and adoption rises.",Emerging Technologies and Safety: From AMR Integration to Urban Air Mobility,61,735
Condition-based maintenance optimization for wind energy systems using a numerical approach," Effective maintenance techniques are key to reducing the cost of wind energy. In existing studies on condition-based maintenance (CBM) for wind power systems, simulation-based methods are primarily used. However, the simulation-based methods rely on randomly selecting a limited number of samples to simulate cost values, resulting in variations in cost evaluation and non-smooth cost function surfaces. The sampling characteristic may lead to issues such as local minima and convergence, which can make the optimization process challenging. In this work, we introduce a numerical method for CBM policy cost evaluation to address these challenges. The CBM policy is defined by two failure probability threshold values at the wind turbine level. We illustrate the proposed numerical method using examples, and provide a comparative study to demonstrate the effectiveness of the approach.",Reliability Analysis I,186,736
Ganufacturing – Revolutionizing Quality Control in 3D Printing with GenerativeAdversarial Networks," In the realm of 3D printing, ensuring quality assurance remains a significant challenge, particularly due to the limitations of manual inspection methods. This study introduces an approach utilizing Generative Adversarial Networks (GANs) and a specially designed image classifier to detect defects in 3D printed objects. The discriminator component of GANs is employed to effectively distinguish between defective and non-defective items. Furthermore, an image classifier, optimized for low-resource environments, is developed and implemented on a Raspberry Pi. This setup offers a practical solution for real-time defect detection in industrial 3D printing applications, potentially revolutionizing quality control processes.",Sensing and Control in Additive Manufacturing Processes I,202,737
Improving Equity in Access to Urban Parks," Local parks are foundational for neighborhoods and communities. Yet, disparities persist in who has access to high-quality parks. To support recreational and government agencies in addressing inequities in the distribution and quality of parks, we propose a mixed-integer program that minimizes insufficient access. Insufficient access is defined as weighted deviations across multiple categories, including distance, acreage, and environmental factors. We apply the model to a case study of Asheville, North Carolina. We conduct extensive data collection to parameterize the model. We evaluate several policies to improve access.","Building Sustainable Communities: Enhancing Early Child Development, Infrastrucure, Park Access and Industrial Efficiency (SDG 11)",22,738
Optimal Route Planning Using Computer Simulation in the Context of Distributor-To-Consumer Supply Network," Effective route planning for distribution centers is a multifaceted challenge crucial to business success, as it directly impacts time and cost savings while enhancing overall delivery efficiency. Oversight of proper planning can lead to problems and inefficiencies in the distribution process. Hence, this work undertakes a comparative experiment of two delivery strategies in a distributor-to-consumer supply network. While the first strategy investigates the delivery process by zip area, the second strategy considers the clustering of the areas for more streamlined delivery fulfillment. The effectiveness of the delivery process is gauged based on a set of metrics, including total distance traveled, average delivery time, missed target deliveries, and resource utilization. The study specifically addresses five distribution centers in the El Paso, Texas, USA, area and the delivery addresses across various zip codes in El Paso. The delivery network was simulated using the AnyLogic software, with results analyzed on both daily and weekly timelines. Simulation data were systematically logged in the AnyLogic database for subsequent analysis. In doing so, this paper presents a comprehensive analysis derived from observed data, offering a comparative assessment of the two delivery strategies. The findings provide a quantitative evaluation of the effectiveness of route planning within diverse scenarios in end-user supply networks.",Supply Chain & Scheduling,214,739
Generative AI and Technical Enterprise Technology for Neurodiverse Individuals: A Literature Review," Neurodiversity is a concept that recognizes and celebrates the natural variation in neurological functioning among individuals. There has been a growing recognition of the unique talents and perspectives that neurodiverse individuals bring to the workplace. Yet, neurodivergent individuals face many challenges at work that require thorough investigation to facilitate smoother operations. This systematic literature review analyzes and explores existing research on technical enterprise technology specifically designed to address the challenges faced by neurodiverse individuals in their work environments. It also reviews existing technologies that work with generative AI solutions to enhance the productivity, well-being, and overall job satisfaction of neurodiverse individuals. The review provides an overview of neurodiversity and its strengths and benefits in the technological enterprise sector. It then explicitly identifies the challenges faced by neurodiverse individuals in technical enterprise settings including issues related to communication, sensory sensitivities, executive functioning, social interaction, and enterprise tools usability. The review includes publications between 2018 and 2023. It synthesizes findings from studies focusing on various types of technical enterprise technologies, including assistive technologies, augmented reality applications, virtual reality simulations, and intelligent automation. The findings of this literature review contribute to the emerging field of neurodiversity in the workplace by identifying gaps and opportunities for future research. These insights can inform the design and implementation of technical enterprise technologies that foster inclusive and supportive work environments for neurodiverse individuals. Ultimately, this research aims to promote equal employment opportunities and bolster the unique talents of neurodiverse individuals in the context of technical enterprises.",Diverse Topics for Human Factors and Ergonomics 1,55,740
"On Model Compression for Neural Networks: Framework, Algorithm, and Convergence Guarantee"," Model compression is a crucial part of deploying neural networks (NNs), especially when the memory and storage of computing devices are limited in many applications. This paper focuses on two model compression techniques: low-rank approximation and weight pruning in neural networks, which are very popular nowadays. However, training NN with low-rank approximation and weight pruning always suffers significant accuracy loss and convergence issues. In this paper, a holistic framework is proposed for model compression from a novel perspective of nonconvex optimization by designing an appropriate objective function. Then, we introduce NN-BCD, a block coordinate descent (BCD) algorithm to solve the nonconvex optimization. One advantage of our algorithm is that an efficient iteration scheme can be derived with closed-form, which is gradient-free. Therefore, our algorithm will not suffer from vanishing/exploding gradient problems. Furthermore, with the Kurdyka-Łojasiewicz (KŁ) property of our objective function, we show that our algorithm globally converges to a critical point at the rate of O(1/k), where k denotes the number of iterations. Lastly, extensive experiments with tensor train decomposition and weight pruning demonstrate the efficiency and superior performance of the proposed framework.",Deep Learning III,42,741
Optimizing Path Planning and Conflict Resolution in Low-Altitude Urban Airspace for Passenger Transport Using Aerial Vehicles," Urban air mobility (UAM) refers to the innovative aerial vehicle operations, including air taxi and delivery drones, designed to transport cargo or people within low-altitude urban airspace. Despite their potential for lower costs and quicker implementation, the ability to integrate UAM traffic flows into the existing air traffic system remains a major challenge. However, it is imperative to effectively manage these mobilities anticipated in urban areas to ensure safety, avoid conflicts, and reduce traffic congestion. Prior studies on conflict-free path planning tend to consider similar-typed aerial vehicles, employing a single conflict resolution strategy to achieve a simplified objective with no consideration for uncertainties related to flight positions. To fill these gaps, in this study, we develop a mixed-integer nonlinear programming (MINLP) model to efficiently manage UAM traffic within a centralized strategic planning scheme while satisfying several conflict resolution strategies. The goal of this model is to minimize the total energy consumption and simultaneously keep safe distances between UAM vehicles under trajectory uncertainties. Furthermore, we propose a novel metaheuristic algorithm to solve the proposed MINLP model. The applicability and practicability of our proposed model is validated through various scenarios with air taxis and air metros within a shared urban airspace in the United States. Simulation results demonstrate the impact of diverse UAM traffic flows and their interactions on low-altitude UAM traffic management. Our study plays an important role not only to offer insights into the UAM path planning for passenger transport, but also to provide valuable information for stakeholders and decision-makers.",Urban Logistics,237,742
Assessing the potential of market prices to drive sawing decisions," Softwood lumber companies deal with complex production processes with heterogeneous raw materials (great diversity in terms of log quality, diameter, length, etc.) and divergent product flows (sawing one log simultaneously generates many products with different characteristics). For each log, optimizers encapsulated in sawing machines select a cutting recipe in real time to maximize the value of the outgoing product basket. As commodity sellers, softwood lumber companies are price takers. Consequently, the value of each product basket produced is determined by market prices, which depend on the interplay of supply and demand. In practice, sawing machines are configured to maximize either material yield or revenue given fixed product prices acting as weights. In this project, we assess the potential of past market prices to drive sawing decisions. Considering a case study inspired by softwood lumber producers located in Eastern Canada, we evaluate different production strategies through simulation and compare them to a know-it-all strategy where weekly market prices are known in advance.",Scheduling/Real-Time Execution,201,743
Optimizing curb space management through Dynamic Pricing," With the growth of new mobility services and increased needs for goods delivery, curb spaces and their use have evolved very rapidly. Especially after COVID-19, active travel has increased, and delivery rates have skyrocketed, which has created a great need to ensure safe and efficient management of the curbs. One way to manage the curb spaces is to implement smart pricing strategies, as they can help manage the demand efficiently. To this end, we have built a dynamic pricing model with a revenue management approach by considering different curb uses. More specifically, we developed a discrete-time Markov decision process model (MDP) in which the objective is the maximization of the expected revenue of cities from all curb space uses. By using our model, we also derived easy-to-implement policies that can be used in curb pricing decisions.",Marketing Management,142,744
Contracting for Referral Coordination in a Tiered Service Network via Pareto Optimization," Balanced resource utilization across tiered service networks is critical in service-oriented industries. Formulating robust referral (outsourcing) coordination contracts between primary and secondary service providers is essential to mitigate operational bottlenecks, declines in service quality, and increased risks of client dissatisfaction. However, crafting effective referral agreements is complex, relying not only on achieving the desired profitability and service level from referrals at both providers but also on managing the impact of additional customers who are not covered by the referral agreement. In healthcare, this is evident in patient referral coordination between hospitals and skilled nursing facilities (SNFs), where patient preference for outpatient rehab at reputable hospitals leads to overcrowding and resource misalignment, while SNFs remain underutilized even with their inpatient rehab service available. To address this, we propose an operational-level control agreement framework for arranging referral decisions between the two care facilities to maximize their respective benefits. This framework allows an easy-to-implement threshold policy based on their bed occupancy levels. To maximize revenue and relieve patient blockage at either facility, we explore Pareto optimality on the threshold pair. This involves executing a modified ordinal transformation and optimal sampling (OTOS) algorithm along with multi-fidelity modeling of patient flows, wherein the low-fidelity model is a tandem queuing network with varied customer types and the high-fidelity model is a discrete-event simulation. We investigate the efficacy of the proposed contract through case studies based on healthcare claims data. We also demonstrate the effectiveness of the modified OTOS algorithm over standard simulation optimization algorithms.",Supply Chain Management,215,745
"Redefining Jordanian Retail: An In-Depth Exploration of Underutilization and Transformative Strategies, Shifting from Traditional Retail Decision-Making to a Data-Driven Market and Unveiling the Power of Predictive Analytics and Optimization Paradigms."," There is a noticeable lack of adoption of data-driven techniques for operational improvement and decision-making in the dynamic Middle Eastern retail market, particularly in Jordan. This research sheds light on how data is underutilized in retail businesses, where the absence of essential data collection tools represents a missed opportunity. This oversight leads to an untapped reservoir of data, hindering informed decision-making, efficient employee scheduling, and balancing demand-supply. The paper investigates behavioural patterns to embrace data-centric practices. It explores the root causes of resistance and proposes strategies that emphasizes the transformative potential inherent in predictive analytics and demand forecasting. To address these objectives, a multi-faceted methodology will be employed. The researcher will personally travel to Jordan to conduct in-depth interviews with retail owners, to assess qualitative insights into their practices, challenges, and perceptions regarding data utilization. Additionally, an extensive analysis will be undertaken, leveraging machine learning to analyze historical sales data, customer interactions, and inventory trends. The insights gained will not only empower retail practitioners but also guide policymakers in formulating strategies that foster a conducive environment for data-driven innovation. Ultimately, this research aims to inspire a paradigm shift, where data becomes the catalyst for excellence in Jordan's retail sector. Furthermore, this research is poised to extend its impact beyond the borders of Jordan. The identified root causes and transformative strategies can serve as a blueprint for other countries facing similar challenges in their retail sectors or regions characterized by analogous conditions, fostering a global shift towards data-driven excellence in retail.",Business Analytics,23,746
Role of Simulation Modeling in Digital Twins for Enhanced Supply Chain Management: A Review," Industry 4.0 (I4.0) technologies are leading the digital transformation by integration of advanced technologies in Supply Chain Management (SCM). The concept of Digital Twins (DT) is one such technological paradigm that offers resilience and adaptability in SCM. Researchers also have given prominence to simulation modeling as an essential aspect of DT integration for forecasting, production planning and optimization and logistics management. In-fact, simulation technologies perform a prominent role in exploration of complex systems for development and planning. This paper provides a critical review that focuses on the role and contribution of simulation modeling in DT for improving SCM processes. The review reveals main challenges, key aspects and applications of simulation in integrated DTs. In addition, this review discusses the integration of Artificial Intelligence (AI) with simulation for enhanced predictive analysis and self-adaptability. The results highlighted the significance of simulation as one of the leading pillars of I4.0 in DT integrated SCM systems. Based on the findings, this review also provides future research directions in context of simulation and I4.0 for enhanced SCM.",Digital Twins,51,747
Strategic Relief Center Placement in Flood-Prone Regions: A Comprehensive MCDM Evaluation," This research focuses on enhancing flood disaster preparedness by evaluating multiple risk mitigation strategies through the application of Multi-Criteria Decision Making (MCDM) techniques, specifically in the context of determining optimal locations for relief centers. In regions prone to flooding, the strategic placement of relief centers is pivotal for efficient response and recovery efforts. This study employs MCDM as a robust analytical tool to systematically assess and prioritize various factors influencing the placement of relief centers during flood scenarios. Multiple risk mitigation strategies, including diverse relief centers placement scenarios, are systematically evaluated against the established criteria. The MCDM technique facilitates a quantitative comparison, allowing for the identification of the most optimal placement strategy based on the weighted criteria. This approach not only enhances the objectivity of decision-making but also provides a systematic framework for stakeholders to navigate the complexities associated with flood disaster management. The outcomes of this research aim to inform policymakers and emergency response agencies, offering a data-driven approach to optimize relief centers placement in flood-prone areas. By leveraging MCDM techniques, the study contributes to the development of adaptive strategies that enhance the resilience of communities facing the escalating threat of flood disasters, ensuring a more effective and timely response to mitigate the impact on vulnerable populations.",Risk Management,195,748
Enhancing Remaining Useful Life in Solid-State Batteries: A Review of Smart Battery Management System Strategies.," This paper focuses on the critical role of Smart Battery Management Systems (SBMS) in enhancing the Remaining Useful Life (RUL) of solid-state batteries (SSBs), a key component in the next generation of energy storage technology. SSBs, known for their high energy density and safety, require advanced management to maximize their lifespan and efficiency. We examine the latest developments and strategies in SBMS, specifically designed for SSBs, to extend their RUL. The paper provides a comprehensive overview of current techniques, including state-of-the-art predictive algorithms and real-time monitoring systems. Special attention is given to innovative approaches such as machine learning and artificial intelligence, which have shown significant potential in accurately predicting battery degradation and failure. We also discuss the unique challenges associated with SSBs, such as their sensitivity to various operational and environmental conditions, and how SBMS can effectively address these issues. By comparing different methodologies and highlighting their strengths and limitations, this review aims to identify the most promising strategies for improving the RUL of SSBs. This paper serves as a valuable resource for researchers and industry professionals looking to enhance battery management practices, contributing to the advancement of sustainable and efficient energy storage solutions.",Microgrids and Energy Storage,145,749
Statistical monitoring of the covariance matrix in multivariate processes: A literature review," This paper presents a comprehensive overview of the literature on control charts for monitoring the covariance matrix in a multivariate statistical process monitoring (MSPM) framework. The existing control charts are classified into four major groups where, for each group, the main ideas and results along with their benefits or drawbacks are briefly discussed. We highlight the challenging areas for research and provide some directions for future research.",Advanced Topics of QCRE II,8,750
Funding opportunities for human-centered engineering research at the US National Science Foundation," Modeling humans in engineered systems contributes to the creation of intelligent systems that seamlessly integrate with human activities and ultimately benefit society. The US National Science Foundation (NSF) offers diverse funding opportunities to support innovative research in this space. This presentation will provide an overview of potential funding opportunities for human factors and ergonomics researchers in tandem with researchers working towards developing transformative technologies that align with human cognitive and physical capabilities. The presenter will provide an overview of NSF and funding mechanisms available, and finally, will go over a sub-set of programs that fund research in human-centered engineered systems.",Diverse Topics for Human Factors and Ergonomics 1,55,751
State Street-Bayfront Parkway Intersection: Traffic Flow Management with Simulation Modeling and Analysis," A common cause of wasted time, increased fuel consumption, environmental pollution, etc. is traffic congestion at intersections. It is a major challenge faced by almost all busy urban societies. Significant congestion at the State Street-Bayfront Parkway intersection is such an issue faced by the City of Erie in Pennsylvania. In order to mitigate this issue, this study aims to analyze and improve traffic flow at this intersection, which would assist with reducing travel time as well as congestion and with improving the overall traffic fluidity. A simulation model, replicating real-world traffic conditions at the State Street-Bayfront Parkway intersection is developed under this study. The model incorporates several factors, including traffic control strategies, queue lengths, traffic volume, etc. As referenced by real-world data, the simulation model indicates moderate traffic congestion eastbound and heavy traffic congestion northbound at the intersection. It is revealed that adjusting traffic light times without increasing congestion on one street or the other is infeasible. Hence, a second left turn lane is recommended to be added for State Street. A second left turn lane at State Street would facilitate a reduction in traffic, which in turn would allow for the red times to be decreased by 5-10 seconds for Bayfront Parkway. Thus, congestion would decrease at the State Street-Bayfront Parkway intersection. The recommendations from this study are expected to assist with achieving better traffic fluidity on both of the streets.",Applications of Work Systems,17,752
Dynamic Analysis of Supply Chain from a Blockchain Perspective," Blockchain technology is a new digital technology that has disrupted the way businesses are performing. It is a decentralized and distributed ledger that enables transactions of any form of value. As blockchain technology provides visibility, transparency, and security through the multi-agent system, the supply chain sector is one of its critical and promising applications. In a highly dynamic environment, the supply chain's efficiency needs to be measured from a blockchain perspective. As the main benefit of blockchain technology is the visibility and real-time access to data, blockchain technology's preeminent affected areas within the supply chain are the responsiveness to the customer and the inventory efficiency among the supply chain partners. This research developed a dynamic model to measure supply chain efficiency from the blockchain perspective. The developed model is based on system dynamics methodology to model a typical three-tier supply chain; manufacturer, distributor, and retailer. It consists of three components: chain system, backlog system, and supply chain efficiency evaluation system.",Supply chain Risk & resilience 1,219,753
Exploration of a generalizable and open-source framework for real-time monitoring and control of localized additive manufacturing processes through ROS," This work explores an open-source control framework for developing intelligent robotic additive manufacturing (AM) systems. Localized AM processes such as directed energy deposition (DED) and fused filament fabrication (FFF) offer unique manufacturing and material capabilities at the cost of high complexity in determining optimal process conditions (thermal input, material feeding rate, travel speed, etc.). A critical need exists in these processes to maintain process outcomes such as melt pool temperature, shape, chemical composition, etc. within a narrow process window to prevent defect formation. This need is rarely satisfied solely by prescriptive process parameters, instead relying on in-process parameter modification by expert operators. Monitoring and controlling process outcomes such as melt pool temperature, track width, and track height in real-time are feasible; however, traditional AM control methods are not amenable to closed-loop feedback for defect prevention and remediation. This work explores an open-source framework for automated path planning and decision-making in AM systems. Prescribed process conditions and paths are augmented with real-time sensing, enabling for process-awareness and on-the-fly parameter modification. Robotic Operating System (ROS) provides ideal communication protocols for receiving in-process signals, extracting useful data, and executing automated decisions about trajectory, performance, and applied process parameters. This framework is well suited for complex geometries and material combinations and is applicable across robotic platforms. As sensing and defect recognition algorithms continue to advance, this work builds a basis for harnessing valuable process information and making informed decisions in AM.",Sensing and Control in Additive Manufacturing Processes-II,203,754
Emerging Edge Computing Systems Sustainment Practices for Ground Vehicles," Artificial intelligence (AI) has improved the operational efficiency of ground vehicles in various applications such as health management, environment detection, passenger safety, and vehicle personalization. The edge computing system, which comprises hardware components like in-vehicle sensors, edge computing devices, and transmitters, and software components like data storage and model containers, is a key enabler of vehicular AI. The system design follows specific patterns, including naïve edge-cloud and network-local architecture, and these patterns have a significant impact on their sustainment needs. The sustainment needs of an edge computing system can be categorized into three levels. The first level is performance verification and validation, which accounts for abnormal behavior detection, AI trustworthiness assessment, and potential tampering and corruption alerts. The second level is failure detection, which accounts for hardware and software failures. The third level is repair actions, which suggest hardware management, model updates, and data management strategies. In this work, we review existing industrial standards, commercial products, and academic publications, and summarize the hardware and software components of different vehicular edge system design patterns with examples. We then proceed to a comparative analysis of the sustainment needs of these edge design patterns. Finally, we highlight emerging sustainment practices and predict future trends by drawing parallels with good practices in other industries. The findings from this study offer insights for both commercial vehicle maintenance and mission-based vehicle two-level maintenance, highlighting additional sustainment efforts due to the addition of the edge computing system.",Logistics II,123,755
"Finding Risk-Aware, Equitably Efficient Benefit Allocations"," This research focuses on problems in which decisions lead to benefit allocations across multiple entities and the decision maker has fairness concerns alongside efficiency concerns. Assuming that the benefits are uncertain, we propose a method for achieving equitably efficient solutions for these multicriteria problems in the context of risk-averse behavior. To accomplish this, we introduce a methodology that combines two distinct concepts: Conditional Value-at-Risk (CVaR) and Ordered Weighted Averaging Scalarizations (OWA). CVaR functions as a risk assessment metric, providing insight into the risk associated with uncertainty. Simultaneously, OWA offers a useful tool for finding equitable efficient allocations across multiple entities. By integrating these two concepts, we aim to establish a framework for equitable, risk-aware decision-making.",Sustainability and equitable Operations,224,756
Layer-direction normalization for robust inference in image segmentation on noisy datasets," Image segmentation through deep learning plays a crucial role in real-world applications of AI-based decision-making in industries. However, neural networks often struggle to maintain consistent performance when the distribution of training and inference datasets differ, especially in the case of corrupted noisy images. As a result, numerous studies have focused on developing robust network architectures or denoising methods for specific types of corruption. However, given the variety of corruption types and the efforts required for developing neural network architectures customized to specific corruptions, a more generally applicable approach at the module level is necessary to solve real-world image segmentation problems that encounter a variety of corruptions. In this paper, we show that modules with layer-direction normalization can achieve robust inference with corrupted noisy images. Specifically, we analyze how layer-direction normalization can reduce the impact of input fluctuation on a layer’s output. Evaluation on corruption benchmark datasets, along with case studies on real-world datasets such as medical and satellite images, affirm that layer-direction normalization significantly contributes to robust inference against corruption.",Advanced Topics of QCRE III,9,757
MMP2Vec: Self-supervised Learning of Continuous Multistage Manufacturing Processes of Liquid Products without Intermediate Output Labels," Numerous studies have been conducted to enhance productivity by utilizing process data in manufacturing operations, focusing on developing data-driven soft sensors for monitoring product quality. Creating high-performance models typically requires a large amount of production output labels and reflecting the physical structure of manufacturing processes. However, continuous multistage manufacturing processes (MMPs) of liquid products, such as petrochemical and food products, present unique challenges due to their inherent properties. In continuous MMPs of liquid products, sequential stages are involved where inputs are transformed into final outputs without interruptions. This process results in limited data availability, as acquiring labels for intermediate products is nearly impossible, and even obtaining final product quality labels requires manual, experimental efforts. Additionally, the data from each stage have a sequential relationship, with lead time differences between stages. To address these limitations, we propose a methodology that leverages self-supervised learning to represent continuous MMPs without intermediate outputs and with insufficient final output labels. Our approach includes developing a specialized deep learning architecture and a pretext task for self-supervised learning to overcome the scarcity of labels. Our proposed architecture extracts representations that reflect the sequential relationship and lead-time difference of each stage. The pretext task focuses on learning from process data without labels, aiming to understand the sequential dependencies, captures temporal patterns, and contrasts varied production scenarios. In evaluation experiments, the proposed methodology demonstrates performance comparable to supervised learning approaches in real-world datasets and offers a significant reduction in the time and resources required for acquiring necessary labels.",Advanced Topics of QCRE III,9,758
Analysis of the Effectiveness and Impact of the Baldrige Performance Excellence Program on High-Performing Organizations, The Baldrige Performance Excellence Program was established in the late 1980s with the mission of assisting organizations in enhancing their overall performance and identifying high-performing organizations. The objective of the research is to analyze the effectiveness of high-performance organizations participating in the Baldrige Performance Excellence Program while utilizing diverse methods to improve efficiency and management. This study employs modern machine learning methods to assess if the winners of the Performance Excellence Award reported the effectiveness of the program in their organization’s operations or the impact the program had on the organization overall. The conclusion of this research will help leaders in these organizations identify the usefulness of the Baldrige Performance Excellence Program as well as the use of different improvement methods. Recommendations will be made based on the findings of the research.,Organizational Culture,157,759
Sales Force Distribution with Linear Programming for a Telecomunications company," The current investigation aims to develop an annual sales force plan using linear programming, directed at enhancing the sales forecast for a telecommunications company. To undertake this study, the company's internal landscape was examined since the empirical approach to the product line's strategy has previously resulted in missed opportunities for high-season sales. To attain the stated objective, an initial step involved conducting an interview with the sales manager. This interview shed light on the company's operational procedures and its existing strategy. This data proved essential in defining variables, the objective function, and the constraints of the model. The outcomes of the investigation encompassed crucial insights gained from the interview, which included information concerning the quantity of salespeople, monthly targets, and overall company strategies. Armed with this data, the subsequent phase involved crafting a mathematical model, delineating the allocation of salespeople per territory monthly throughout the year. Finally, the model underwent validation to ascertain its efficacy, achieved through a comparative analysis between the current methodology and the proposed approach.",Marketing Management,142,760
Quantifying Productivity Gains and Building Operator Trust in Collaborative Robot in a Simulated Manufacturing Assembly Operations," Collaborative robots, or cobots, are an emerging form of automation designed to safely work alongside humans in a variety of work contexts, including manufacturing. Unlike traditional industrial robots that operate in isolation, cobots possess sensing and control capabilities to enable close physical interaction with human coworkers. Frequent product changeovers in modern agile manufacturing environments lead to significant productivity losses from increased downtimes. A current study experimentally evaluates the potential of cooperative robotic technology to mitigate such downtime losses. This human subjects research empirically investigates the efficacy of a cobot-assisted workstation to support completion of a simulated manufacturing assembly task. The study implements an Automated Manufacturing Assembly Platform with an emergency-stop equipped FANUC CRX-10iA cobot. Participants are trained to manually assemble non-functional control panel units using tools and provided components. Two 3-hour assembly sessions are performed, one session involving fully manual assembly, and one session with cobot assistance, such as holding and repositioning the panel. A mixed-effects model will analyze resulting productivity data, controlling for learning effects. As an additional key question of this research, trust between the human operators and the cobot is assessed under various cobot configurations. Rigorous safety protocols minimize participant risk, including restricted cobot speeds, demarcated workspace, required PPE, and staff monitoring. By comparing output under both solo and cobot-assisted conditions, results will quantify potential productivity improvements. Findings can inform adoption benchmarks for manufacturers considering cobots and catalyze advancement of interfaces and control strategies to leverage cobot flexibility while ensuring safe and productive work systems.",Manufacturing & Design for Human Factors and Ergonomics,134,761
Predicting Emotional Clusters: Analysis of Drivers’ Valence and Arousal in Varied Environmental Conditions," Evidence supporting the impact of emotions on drivers’ performance is well-established: emotions impact many cognitive functions and can have a negative impact on drivers’ safety. Designing driver emotion monitoring systems that can measure and respond to the driver's emotional state is critical but challenging. One challenge is measuring the emotion, and another is operationalizing it. In affective science, two primary models are used for identifying and contrasting emotional states: categorical and dimensional. The dimensional models represent emotions on a continuum, using axes like valence and arousal. Such models suggest an infinite number of possible emotional states and a high level of emotional granularity. However, this raises a question: how important is the precise location of an individual's emotional state for emotion monitoring systems? To answer this question, we used unsupervised and supervised machine learning techniques on survey data that examined the impact of five environmental variables—weather, time of the day, surroundings, traffic, and driving area—on drivers’ emotional state. Through K-means clustering, we identified four critical emotional clusters within the valence-arousal space. Subsequently, we used a decision tree algorithm to predict the emotional cluster of the driver based on the driving environments.  Our findings suggest that focusing on these broader emotional clusters, rather than exact arousal and valence levels, might lead to more effective designs of emotion monitoring systems and consequently intuitive and adaptive driver assistance technologies.",Transportation,232,762
Driving Emotions: Understanding Contextual Impacts through an Innovative Shiny App," Emotions are highly context-dependent. This is especially true in applications like driving where context is not just a backdrop, but a dynamic and integral part of the task. Capturing and documenting the influence of context on emotions is important for enabling researchers to validate findings, discern the impact of other factors on emotional responses, and understand how emotions influence behaviors. This paper presents an interactive web application designed to facilitate an in-depth exploration of the effect of driving context on drivers’ emotions. The app was developed using the R programming language and the Shiny package. It integrates empirical data from a survey study, where participants reported their emotional states in response to different images of driving contexts, generated using DALL-E. The application serves two key purposes: it allows for an interactive exploration of the impact of varying driving contexts on drivers' emotional states, and it offers a comprehensive visual database of driving contexts to enable researchers to visualize and replicate the scenarios for future studies. This application is a valuable resource for advancing research in driver emotion measurement and monitoring.",Cognitive Ergonomics,27,763
Optimizing Input Data Collection for Ranking and Selection," We consider a Bayesian ranking and selection problem under input uncertainty when all solutions share the common input models. We assume that there are multiple independent input data sources from which data can be collected at a cost to reduce input uncertainty. To optimize the data collection, we first show that the most probable best (MPB)—the solution with the largest posterior probability of being optimal (posterior preference)—is a strongly consistent estimator for the true optimum. We investigate the optimal asymptotic static sampling ratios from the input data sources that maximize the exponential convergence rate of the MPB’s posterior preference. A sequential sampling rule that balances the simulation and input data collection effort is created and demonstrated. The proposed algorithm stops with posterior confidence in the solution quality. We benchmark our algorithm against other state-of-the-art methods that optimizes simulation and data collection effort simultaneously and show that we indeed provide a faster empirical convergence in the probability of correct selection.",Production and Inventory Planning,182,764
A study to explore heart rate variability metrics for real-time assessment of cognitive workload in multitasking environment," The concept of mental workload, and its measurement, represents a crucial area of Human Factors research, particularly as task-imposed workload approaches one’s cognitive limits and increases risk of performance decrements. Traditional methods of assessing mental workload often involve subjective surveys such as NASA-TLX or Cooper-Harper scales. These methods are limited, requiring disruption of ongoing tasks to administer the surveys or retrospective assessments that are susceptible to forgetting key experiential aspects. Working around these limitations, researchers have explored psychophysiological measurement to infer workload dynamically. Psychophysiology, focusing on physiological responses to cognitive phenomena, provides near real-time insights into workload without disrupting ongoing tasks. Heart Rate Variability (HRV) is a prominent psychophysiological workload metric, involving analysis of the complex patterns of accelerating and decelerating heartbeats. Less-variant heartbeats (a more consistent cadence) suggest increased workload. This study explores prominent time-domain heart rate variability metrics, calculated over varied windows of time. Wider time windows are sensitive to longer-term sources of workload, such as the effects of tasks assigned to a particular operator role, while narrower windows capture event-based workload changes. In the current study, participants perform tasks in a multitasking environment designed in NASA’s Multi-Attribute Task Battery-II (MATB-II) environment, with low, medium, and high levels of imposed workload. Results will provide insight into the selection of particular HRV metrics for use in ongoing military domain research which is concerned with measuring both task-based and event-based workload dynamics. These findings will be insightful for the real-time measurement of experienced cognitive workload in human factors research.",Diverse Topics for HFE 3,54,765
Deep Learning-Based Anomaly Detection and Localization for Riser Inspection," In offshore oil and gas operations, the inspection and maintenance of risers play a critical role in ensuring asset integrity and safety. Traditional inspection strategies are often time-consuming and labor-intensive. In this paper, we present a method for riser inspection through Convolutional Neural Networks (CNNs) for anomaly detection and localization. The proposed method uses UAV drone’s captured images, providing a comprehensive and high-resolution dataset for training and evaluation. A dataset of riser inspection images is compiled for the CNN model training. The compiled dataset includes both normal and anomalous examples for the different riser components. We demonstrate the effectiveness of CNNs in automatically identifying and localizing anomalies within the components. The proposed method achieves remarkable sensitivity and specificity in distinguishing between normal and defective areas and among the different types of anomalies as well. The integration of localization capabilities provides insights into the specific regions affected, facilitating targeted maintenance efforts. By leveraging this technology, offshore operators significantly reduce inspection times and human effort while improving the overall safety and reliability of riser systems. We discuss the model architecture, training procedures, and showcase the results of our experiments, highlighting the potential for real-world applications in riser inspection.",Reliability II,188,766
A Robust Optimization Framework for Condition-Based Operations and Maintenance," We formulate a novel robust optimization model to manage operations, maintenance and degradation in multi-component systems. Our approach embeds degradation models within a robust optimization formulation to explicitly capture complex degradation uncertainties due to component-to-component interactions and operational loading. Comprehensive case studies demonstrate that the proposed approach offers significant improvements in reliability and cost.",Energy Systems Maintenance and Forecasting,65,767
Promoting Exploration for High-dimensional Batch Bayesian Optimization," Navigating high-dimensional spaces becomes challenging when optimizing expensive black-box functions due to the intricate nature of the exploration-exploitation tradeoff. Conventional Bayesian Optimization (BO) techniques often encounter difficulties in efficiently exploring the search space due to the curse of dimensionality. In these scenarios, sampling an optimal batch of points becomes more challenging, primarily because conventional BO approaches may favor exploitation, depending on the degree to which exploration or exploitation is emphasized within their algorithms. Moreover, most BO approaches tend to overlook inter-point relationships within the batch. In this paper, we propose an improved Upper Confidence Bound (UCB) acquisition function, by integrating a determinant-based criterion that considers the volume spanned by points within each batch, thus surpassing traditional surrogate uncertainty considerations. By incorporating this criterion into the acquisition function, our method demonstrates enhanced capabilities in high-dimensional spaces, effectively balancing exploration and exploitation. Through empirical evaluations and comparative analyses, we showcase the efficacy of our approach in promoting exploration while optimizing high-dimensional problems.",Integrating AI/ML in Simulation II,115,768
A Chance-Constrained Optimization Framework for Wind Farms to Manage Fleet-Level Availability in Condition Based Maintenance and Operations," Wind farm maintenance requires a proactive orchestration of O&M dependencies across turbines along with multiple sources of uncertainty associated with asset availability, operational and market conditions. This talk introduces a unified condition-based maintenance and operations scheduling approach for wind farms that models uncertainties related to turbine availability, wind power output and market price. The proposed formulation explicitly considers the turbine-to-turbine dependencies in operations and maintenance, such as opportunistic maintenance, to identify the O&M decisions that are optimal for multiple wind farms. The problem is formulated as a chance-constrained stochastic programming model to maximize operational revenue while ensuring high levels of turbine availability and generation. Our results on a comprehensive set of experiments demonstrate that the proposed approach provides significant improvements in asset availability, market revenue and maintenance costs in large scale wind farms.",Predictive analytics for Wind Power Generation,171,769
Improving forestry transportation: addressing challenges through optimized truck platooning transportation," This study explores truck platooning transportation planning models and methodologies based on Operations Research in the literature. It also outlines the benefits and challenges associated with truck platooning transportation. Moreover, this research investigates the transformative integration of truck platooning technology in forest transportation, presenting an approach to address major challenges in the industry. In the face of high transportation costs, our research explores how truck platooning and optimal transportation planning can improve transportation efficiency, minimizing overall transportation costs in forestry transportation through the gradual integration of platoon trucks into the transportation network. Furthermore, the study analyzes the potential for truck platooning to reduce fuel consumption, contributing to lower GHG emissions in forestry transportation. Due to industry-wide truck driver shortages, we explore how truck platooning technology can address this issue. By enhancing truck operations efficiency and reducing the need for an individual driver per truck, truck platooning presents a promising solution to address workforce shortages in the forestry transportation sector. We also study how the collaborative use of platoon trucks results in cost reductions depending on the level of collaboration and network coverage among participating companies. This study provides insight into how truck platooning can enhance forestry transportation.",Supply Chain Management and Transportation in Forestry,216,770
Disrupting Labor Exploitation," In work settings dominated by short-term contracts and high worker turnover, there is a heightened risk of wage exploitation. In this paper, we introduce a game-theoretical model to study wage theft in such settings. We use the principal-agent framework, categorizing the employer as the principal and the worker as the agent. We analyze the problem when the worker has no awareness of wage theft, and the only deterrence for exploitation is through external inspection and penalties. We show that the problem can be reduced to a single-decision variable and partially characterize the optimal solution to the principal-agent problem to understand the structure of verbal contracts and the resulting wage theft as a function of system parameters. Our analysis extends to different system factors, such as worker skill level, reservation utility, the frequency of inspections, and penalties. This analysis highlights the factors that amplify worker vulnerability, offering strategic insights to mitigate wage theft.",Human trafficking and other humanitarian crises,93,771
Enhancing In-Situ Monitoring in Additive Manufacturing with LSTM Autoencoder: A Deep Learning Approach to Analyze Backscattered Electron 1D Signals," This paper presents a novel application of Long Short-Term Memory (LSTM) autoencoders for in-situ monitoring in Additive Manufacturing (AM), focusing on analyzing 1D backscattered electron signals. Our aim is to enhance quality control and process reliability in AM, crucial for industrial use. We introduce a deep learning framework using LSTM autoencoders to interpret complex backscattered electron signal data, enabling real-time anomaly detection and accurate prediction of material properties during the AM process. The development of LSTM-based autoencoder models is central to our study. These models effectively capture temporal dependencies and patterns in 1D electron signals, identifying subtle yet significant variations indicative of defects or material changes. This surpasses the capabilities of traditional monitoring methods. We provide a comprehensive analysis of model's application across various AM scenarios, emphasizing its adaptability, computational efficiency, and real-time processing. Our experimental results demonstrate significant improvements in defect detection accuracy and a deeper understanding of the layer-wise manufacturing process. This paper's contribution is the innovative use of LSTM autoencoders for advanced monitoring in AM, marking a major advancement in intelligent manufacturing systems. Our research not only signifies a breakthrough in AI application in manufacturing but also establishes a new benchmark for integrating deep learning in real-time monitoring and quality assurance in AM. The methodologies and insights offered have substantial implications for both academic research and industrial application, propelling AI-driven manufacturing technology forward.",Sensing and Control in Additive Manufacturing Processes-II,203,772
Resilient Healthcare 5.0: Advancing Human-Centric and Sustainable Practices in Smart Healthcare Systems," Industry 5.0 represents a synergistic blend of advanced technologies and organizational principles, focusing on sustainability, resilience, and human-centred applications in production systems. This evolution is marked by the increasing implementation of cutting-edge technologies such as Big Data, Artificial Intelligence (AI), Virtual Reality/Augmented Reality (VR/AR), Internet of Things (IoT), and Cloud Computing. Therefore, healthcare solutions have seen major development leaps in smart healthcare implementations. As an integral component of Industry 5.0, Healthcare 5.0 seamlessly integrates emerging technologies such as AI, Internet of Medical Things (IoMT), 5G, and nanotechnology. This integration aims to revolutionize patient care and smart healthcare systems by focusing on wellbeing, personalized healthcare, wellness monitoring, and sustainability. Despite its potential, Healthcare 5.0 faces unique challenges. These include ensuring data security and privacy issues on sensitive healthcare information, addressing the lack of technological infrastructure required for integrating smart healthcare systems, bridging skill gaps on AI solutions, addressing funding issues on small and medium-sized enterprises, and establishing appropriate policy and regulatory frameworks at professional and organizational levels. In the era of smart healthcare technologies, achieving a long and healthy life has become a focal point of society. To address the needs of society, it is crucial to understand the underlying issues and shortcomings of current smart technologies. In this paper, therefore, we discuss Healthcare 5.0 and its emerging technologies on smart healthcare systems, the challenges they face, and future directions for sustainable and human-centric implementations.",Health Systems for Human Factors and Ergonomics 1,79,773
Validating a digital twin simulator with multi-epoch multi-dimensional data," Digital twins involve a stochastic simulation model running alongside a real-world system. To ensure accuracy, a fundamental task is to validate the simulation model. This work tackles the challenge of validating digital twins with the goal of matching the distribution of the system-observed and simulated key performance indicators (KPIs) at multiple epochs. Such KPIs evolve throughout time and are often multi-dimensional, whereas most simulation validation tests can handle only one-dimensional simulation outputs. We propose a hypothesis testing framework that accommodates high-dimensional KPIs by measuring how different the system KPI’s distribution is from that of the simulated by applying the Tukey depth. We propose an experiment design to estimate the test statistic and derive the required number of simulation sample size as a function of the number of epochs to make the test valid. We also demonstrate our methodology using several numerical examples.",Algorithmic Approaches,15,774
Practical Advantages of Matching Moments for Parameter Estimation," The most commonly used distribution parameter estimation method today is the maximum likelihood estimator (MLE), but it has its pitfalls in complexity and poor direct interpretation. MLE is computationally complex and works best when the distribution type is easily estimated. We explore using the method of moment (MoM) estimation as a practical tool with a straightforward interpretation for parameter estimation. This enables exploitation of the generalized Erlang distribution to construct Markovian models for system designs quickly, study the statistical quality of the parameter estimation, and evaluate the practical differences between MLE and MoM. We demonstrate a practical method to model non-exponential processes utilizing the generalized Erlang distribution and study the associated errors.",Machine Learning I,125,775
Harnessing Rocket Technology for Strategic Humanitarian Logistics: A Simulation Perspective," This paper presents a comprehensive study integrating logistics research with aerospace and mechanical engineering to revolutionize cargo transport through rocket power. The US Air Force, in conjunction with the US Space Force, is developing programs (Rocket Cargo Vanguard) that will leverage commercial rocket capabilities (e.g., SpaceX) to transport up to 100 tons of humanitarian aid worldwide. This research designs a logistics framework that addresses each aspect of the cargo transport process, comprising four models. The first model addresses the challenges of regional logistics in Florida, USA, and employs an Agent-Based Model with GIS mapping to understand the complexities of transportation and distribution better and follow the current protocols. Next, a model focusing on requisition and warehousing employs a discrete event simulation (DES) framework, integrating automation and robotics for warehousing operations and maintaining cargo integrity and timeliness, which are critical for the logistics framework. A manifest list of humanitarian supplies is identified for the third model, and the objective is to efficiently pack supplies into a rocket pod while adhering to safety regulations. Considerations include cargo pod design and centroid of gravity, ensuring maximum space utilization and compliance with safety procedures. The fourth model simulates ground processes, including cargo pod loading and assembly into rockets, and DES is employed to enhance operational efficiency and optimization of processing times. These models form a comprehensive logistics framework with more models (e.g., twelve of them) tied in a multiple-resolution modeling hierarchy to an optimization engine.",Humanatarian logistics 2,95,776
Sustainable energy optimization in mobile edge computing network with multi-agent actor critic algorithm," Recognizing the paramount importance of sustainability in contemporary technological landscapes, the research addresses the challenges posed by Mobile edge computing (MEC) applications. The study delves into enhancing the efficiency of energy utilization in densely deployed MEC hosts across wireless networks. To mitigate the energy consumption associated with high-capacity MEC hosts, the strategy involves the integration of self-powered bas station (BS) units. The present study introduces a sophisticated approach through a decentralized energy management system which formulates a dynamic optimization problem aimed at minimizing the overall energy consumption while meeting the systems energy demand. To tackle this, we introduce a novel approach utilizing a multi-agent actor critic algorithm. In this approach, each BS acts as an independent agent making decisions based on its local observations. The collaborative interaction among these agents, facilitated by the multi-agent actor critic framework, results in optimized energy dispatch strategy. This strategy is then assessed on various metrics, including energy consumption, energy costs and the overall system performance.","Advancing Climate Action in Business, Technology and Transportation (SDG 13)",13,777
Reinforcement Learning based End Point Control for Polishing Operations," Manufactured components oftentimes necessitate post-processing operations such as polishing to improve surface quality. Conventionally, this iterative multi-stage process relies heavily on the practitioner’s experience and visual inspection for decisions on pad changes and fine-tuning of control parameters.Polishing processes exhibit notable energy inefficiency stemming from substantial heat dissipation (>50%) due to friction.Moreover, a pronounced tendency for overpolishing heightens the risk of scratches/defects.The stochastic nature of asperity-abrasive interaction poses a significant challenge to simulating polishing processes.This study introduces a continuous state Markov Decision Process (MDP) for surface polishing, allowing for sequential decision-making contingent upon the current state of surface and offers comprehensive recommendations on the choice of pad, downforce, rotational speed, and polish time. We employ an actor critic based reinforcement learning framework utilizing proximal policy optimization to determine the optimal number of polishing steps and corresponding actions for various surface roughness endpoints. The proposed reward structure encompasses both dense and sparse components aiming to achieve the desired surface finish with minimum energy consumption, while simultaneously accounting for cost implications of individual polishing steps and mitigating risk of scratches/defects. The performance of the approach was assessed for a nonlinear differential equation model that accounts for both material removal and redistribution and serves as a digital twin to capture the surface morphology evolution during polishing of 3D printed materials. Results suggest that higher down force and lower rotational speed minimize energy consumption, in addition to emphasizing the critical role of number of polishing steps and pad choice in achieving precise end point criteria.",M&D Best Student Paper Competition,124,778
"Beyond Limits: Unleashing Industrial and Systems Engineering and AI for Swift, Inclusive Solutions to Global Sustainability Challenges"," This research revisits the seminal 1972 work The Limits to Growth, wherein systems engineers played a pivotal role in establishing the foundations of the sustainability movement, emphasizing the urgent need for immediate action to prevent enduring environmental repercussions. Despite a widespread acknowledgment of human-induced climate change, recent reports indicate insufficient progress in mitigating greenhouse gas (GHG) emissions to avert the worst impacts of global warming. The paper delves into the potential of Industrial and Systems Engineers (ISEs) re-entering this arena, leveraging their expertise in tandem with Artificial Intelligence (AI). This collaboration aims to transform processes necessary to realize the vision articulated by our predecessors half a century ago: achieving “ecological and economic stability that is sustainable far into the future.” The problem statement addresses the complexities of current sustainability frameworks, diverse stakeholders, and resource-intensive practices that are primarily accessible to large entities. The research questions whether the integration of systems thinking, ISE skills, and AI can revolutionize development, implementation, and monitoring of sustainability plans-- making them accessible to smaller organizations, accelerating efforts to combat climate change. The methodology involves a comprehensive literature review, a survey of Chief Sustainability Officers (CSOs), and interviews. The research outlines current sustainability practices, identifies existing consulting services, highlights the role of ISEs in supporting CSOs, and explores how AI can enhance ISE capabilities. The study presents initial conclusions on the potential of ISEs utilizing AI to make services more cost-effective, efficient, and holistic, thereby expediting the achievement of GHG reduction and other sustainability goals.",Industrial Engineering Solutions for Sustainability Planning and Reporting,101,779
Tree-Based Recursive Modeling for Optimizing Baseball Lineups and Expected Runs Prediction," This research proposes an in-depth analysis of a deterministic, recursive model designed to simulate baseball game dynamics and optimize batting lineups. The recursive model utilized a tree based-approach, exhaustively exploring player outcomes to computer expected runs for various lineup configurations of nine different players. The depth-first tree expansion multiplies the probabilities of concurring nodes until reaching a leaf node, then backtracks and continues the search. This tree-expansion approach to simulation enables utilization of player outcome probabilities to determine the probability of certain branches of outcomes occurring. Lineups are generated recursively as well, exploring all possible combinations of the nine players studied. The study compares the model’s tree expansion method to a random sampling technique, highlighting accuracy and computational efficiency differences. The tree-expansion method outpaces simulating 107 game samples using the random number generating method by a factor of 12, while maintaining a 0% error rate in calculating expected runs. The simulation results demonstrate the model’s precision in predicting expected runs, emphasizing its potential impact on strategic decision-making in baseball. Potential enhancements to this model may include adapting to player rotations, addressing dynamic base running scenarios, and implementing a tree-expansion search past a maximum depth of 9 levels to better replicate a true baseball game.",Advanced Simulation Models,3,780
Beyond Numbers: Leveraging Qualitative Insights to Enhance Human-Centered AI Recommendation Systems," On a stage where quantitative data so frequently bears the spotlight, qualitative data is often overlooked. This paper navigates the intrinsic value of qualitative insights, analyzing their capacity to catalyze nuanced perspectives that can elevate our understanding of human decision-making in complex, sequential processes. Specifically applied to long-distance travel user study framework involving battery-electric vehicles (BEVs), our research explores the interplay between individuals and AI-generated recommendations for charging stops in the presence of uncertain traffic conditions. In our framework, participants are asked to make sequential decisions on whether to exit to charge their vehicle or continue driving the next segment facing uncertain traffic. Consequently, human drivers may prefer to follow their own strategy or intuition rather than adopt the recommendation suggested by AI, and consequently provide information on the motivations behind their strategic inclinations. Drawing from extensive qualitative data derived from participant responses, we illuminate the intricacies of human decision-making and guide the refinement of the game’s recommendation system. By examining perspectives and rationales on AI-generated advice and eliciting high-level tips for gameplay, our analysis uncovers diverse behaviors, ranging from forward-looking actions to preferences for the level of detail of provided advice. We then utilize these insights to redesign our recommendation system to enhance user acceptance and trust in AI-driven decision support. Ultimately, this research contributes to the evolving landscape of AI system design principles, facilitating the seamless integration of qualitative data-driven insights into the fabric of human decision-making processes.",Modeling & Simulation for Human Factors and Ergonomics,146,781
Investigation of Arc jump phenomenon in Wire Arc Additive Manufacturing process," This research paper presents an investigation of arc jump/arc swing phenomenon in Wire Arc Additive Manufacturing (WAAM), an a significant process issue in WAAM process. WAAM is one of the advanced manufacturing techniques that can produce large components with a high deposition rate and short production time. This technology relies heavily on the precise control of the electric arc that is used to melt the metal wire in layer-by-layer fabrication. Arc jumps can disrupt the welding process and result in incomplete fusion, porosity, and surface defects due to surface irregularity, and improper welding parameters. This issue received limited attention in existing literature. This paper will examine the impact of arc jump on layer uniformity and overall stability of the manufacturing process and will investigate through arc jump phenomena with a methodology that includes a combination of modeling, simulation, and experimental validation. The findings of this study will contribute significantly by providing guidelines for improved WAAM processes and opening avenues for future research in this domain.",Sensing and Control in Additive Manufacturing Processes I,202,782
"Exploring the Network Characteristics pertinent to supply chain resilience from a Hunger Relief Perspective: Connecting Equity, efficiency, and effectiveness."," Supply chain resilience has gained traction in recent years as the supply chain has become more complex and impacted by various external factors. Supply chain resilience holds a crucial role in the context of hunger relief operations as a more resilient network can lead to better performance in the events of disruption, and also during regular operations. In this study, we aim to explore the various network characteristics related to supply chain resilience and connect with equity, efficiency, and effectiveness. Using these relationships, we would also explore the impact of information sharing among the agencies on supply chain resilience. Lastly, we implement these in the greater Raleigh area foodbank network data.",Humanatarian logistics 2,95,783
Ant Colony Optimization for Solving Capacitated Vehicle Routing Problem in a Carton Manufacturing Company," In this study, we aim to optimize the distribution planning for a carton manufacturing company by applying the Capacitated Vehicle Routing Problem (CVRP) framework. Focusing on designing efficient delivery routes from a central depot to various customer locations, the research employs the Ant Colony Algorithm inspired by the path-finding strategies of ant colonies. This approach is chosen because it effectively balances the trade-offs between minimizing travel distances and optimizing the number of vehicles, thereby reducing overall transportation costs. We also detail the current inefficiencies in the company's region-based distribution system and demonstrate how the Ant Colony Algorithm can offer a more optimized routing solution. The comparative analysis underscores the advantages and limitations of the Ant Colony Optimization technique in addressing CVRP, highlighting its potential for broader logistical applications.",Routing 2,198,784
Assembly Line Balancing Considering Stochastic Task Durations and Production Defects," In real-world manufacturing scenarios, the traditional deterministic approach to assembly line balancing often falls short. This is primarily due to the unpredictable nature of task times, which deviates from the assumptions of the Simple Assembly Line Balancing (SALB) problem. Additionally, the manufacturing process frequently grapples with defects, which remain a prevalent issue despite concerted efforts to minimize them. This results in the ineffectiveness of traditional deterministic assembly lines, often leading to significant failures. To address these challenges, this research proposes a framework that moves away from the standard reliance on fixed processing times and instead recommends an 'adjusted processing time'. This time adjustment accounts for both the variability in task durations and the incidence of defects, offering a more realistic and effective approach to assembly line management. This framework has been rigorously tested across various established problems, proving its efficacy. Its main strengths lie in its simplicity, from understanding to development and implementation, positioning it as a practical solution for modern manufacturing challenges.",Facilities Design & Planning III,73,785
Human factors considerations for ergonomic assessment in distribution centers for case studies.," The manual handling of loads is an activity that will continue to be very important in many sectors of the economy. In Colombia, by 2022, the economic sectors with the largest number of workers will be real estate, commerce, manufacturing, public administration and defence, and transport, storage and communications, the latter with a figure of 1,053,660 affiliates in October 2022 and occupying the sixth place in work accidents and the tenth in work-related illnesses, the same place it occupied in 2021. A literature search was developed, a search phrase was proposed, which was filtered by year, looking only at what had happened in the last ten years, that is, from 2010 onwards, which resulted in 517 articles. This was followed by a search by title, which yielded 114 articles. Finally, a filter by abstract was applied, which reduced the search to 80 articles for further reading. According to this review of articles related to the assessment for the improvement of working conditions in distribution centres, taking into account ergonomic aspects or human factors, it has been established that the main task, regardless of the type of technological advance that the distribution centre has, is the picking activity, and this has a great impact since it has factors that allow the development of musculoskeletal disorders. There are mechanical aids in distribution centre operations, such as forklifts or stackers, pulleys and cranes, manual stackers and exoskeletons. And also assistive devices like barcoding and RFID, voice headsets, and virtual and augmented reality support.","Systems Engineering, Logistics and Supply Chains for Human Factors and Ergonomics",228,786
"WISE Initiative: Empowering Women in Industrial and Systems Engineering – Impacts, Strategies, and Future Plans"," The Women in Industrial and Systems Engineering (WISE) initiative originated as an informal social affinity group within the Grado Department of Industrial and Systems Engineering (ISE) at Virginia Tech (VT) in 2016. WISE then evolved into an official student group in 2021. Operating under the broader umbrella of the ISE department at VT, which encompasses specialties such as human factors, ergonomics, operations research, management systems, and manufacturing systems, WISE fills a unique role by fostering connections between these specialties given that many have their own sequestered student groups/conferences. Our belief is that a mixed grad/undergraduate student group for female-identified students that bridges specialties of ISE not only ensures the development of well-rounded engineers but also enhances mentorship and empowerment for women in ISE. Our mission is to cultivate a supportive environment that empowers WISE members through a variety of activities, both formal and informal. These include formal networking events, workshops, site visits, as well as informal gatherings like cookie decorating and dinners. Currently boasting over 60 active members, WISE organizes at least four events per year. As part of our strategic vision, we are actively working on establishing a WISE alumni network. This work explores the realized impacts of WISE as reported by our members, our implementation strategies, and our future plans, with the goal of inspiring the expansion of WISE initiatives across institutions by providing an outline / example implementation from which to grow.",Inclusive Excellence in ISE Education,100,787
Randomized Rounding for the Preventive Healthcare Facility Location Planning Problem," Krohn, Muller and Haase [OR Spectrum (2021) 43, 59-87] introduced a constrained p-hub approach to increase the expected participation in a preventive healthcare program; e.g., breast cancer screening. Unlike patients who need urgent care, customers who use preventive healthcare decide whether to go to a specific facility or participate in a program. Considering clients' utility functions, the preventive healthcare facility location planning problem (PHCFLPP) selects p facilities to establish with their specific modes which are determined by the waiting time for an appointment and the quality of care. We develop a randomized rounding approach to the problem and optimally solve their instances with up to 400 demand nodes and 15 candidate locations within a few seconds, which Krohn~et al. had solved for an hour. Then our randomized rounding procedure solves the real-world problem of 9,679 demand nodes and 56 candidate locations in the Greater Sydney area.",Healthcare Optimization,87,788
Cognitive Classification using MRI and Blood Biomarkers," Elderly individuals often encounter cognitive decline as a natural aspect of the aging process. However, there are some individuals who maintain (i.e., Cognitive-Maintainers) or improve cognitive performance as they age (i.e., Positive-Agers). Distinguishing between Positive-Agers and Cognitive-Decliners is the first step toward understanding the factors that protect against or prevent cognitive decline and contribute to successful aging. This research study involved 1,665 participants aged 65 and above from the UK Biobank. We grouped the participants into Positive-Agers and Cognitive-Decliners based on four cognitive function tests: Reaction Time (RT), Fluid Intelligence (FI), Prospective Memory (PM), and Pairs Matching Memory (PMM). To classify Participants into one of these groups, we incorporated 942 features comprising of demographic information, blood biomarkers, and multiple MRI sources, including Resting-State Functional Magnetic Resonance Imaging (rsfMRI), Diffusion Magnetic Resonance Imaging (dMRI), and Structural Magnetic Resonance Imaging (sMRI). This study introduces the optimal subset of features that are helpful in accurately identifying cognitive groups.",Recent Advances in Health Systems II,185,789
Improvement of Takt Time for Mining Truck Wheels," Process takt time plays a colossal role in shaping up the efficiency of production. While improving the efficiency of manufacturing a product, process takt time is, therefore, taken into account. The process takt time for mining truck wheels, which is a recurring product of a number of manufacturers, can vary by each cycle or batch. Simulation modeling and analysis is employed by this study for identification of the process takt time for mining truck wheels. Areas where changes within the manufacturing process of mining truck wheels can be made to reduce the process takt time are also determined. This study develops a model of the operations area to perform a simulation analysis, so that the product goes through the stations, and the time for completion at each station is found. Throughout the simulation, a reduction in the process takt time is aimed, whether that is moving around areas or implementing different processes. The rework time for mining truck wheels that do not pass testing is taken into account as well. In order to resolve the issue of long process takt times, some recommendations are outlined, which are based on computational experiments. Such recommendations comprise performing more audits/inspections to identify breakdowns and defective parts earlier, upholding cleanliness on the shop floor, along with hiring more personnel.",Contemporary Work Environments,32,790
Impact of a Revise and Resubmit Project Structure in an Undergraduate Deterministic Operations Research Course," This presentation will examine a semester-long project in a linear programming course that uses a revise and resubmit structure. Students work in groups of 3 or 4, and groups are formed using a combination of student partner selection and instructor assignment of final groups. Students identify their own project topic and generate the problem statement and math model over the course of the semester. In each submission, students revise their previous work based on feedback from their peers and the instructor, and add a new component. Both the math model and the written report are revised each time. Peer evaluations between groups occur three times, and students complete self and group evaluations within their groups at the project midpoint and end.  Changes in student performance on project submissions within a semester as well on the project final grade across semesters are quantified. Comparisons within students groups and across semesters are conducted with paired and unpaired t-tests. Regression is used to determine which assignment design components have a significant impact on student project grades.",Operations Research and Modeling in Education,153,791
Industry Superstars: Unmasking Key Features that Drive Firm-Level Performance in Chinese Markets using Ensemble Learning with Genetic Algorithm," This study presents a comprehensive analysis of firm-level performance within five distinct industries, utilizing data from the Chinese Industrial Enterprises Database covering the years 2002-2007. Our objective is to unravel the dynamics that govern market share in a given industry, with a focus on identifying key features that makes a firm a “Superstar” in that industry. We designed an ensemble machine learning algorithm, with Random Forest, XGBoost, Adaboost, and Lasso as the base learners coupled with a Genetic Algorithm (GA) for the optimal aggregation. We evaluated the sequential interplay of features influencing market share, allowing us to capture the temporal and causal relationships within these industries, highlighting the heterogeneity and industry-specific factors that shape market leadership. Our findings reveal that ""Last year's market share"" consistently emerges as a significant predictor across all industries, underscoring the impact of historical performance on future market trajectory. However, the importance of other factors such as ""net total fixed assets"" and ""main business revenue"" varies significantly across industries. This study not only contributes to the academic understanding of market dynamics but also offers practical insights for policymakers and business strategists, emphasizing the need for industry-specific approaches in decision-making.",Business Analytics,23,792
The importance of explainable AI in medical decision-making: Insights from predicting bone marrow transplant survival," Bone marrow transplant (BMT) is a common treatment choice for leukemia, lymphoma, and other blood and immune disorders, but success rates are low. We develop machine learning methods to better predict BMT outcomes for individual patient-donor pairs, using single-center data to best capture patient demographics and hidden but important factors. Our framework stratifies patients into risk-based Kaplan-Meier survival curves, providing more individualized treatment decisions compared to the broad population-based curves used in clinical practice, which may not be relevant to specific patients or transplant centers. We then use explainable AI methods to discover new and impactful correlations between variables and outcomes that can be communicated to clinicians, specifically finding and verifying that CD34+ dose should be tailored by patient age for acute leukemia patients.",AI in Health Systems,1,793
Savings in fuel consumption with the application of regenerative braking in a hybrid electric log truck.," Electrification in log-hauling attracts social concern in forest transportation. However, most studies on parallel hybrid electric vehicles (HEV) focused on heavy buses or light-duty vehicles. There are no such studies done in forestry. Of particular concern is the use of regenerative braking, which is usually based on a horizontal road mechanics model that ignores the effects of frictional and aerodynamic losses. Thus, this paper investigates the fuel consumption savings when using a HEV log trailer and analyses its impact on the forest value chain. A longitudinal vehicle dynamics model is used to predict fuel savings when using an electric powertrain. A regression analysis was employed to quantify the coefficient effects of several factors. The results show that descending from high to low elevations, the recovered brake energy can increase the state of charge by 30% and is directly proportional to the regenerative braking force. For the studied drive cycle, hybrid powertrains can help save up to 13% of fuel consumption. Using an electric motor, the truck consumed up to 63 liters/100km with regenerative braking compared to a diesel truck with 72 Litres/100km. Our next step is to use new data to model truck operations in rural areas and evaluate how our analysis can advance the transition to fleet electrification in forest transportation.",Supply Chain Management and Transportation in Forestry,216,794
Integrating Ergonomics into Academic Classroom Design for Effective Learning," Classroom environments, encompassing factors like space optimization, lighting, furniture design, and layout, are pivotal in fostering an effective teaching and learning atmosphere. Academic institutions are in increasingly need of classroom environments that not only promote effective learning but also integrate and prioritize ergonomic considerations to improve the well-being of students and educators. In this study, we focus on optimization of classroom designs through creation of ergonomic learning environments that support both the physical comfort and educational needs of students and faculty. In our study, we conduct an extensive analysis of existing classroom setups and perform ergonomic assessments as well as integrate feedback from academic stakeholders. Through simulations and design models, we then explore the impact of various layout scenarios and factors, such as lighting, acoustics, and furniture design, on learning effectiveness and ergonomic suitability. Our study offers valuable insights and practical solutions for the development of ergonomically optimized learning environments.",Applications of Work Systems,17,795
"Enhancing Military Combat Effectiveness through the Fusion of Machine Learning, Virtual and Constructive Simulation, and Agent-Based Modeling: A Focus on Operator Performance and Weaponry Dynamics"," We introduce an approach that synergizes Artificial Intelligence (AI) and Virtual Constructive (VC) simulation to improve training and mission design. The first phase of the methodology is centered on the simulation of a jet fighter pilot’s performance, emphasizing scenario variability and sensitivity analysis, identifying critical success factors, and reducing bias, demonstrating the value of VC simulation, and its ability to generate data. Simulations consisted of one to three jet fighters (always there is one jet fighter with a human pilot and the other are AI-based – the constructive side is based on AI and the Virtual side is by a human being), engaged in attempting to destroy control towers that are defended by a radar-guided missile defense system that can launch counterstrikes. Comprehensive data encompassing agent attributes and aerial reconnaissance imagery of the radar-guided defense system and landscape are collected, which are instrumental in training a Convolutional Neural Network (CNN). The second phase uses the developed CNN to augment the decision-making process. A second agent-based modeling environment is introduced for evaluation purposes and includes various agents (AI-driven fighter pilots, radars, defense systems, and missiles). The developed environment that has a degree of similarity with the original one facilitates comprehensive testing across a variety of scenarios and making decisions. The integration of VC simulations and machine learning captures an operator’s capabilities and facilitates the transfer of these capabilities into other environments, allowing for the development of a more complex environment aimed at evaluating new training and resource allocation.",Integrating AI/ML in Simulation I,114,796
Optimal regulation and enforcement against diversion in controlled drug networks," Prevalence of prescription drug use and abuse, such as with opioids, is a current widespread problem in the United States. Diversion is any act of illegal distribution or abuse of prescription drugs or their use for purposes not intended by the prescriber. In this research, we look at three characteristics that set the act of diversion apart from other illicit activities. First, Diversion practices have significant association to the neighborhood characteristics as established in the literature. Second, the “dual nature” of prescription drugs, where there are benefits and risks involved with distribution and consumption of these drugs, makes it difficult to identify and control for diversion. Third, the inherent interplay between regulation (for e.g. threshold decisions) and enforcement (for e.g. monitoring and shutdowns) affects the diversion behavior statistics of the actors involved, further adding complexity and tradeoffs in the decision making. We develop a network based optimization framework which informs regulatory and monitoring practices around diversion prevalent in controlled prescription drugs supply chain, incorporating the above three facets : Dual-Nature, Regulation-Enforcement-Interplay and Neighborhood Effect. The supply chain is modeled as a directed network with nodes representing prescribers, pharmacies and patients; and edges representing flows of the controlled drug. We solve this as a three stage problem: (i) setting up thresholds above which the behavior can be classified as diversion, (ii) selection of points to be flagged for monitoring given the thresholds, and (iii) decision of shutdowns of diversion points given flagging status using a mixed integer optimization program.","Privacy, security, and resilience",174,797
Process Management and Improvement of a Mobile Integrated Healthcare Program," Mobile Integrated Healthcare (MIH) programs are health care delivery models that use specially-trained community paramedics to provide services in a patient’s home or other out-of-hospital settings. In coordination with healthcare facilities, MIH visits may prevent the need for transportation to and use of an emergency department. Such programs are being launched by many health care systems in the United States (U.S.) in response to increased emergency department utilization. Studies, based on programs in the U.S. and other countries, have shown MIH programs can improve patient outcomes and reduce healthcare costs. Because most MIH programs are recent innovations, identifying appropriate patient populations, improving delivery processes to support effective care coordination, and scaling operations to create sustainable programs remain important challenges. In this study, industrial engineering tools were applied to examine and improve an MIH program affiliated with a large health system. The program was launched in 2021, and currently provides services for acute needs as well as to support frail elders with transitions from hospital to home. The project began by analyzing operational data and interviews with MIH stakeholders to identify and prioritize opportunities for improvement. We describe results focused on improving communication between community paramedics and patients’ primary care physicians by standardizing notes. In addition, we present a capacity planning model that was developed to support decision-making around staffing as new patient populations and services were added (for example, by expanding the geographic reach of the program).",Home and Mobile Health Systems,92,798
Using participatory agent-based modeling to teach systems thinking for inventory control," While systems thinking is critical to making good decisions in complex situations that frequently arise in supply chains, it is neither intuitive nor innate and must be trained explicitly. However, systems thinking and complexity are not formally taught in classrooms, and there is limited research on how to apply and assess approaches to teaching systems thinking in higher education. To address this gap, this research uses participatory agent-based modeling to improve learners’ systems thinking skills and their ability to understand the consequences of complexity in supply networks when analyzing inventory control strategies. An agent-based model of a supply chain, in which agents represent suppliers and retail shops, was created using NetLogo. Students in an undergraduate course on production and inventory control were given a description of the supply chain and were asked to devise a suitable procurement and inventory control strategy for maximizing a retail shop’s profit. The students then engaged with the model via HubNet, which allowed them to jointly participate in the simulation in the role of retail shops, making strategic, tactical, and operational inventory control decisions over the course of one simulated month. Student learning was assessed via sentiment analysis on reflection papers, with results indicating that engagement with the model helped students to better understand the role of production systems withing a larger supply network, as well as increasing their understanding of the challenges associated with making good decisions in a complex and dynamic environment.",Innovations in Teaching and Learning Technologies,109,799
Title: Emotion Monitoring in Video Gaming: Utilizing Facial Action Units and Emotional Analysis for Enhancement of Player Experience.," The gaming industry offers immersive experiences that captivate players through differing storylines, challenging games, and interactive environments. The elements in a video game often cause players engaged to undergo varying emotions ranging from happiness to anger, frustration to excitement and more. Understanding these emotional fluctuations is a vital aspect of creating video games that resonate with players and provide an enjoyable experience. This research investigates the correlation between facial action units (AU’s) and different emotional responses using the Facial Action Coding System. The study examines the combination of different AU’s and what emotional responses are induced during gameplay.The association between different action units and emotions assists game developers with insights on what emotions are induced in different parts of the game. This allows them to tailor gaming experiences to enhance player engagement and satisfaction. This research also benefits players directly by enabling individuals to understand the emotional impact of games on themselves. This study proposes an intervention method to manage excessive negative emotions such as anger, frustration, and stress in players by defining a threshold level for each negative emotion tested. Facial action units are analyzed in combinations to determine what emotion is being expressed and if there are prolonged negative emotions then the proposed intervention methods will help both the developer and players in optimizing video game experiences. This creates a more sustainable gaming environment and contributes to gaming strategies to help players understand and manage their emotional responses during gameplay.",Diverse Topics for Human Factors and Ergonomics 2,56,800
3D Modeling and Standardization to Improve Engineering Design Process, USSI is a 40 year old engineering consulting company specializing in warehouse design. Despite the breadth of experience there are opportunities for modern Computer Aided Design and Process standardization to improve critical business functions. This presentation will focus on the methods used to reduce the parts list generation process from 8 hours to 59 minutes.,Construction Performance,30,801
Generative Artificial Intelligence (GENAI) & Operational Excellence," In Nov 2022, OpenAI released ChatGPT, which revolutionized the art of operational excellence. Artificial Intelligence (AI), has been researched for the past few decades. Generative artificial intelligence, or GENAI, enables the generation of new content for words, images, numbers, audio, and video (WINAV) through Large Language Learning Models (LLMS). GENAI instantly impacts many areas of WINAV-based jobs and projects by boosting productivity. In this presentation, you will learn about a.) The state of GENAI, b.) How Operational excellence leaders and practitioners can embrace GENAI to turbocharge their initiatives. (c) How leading companies adapt and adopt elements of GENAI in sales, marketing, customer service, research, technology operations, and product development. (d) What are the ethical and risk considerations for experimenting with GENAI projects?",Healthcare,81,802
Measuring the Effects of Lean and Green Manufacturing Practices on the Triple Bottom Line," Concerns for both the environment and the economy push companies to adopt more sustainable operations. The demand for management models, such as Lean and Green Tools, that improve sustainable performance has never been higher. The literature reveals that many Key Performance Indicators (KPI) give insights about corresponding dimensions of sustainability, and that lean and green tools can impact the Triple Bottom Line with varying success. The main shortcomings are that some metrics require a deep knowledge of material compositions, are not widely applicable, or measure effects over a very long period. In addition, the many possible metrics and absence of standards makes it difficult for organizations to reasonably select KPIs. This paper selected suitable KPIs in each respective sustainability dimension for measuring the effects of implementing lean and green manufacturing principles. In this work, a case study is described where a production system was changed considering Lean and Green practices. The results revealed that the KPI Throughput is a valid method for the economic pillar, which matches traditional analysis methods. Also, the social KPIs of occupational safety, ergonomics, and workers satisfaction measured the effects of implementing Lean and Green practices in the social dimension. On the other hand, the environmental KPI amount of rejected parts showed limitations in a real-world setting because measured changes could not clearly be associated with the changes in the observed production system. Companies must continuously improve their Triple Bottom Line and use appropriate KPIs for tracking progress.",Aligning Profit and Planet and Addressing Water Challenges (SDG 6/SDG 12),16,803
"Predicting lifetime in lithium-sulfur batteries, a reliability fuzzy logic approach"," The nonlinear nature of the remaining useful life (RUL) phenomenon in lithium-sulfur batteries makes it challenging to measure; performance tests to assess and forecast the RUL require lengthy durations and large sample sizes, which are occasionally insufficient to allow for an adequate characterization. The current study uses fuzzy number theory to handle the issue while taking into account a highly censored reduced sample. This results in a characterization of fuzzy reliability, key reliability indicators, and RUL while taking estimation uncertainty into account. The outcomes demonstrate the method has capacity to forecast lithium-sulfur battery RUL and it is shown a valuable fuzzy reliability approach.",Industrial Prognostics and Decision-Making,102,804
Shifting Currents: Load Forecasting Challenges in the Evolving Distribution Grid.," The electric grid was initially designed with a hierarchical and unidirectional structure. Power traditionally flowed from generation resources through transmission lines before being distributed to cities and individual households. However, this historical one-directional pattern has evolved in recent decades, notably with the growing popularity of distributed energy resources, particularly rooftop solar installations. Currently, the power flow has become bidirectional, moving both into and out of households, presenting new challenges in forecasting, scheduling, and managing load bids within the electricity market. The integration of millions of electric vehicles (EVs) into this distribution system further amplifies these challenges. Utilities are now confronted with the task of efficiently serving customers, optimizing assets, and minimizing costs amidst this evolving landscape. A key challenge lies in forecasting customer loads. The addition of distributed energy resources and the diverse charging patterns associated with EVs introduce complexities in accurately predicting consumer consumption. A more accurate demand forecast could improve market optimization, ultimately reducing consumer bills. This presentation explores the imminent challenges facing utilities and their crucial role in transitioning towards a more adaptable distribution system, allowing power to flow in any direction. The focus is on addressing these challenges and enhancing the efficiency of the system to better serve customers, optimize assets, and minimize costs.",Risk and Uncertainties In Energy Planning,196,805
Decision Engineering Isomorphology with Quantum Mechanics: EDRM Proximity and the Born Rule," Isomorphologies between decision sciences, economics, and physics have been observed and applied for quite some time. Even von Neumann, who established the foundations of the mathematics for quantum mechanics and game theory, noted what he considered obvious relationships between these fields of study. However, it is the physical world that is often used as a source of models for application in behavioral, micro, and macroeconomics rather than the other way around. This research seeks to advance prior work that identified an analogy between the Entropy Decision Risk Model’s (EDRM) definition of proximity, which relates objective and subjective probability to explain how subjects perceive uncertainty, and the Born Rule of Quantum Mechanics. So far, there has been no derivation for the Born Rule, as it is based only upon an editor’s remark in a footnote of Born’s foundational 1926 paper, leaving an unanswered question. The goal of this research is to understand isomorphologies between quantum mechanics and decision engineering that will benefit both disciplines.",Technology and Digital Economy,230,806
Introducing Undergraduate Students to Applied Research and Modelling Cases in Probabilistic Operations Research at Texas Tech University - Costa Rica," Operations Research (OR) is a major area of study and application within Industrial and Systems Engineering undergraduate programs. We present here several cases of probabilistic OR projects, aimed at initiating undergraduate students in modeling applications and research. This is particularly interesting given the context that our campus is quite new and at an international location, and the work was done by some of the first cohorts of students going through the IE curriculum. The main goal of introducing this type of projects was that of initiating students into a culture of research and exploration, via the application of the methods and concepts learned in the classroom, to realistic situations that students can comfortably relate to. More specifically, this paper presents two probabilistic operations research modeling cases based on Markov Chains and Little’s Law for queueing systems. First, we present the application of a Markov Chain Model to analyze the dynamics of students moving through the different stages of the Industrial Engineering program at Texas Tech University – Costa Rica. A specific Markov Chain Model is build and applied to the Industrial Engineering program scenario, and quantitative results and analysis are provided. The second case studied consists of utilizing Little’s Law to analyze the admission process and waiting line (queue) required to enter campus, during (pandemic) restricted access conditions.",Operations Research and Modeling in Education,153,807
Building Flood-Resilient Communities through Strategic Retrofitting of Buildings under Uncertainty," This research develops an optimization model that use stochastic methods to manage the uncertain impact of flood intensity on building structures. The model focuses on supporting cost-effective mitigations to buildings to withstand floods without exceeding a specified budget. It seeks to minimize potential financial damage from varying flood levels, preparing for the most extreme cases. By incorporating a range of possible flood situations, the model ensures that retrofitting plans are economically viable and effective, even in the worst conditions. Aimed at helping building owners and policy makers, the model assists in making informed decisions to enhance building durability against floods. This mathematical model is formulated to be flexible, accommodating different risk factors and capable of expanding to include multiple objectives, which makes it a valuable asset for enhancing the resilience of communities against flooding.",Resilience in Construction,192,808
"Legal, ethical, and practical considerations when hiring front-line leadership in higher education"," Suggested by data from the American Council on Education, leadership cycle durations are shrinking in higher education (ACE, 2023), with speculation that an increasing number of roles are filled with interim leaders. If these trends continue, leadership continuity planning will become increasingly important to universities and colleges of engineering, as they strive to maintain strategic advantage and relevance without loss of marketing position and momentum. General business case best-practices for any organization (SHRM, 2023) suggest solutions should be supported by well-constructed strategic approaches and leadership development programs. However, unexpected turnover in front-line leadership roles in higher education creates specific challenges for organizations related to the immediacy of response time to unexpected changes, with adherence to deliberate strategy. The authors review key strategic and tactical organizational variables, in the development of a proposed prescriptive model, to guide organizations as they search for front-line academic leadership.",Leadership and Teamwork Development in Engineering Education,119,809
Greenwashing as an Educational and Ethical Sustainability Dilemma," Modern Sustainable companies must combine economic interests (costs, profitability), environmental interests (face the risks of global warming) and social ones (generate well-being for people related to the company). This approach requires that efforts related to environmental impact would not only be “less harmful” but “very positive”. Currently, products called as “green” are advertised as such to sell more, leaning towards an image of involvement with ecology and the environment are more appreciated by the population, especially if they are in an age group willing to pay more for a certain item if it has been produced under parameters of sustainability and ecology. Companies try to blend in with the green cause but some of them “cheat” and sell themselves as aware and involved, but they only show a “false interest” in this through greenwashing. This paper explore this conduct from and educational and ethical perspective and possible solutions. Greenwashing consist in companies or institutions which try to wash their image (or our way of thinking) and take advantage of the commercial prestige of green thinking, advertising their products and policies as environmentally friendly, or ecological, when this is not entirely true. To do this, they put the focus on the data that benefits them, hiding other less sustainable factors or simply manipulating the information at their convenience.",Towards Responsible Production: Innovations in Sustainability and Ethical Practices (SDG 12),231,810
Revolutionizing the Canning Industry: A Leap Towards Smart Manufacturing," The canning industry, a multi-billion dollar sector, has been around for a long time. Despite its longevity and economic significance, much of the industry remains highly manual, leading to inefficiencies. Canning lines suffer from frequent breakdowns that severely affect throughput, productivity, and safety. These breakdowns can occur due to multiple fault sources, such as imprecisions in the can geometry, nonuniform sizes of the food lumps, variations in the food flow patterns, and anomalies in the machine structure and its various components. In the era of Industry 4.0, the canning industry is on the cusp of a transformative leap. The integration of cyber-physical systems, IoT, and advanced data analytics can lead to the creation of smart canning factories, significantly improving the overall process. Implementing smart manufacturing principles across the entire canning line can provide for detection and prevention of faults using a combination of IoT sensors, machine learning, and computer vision. This can reduce unplanned breakdowns and augment the condition monitoring and fault premonition capabilities. These smart modifications are expected to provide real-time data, enabling predictive maintenance, reducing downtime, and significantly improving the overall operational efficiency. These advancements promise to bring about a significant transformation in the canning industry, enhancing its competitiveness and sustainability.",Manufacturing II,136,811
A non-linear regression model with Bayesian inference for state-of-health prediction of lithium-ion batteries.," The state of health (SoH) of the lithium-ion battery (LiB) is a vital prognostic factor that characterizes its performance degradation and system reliability. It plays a crucial role in the optimal operation and health assessment of battery systems. However, most existing models for predicting SoH are either computationally demanding or exhibit poor adaptability to new battery cells with limited data. To address this concern, this paper proposes a Non-Linear Regression Model with Bayesian Inference (NRMBI) for robust long-term SoH predictions. The proposed model is designed as a hybrid approach, collaboratively leveraging the strength of a semi-empirical model and a data-driven model. Before predicting the SoH of the new battery cells, the proposed model initially trains a highly accurate non-linear regression model. This enables the construction of a comprehensive prior based on a population of aged battery cells with complete life cycle data. Subsequently, for the new cell(s) of interest, a reasonable number of potential solution sets are drawn from the established prior. Their likelihood is then calculated and used for predictions based on the available limited information using Bayesian inference procedures. The efficacy of the NRMBI is validated and compared to state-of-the-art benchmark methods on publicly available battery capacity degradation datasets for fast-charged battery cells. Preliminary results show that the proposed method outperforms existing benchmarks. More details on the validation results will be provided in the paper.",Reliability II,188,812
Scheduling Batch Processing Machines in a Flow Shop with Limited Time Waiting Constraints," This paper presents mathematical formulations to a machine scheduling application identified at an electronics manufacturing company. After assembly, the electronic products are subjected to various kinds of accelerated tests using Batch Processing Machine (BPMs) arranged in a flow shop environment. A BPM can process several jobs simultaneously. When forming batches, the total size of all the jobs contained in a batch cannot exceed the machine capacity. The processing time of the batch is equal to the longest processing time job contained in the batch. The configuration of the batch affects the batch processing time and hence the schedule. Due to the nature of the test conducted, the jobs cannot wait for more than a certain amount of time between two machines. The objective is to minimize the makespan or the completion time of the last batch of jobs. The processing times and sizes of the jobs are given. The capacity of the machines at various stages of the flowshop is also known. This paper presents the formulations developed and experimented with. The experimental study highlights the usefulness of the formulations and their pros and cons. With the help of the formulation, the scheduler’s job is made easier and good quality solutions are obtained in a reasonable time.",Manufacturing Optimization,138,813
Navigating the Operational Landscape: Addressing Challenges for Successful Implementation of Industry 4.0 in Manufacturing Environments," In the era of Industry 4.0, which is marked by the integration of automation and data exchange in manufacturing processes, significant advancements are realized, resulting in tangible benefits such as heightened productivity and efficiency on the shop floor. However, the successful implementation of Industry 4.0 is contingent upon addressing a spectrum of operational challenges with precision and strategic foresight. This research explores the transformative landscape of Industry 4.0, emphasizing the need for a comprehensive understanding of operational hurdles and proposing strategies to navigate and overcome these challenges, thereby ensuring the seamless integration and sustainable success of Industry 4.0 initiatives in manufacturing environments.",Digital Manufacturing and Industry 4.0-I,45,814
Prediction and Exploration of Risk Factors Associated with Nurses' Attrition," Nurses’ attrition is a pressing global concern due to its impact on patient care quality and the resultant financial strain on the healthcare system as a whole. To tackle this challenge, this study explored various factors influencing nurses’ attrition such as monthly income, work-life balance, job satisfaction, and performance rating to mention a few, and utilized multiple feature selection techniques with five machine-learning approaches including random forest, linear discriminant analysis, gradient boosting, gaussian naïve Bayes, and support vector machine algorithms to classify and predict nurses’ attritions. The model accuracy, precision, recall, f-1 score, and the area under the receiver operating characteristic (AUC_ROC) curve were used to evaluate the performance of the various classifiers implemented. Gradient boosting, followed by linear discriminant analysis showed better accuracy in classifying attritions among nurses accurately over the support vector machine algorithm. The most important indicators (predictors) of nurses’ attrition are job satisfaction, years in a current role, distance from home, total working hours, and years with the current manager.",Work environment in health systems,241,815
Minimizing the Meal Gap: A time-window Based Pop-up Market Placement for Hunger-relief Operations," Regional food pantries are instrumental in combating the hunger problem by serving food to neighbors in need and providing last-mile linkage. However, different operation hours of pantries on different days of the week create a gap between supply and demand. Pop-up markets/mobile pantries can play an important role in this regard by serving as temporary facilities to close the gap. In this study, we consider a foodbank and its affiliated pantry network and develop a mixed-integer linear programming (MILP) model to place the limited mobile pantries in order to minimize the overall unmet demand. We consider the logistics and time-window constraints of the pop-up markets. Using data from a regional food bank, we illustrate the result of the study, which can help decision-makers strategically schedule pop-up markets while also ensuring the accessibility of foods to people in need.",Humanatarian logistics 1,94,816
Object Process Methodology to Turning Focused System Architecture Design for Manufacturing," Monitoring and predicting tool wear and surface roughness are considered crucial factors of automation and maximization of the manufacturing process like turning operations. However, nonlinearity and stochasticity in the formation and variation of tool wear, contribute to considering turning as a complex system, making it difficult to design a precise prediction model to optimize machining parameters for maximum quality and production. Therefore, it is required to apply a systematic approach to identify the entities and relationships from a system design perspective and learn about the emergents like tool wear, surface roughness, force, etc., derived from the interaction of ‘form’ and ‘function’ during turning operation. The representation of the instruments (machining parameters) of the process and their impacts on the operand (workpiece) could be worthwhile to explore the sources of stochasticity. Object Process Methodology (OPM) has been established as an effective and integrated model that can incorporate the form, function, entities, and their relationship into a single model. Through the OPM, the objects, processes, and their relationships for the turning-focused complex system architecture are represented in this research. In consequence, nonlinear theoretical equations have been used to generate synthetic data using Monte Carlo Simulation (MCS) in the system. At last, a Long Short-Term Memory (LSTM)-based Recurrent Neural Network (RNN) is considered to design a predictive model for the emergent properties. This proposed design of the turning-focused complex system architecture could be useful for the development of system pipelines concerning automation, digital twin technology, and Industry 4.0.",Process Planning-II,181,817
Water Sustainable Education: Mexico´s Management Challenge," Tecnológico de Monterrey an educational institution, as a natural partner for industry has been using Challenge Based Education to develop New Generations of Professionals in Sustainability engineering. The implementation of an environmental project for an educational challenge is an opportunity to create a conscience in the importance of creating new forms of efficient engineering management within a sustainability context. Mexico faces severe water availability problems, resulting in higher stress on its distribution in many states. Regulatory authorities play a crucial role in the governance of water resources by supervising providers and ensuring services’ sustainability to foster sectors’ efficiency (Sampaio and Sampaio 2020; Tourinho et al., 2022). An effective governance for sustainable and integrated management of water resources is necessary to overcome water supply problems. Governance refers to the administrative, political, and institutional rules, processes, and practices necessary for decision-making and implementation (OECD, 2015). Therefore Water Management as a case of study and data analysis fit well with the subject of “Data Analytics Project” for industrial engineering undergraduate course, in this paper the authors explore the industrial engineering tools used by the students to analyze possible improvements in the water management strategy as well as part of the experience obtained by the students in analyzing this major sustainability issue.",Aligning Profit and Planet and Addressing Water Challenges (SDG 6/SDG 12),16,818
Decision Support Tool for Planting Schedule through Stochastic Programming," Given the current world population growth rate, it is anticipated that by 2050, the total population will reach 10 billion. Feeding this large population needs efficient farm management. One essential aspect of farm management is deciding on a planting schedule. An appropriate planting schedule supports an increase in yield and provides uniformly distributed harvesting quantities to reduce food wastage. Since planting decisions must be made at the beginning of the season when several crucial factors are unknown (i.e., weather conditions, harvesting quantities), considering these uncertainties in these factors during planting scheduling is essential. Therefore, in this research, we utilized stochastic programming to build a decision-support tool for planting. Weather scenarios and harvesting quantities were considered the source of uncertainty in the stochastic model. We proposed a two-stage stochastic model formulated as a recursive problem (RP), where the first stage decision involved deciding the planting schedule and storage capacity after harvesting. The second stage focused on having uniform harvesting quantities. Historical data on weather and harvesting qualities were used to generate scenarios for the RP. The proposed model was evaluated using synthetic data generated from real data. The RP was solved using the extensive form (EF) method, and the solution was found to be consistent by performing a stability test. We found that the planting schedule considering stochastic programming varies from the deterministic scenario consideration.",OR Methods,151,819
Initiating Senior Design Projects at Texas Tech University - Costa Rica: Case Study of a Major Retailer's Distribution Center.," Texas Tech University – Costa Rica is a (satellite) component of the TTU System. This young institution began operations in 2018, and as such has the many challenges of getting up-and-running and establishing good recognition and reputation within the local and regional audiences. A key component in achieving this is to ensure that graduates will become top-notch and well-rounded professionals, with excellent abilities to transfer knowledge and training received during their studies, to their future areas of professional endeavors. For the Industrial Engineering (B.Sc.) program, Senior Design Project is a summative capstone course that requires students to work with a company client in defining a problem, analyzing, and designing solutions, and providing concrete deliverables that are accepted by the client. As a new institution, at TTU-CR the above projects have the added challenge of having local industry agree to receive a group of students to work on problems of significant relevance and impact to their operations. Here the first experience in conducting such a project for TTU-CR is presented, where the processes and logistics of a distribution center for a major retail local company were studied. The students were able to provide a set of solutions that included: understanding of the company’s process, data specification and gathering, problem definition, workflow and SIPOC diagrams, work standards, a capacity spreadsheet to calculate the number of workers needed for the current process, and a layout proposal with the implementation of conveyor belts to transport products between two different work areas.",Engineering Education Pedagogy and Assessment,67,820
Indigenous Design: Cases from the Diaspora," Informal developments in the Caribbean diaspora typically feature products, equipment and infrastructure that have never undergone formal engineering design. Some of these artifacts function remarkably well, and better than commercially available products which would have undergone the formal Product Development and Design process. Not surprisingly, researchers do not show much interest in this phenomenon. In fact, they are often the topic of much ridicule online, and total indifference in academia. As interest shifts in other fields such as medicine and art, to the contributions of indigenous practitioners, this study serves to investigate the engineering field, starting with a survey of evidence from the Caribbean and its diaspora.","Innovating for Impact: Exploring Interdisciplinary Collaboration, Sustainability Challenges, and Indigenous Design (SDG 9)",107,821
Modeling and Analyzing Project Resilience Under Uncertainty Considering Value of Information," Managing a project as a collection of activities undertaken to accomplish specific goals or fulfill particular needs is always prone to unavoidable circumstances that may cause delays and failure to meet deadlines. Conceptualizing project resilience as its ability to withstand initial disruptions (absorptive capacity) and make short-term adjustments to alleviate the effects of disruptions (adaptive capacity), this work proposes a soft-robust optimization model to enhance project resilience by (ii) seeking strategies to allocate a limited budget to enhance absorptive/adaptive capacity, and (iii) assessing the value of information in decision making under uncertainty.",Systems Engineering & Life Cycle Management II,226,822
Integrated Model of Organizational Resilience: A Multi-Level System Dynamics Approach," Modern organizations operate in complex and dynamic environments where the ability to be resilient against disruptions is critical to organizational health and sustainability. Organizational Resilience (OR) describes an organization’s capability to prepare for, respond to, and learn from disruptive events. Although OR has been increasingly studied in a variety of contexts, relatively few studies consider models of OR that integrates insights from related dimensions of resilience within organizations such as employee, leadership and team resilience. Further, there is a lack of commonly-accepted constructs for assessing resilience capabilities and more work is needed to investigate the dynamic nature of building resilience capabilities over time. This study extends previous research that applied multi-level causal loop modeling to develop an integrated model of OR that describes the factors that affect the development of OR capabilities at both individual and aggregate levels. This paper explores potential stock-and-flow mechanisms based on the casual model and proposes an initial multi-level system dynamics model. The resulting model provides an approach for quantitatively investigating strategies for building resilience capabilities in organizations.",Problem Solving and Decision Making I,175,823
Modeling Human Decision-Making During Assembly Tasks under Varying Levels of Complexity," Many assembly tasks in manufacturing are targeted for automation to increase operational efficiency. However, there are some tasks that cannot be automated due to the complexity of the task and limitations of current technologies leading manufacturing companies to rely on human-led processes where operator performance is critical for effectiveness. Although there have been many studies focused on optimizing assembly tasks through work design and development of assistive technologies, more work is needed to investigate how human decision-making is affected by task complexity during manual assembly tasks. This paper presents the results of a controlled laboratory experiment where subjects completed an assembly task under varying levels of task complexity in terms of number of assembly items, visual contrast of items, and assembly procedure. The study evaluated the effects of task complexity on operator effectiveness including task completion time and accuracy. The study also investigated the types of mistakes made during the assembly. The results provide a model for the effects of task complexity on human decision-making that can be used to optimize operator performance during complex assembly tasks.",Diverse Topics for HFE 3,54,824
A controllable deep learning model with knowledge transfer for state-of-charge estimation of lithium-ion batteries.," The state-of-charge (SOC) is one of the key prognostic parameters for assessing performance level and reliability of Lithium-ion Battery’s (LiB). Several methods have been proposed in the literature for SOC estimation, including deep learning models. Deep learning models have garnered considerable attention due to their ability to capture intricate temporal patterns. However, many of these models fail to consider the cell-to-cell variations and mostly aim for short-term predictions, which may not be practical for battery cells with limited charging-discharging history. To address this challenge, this paper proposes a Controllable Deep Learning model with Knowledge Transfer (CDLKT) for both short and long-term SOC estimations. The CDLKT leverages transferable knowledge from a population of source battery cells to the target battery cell via a controllable Multiple Domain Adaptation (MDA) mechanism. The proposed framework consists of two long-short term memory (LSTM) networks, the source LSTM, and the target LSTM. The source LSTM is trained on SOC data from historical battery cells. The target LSTM is then trained using limited available SOC data from the target cell and the transferred knowledge from the source LSTM using controllable MDA. The controllability of the transferred knowledge reduces the likelihood of negative transfer learning and offers theoretical guarantees on the controllability and convergence of transferred knowledge. The performance of the CDLKT is validated and compared to existing deep and transfer learning benchmark methods using publicly available battery capacity degradation datasets for fast-charged battery cells. Preliminary results show that the proposed method outperforms existing benchmarks.",Microgrids and Energy Storage,145,825
Artificial Intelligence Perspective on System Development," Artificial intelligence (AI) technology is advancing at a rapid rate. While the current technology readiness level of the technology is still maturing, the potential within engineering system development is promising. Currently, the metrics of the technology require significant refinement to reduce the level of uncertainty of any AI-generated content, particularly with quantitative content. The ability to verify the accuracy of AI-generated content is paramount before implementing the technology into the systems engineering development process or the system itself. Not only is the accuracy of AI-generated content suspect, but the ability to even detect AI-generated content is dubious. The goal of this study is to explore the accuracy of AI-generated quantitative content typically generated during system development. Specifically, the approach will examine reliability requirement metrics generated from traditional techniques to AI-generated metrics.",Information Systems & Software,104,826
MOFSAut: Multi-task One-shot Feature Selection Autoencoder for Prognostics," Prognostic aims at predicting the lifetime at which a component or a system will be unable to perform a desired function. Data-driven models have been shown in recent literature to be reliable prognostic models. However, with the advancement of the Internet of Things, real-time monitoring of more features for components/systems under study has become easier. The availability of too many dimensions or features in the data acquisition stage has enriched data-driven prognostic models, but it has also presented new challenges, including overfitting and lack of explainability. With a focus on feature selection, in this paper, we introduce the MOFSAut, the Multi-task One-shot Feature Selection Autoencoder, which is a deep learning-based model capable of generating lifetime predictions. The model selects from the original feature space the relevant features that are both globally representative and hold key information for lifetime predictions; this is achieved via multi-task learning. In addition, one-shot training embeds the prognostic model training with a feature selection task, eliminating the need for multi-step exploration for an adequate feature subset. Moreover, this approach adds interpretability to the selected features which are shown to be important in predictability. The effectiveness of the approach is judged by applying it to a real-world case for the lifetime prediction of degrading equipment.",Industrial Prognostics and Decision-Making,102,827
A Critical Review of Human Reliability Assessment Models and Recent Advances for Healthcare Systems," Human reliability assessment (HRA) methods evaluate potential human errors threatening safety in complex sociotechnical systems like healthcare. This review summarizes foundational HRA approaches, demonstrates healthcare applications, and highlights advances from related industries to expand HRA adoption. First, HRA draws from human factors and cognitive systems engineering to model individual, team, organizational, and technological drivers of human performance. Qualitative and quantitative techniques exist, including recent data-driven Bayesian models. Second, healthcare HRA applications assess issues like nursing coordination breakdowns, medication administration mistakes, alarm response reliability, and other safety threats. Measurement of systemic factors facilitates risk analysis and mitigation. Third, aviation advances translate to healthcare, like hybrid data-simulation models systematically diagnosing latent threats. Overall, HRA provides the methodological rigor needed to address preventable adverse medical events. Continued human factors and clinical collaborations should enhance HRA techniques and deployment for healthcare. Quantitative HRA supports proactive, predictive risk modeling and management to drastically improve patient safety. Next steps include further development of data-driven Bayesian models evaluating interrelated performance drivers, and increased partnerships to tailor tools for healthcare contexts. Expanded HRA adoption could revolutionize risk management in patient care by providing vital data to strengthen organizational, teamwork, and individual factors enabling high reliability.",Recent Advances in Health Systems II,185,828
3D Thermal Imaging in Additive Manufacturing," The ability to present 3D thermal images is of great interest for many applications. In additive manufacturing, heat is the most important factor in the properties of manufactured parts. So, the heat control strategy is playing a pivotal role in quality assurance of parts. The 3D thermal imaging will help manufacturers to have a digital twin of the part during the manufacturing process. Image alignment and data fusion are the main steps to reach 3D thermal image. The proposed system is based on a thermal camera and laser 3D scanner. For image alignment, the intrinsic parameters are calculated, and based on that, the point cloud and image will be aligned in one coordinate system. Main challenge for fusing the data is related to the difference between the resolution of depth sensors and 3D scanners and thermal cameras in which the latter has less resolution. Computer vision algorithms and convolutional neural networks have been studied by previous researchers for fusing the images. However, the accuracy of the proposed methods is not high enough, so the output is not fit to additive manufacturing usages. In our proposed method, we developed a convolutional graph auto encoder to down sample the high-resolution point cloud based on the thermal image resolution. Then the thermal data will be added to the point cloud and finally the auto encoder will generate the fused 3D point clouds. This model can upscale to the initial point cloud and the output accuracy is 20 microns.",Sensing and Control in Additive Manufacturing Processes I,202,829
Electric Vehicle Batteries End-of-Life Management: A Systematic Literature Review of Return Rates and Influential Factors," The global commitment to address climate change, as seen in the United States' pledge to achieve net-zero emissions by 2050, underscores the urgency of mitigating environmental challenges within specific sectors. The transport sector, responsible for 70% of road transportation emissions, has witnessed a notable shift towards Electric Vehicles (EVs) as a key strategy for reducing greenhouse gas emissions. However, this transition introduces an immediate concern in managing end-of-life Electric Vehicle Batteries (EVBs), encompassing remanufacturing, refurbishing, repurposing, and other processes. This literature review navigates existing research on EVB end-of-life management, emphasizing the critical need for a circular economy approach. Despite the environmental benefits of EVs, the surge in spent Lithium-ion Batteries (LIBs), commonly found in the majority of EVB packs, poses a multifaceted challenge. Barriers to a circular supply chain for EVBs, identified in prior studies, underscore the necessity of addressing uncertainties in spent batteries quantity, and quality. The review seeks to answer fundamental research questions, delving into existing prediction methods and influential factors determining return rates for EVBs. By conducting a systematic analysis following PRISMA guidelines, this paper aims to bridge the gap in understanding the comprehensive methods employed in prior research and the factors influencing return rates. The structured method employed in this review, encompassing theoretical foundations, selection criteria, content analysis, and future research considerations, enriches the ongoing research on sustainable EVB management.",Driving Towards Clean Affordable Energy: Advances in Electric Vehicles and Battery Management (SDG 7),57,830
Advancing the Digital Twin of Stencil Printing in Surface Mount Technology using Transfer Learning," This research introduces a neural network-based domain adaptation transfer learning method to enhance the digital twin of the stencil printing process (SPP) in surface mount technology (SMT) assembly lines. The approach focuses on refining the existing SPP simulation model to better mirror the complexities of real-world SMT operations. Emphasizing the importance of the digital twin concept in SPP, this method provides a time and cost-effective alternative to physical experiments and serves as a critical tool for researchers and technologists exploring advanced SMT printing algorithms and methodologies. Despite the effectiveness of existing models, a significant challenge has been their inability to accurately simulate the diverse conditions encountered in real-world SMT operations, especially due to variations in different printer machine behaviors and PCB designs. To overcome these limitations, this research integrates a domain adaptation transfer learning approach into the simulation process. This method enhances the model's ability to accurately reflect real-world conditions. This approach not only improves the model's adaptability and accuracy but also minimizes the need for extensive new real-world data collection. The findings reveal a significant advancement in the digital twin simulation of SPP, demonstrating increased adaptability across different printer machines and PCB designs. This enhanced model, empowered by domain adaptation transfer learning, offers a more accurate representation of the SMT printing process and is capable of adapting to a variety of PCB materials. These improvements are pivotal for advancing PCB production quality and efficiency, marking a significant contribution to the field of SMT assembly line technology.",Advanced Simulation Models,3,831
A Predictive Framework for Identifying Unnecessary Lab Tests for Chronic Kidney Disease Patients in Critical Care Unit," The repeated and regular use of lab tests contributes to the rapid increase in healthcare expenses. Unnecessary lab tests may not only cause waste in resources but can also negatively affect patient care. The purpose of this research is to systematically identify low-information laboratory tests for patients admitted to critical care with chronic kidney disease to help reduce unnecessary repeat lab tests. Predictive models are built with a variety of machine learning algorithms using the Medical Information Mart for Intensive Care, Version IV (MIMIC-IV) dataset to predict the results of follow-up laboratory. Various data inputs are incorporated into the model to aid proactive clinical decision-making, including demographics, vital signs, prescriptions, and common lab tests. We predict a future lab test result based on previous findings during the pre-definied observation windows of a patient in a critical care unit. Additionally, we provide a framework to determine the association between the lab test result and the patient's outcome, whether they are readmitted, discharged from the intensive care unit, or die. Our model offers to facilitate more effective and well-informed clinical decision-making by establishing a connection between progression of patients as indicated by series of lab tests and their final outcome. By reducing unnecessary testing, the suggested methodology may optimize resource allocation as well as improve patient care in the critical care unit.",Predictive Models in Health Systems,170,832
Lean Six Sigma in Higher Education Institutions: An Action Research Project," Lean Six Sigma, a well-established methodology, has made substantial contributions to various industries worldwide, primarily in the manufacturing sector, by enhancing performance and reducing costs. Although its adoption has been relatively sluggish in the service sector, notable progress has been witnessed recently. This research project undertakes a comprehensive investigation into the application of Lean Six Sigma within a higher education institution (HEI), primarily categorized as a service industry. Employing the action research methodology, this study delves into the intricacies of Lean Six Sigma adoption. The goal of the study is to increase customer satisfaction and reduce nonvalue added activity performed by the Undergraduate Director for the Industrial and Management Systems Engineering Department (IMSE). The IMSE department consists of 300 undergraduate students, 15 faculty and 2 staff members and is located in the college of engineering. The department resides in a public university in the southeastern United States with the R1 Carnegie classification, a doctoral granting institution with very high research activity. Our action research cycle will be guided by what the extant literature states as relevant critical success and failure factors for HEIs. The research team includes the Undergraduate Program Director, an outside faculty member and three IMSE undergraduate students. The results of our research will contribute to what is known about the unique challenges of implementing lean six sigma in HEI and service industries more broadly.",Service Organizations,204,833
Order Acceptance and Detailed Scheduling in A Make-To-Order Job Shop with Discrete and Batch-Processing Machines Using Heuristics," In today's dynamic production landscape, marked by rising demand for personalized products and increasing consumer expectations, the strategic focus on high-mix, low-volume manufacturing— especially through the Make-To-Order (MTO) approach—has become critical. This scholarly exploration delves deeply into the intricate realm of job shop scheduling, a complex challenge where manufacturers strive to streamline production time and costs while effectively utilizing machinery and resources. The core of the discussion revolves around the dynamic interplay between order acceptance and meticulous scheduling within the diverse environment of a job shop, encompassing both discrete and batch processing machines. Order acceptance involves a thorough evaluation of incoming orders, considering factors like available capacity and profitability. This research focuses on the seamless execution of customer orders in a job shop setting, maneuvering through operations with linear precedence constraints, predictable processing times, due dates, size considerations, and established selling prices. The ultimate goal is to optimize profits while ensuring the completion of accepted orders within the due date. The job shop, comprising discrete processing machines and a batch processing machine capable of handling multiple jobs within its capacity limits, adds another layer of complexity. This study aims to tackle large-scale instances of the problem through the application of heuristics, seeking practical and effective solutions. The algorithm considers factors such as machine availability, processing times, and precedence constraints. By prioritizing the most critical aspects of the scheduling problem, the heuristic ensures a practical and near-optimal solution within a reasonable timeframe.",Manufacturing Optimization,138,834
Reliability Modeling and Redundancy Allocation for Systems of Dependent Components Using Copula Functions," This study introduces a novel approach for redundancy allocation in series-parallel systems, incorporating component dependency via copula functions. By modeling these dependencies, we enhance the accuracy of system reliability assessment. Our methodology employs mixed-integer nonlinear optimization, balancing system reliability with constraints like cost and weight. In practical applications, the condition and reliability of components within the same system are influenced by similar external factors or by the condition of each other component, leading to dependencies in their operational state and reliability assessments. When component reliability models are applied to complex systems composed of multiple elements, the observed reliability behaviors tends to be more detailed and complicated. This complexity necessitates the adoption of novel perspectives to accurately evaluate and manage system reliability. We applied two distinct methodologies to solve the mixed-integer nonlinear optimization problem for our series-parallel model: surrogate optimization and genetic algorithms. Surrogate optimization proved invaluable in efficiently approximating the complex relationship between decision variables and the objective function. This approach significantly reduced computational overhead by using a simplified model of the objective function, enabling quicker evaluations and facilitating the identification of feasible solutions within the system constraints.",Reliability Analysis I,186,835
Bayesian Prognosis Analysis of Human Papillomavirus-Associated Head and Neck Cancer using Hierarchical Dirichlet Process Mixture Models," The incidence and prognosis of head and neck cancer (HNC) depend heavily on patients’ human papillomavirus (HPV) status. Prognosis analysis of HPV-associated HNC is of clinical importance because in-depth understanding of the survival distribution is valuable for designing more informed treatment strategies. In this paper, we develop a novel hierarchical Dirichlet process Weibull mixture model (HDP-WMM) to study the prognosis of HNC patients given their HPV status. The HDP-WMM is capable of simultaneously characterizing the survival distributions of grouped data and capturing the dependence among different groups. Moreover, the HDP-WMM can identify clusters of patients based on their outcomes, providing additional information for exploring patient subtypes. Effective Markov chain Monte Carlo sampling algorithms are designed for model inference and function estimation. The clustering structure is identified by summarizing the posterior samples of the data random partition using the Bayesian cluster analysis tool. A simulation study is designed to validate the performance of the proposed inference methods. The practical utility of the proposed HDP-WMM is demonstrated by a case study on prognosis analysis of HPV-associated HNC. Our results show that the Bayesian HDP-WMM achieves satisfactory performance on estimating the survival functions and clustering patients based on their outcomes.",Advanced Topics of QCRE V,11,836
Discriminant subgraph learning from functional brain sensory data," The human brain is a complex system with many functional units interacting with each other. This interacting relationship, known as the Functional Connectivity Network (FCN), is critical for brain functions. To learn the FCN, machine learning algorithms can be built based on brain signals captured by sensing technologies such as EEG and fMRI. We propose a novel Discriminant Subgraph Learner (DSL) to identify a functional sub-network that best differentiates patients with a specific disease from healthy controls based on brain sensory data. We develop an integrated optimization framework for DSL to simultaneously learn the FCN of each class and identify the discriminant sub-network. We apply DSL to identify a functional sub-network that best differentiates patients with episodic migraine from healthy controls based on a fMRI dataset. DSL achieved the best accuracy compared to five state-of-the-art competing algorithms.",IISE Transactions Best Paper,98,837
Inverse Markov decision processes with unknown transition probabilities," Inverse optimization involves recovering parameters of a mathematical model using observed values of decision variables. In Markov Decision Processes (MDPs), it has been applied to estimate rewards that render observed policies optimal. A counterpart is not available for transition probabilities. We study two variants of this problem. First, the decision-maker wonders whether there exist a policy and transition probabilities that attain given target values of expected total discounted rewards over an infinite horizon. In the second variant, the decision-maker wishes to find transition probabilities that make a given policy optimal.",IISE Transactions Best Paper,98,838
Branch-price-and-cut for trucks and drones cooperative delivery," The truck and drone-based cooperative model of delivery can improve the efficiency of last mile delivery, and has thus increasingly attracted attention in academia and from practitioners. In this study, we examine a vehicle routing problem and apply a cooperative form of delivery involving trucks and drones. We propose a mixed-integer programming model and a branch-price-and-cut-based exact algorithm to address this problem. To reduce the computation time, we design several acceleration strategies, including a combination of dynamic programming and calculus-based approximation for the pricing problem, and various effective inequalities for the restricted master problem. Numerical experiments are conducted to validate the effectiveness and efficiency of the proposed solution.",IISE Transactions Best Paper,98,839
Safety stock placement with market selection under load-dependent lead times," We study the problem of safety stock placement in a supply chain with market selection decisions. A manufacturer with deterministic, load-dependent lead time supplies multiple warehouses, each serving multiple retailers. Each retailer has access to a set of potential markets with different characteristics. Serving more markets increases revenues, but also increases the manufacturer’s lead time, resulting in higher inventory costs. Adopting the Guaranteed Service Approach, we present a nonlinear mixed-integer programming model and reformulate it to eliminate integer variables related to service times at warehouses. The benefit of integrating market selection and safety stock decisions is greatest when capacity is limited and marginal revenue is relatively low.",IISE Transactions Best Application Paper,97,840
Optimizing diesel fuel supply chain operations to mitigate power outages for hurricane relief," Hurricanes can cause severe property damage and casualties in coastal regions. Diesel fuel plays a crucial role in hurricane disaster relief. It is important to optimize fuel supply chain operations so that emergency diesel fuel demand for power generation in a hurricane’s immediate aftermath can be mitigated. It can be challenging to estimate diesel fuel demand and make informed decisions in the distribution process, accounting for the hurricane’s path and severity. We develop predictive and prescriptive models to guide diesel fuel supply chain operations for hurricane disaster relief. This predictive model feeds a prescriptive stochastic programming model implemented in a rolling-horizon fashion to dispatch tank trucks. This data-driven optimization tool provides a framework for decision support in preparation for approaching hurricanes, and our numerical results provide insights regarding key aspects of operations.",IISE Transactions Best Application Paper,97,841
Multiple event identification and characterization by retrospective analysis of structured data streams," The sensors installed in complex systems generate massive amounts of data, which contain rich information about a system’s operational status. This article proposes a retrospective analysis method for a historical data set, which simultaneously identifies when multiple events occur to the system and characterizes how they affect the multiple sensing signals. The problem formulation is motivated by the dictionary learning method and the solution is obtained by iteratively updating the event signatures and sequences using ADMM algorithms. A simulation study and a case study of the steel rolling process validate our approach.",IISE Transactions Best Application Paper,97,842
Reconstructing original design: Process planning for reverse engineering," Reverse Engineering (RE) has been widely used to extract geometric design information from a physical product for reproduction or redesign purposes. A scan of an object is often implemented to (re-)construct the computer-aided design model. However, this model is most likely an inaccurate representation of the original design, due to the existing uncertainties in each part and the scanning process. This randomness can result in shrinking the original tolerance region or even yielding asymmetric tolerance regions, which can call for unnecessarily high precision reproduction. We propose an algorithm to generate the mean configuration based on the data clouds collected from several scans and multiple parts (if applicable). Simulations and industrial case studies, including both unique freeform objects and mechanical parts, are conducted to illustrate and evaluate the performances of proposed methods",IISE Transactions Best Application Paper,97,843
Landmark-embedded Gaussian process with applications for functional data modeling," In practice, we often need to infer the value of a target variable from functional observation data. A challenge in this task is that the relationship between the functional data and the target variable is very complex: the target variable not only influences the shape but also the location of the functional data. In addition, due to the uncertainties in the environment, the relationship is probabilistic, that is, for a given fixed target variable value, we still see variations in the shape and location of the functional data. To address this challenge, we present a landmark-embedded Gaussian process model that describes the relationship between the functional data and the target variable. A unique feature of the model is that landmark information is embedded in the Gaussian process model so that both the shape and location information of the functional data are considered simultaneously in a unified manner. Gibbs–Metropolis–Hasting algorithm is used for model parameters estimation and target variable inference. The performance of the proposed framework is evaluated by extensive numerical studies and a case study of nano-sensor calibration.",IISE Transactions Best Paper,98,844
Addressing the Skills Gap in Model-Based Systems Engineering (MBSE)," The field of systems engineering is experiencing rapid growth, leading to an increasing demand for expanding the workforce. This expansion is also driven by evolving contractual standards and the emergence of new application areas for Model-Based Systems Engineering (MBSE) tools. However, there is a significant shortage of skilled professionals in the field. To address these challenges, our team has taken a novel approach to create training pathways for various demographics. We propose a systematic approach to designing curricula to equip multiple populations with MBSE methodologies. Additionally, we introduce a prototype training program tailored for practicing engineers, with an emphasis on exploring its potential scalability for integration into community college and university curriculums. Our initiative aims to bridge the skills gap across industries, ensuring a proficient workforce capable of harnessing model-based approaches effectively across different contexts.",Systems Engineering in the ISE Curriculum,227,845
A Novel Approach for Teaching Systems Design to ISE Undergraduates," Engineering design within the MBSE context has three fundamental requirements: (1) a domain-specific language (DSL) for the domain in which the system is being designed; (2) a design methodology that reliably translates stakeholder requirements into a physical system configuration; and (3) computational tools that support both. This talk will describe how these three requirements are being met in an innovative course being taught both to undergraduate and graduate students. The DSL addresses systems in which discrete units of flow move through a network of resources where transformations are performed, a domain that includes manufacturing, warehousing, supply chains, healthcare systems and more. The methodology is the Requirements, Functions, Logic, Physical realization (RFLP) widely used in the aerospace industry. The computational tool is Capella, an Eclipse-based open-source design tool that supports RFLP.",Systems Engineering in the ISE Curriculum,227,846
From Maple Syrup to African Irrigation: Enhancing the operations of Vergers d'Afrique (Orchards of Africa)," IE consulting services provided to Vergers d'Afrique – a non-profit collects, sorts and recycles plastic tubes from maple sirup manufacture to support entrepreneurship of women in Burkina Faso generating income by growing, processing and market gluten-free and fair trade cassava flour.",Enhancing the Sustainability of Three Non-profits: Annual IISE Volunteer Project Review,70,847
Eco-responsible event and stage production: Furthering Écoscéno's sustainable practice integration, IE consulting services provided to Écoscéno – a non-profit that provides personalized eco-design consulting service with a team that works closely with creative projects from conception to strike They offer the production team constant support in integrating eco-responsible practices at each key stage of production.,Enhancing the Sustainability of Three Non-profits: Annual IISE Volunteer Project Review,70,848
Circular IT: Improving Insertech's ability to provide affordable community access by giving computer equipment a second life," IE consulting services provided to Insertech – a non-profit that trains unemployed young adults, while giving a second life to the computer equipment collected from companies and organizations by offering affordable IT solutions to the community. This fights overconsumption, too rapid obsolescence, pollution and waste of resources.",Enhancing the Sustainability of Three Non-profits: Annual IISE Volunteer Project Review,70,849
Improving the Volunteer Experience: Hands-one experience driven recommendations for Vergers d'Afrique, ISEs joined a typical volunteer session with Vergers d'Afrique and then provided recommendations to enhance the volunteer experience and improve the productivity of volunteer activities.,Enhancing the Sustainability of Three Non-profits: Annual IISE Volunteer Project Review,70,850
